export const data = [
  {
    content:
      "\nChi mi conosce sa che sono sempre stato un tipo molto preso dalla matematica, al liceo sono sempre stato\nbravo senza impegnarmi minimamente, e all'università ero sempre quello che arriviva prima ad afferrare le cose.\n\nMi sono sempre un po' vergognato di questa mia capacità, che per molti era vista come una stranezza, ma la realtà\ndei fatti è che, invece di seguire il percorso classico con cui veniva spiegata la matematica a scuola, sono sempre\nstato curioso di questa disciplina e ho imparato alcune scorciatoie che mi aiutavano.\n\nOggi voglio parlarvi di una mia scoperta che credo ho fatto durante il primo o il secondo superiore che mi ha\ndato alcune \"capacità\" di calcolo che dall'esterno sembrano impossibili. La cosa divente è che tutti lo possono imparare a fare!\n\nMi riferisco a quello che viene chiamato **Matematica Vedica**, che non sono altro che una serie di trucchetti (o scorciatoie) mnemoniche che sotto alcune condizioni ci permettono di fare calcoli molto complessi a mente.\n\nIn realtà alcuni di questi trucchi sono già conosciuti ai più, come ad esempio il classico:\n\n> per moltiplicare un numero per 5 basta agiugnere un '0' alla fine e prenderne la metà.\n\nIn questo post voglio parlavi di alcuni di questi trucchi e divertirmi a dimostrarli matematicamente!\n\nPartiamo dal più semplice:\n\n### 1. Moltiplicare un numero per 10\n\nQuesto credo sia banalissimo ma è alla base di tantissimi altri tricchetti: per motiplicare per 10 un numero (si parla di numeri interi) basta aggiungere uno \"0\" alla fine!\n\n$2345 \\cdot 10 = 2345\\mathbf{0}$\n\n### 2. Moltiplicare un numero per 5\n\nEsempio più noto ma volevo partire da cose semplici:\n\n> per moltiplicare un numero per 5 basta agiugnere uno '0' alla fine e prenderne la metà.\n\nAd esempio: $243 \\cdot 5 = 243\\mathbf{0} / 2 = 1215$, veloce e indolore (non lo testo nemmeno con la calcolatrice per quando ne sono sicuro).\n\nMa perchè funziona? In realtà è semplicemente perchè moltiplciare per 5 è come moltiplcare per 10 e dividere per 2, dato che $ 5 = 10 / 2$ sappiamo che $n \\cdot 5 = n  \\cdot 10 / 2 = (n \\cdot 10) / 2$.\n\n### 3. Quadrati di numeri che finiscono con 5\n\nOk, ora le cose iniziano ad essere divertenti, questo è il primo trucchetto che fatto a mente fa dire \"wow\" alla persone che non lo conoscono:\n\n> per fare il quadrato di un numero che finice con 5, togli il 5, prendi quello che rimane e moltiplicalo al suo successivo, quindi metti '25' in fondo al numero che viene fuori\n\nEsempio:\n\nSe voglio calcolare 65 al quadro devo:\n\n1. Togliere il 5 (quindi rimane 6)\n2. Moltiplciare 6 per il suo successivo -> $6\\cdot 7 = 42$\n3. Accodare $25$ al risultato -> $42\\mathbf{25}$\n\nDa qui è facilissimo fare a meno\n\n- $35^2 = 12\\mathbf{25}$\n- $85^2 = 72\\mathbf{25}$\n- $115^2 = 132\\mathbf{25}$ (per questo ho applicato un altro tricchetto per moltiplicare numeri per 11)\n\nMa perchè funziona? Ogni numero che finisce per 5 è scrivibile nella forma $10n \\cdot 5$, proviamo a calcolarne il quadrato:\n\n$(10n + 5) \\cdot (10n + 5) = 100n^2 + 25 + 2 \\cdot 5 \\cdot 10n = 100n\\cdot n + 25 + 100n = 100 n \\cdot (n+1) + 25$.\n\nDa qui è facile vedere la regola: abbiamo la somma di 25 e di $n(n+1)$ moltiplicato per 100. Ma il moltiplicare per 100 $n(n+1)$ non è altro che metterci due zeri davanti, e il sommare 25 equivale a prendere $n(n+1)$ e metterci 25 davanti!\n\n### 5.1 Moltiplicare tra loro due numeri vicini (ma più piccoli) di una potenza di 10.\n\nQuesto è stato il primo trucco che ho imparato che mi ha fatto avviciniare a questo mondo al tempo, e rimane il mio trucchetto preferito.\nSupponiamo di avere due numeri grandi ma vicini a una potenza di 10 (però più piccoli), tipo 994 e 989, per moltiplicarli tra loro dobbiamo:\n\n1. Prendere la differenza tra quei numer e la potenza di 10 a cui sono vicini (quindi 6 e 11).\n2. Calcolare la differenza tra i numeri originali e questi due numeri derivati scambiati: quindi $994 - 11 = 983$ o $989 - 6 = 983$ (notare che questo conto è sempre uguale indipendentemente da cosa si sceglia, quindi si può fare una volta sola).\n3. Calcolare il produtto dei due numeri derivati: quindi $6 \\cdot 11 = 66$\n4. A sto punto basta mettere in sequenza i due risultati, mettendo degli zero al centro sapendo che il numero finale deve avere 6 cifre (o in generare un numero di cifre pari al doppio di quelle die numeri di partenza). Quindi 983 - 0 - 66\n5. $994 \\cdot 989 = 983066$\n\nProvare per credere.\n\nDimostrazione al punto successivo!\n\n### 5.2 Moltiplicare tra loro due numeri vicini (ma più grandi) di una potenza di 10.\n\nQuesto è parente del precedente, anche se essendo numeri visimanete semplici ma meno \"magico\" rispetto al precedente. Vediamo che succede se vogliamo moltiplicare due numeri vicini (ma più grandi) ad una potenza di 10, tipo 10004 e 10023.\n\n1. Prendere la differenza tra quei numer e la potenza di 10 a cui sono vicini (quindi 4 e 23).\n2. Calcolare la somma tra i numeri originali e questi due numeri derivati scambiati: quindi $10004 + 23 = 10027$ o $10023 +4 = 10027$ (come prima, anche questo conto è sempre uguale indipendentemente da cosa si sceglia, quindi si può fare una volta sola).\n3. Calcolare il produtto dei due numeri derivati: quindi $4 \\cdot 23 = 92$\n4. A sto punto basta mettere in sequenza i due risultati, mettendo degli zero al centro sapendo che il numero finale deve avere 9 cifre (o in generare un numero di cifre pari al doppio di quelle due numeri di partenza meno). Quindi 10027 - 00 - 92\n5. $10004 \\cdot 10023 = 100270092$\n\nPer dimostrare perchè funziona dobbiamo ricorarci che un numero vicino ad una potenza di 10 può essere scritto come $10^k + n$, con n piccolo e intero.\n\nQuindi possiamo scrivere la moltiplicazione come: $(10^k + n) \\cdot (10^k + m)$ che possiamo svolegere:\n\n$(10^k + n) \\cdot (10^k + m) = 10^{2k} + 10^kn + 10^km + n\\cdot m = 10^{2k} + 10^k (n \\cdot m) + (n + m)$\n\nDa qui ci siamo quasi. La regola numero (3) è visibilissima nell'ultimo addendo $(n+m)$ mentre la regola numero 2 non è ancora chiara. Per farla venire fuori basta riscrivere la prima parte del risultato del prodotto $10^{2k} + 10^k (n \\cdot m)$ mettendo in evidenza un $10^k$.\n\n$10^{2k} + 10^k (n \\cdot m) = 10^k ((10^k + n) + m)$, e notiamo subito che il $10^k + n$ è il numero originale.\n\n## Conclusioni\n\nOggi mi sono divertito a raccontarvi pochissimi trucchi di matematica vedica che conoscevo al liceo, ovviamente ce ne sono tantissimi altri che forse racconterò nei prossimi post. Ma se vi interessa vi suggerisco [questo sito](http://mathlearners.com/) da cui poter approfondire o di cercare su internet essendoci tantissimo materiale sull'argomento. Un grazie alla mia amica Silvia per avermi ispirato a scrivere questo articolo!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2021-10-06-matematica-vedica/index.md",
    frontMatter: {
      path: "/2021/10/05/matematica-vedica/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2021-10-05T00:00:00.000Z",
      publishedReadable: "5 Ott 2021",
      featured: false,
      tags: ["Blog", "Math"],
      title:
        "Matematica Vedica: trucchi per essere più veloci di una calcolatrice (e perchè funzionano)!",
      description: "Come diventare supereroi facendo i conti a mente!",
      href: "/2021/10/05/matematica-vedica/",
      image: "/content/blog/it/2021-10-06-matematica-vedica/main.png",
      imagePath: "/content/blog/it/2021-10-06-matematica-vedica",
    },
  },
  {
    content:
      "\n[![image](./main.png)](https://www.youtube.com/watch?v=FmeLTll33a4&ab_channel=ludusrusso)\n\nSia io che [Jaga](https://jagasantagostino.com/) ci divertiamo con un po' di **side project** che avrebbero un bel supporto dalla possibilità di deployarli su Kubernetes. Però solitamente scartiamo questa possibilità dovuti ai costi non molto accessibili di cluster kubernetes dei principali cloud vendor, che richidono la spesa di almeno qualche decina di euro al mese per un cluster molto poco potente.\n\nPer questo motivo, abbiamo deciso di unire le forze per creare un cluster kuberentes (ed in generale un sistema completo per deployare i nostri progetti, quindi con database, CI/CD, etc.) spendendo in meno possibile.\n\nDomanica 06 Dicembre, alle 15:00 sui nostri canali youtube cercheremo di fare tutto questo spendendo il meno possibile. Il nostro goal è creare un sistema completo che costi meno di 5€ al meso.\n\nSegui la diretta qui: https://www.youtube.com/watch?v=FmeLTll33a4&ab_channel=ludusrusso\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2020-12-05-k8s-dei-poveri/index.md",
    frontMatter: {
      path: "/2020/12/05/k8s-dei-poveri/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2020-12-05T00:00:00.000Z",
      publishedReadable: "5 Dic 2020",
      featured: false,
      tags: ["Blog", "kubernetes"],
      title: "Kubernetes dei Poveri",
      description:
        "Creiamo un cluster k8s per gestire i nostri side project senza spendere un patrimonio!",
      href: "/2020/12/05/k8s-dei-poveri/",
      image: "/content/blog/it/2020-12-05-k8s-dei-poveri/main.png",
      imagePath: "/content/blog/it/2020-12-05-k8s-dei-poveri",
    },
  },
  {
    content:
      "\n[![image](./main.png)](https://www.youtube.com/watch?v=nkTc6roP7jA)\n\nQuesto blog è ormai diventato un po' anzianotto!\nQuindi ho deciso di riprendo ed aggiornarlo un pochettino con le nuove tenconologie che nel frattempo ho scoperto!\n\nPer questo farò un piccolo esperimento!\nVoglio prendere il mio blog e migrarlo su GatsbyJS! E voglio farlo in streaming.\n\nNon so come andrà, e probabilmente sarà un disastro! Ma credo che sarà divertente! Chi si vuole aggiungere, e magari aiutarmi, è ben accetto!\n\nVi aspetto Giovedì 3 Dicembre alle ore 18:00 su YouTube!\n\nPer seguirlo basta cliccare qui: https://www.youtube.com/watch?v=nkTc6roP7jA\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2020-12-01-migriamo-blog-su-gatsby-js/index.md",
    frontMatter: {
      path: "/2020/12/01/migriamo-blog-su-gatsby-js/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2020-12-01T00:00:00.000Z",
      publishedReadable: "1 Dic 2020",
      featured: false,
      tags: ["Blog"],
      title: "Migriamo il blog su GatsbyJS",
      description:
        "Questo blog è ormai diventato un po' anzianotto! Quindi ho deciso di riprendo ed aggiornarlo un pochettino con le nuove tenconologie che nel frattempo ho scoperto!",
      href: "/2020/12/01/migriamo-blog-su-gatsby-js/",
      image: "/content/blog/it/2020-12-01-migriamo-blog-su-gatsby-js/main.png",
      imagePath: "/content/blog/it/2020-12-01-migriamo-blog-su-gatsby-js",
    },
  },
  {
    content:
      "\nChi mi segue sa che ultimamente ho un po' abbandonato questo blog: mentre fino a due anni fa riuscito a pubblicare tranquillamente un articolo ogni settimana, ultimamente non pubblico più di 1 articolo ogni due o tre mesi.\n\nPer trovare la voglia di riprendere a pubblicare, ultimamente ho lanciato un nuovo progetto personale: un nuovo blog, questa volta con articoli in inglese e con un target un po' più avanzato di quelli che solitamente pubblicavo su questo sito, quindi rivolti non a chi vuole iniziare a programmare, ma a programmatori più esperti.\n\nIl nuovo blog è stato realizzato in GatsbyJS, un generatore di siti statici molto più evoluto rispetto a Jekyll (il motore del blog attuale). Ed è online al dominio [ludusrusso.space](https://ludusrusso.space/)!\n\nParallelamente, sto lanciando alcune nuove iniziative personali che potrebbero aiutare i più che seguono questo blog!\n\n## Mentoring\n\nLa prima iniziativa è un programma di [_mentoring_ one2one](https://ludusrusso.space/mentoring) in cui do la possibilità a chi vuole di avere uno slot di tempo di 45 minuti dedicato a parlare con me (o direttamente a programmare) sui temi che mi interessano di più!\n\n## Remote Show\n\nLa seconda iniziativa è ancora in fase di definizione. In particolare la mia idea è di realizzare un show YouTube a puntate in cui, in ogni puntata, insieme ad un ospite dal mondo dell'innovazione italiana, si realizza un piccolo progetto insieme che a fine puntata viene rilasciato in formato Open Source. Credo che questa forma di creazione di contenuti sia molto efficace e non vedo l'ora di provarla e vederne il funzionamento.\n\nSe vi interessa la cosa, vi consiglio di seguirmi sul mio [canale youtube](https://www.youtube.com/user/Ludus489), perchè i primi esperimenti andranno in onda molto presto!!\n\n# Cosa sarà di questo blog?\n\nLa mia idea a questo punto è, nel futuro, di mergiare i contenuti di questo blog sul nuovo sito! Non so quando questo succederà ma sicuramente ve lo farò sapere :D\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2020-09-03-nuovo-blog/index.md",
    frontMatter: {
      path: "/2020/09/03/nuovo-blog/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2020-09-03T00:00:00.000Z",
      publishedReadable: "3 Set 2020",
      featured: false,
      tags: ["Blog"],
      title: "Introduzione a ludusrusso.space",
      description:
        "Sto lavorando ad un nuovo blog, questa volta in inglese, che verrà fuso con questo",
      href: "/2020/09/03/nuovo-blog/",
      image: "/content/blog/it/2020-09-03-nuovo-blog/main.png",
      imagePath: "/content/blog/it/2020-09-03-nuovo-blog",
    },
  },
  {
    content:
      '\nIn questo articolo, voglio fare una veloce introduzione a [Firebase Hosting](https://firebase.google.com/),\nil servizio di google all\'interno di **Firebase** che ci permette in pochissimo tempo di pubblicare\nla nostra applicazione sul web e renderla disponibile a tutti.\n\nPer il progetto utilizzerò [Angular](https://angular.io/), creeremo un\'applicazione in **Angular 10** e\nla deployeremo online in pochissimo tempo, ovviamente pensando anche (almeno un po\') alla grafica\ntramite [**Angular Material**](https://material.angular.io/).\n\n## Prerequesiti\n\nOvviamente non si può fare tutto in pochissimo tempo se non si ha almeno un po\' di prerequesiti, ecco\nquali sono quelli necessari (almeno per me)!\n\n1. Avere installato nella nostra macchina [**nodejs**](https://nodejs.org/it/) e [il client Anglular](https://angular.io/cli)\n2. Avere installato [il client firebase](https://firebase.google.com/docs/cli)\n3. Avere un minimo di familiarità con il terminale\n4. Avere un account google (con cui accedere a Firebase).\n\n### 1. Creiamo un progetto firebase!\n\nPartiamo con le cose più semplici. Ci serve accedere [alla console firebase](https://console.firebase.google.com) e creare un nuovo progetto. Il processo è super semplice, dobbiamo scegliere un nome, abilitare google analytics (se vogliamo) e aspettare qualche secondo!\n\nFirebase è (ovviamente) a pagamento, ma esiste un piano grautito molto generoso che ci permette di testarlo completamente, com poche limitazioni. Se le quote gratuite vengono superate il progetto semplicemente si blocca senza farci pagare nulla fino al mese successi, ma vi assicuro che per progetti hobbistici è molto difficile arrivare a questo!\n\n![Creare app Firebase](./firebase-1.png)\n\n![Creare app Firebase](./firebase-2.png)\n\n![Creare app Firebase](./firebase-3.png)\n\n![Creare app Firebase](./firebase-4.png)\n\n![Creare app Firebase](./firebase-5.png)\n\n### 2. Si crea l\'app Angular!\n\nSpostiamo ci sul termina ed iniziamo a smanettare un po\' con la shell.\n\nPer prima cosa dobbiamo loggarci con il client firebase (lo avete installato vero) al nostro account, per poter accedere al progetto e configurare l\'app.\n\nPer farlo, digitate sul terminale\n\n```bash\n$ firebase login\n```\n\nFirebase vi aprirà una finestrea del browser in cui vi dovrete loggare con lo stesso account google con cui avete creato il progetto.\n\nPossiamo quindi creare la nostra applicazione Angular, nel nostro workspace, digitiamo il comando\n\n```bash\nng new <nome progetto>\n```\n\n<script id="asciicast-aMKnWHeicTOAWuoEvzieR6RPh" src="https://asciinema.org/a/aMKnWHeicTOAWuoEvzieR6RPh.js" async></script>\n\nApriamo il progetto appena creato con un editor di testo (io uso VSCode ormai) ed installiamo (tramite il tool `ng add`) [Angular Material](https://material.angular.io/) per avere una UI leggermente carina in modo semplice.\n\n```bash\n$ ng add @angular/material\n```\n\n<script id="asciicast-6Wd52K6z8yHc743OV3Q9xZlp1" src="https://asciinema.org/a/6Wd52K6z8yHc743OV3Q9xZlp1.js" async></script>\n\nSeguiamo e completiamo il wizard che angular ci propone.\n\nA questo punto possiamo installare [`@angular/fire`](https://github.com/angular/angularfire), la libreria angular ufficiale di Firebase.\n\n```bash\n$ ng add @angular/fire\n```\n\nNotare che il wizard che appare ci chiederà di selezionare un progetto firebase. Scegliamo il nostro e andiamo avanti!\n\n<script id="asciicast-6Be0gm8tXsJMSXQokSV20nK5a" src="https://asciinema.org/a/6Be0gm8tXsJMSXQokSV20nK5a.js" async></script>\n\nFatto! Come vedete è stato semplicissimo! Tutto pronto per il deploy!\n\n### 3. Abbelliamo un po\' il progetto!\n\nPrima di deployare facciamo in modo che l\'app siamo un po\' decente :D\nPer prima cosa svuotiamo completamente il file `src/app/app.component.html`, che angular riempe con del codice di esempio che non ci interessa!\n\nAll\'interno del file `app.module.ts` importiamo un po\' di moduli di angular material che ci serviranno per abbellire l\'app. In particolare, useremo [MatToolbar](https://material.angular.io/components/toolbar/overview), [MatButton](https://material.angular.io/components/button/overview) e [MatCard](https://material.angular.io/components/card/overview).\n\nDobbiamo importarli dalle relative librerie e poi inserirli all\'interno della tupla `imports` di `@NgModule`.\n\n```ts\n// app.module.ts\n\nimport { NgModule } from "@angular/core"\nimport { BrowserModule } from "@angular/platform-browser"\nimport { BrowserAnimationsModule } from "@angular/platform-browser/animations"\nimport { AppRoutingModule } from "./app-routing.module"\nimport { AppComponent } from "./app.component"\n\nimport { MatButtonModule } from "@angular/material/button"\nimport { MatCardModule } from "@angular/material/card"\nimport { MatToolbarModule } from "@angular/material/toolbar"\n\n@NgModule({\n  declarations: [AppComponent],\n  imports: [\n    BrowserModule,\n    AppRoutingModule,\n    BrowserAnimationsModule,\n    MatCardModule,\n    MatToolbarModule,\n    MatButtonModule,\n  ],\n  providers: [],\n  bootstrap: [AppComponent],\n})\nexport class AppModule {}\n```\n\nA questo punto, mettiamo un po\' di contenuti dentro `app.component.html`\n\n```html\n<!-- app.component.html -->\n\n<mat-toolbar color="primary">\n  <span> Angular Firebase in 10 mins </span>\n</mat-toolbar>\n\n<mat-card>\n  <h1 mat-card-title>Visita il progetto su GitHub</h1>\n\n  <mat-card-actions align="center">\n    <a\n      href="https://github.com/ludusrusso/firebase-10-minutes"\n      target="_blank"\n      mat-raised-button\n      color="primary"\n    >\n      GitHub repo\n    </a>\n    <a\n      href="https://ludusrusso.cc/2020/03/31/pubblicare-una-app-angular-in-10-minuti-con-firebase-hosting/"\n      target="_blank"\n      mat-raised-button\n      color="primary"\n    >\n      Blog Post\n    </a>\n  </mat-card-actions>\n\n  <mat-card-footer>\n    <p>Designed by @ludusrusso</p>\n  </mat-card-footer>\n</mat-card>\n```\n\ne aggiustiamo un po\' gli stili\n\n```scss\n// app.component.scss\n\n:host {\n  display: block;\n  min-height: 100vh;\n  background-color: #eee;\n}\n\nmat-card {\n  margin: auto;\n  display: grid;\n  margin: 20px auto;\n  width: 80%;\n}\n```\n\nLa nostra app è pronta. Per testarla in locale, digitiamo il comando\n\n```bash\n$ ng serve --open\n```\n\nChe compilerà l\'app e ci aprirà una finestra del browser all\'url `http://localhost:4200` con la nostra applicazione!\n\n### 4. Deploy\n\nOk, se abbiamo fatto tutto bene, basterà digitale sul terminale\n\n```bash\n$ ng deploy\n```\n\nper deployare la nostra applicazione.\n\n<script id="asciicast-wjSdIKxgFJ8DsiGzkTKb5xAiS" src="https://asciinema.org/a/wjSdIKxgFJ8DsiGzkTKb5xAiS.js" async></script>\n\nQuesto comando compila la nostra app in produzione e la deploya su firebase! Se tutto va liscio senza errori, alla fine del processo avremo l\'url con cui raggiungere la nostra app! Nel mio caso [https://fir-10-minutes.web.app](https://fir-10-minutes.web.app)!\n\n![Creare app Firebase](./app.png)\n\n## Conclusioni\n\nCome avete visto, il processo di deploy di Firebase è veramente semplice, ed in pochissimo tempo possiamo avere online un\'app accessibile da tutti!\n\nOvviamente firebase è molto di più! Voi cosa ne pensate? Lo usate già?\n\nPS: Trovate [a questo link](https://github.com/ludusrusso/firebase-10-minutes) la repo del progetto su github!\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2020-03-31-pubblicare-una-app-angular-in-10-minuti-con-firebase-hosting/index.md",
    frontMatter: {
      path: "/2020/03/31/pubblicare-una-app-angular-in-10-minuti-con-firebase-hosting/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2020-03-31T00:00:00.000Z",
      publishedReadable: "31 Mar 2020",
      featured: false,
      tags: ["Angular", "Firebase"],
      title:
        "Firebase Hosting: dalla creazione del progetto al sito online in 10 minuti",
      description:
        "Vediamo come possiamo pubblicare un'app Angular dopo 10 minuti dalla creazione del progetto sfruttando firebase hosting",
      href: "/2020/03/31/pubblicare-una-app-angular-in-10-minuti-con-firebase-hosting/",
      image:
        "/content/blog/it/2020-03-31-pubblicare-una-app-angular-in-10-minuti-con-firebase-hosting/main.png",
      imagePath:
        "/content/blog/it/2020-03-31-pubblicare-una-app-angular-in-10-minuti-con-firebase-hosting",
    },
  },
  {
    content:
      "\nPer ragioni di lavoro sono stato un po' costretto ad abbandonare questo blog,\nma da oggi mi impegno a riprenderlo e ricominciare a scrivere contenuti come\nuna volta.\n\nForse l'argomento sarà un po' diverso, in quest'ultima anno, dopo il trasferimento\na Milano ed un cambiamento di lavoro, mi sono fortemente interessato al mondo\ndel cloud computing ed in particolare a Kubernetes.\n\nOggi, vi segnalo un mio intervento in live streaming su Youtube dal titolo\n**[webMeetup #1] GDG Cloud Milano - Live Code: CI/CD con Gitlab-CI e Kubernetes**,\nin cui, insieme agli amici di **GDG Cloud Milano**, che mi hanno recentemente\naccolto come organizzatore, discuteremo del mondo del Continuous Integration and\nContinuous Deployment con Kubenretes e Gitlab-CI sulla piattaforma Google Cloud\nPlatform.\n\nPotete seguire l'evento oggi dalle 18:30 cliccando sulla locandina qui in basso:\n\n[![Diretta Streaming](./main.jpg)](https://youtu.be/IBNwrk24BLk)\n\nVi lascio l'agenta, e vi aspetto numero alla live, dove sarà possibile anche\ninteragire in Tempo Reale con noi speaker per mezzo di strumenti digitali!\n\nIl primo evento online di GDG Cloud Milano vede una live code in cui impareremo a sviluppare un’app in Angular da zero e deployare all’interno di Google Kubernetes Engine per mezzo della piattaforma CI/CD Gitlab CI.\n\n👉 Potrete seguire l'evento nel nostro [canale Youtube](https://www.youtube.com/channel/UCs2L)\n\nAGENDA\n18:30-18:40 Inizio stream live e introduzione\n18:40-19:00 Introduzione a Docker, Kubernetes e GitLab-CI (per i più inesperti)\n19:00-19:30 Sviluppiamo una semplice app con Angular\n19:30-20:00 Setup e deploy tramite GitLab-CI\n20:00-20:30 Go live e test tramite la community :)\n20-30:21:00 Aperitivo di Networking Digitale, Q&A e Smanettamento\n\n📑 Sei interessato ad avere slide e codice? Compila un piccolo form alla fine dell'evento ed avrai accesso a tutto il materiale :)\n\nCosa ti serve?\nUna connessione ad internet ed un po’ di tempo libero per seguire lo stream. Prepara qualcosa da bere e da mangiare insieme agli altri della community :)\n\nQuanto costa?\nNulla. L'evento è assolutamente gratuito!\n\nChi e' lo Speaker?\nLudovico Russo ha ottenuto un PhD in Cloud Computing and Robotics presso il Politecnico di Torino. Attualmente lavora come consulente e inprenditore nel mondo del Cloud Computing, utilizzando principalmente kubertes e GCP!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2020-03-31-webminar-ci-cd-con-gitlabci-k8s/index.md",
    frontMatter: {
      path: "/2020/03/31/webminar-ci-cd-con-gitlabci-k8s/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2020-03-31T00:00:00.000Z",
      publishedReadable: "31 Mar 2020",
      featured: false,
      tags: ["Gitlab", "Kuberentes", "CI/CD", "GDG Cloud Milano"],
      title: "GDG Cloud Milano - Live Code: CI/CD con Gitlab-CI e Kubernetes",
      description:
        "Il primo WebMeetup di GDG Cloud Milano è dedicato al mondo Kuberntes e Continuos Integration!",
      href: "/2020/03/31/webminar-ci-cd-con-gitlabci-k8s/",
      image:
        "/content/blog/it/2020-03-31-webminar-ci-cd-con-gitlabci-k8s/main.jpg",
      imagePath: "/content/blog/it/2020-03-31-webminar-ci-cd-con-gitlabci-k8s",
    },
  },
  {
    content:
      "\nIl primo post di quest'anno è stato inspirato da una domanda di un utente su un [precedente articolo](https://ludusrusso.cc/2017/10/29/bot-telegram-telepot-2/), che mi chiedeva questo:\n\n> \"ho implementato il bot senza problemi, mando un comando e mi restituisce quando mi serve, vorrei nel frattempo, monitorare un GPIO, il quale se cambia stato, manda un messaggio al bot senza che io abbia fatto esplicita richiesta con un comando, è possibile farlo ? grazie mille\"\n\nDato che l'idea è molto interessante e permette di lavorare su progetti molto utili, ad esempio un allarme fatto in casa, ho deciso di scrivere un post per spiegare come fare!\n\nIniziamo quindi, al solito, ad tirare su l'ambinete di sviluppo ed iniziare a lavorare.\n\n## Componenti necessari\n\nIl progetto si basa su Raspberry Pi, quindi sarà necessario avere a disposizione in casa questo computerino. Nel mio caso, ho usato un [Raspberry Pi Model 3B+](https://amzn.to/2R4LoCQ) con relativi componenti necessari e su cui ho installato [Raspbian Lite](https://www.raspberrypi.org/downloads/raspbian/), che come sapete è la mia Distro preferita per Rpi. Ovviamente dovrebbe andare bene qualsiasi Distro e qualsiasi versione del Raspberry.\n\nVi servirà anche un modo per inviare comandi al GPIO di ingresso che invierà il segnale. Nel mio caso, ho usato un semplice bottone connesso al PIN come descritto più sotto.\n\n## Setup Ambiante di Sviluppo\n\nAssicuriamoci, una volta entrati nel Raspberry pi, di avere installato `python3` (che dovrebbe essere installato di default in Raspbian).\n\nA questo punto, dobbiamo installare virtualenv con il comando\n\n```bash\npython3 -m venv env\n```\n\nE siamo finalmente pronti a lanciare il nostro ambiente virtuale ed installare le dipendenze:\n\n1. `telepot` per creare il nostro bot,\n2. `RPi.GPIO` per interagire con i GPIO del Raspberry PI.\n\n```bash\n$ mkdir bot-telegram && cd bot-telegram\n$ python3 -m venv env && source ./env/bin/activate\n(env)$ pip install telepot RPI.GPIO\n```\n\nNotate che, a differenza di quello fatto nei miei [precedenti tutorial](https://ludusrusso.cc/2017/04/27/implementiamo-un-bot-telegram-con-python/), questa volta ho installato l'ambiente virtuale con il comando `python3 -m venv env`, e che stiamo usando Python 3 invece che Python 2.\n\n## Creiamo il BOT\n\nCreiamo un file chiamato `bot.py` (o come preferite) e apriamolo con un qualsiasi editor di testo (io uso `vim`, ma voi potete usare quello che volete).\n\nCome punto di partenza, prendiamo il codice che trovate nel mio [precedente tutorial](https://ludusrusso.cc/2017/04/27/implementiamo-un-bot-telegram-con-python/). Ho dovuto solo modificare la linea `print 'Listening ...'` con `print('Listening ...')` in quanto questa volta usiamo **Python3** invece che **Python2**.\n\n```python\nimport telepot\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n\nTOKEN = '*** inserisci il tuo token qui  ***'\n\nbot = telepot.Bot(TOKEN)\nbot.message_loop(on_chat_message)\n\nprint('Listening ...')\n\nimport time\nwhile 1:\n    time.sleep(10)\n```\n\nCome sapete, questo bot è un semplicissimo bot che risponde a qualsiasi messaggio con un semplice `'ciao, sono un bot molto stupido!'`. Se volete più informazioni su come scrivere questo codice o sapere esattamente cosa fa vi consiglio di rileggere il mio [primo articolo su Telegram e Python](https://ludusrusso.cc/2017/04/27/implementiamo-un-bot-telegram-con-python/). Non credo sia necessario ripetermi qui.\n\nAltro consiglio, dato che questo bot è super testato, prima di andare avanti lanciatelo e provate almeno una volta che funziona. Saprete, in futuro, che se qualcosa non funziona è colpa di quello che avete aggiunto dopo :D\n\n### Callback e GPIO\n\nSe avete letto questi articoli, vi ricorderete che quando parlo della funzione `on_chat_message` vi metto in guardia sul fatto che questa funzione non viene mai chiamata direttamente dal nostro codice, ma è la libreria `telepot` che si occupa di invocarla quando qualcuno scrive un messaggio al bot. In gergo, questo tipo di funzioni vengono chiamate _callback_, e vengono usate ogni volta che creiamo un programma che deve gestire _eventi_ che vengono generati esternamente al programma stesso.\n\nLe funzioni di callback, oltre ad essere definite, devono anche essere _registrate_ all'evento che devono gestire. Ogni libreria o tool che usiamo ha un modo proprio di gestire le registrazioni, ad esempio, in `telepot` la registrazione avviene con la riga `bot.message_loop(on_chat_message)`, in cui essenzialmente diciamo al nostro bot:\n\n> Hey bot! Ogni volta che qualcuno ti scrive un messaggio, chiama gentilmente la funzione `on_chat_message`. Si occuperà lei di generare la risposta.\n\nPerchè ho fatto questa lunga premessa? Il motivo è semplice, anche il cambio dello stato di un GPIO (in ingresso) del Raspberry Pi è un evento esterno al programma, quindi deve essere gestito in un modo simile :)\n\nEd infatti, la libreria `RPi.GPIO` mette a disposizione un modo per registrare una funzione di callback quando lo stato di un GPIO cambia. Questa funzione è la seguente:\n\n```python\nGPIO.add_event_detect(PIN, EVENT, callback=cfunc)\n```\n\ne che prende i seguenti parametri:\n\n1. `PIN` è il numero del GPIO che vogliamo \"ascoltare\".\n2. `EVENT` è il tipo di evento a cui vogliamo rispondere. Ci sono 3 tipi di eventi:\n   - `GPIO.RISING`: risponde all'evento cambio stato da _LOW_ a _HIGH_.\n   - `GPIO.FALLING`: risponde all'evento cambio stato da _HIGH_ a _LOW_.\n   - `GPIO.BOTH`: risponde indistintamente ad entrambi gli eventi.\n3. `callback`, il nome della funzione di Callback che dobbiamo chiamare al verificarsi dell'evento.\n\nCapito questo, il resto è facile. Per prima cosa, dobbiamo creare una funzione che invia un messaggio tramite il nostro bot. La cosa è molto facile, infatti basta implementare questo:\n\n```python\ndef bot_cb(pin):\n    print('il pin {} ha cambiato stato'.format(pin))\n    bot.sendMessage(admin_id, 'il pin {} ha cambiato stato'.format(pin))\n```\n\ned attaccare questa funzione al nostro PIN di input nel seguiente modo:\n\n```python\nINPIN = 2\n\nGPIO.setmode(GPIO.BCM)\nGPIO.setup(INPIN, GPIO.IN)\n\nGPIO.add_event_detect(INPIN, GPIO.BOTH, bot_cb)\n```\n\nNotate che, a differenza del caso normale in cui il bot risponde ad una chat, in questo caso il bot deve conoscere _a priori_ l'id chat a cui mandare il messaggio. Ci sono vari modi per farlo, ma il più semplice è embeddare nel codice il proprio _chat id_. Basta quindi definire la variabile `admin_id = 00000000` (con il proprio chat id) e poi usarla per inviare il messaggio.\n\nPer scoprire il proprio chat id ci sono vari modi, il più immediato è quello di usare uno dei bot disponibili su telegram, come [@chatid_echo_bot](https://t.me/chatid_echo_bot), che vi risponderà con il vostro chat id a qualsiasi messaggio gli invierete.\n\n## Programma Completo\n\nIl programma finale, quindi, è il seguente:\n\n```python\nimport telepot\nimport RPi.GPIO as GPIO\n\nadmin_id = 0000000 # Inserisci il chat id di chi deve ricevere il messagio\nINPIN = 2\nTOKEN = '*** INSERISCI IL TUO TOKEN ***'\n\nGPIO.setmode(GPIO.BCM)\nGPIO.setup(INPIN, GPIO.IN)\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n\nbot = telepot.Bot(TOKEN)\nbot.message_loop(on_chat_message)\n\ndef bot_cb(pin):\n    print('il pin {} ha cambiato stato'.format(pin))\n    bot.sendMessage(admin_id, 'il pin {} ha cambiato stato'.format(pin))\n\nGPIO.add_event_detect(INPIN, GPIO.BOTH, bot_cb)\n\nprint('Listening ...')\n\nimport time\nwhile 1:\n    time.sleep(10)\n```\n\n### Test con un bottone\n\nPer testare il tutto, ho creato un semplicissimo circuito con un pulsante sul Raspberry, collegato al GPIO 2 secondo il seguente schema:\n\n![Schema Collegamenti](./button.png)\n\nIl bot funziona bene, ci sono alcuni problemi che non ho voluto risolvere perchè questo test è (appunto), un semplice test di funzionamento e non un vero e proprio caso d'uso.\n\nIn particolare, a causa dei rimbalzi meccanici delle perti interne del bottone, capita che la funzione di callback venga chiamata più volte quando il bottone cambia stato. Questo è normale ed anche facilmente risolvibile, ma non ho voluto complicare il codice per un esempio di questo tipo.\n\n## Che ne pensate?\n\nAvete in mente applicazioni e casi d'uso dove è richiesto che un raspberry invii messaggi a qualcuno quando lo stato di un pin (od un sensore in generale) cambia? Io si, e la mia idea consiste anche nel dover fare un po' di analisi di immagini. Quindi aspettatevi a breve un nuovo tutorial!!!!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2019-01-04-invio-messaggi-telegram-da-eventi-gpio/index.md",
    frontMatter: {
      path: "/2019/01/04/invio-messaggi-telegram-da-eventi-gpio/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2019-01-04T00:00:00.000Z",
      publishedReadable: "4 Gen 2019",
      featured: false,
      tags: ["Raspberry", "Telegram", "GPIO"],
      title:
        "Un bot telegram che invia messaggi al verificarsi di eventi sui GPIO del Raspberry Pi",
      description:
        "Mandare un messaggio tramite telegram quando il un GPIO del Raspberry cambia stato è possibile, ecco come!",
      href: "/2019/01/04/invio-messaggi-telegram-da-eventi-gpio/",
      image:
        "/content/blog/it/2019-01-04-invio-messaggi-telegram-da-eventi-gpio/main.jpg",
      imagePath:
        "/content/blog/it/2019-01-04-invio-messaggi-telegram-da-eventi-gpio",
    },
  },
  {
    content:
      "\nPer chi lavora e sviluppa su Raspberry Pi, sa bene che utilizzare la GUI del Raspberry per lo sviluppo risulta molto scomodo e lento.\nIl mio workflow abituale consiste, infatti, nello sviluppare [principalmente con Docker](https://ludusrusso.cc/2018/06/29/docker-raspberrypi/) e trasferire le immagini su Raspberry solo per test e quando il sistema è finito.\n\nMi sono quindi abituato a lavorare senza interfaccia grafica né monitor, avendo il Raspberry semplicemente connesso (via ethernet o wifi) al router e accedendoci via SSH, utilizzando come sistema operativo principale [Raspbian Lite](https://www.raspberrypi.org/downloads/raspbian/), cioè la versione di Rasbian senza interfaccia grafica installata.\n\nPurtroppo sorge continuamento lo stesso problema ogni volta che mi trovo a lavorare su un nuovo progetto: **Come faccio ad accedere via SSH al mio Raspberry Pi con SD appena creata?** Infatti, da ormai qualche anno, l'SSH è disabilitato di default per ragioni di sicurezza su Raspbian, e per abilitarlo risulta necessario trovare un monitor ed una tastiera, accedere al Raspberry ed utilizzare il comando `raspi-config` per abilitare il server SSH.\n\n![Abilitare SSH](./enable-ssh.jpg)\n\nLa cosa è scocciante ma non crea grossi problemi finchè non capita di non aver a disposizione un monitor e/o una tastiera nel momento della configurazione, cosa che mi è capitata giusto qualche giorno fa mentre lavoravo ad un progetto. Per fortuna, ho scoperto che gli sviluppatori del Raspberry Pi hanno pensato ad una soluzione per questo tipo di problemi.\n\n### Come abilitare SSH all'avvio se non possiedo un Monitor?\n\nIl procedimento è molto semplice. Una volta creata la nostra SD a partire dall'immagine ufficiale, dobbiamo collegarla al nostro computer principale.\n\nAll'interno della SD, ci sarà una partizione chiamata `/boot`. Dobbiamo andare a creare un file vuoto all'interno di questa partizione chiamato `ssh`. A questo punto, possiamo inserire la SD nel Raspberry e, una volta collegato al router tramite ethernet, avviarlo. A questo punto, possiamo tranquillamente collegarci al nostro Raspberry utilizzando SSH.\n\n![SSH file](./ssh.png)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-12-31-ssh-raspberry-pi-avvio/index.md",
    frontMatter: {
      path: "/2018/12/31/ssh-raspberry-pi-avvio/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2018-12-31T00:00:00.000Z",
      publishedReadable: "31 Dic 2018",
      featured: false,
      tags: ["Raspberry", "SSH"],
      title: "Abilitare l'accesso SSH del raspberry pi senza usare un monitor",
      description:
        "Un piccolo trucco per gestire al meglio lo sviluppo su Raspberry Pi, specialmente se non si ha a disposizione un monitor.",
      href: "/2018/12/31/ssh-raspberry-pi-avvio/",
      image: "/content/blog/it/2018-12-31-ssh-raspberry-pi-avvio/main.png",
      imagePath: "/content/blog/it/2018-12-31-ssh-raspberry-pi-avvio",
    },
  },
  {
    content:
      "\n![I 4 tool che ogni Sviluppatore Cloud deve conoscere nel 2019](./main.png)\n\nDa un po' di tempo mi sto dedicando sempre di più allo sviluppo di software in Cloud, e ho costruito e sviluppato una serie di skills su software, tools e strategie per lo sviluppo di software in cloud in modo semplice e veloce.\n\nIn questo post, vi voglio raccontare queli che sono i tool più importanti che ogni _Cloud Developer_ deve conoscere, e a cosa servono!\n\n## 1. Docker\n\n![Docker](./docker.png)\n\nHo [parlato di Docker](https://ludusrusso.cc/tags/#docker) in alcuni post in questo blog.\n\n**Docker** è probabilmente il progetto Open Source che ha avuto più impatto nel mondo del Cloud Computing negli ultimi tempi, basti pensare che in meno di 5 anni (Docker è stato rilasciato nel 2013) è diventato uno standard di fatto accettato ed utilizzato da tutti i Big del mondo Cloud Computing, ma già in [meno di 2 anni dal rilascio](https://www.datacenterknowledge.com/archives/2014/08/22/docker-ceo-dockers-impact-data-center-industry-will-huge) era sotto il mirino dei vari cloud provider, per la sua capacità di impacchettare. spostare e distribuire applacazioni tra i vari ambienti Cloud.\n\nDocker è basato sulla tecnologia dei Linux container, che possono essere visti (mi scusino i puristi del cloud ma ho bisogno di un esempio pratico) come delle _Macchine Virtuali Superleggere_. Docker permette di gestire la creazione, distribuzione, condivisione e gestione di Linux Container.\n\nImpacchettando un'applicazione con Docker all'interno di un Container Linux, siamo sicuri che le dipendenze dell'applicazione e l'ambiente di configurazione sarà sempre lo stesso indipendentemente da dove verrà deployata l'applicazione stessa, sia sul nostro PC di sviluppo su cui gira Ubuntu, che su un server remoto basato su Debian o un cluster di Server (si veda la voce Kubernetes) in Cloud.\n\nDocker inoltre standardizza il modo in cui un'applicazione viene Buildata e Testata, semplificando notevolmente la gestione del Continuous Integration delle applicazioni in Cloud.\nIl build delle applicazioni Docker è _incrementale_, questo vuol dire che docker permette di risparmiare tantissimo tempo in fase di compilazione, in quanto le parti delle immagini già compilate possono essere riutilizzare nei build futuri.\n\nPer finire, Docker permette di distribuire le immagini tramite Internet con i Container Registry. Questi possono essere utilizzati sia per spostare in modo semplice le applicazioni\ndal nostro ambiente di test locale all'ambiente di produzione in cloud, ma anche permette di condividere le immagini di progetti in modalità Open (o anche no). Basta fare un giro sul sito [Docker Hub](https://hub.docker.com/) per capire di che parlo.\n\n### 1.1 Docker per IoT\n\nUn piccolo bonus, prima di andare avanti, lo voglio dedicare al mondo IoT, che è stato anche questo influenzato tantissimo dalla tecnologia Linux Container e quindi da Docker.\n\nCome ho già detto, i container molto leggeri con un overhead minimo. Per questo motivo, questa tecnologià sta avendo lo stesso impatto che ha avuto la Virtualizzazione all'interno dell IoT. I container Docker possono infatti essere tranquillamente eseguti all'interno di macchine ARM su Embedded Linux. Con i registry Docker, le immagini possono essere distruibuite come aggiornamenti su dispositivi IoT in produzione.\n\nPer approfondimenti, ho trattato il tema su questo blog nell'articolo [Buildare e usare container Docker per Raspberry Pi](https://ludusrusso.cc/2018/06/29/docker-raspberrypi/)\n\n## 2. docker-compose\n\n![Docker Compose](./compose.png)\n\nLo sviluppo di applicazioni Docker richiede una certa conoscenza del tool linea di comando `docker`, che risulta essere (ve ne accorgerete subito) molto prolisso per compilare, lanciare e gestire applicazioni Docker. Il tutto si complica quando iniziamo ad avere progetti con più di un container docker in azione (e vi assicuro che è normale avere almeno due container che lavorano insieme), e se si vogliono sfruttare le funzionalità di docker come la gestione dei `volumi`, il networking virtuale o il semplice passaggio di configurazioni (come variabili d'ambiente) al container.\n\n`docker-compose` è un tool (implementato in Python) che permette di gestire in modo semplice e veloce la gestione dei container. Al posto di gestire l'intera vita dei container a mano da line a di comando, possiamo creare un file di configurazione `docker-compose.yaml` che descrive i nostri container e come questi interagiscono tra loro. Una volta creato ed implementato questo file, possiamo usare dei comandi semplificati per creare, gestire e distruggere i container!\n\n## 3. Kubernetes\n\n![Kubernetes](./kubernetes.png)\n\n**Kubernetes** (**k8s** per gli amici) è un progetto Open Source nato e spinto da Google, e attualmente matenuto dalla **Cloud Native Computing Foundation**. Kubernetes è il progetto che, dopo Docker, ha radicalmente ridefinito il concetto di Cloud Computing moderno. Kubernetes è un sistema che permette di orchestrare e gestire applicazioni basate su container. Permettendo di automatizzare e semplificare il deployment, lo scaling e la gestione di applicazioni i cui _building blocks_ sono, appunto, container.\n\nKuberentes introduce alcuni concetti che richiedono un po' di tempo per essere appresi e digeriti, ma, una volta capiti, ci permettono gestire interamente un'applicazione cloud con uno (o più) file di configurazione e una serie di semplici comandi basati sul tool `kubeclt`.\n\n## 4. Helm\n\n![Helm](./helm.jpeg)\n\nPer finire, **Helm** è l'ultimo tool che ho iniziato ad utilizzare in questo periodo, ma che,in pochi giorni, ha rivelato tutta la sua potenza. Come viene definito dagli stessi creatori del progetto, Helm è un packet manager per kubernetes, e ci permette di condividere ed utilizzare applicazioni kubernetes in modo semplice e veloce. Il progetto ha permesso di costruire repository di applicazioni _kubernetes-ready_, come [Kubeapps](https://hub.kubeapps.com/), che possiamo installare ed utilizzare sul nostro cluster persone pochi click!\n\n## Conclusioni\n\nLe tecnologie informatiche si evolvono velocemente, le tecnologie web lo fanno molto velocemente e anche il Cloud Computing non è da meno. Lo sviluppo di applicazioni Cloud è cambiato notevolmente in pochissimi anni (se non mesi), e con questo post ho voluto fare una carrellata sulle tecnologie che, a mio pararere, sono le più importanti da conoscere per chi vuole lavorare nel mondo del cloud computing.\n\nVoi cosa ne pensate? Ho dimenticato qualcosa? Avete dei suggerimenti o creitiche per migliorare questo post?\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-12-12-i-4-tools-per-sviluppare-in-cloud/index.md",
    frontMatter: {
      path: "/2018/12/12/i-4-tools-per-sviluppare-in-cloud/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2018-12-12T00:00:00.000Z",
      publishedReadable: "12 Dic 2018",
      featured: false,
      tags: ["Docker", "Kubernetes", "Helm"],
      title:
        "I 4 tool Open Source che ogni Sviluppatore Cloud deve conoscere nel 2019",
      description:
        "I tool Open Source più importanti per lo sviluppo di software e architetture Cloud nel 2019.",
      href: "/2018/12/12/i-4-tools-per-sviluppare-in-cloud/",
      image:
        "/content/blog/it/2018-12-12-i-4-tools-per-sviluppare-in-cloud/main.png",
      imagePath:
        "/content/blog/it/2018-12-12-i-4-tools-per-sviluppare-in-cloud",
    },
  },
  {
    content:
      "\nDa tanto tempo ormai sono abituato a lavorare con Raspbian (Lite), la distro ufficiale del Raspberry Pi senza interfaccia grafica, che molto si adatta a sviluppare applicazioni come piccoli robot o progetti IoT, che spesso non sono dotati di schermo.\n\nUno dei problemi più spesso riscontrati è la gestione del WiFi in queste condizioni. Solitamente\nil Raspberry Pi deve connettersi ad una rete wifi nota per poi poter eseguire il proprio compito.\nQuindi è necessario istruire il Raspberry in modo che si connetta ad una rete WiFi prima di iniziare a fare qualsiasi cosa.\n\nFino ad ora, usavo il tool `wpa_cli`, che ha due grossi problemi:\n\n1. E' molto scomo da utilizzare e\n2. Non è installato di default su Raspbian.\n\nIl punto (2) comporta un'ulteriore scomodità: prima di inizare a lavorare con una nuova scheda, è necessario connetterla fisicamente alla rete ethernet per poter scaricare i pacchetti necessari ad utilizzarla.\n\nPer fortuna, ieri ho scoperto che raspbian monta al suo interno un tool super semplice che ci permette di collegare il raspberry al WiFi in 2 min. Vediamo come fare.\n\nPer prima cosa, accediamo a `raspi-config` con il comando:\n\n```bash\n$ sudo raspi-config\n```\n\nA questo punto, andiamo su `Network Options` -> `Wi-Fi`. Inseriamo nome e password della rete a cui vogliamo conneterci, chiudiamo il tool e riavviamo il raspberry con il comando\n\n```bash\n$ sudo reboot\n```\n\nAl riavvio, il raspberry sarà connesso alla rete (ovviamente se i dati inseriti sono corretti).\n\n![](./step1.png)\n![](./step2.png)\n![](./name.png)\n![](./password.png)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-07-01-raspberry-pi-wifi-setup-super-semplice/index.md",
    frontMatter: {
      path: "/2018/07/01/raspberry-pi-wifi-setup-super-semplice/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2018-07-01T00:00:00.000Z",
      publishedReadable: "1 Lug 2018",
      featured: false,
      tags: ["Raspberry"],
      title: "Setup Wifi super semplice per Raspbian Lite",
      description:
        "Vi propongo un trucchetto per gestire in modo semplicissimo il WiFi su Raspbian (Lite).",
      href: "/2018/07/01/raspberry-pi-wifi-setup-super-semplice/",
      image:
        "/content/blog/it/2018-07-01-raspberry-pi-wifi-setup-super-semplice/step2.png",
      imagePath:
        "/content/blog/it/2018-07-01-raspberry-pi-wifi-setup-super-semplice",
    },
  },
  {
    content:
      "\nRiprendo con questo post il mio progetto [Costruiamo un robot Open Source](robot-open-source/),che ho lasciato un po' accantonato per vari impegni in questi ultimi due mesi.\n\nLa scrittura di questo post nasce dall'esigenza di spiegare alcuni concetti molto tecnici legati al mondo di Docker per sistemi embedded che preferisco presentare in forma scritta, per poi riprenderli nei prossimi video che verranno rilasciati sul mio canale YouTube, in cui ci focalizzeremo sull'utilizzo di ROS e Docker all'interno del nostro Raspberry PI.\n\nSe non sapete di cosa si parla, Docker è un progetto che semplifica lo sviluppo ed il deploy di applicazioni informatiche per il web. Questo è utilizzatissimo nel mondo dello sviluppo e gestione di server web ma sta diventando popolare anche nel mondo di Linux Embedded, specialmente perchè semplifica di tantissimo la gestione di dispositivi IoT.\n\nI problemi legati all'utilizzo di Docker su Raspberry (ed in generale su Linux Embedded basati su tecnologia ARM), sono due:\n\n1. Installare Docker su questi dispositivi;\n2. Cross-buildare i container Docker su computer convenzionali, per semplificare e velocizzare l'intero processo di sviluppo.\n\nIl primo problema, fortunatamente, è già risolto dagli stessi sviluppatori docker, che al momento hanno rilasciato uno script che permette, con un semplicissimo comando, di installare docker praticamente su qualsiasi ambiente linux supportato (e quindi anche ambiente ARM).\n\nIl secondo problema è un po' più incasinato, ma per fortuna [i ragazzi di hypriot.com](https://blog.hypriot.com/post/setup-simple-ci-pipeline-for-arm-images/) hanno rilasciato un bellissimo post che spiega una procedura semplice da atturare per fare questa operazione.\n\nQuesto post quindi ha il triplice scopo di:\n\n1. Insegnare come installare Docker su Raspberry Pi in modo semplice e veloce.\n2. Proporre una possibile build chain per cross-compilare immagini Docker su un computer Intel.\n3. Presentare una soluzione per il deploy delle applicazioni direttamente su Raspberry Pi.\n\nOltre all'utilizzo di Docker vero e proprio, vedremo anche come si usa **docker-compose**, un tool che semplifica di molto la gestione delle varie immaigni Docker.\n\n## Installare Docker su Raspberry Pi (2 o 3)\n\nCome già accennato, l'installazione di Docker su Rasperry è un processo diventato molto semplice grazie al team di Docker. Questa procedura è stata testata dal sottoscritto su Raspberry Pi model 2 e 3 (compreso 3+). Purtroppo non funziona su Rasperry Pi Zero (almeno secondo la mie esperienza di qualche mese fa).\n\nIn particolare, per questo tutorial ho utilizzato il sistema operativo Raspbian Lite (potete scaricare l'ultima versione [questo link](https://www.raspberrypi.org/downloads/raspbian/)). La differenza rispetto a Raspbian originale consiste nel fatto che questa immagine non monta l'interfaccia grafica, ed è quindi una versione più _leggera_ (da qui il nome _lite_). La mia scelta deriva semplicemente dal fatto che, dovendo spesso lavorare con Robot o comunque dispositivi IoT che non hanno uno schermo, preferisco avere un OS alleggerito dall'interfaccia grafica. Nulla vieta di eseguire questo stesso tutorial su altre versioni di Raspbian o in generale su altri OS Linux compatibili.\n\n### Installazione di Docker\n\nPer installare docker, da terminale, basta eseguire il seguente comando:\n\n```bash\n$ curl -sSL https://get.docker.com | bash\n```\n\nIl quale esegue uno script che installa e configura docker sul vostro Raspberry Pi (si noti che lo stesso identico comando funziona anche su macchine standard Linux e su ogni macchina Linux compatibile con docker, non è quindi specifico del Raspberry Pi).\n\n![Get Docker](./getdocker.png)\n\nQuesto script impiega un po' di tempo per essere eseguito (state attenti che ad un certo punto potrebbe chiedere di inserire la password). Un volta concluso, lo script vi chiederà di eseguire un comando:\n\n```bash\n$ sudo usermod -aG docker pi\n```\n\n![Docker add user](./setgroup.png)\n\nQuesto farà si che il vostro utente possa accedere a Docker ed alle sue risorse senza digitare ogni volta il comando `sudo`.\n\n### Test dell'installazione\n\nUna volta eseguito il comando vi conviene riavviare il Rasperry Pi. Possiamo quindi testare la corretta installazione digitando il comando:\n\n```bash\n$ docker run -t hello-world\n```\n\nChe, se tutto è andato bene, mostrerà l'output come in figura.\n\n![Hello World Docker](./testhelloworld.png)\n\n### Installiamo Docker Compose\n\nA questo punto, possiamo procedere ad installa Docker compose, un tool (scritto in Python) molto utile per gestire macchine docker in modo semplice e veloce.\n\nPer installarlo, basta digitare il comando\n\n```bash\n$ sudo pip install docker-compose\n```\n\nChe richiede il comando pip. Nel caso non fosse installato sul vostro Raspberry Pi (raspbian lite non lo ha di default), basta usare il comando\n\n```bash\n$ sudo apt-get install python-pip\n```\n\n## Cross Build di Docker su computer Intel\n\nLa **Cross Compilazione** o **Cross Build** è un concetto un po' complesso, che provo a spiegare qui: l'idea è quella di creare un _eseguibile_ (o in questo caso un _container_) pensato per funzionare su un'architettura hardware diversa rispetto a quella in cui è viene eseguita il build. Nel nostro caso, in particolare, quello che ci interessa è creare container docker per Raspberry Pi (quindi architettura ARM) su un computer classico, solitamente dotato di architettura Intel.\n\nIl crossbuild è utile per due motivi:\n\n1. Quando la nostra macchina target è poco performante, e quindi un build diretto sarebbe enormemente lento. Il Raspberry Pi è una macchina che, specialmente nelle versioni 3 e 3+, ha ottenuto potenze di calcolo non indifferenti. Ciò non toglie che un computer consumer è comunque più veloce in questo tipo di processi:\n2. Quando (e questo è il motivo principale per cui preferisco preferisco fare il cross build) lavorare direttamente sulla macchina target è scomodo perchè non abbiamo a disposizione un buon ambiente di sviluppo.\n\nPrima di procedere, ricordiamoci che docker ha un metodo di build piramidale. Quando si vuole creare un nuovo container, solitamente quello che si fa è partire da un container già esistente che viene customizzato come descritto nel _Dockerfile_. Se vogliamo creare un container con target ARM, dobbiamo quindi partire da un container già creato per ARM.\n\n### Container per Architetture arm32v7\n\nFortunatamente, anche in questo caso ci vengono in aiuto gli ideatori e mantainer di Docker, che mettono a disposizione, parallelamente alle varie immaigni ufficiali docker, anche immagini per differenti architetture. Per accedere a queste immagini, basta anteporre il tag dell'architettura che ci interessa usare (ad esempio `arm32v7` nel caso del Raspberry PI) al nome dell'immagine da scaricare.\n\nSe, per esempio, ci interessa scaricare `ubuntu:16.04` per Raspberry Pi, useremo il nome `arm32v7/ubuntu:16.04`.\n\n### Cross Build di container per architettura arm32v7\n\n> Nota: Ho testato questa procedura sia su macOS che su Linux, non ho avuto modo di usarla sotto Windows, che comunque sconsiglio perchè notorialmente ha un bel po' di problemi nello sviluppo.\n\nUna volta ottenuta la nostra immagine di partenza, il prossimo passo è quella di poter lanciare il container sulla nostra macchina in emulazione. Per farlo, usiamo il progetto **qemu**, e per fortuna anche in questo caso docker ci fornisce dei tools per configurarlo al meglio.\n\nInfatti, tutto quello che serve per far gestire il sistema di cross compilazione è lanciare questo script una volta sul nostro computer:\n\n```bash\ndocker run --rm --privileged multiarch/qemu-user-static:register\n```\n\nFatta questa operazione, potremo utilizzare tutti i container che hanno registrato il file `qemu-*-static` per la loro architettura. Nella community docker sono già presenti un po' di container che hanno già fatto questa operazione (si veda il progetto [multiarch](https://hub.docker.com/u/multiarch/)). Ad esempio, non dovremmo avere problemi a lanciare il container `multiarch/ubuntu-core:armhf-wily`, come mostrato in figura\n\n![Docker run multiarch](./runmultiarch.png)\n\nPerò non funzionerà il container (o la classe di container) che ci interessa (`arm32v7/ubuntu:16.04`), che restituirà l'errore `standard_init_linux.go:178: exec user process caused \"no such file or directory\"` che essenzialmente indica che `qemu-arm-static` non è ancora stato registrato al suo interno.\n\n![Errore di Qemu nel docker](./qemuerror.png)\n\nQuesto non è un problema quando vi interessa solo usare un container linux base: in questo caso potete spulciare la libreria **multiarch** e trovere tantissimi container già pronti all'uso.\n\nDiventa un problema, invece, quando ci interessa utilizzare container basati su `arm32v7/ubuntu:16.04` (o simili), come ad esempio tutti i container ufficiali di ROS.\n\n### Registrare qemu nel vostro container\n\nLa registrazione di qemu nel container è un processo molto facile che va sempre eseguito all'inizio della fase di build di un container non ancora registrato. Una volta fatto, tutti i container costruiti su questo saranno automaticamente registrati, e non sarà necessario ripetere l'operazione.\n\nPer eseguire la procedura, quindi, dobbiamo creare un nuovo ambiente docker in cui eseguire il build della nostra nuova immagini. Creiamo una cartella `docker-img-rpi` e creiamo, al suo interno, il file `Dockerfile` in cui andremo a lavorare. Dobbiamo quindi utilizzare un file di qemu chiamato `qemu-arm-static`. Questo file si trova nel vostro computer (è uno dei file registrati dalla procedure fatta sopra), ma per semplicità potete scaricarlo [cliccando qui](https://github.com/HotBlackRobotics/ntbd/blob/devel/NTBD_base/qemu-arm-static?raw=true)\n\nScaricatelo e mettetelo nella cartella di lavoro. A questo punto, è anche necessario dargli i permessi di esecuzione con il comando:\n\n```bash\n$ chmod +x qemu-arm-static\n```\n\nAndiamo quindi a creare il `Dockerfile`:\n\n```Dockerfile\nFROM  arm32v7/ubuntu:16.04\nCOPY ./qemu-arm-static /usr/bin/qemu-arm-static\n```\n\nDove la prima riga `FROM arm32v7/ubuntu:16.04` dice di creare la nuova immagine a partire da `arm32v7/ubuntu:16.04`, mentre la seconda è quella che si occupa (effettivamente) di eseguire la registrazione.\n\nA questo punto, buildiamo il tutto e testiamo se tutto funziona:\n\n```bash\n$ docker build -t ubuntu-16:rpi3 .\n$ docker run -it ubuntu-16:rpi3\n```\n\nE come vedete, adesso l'immagine adesso viene eseguita correttamente.\n\n![Qemu registrato nel docker](./qemuregistered.png)\n\n## Build e Deploy con Docker Compose\n\nUna volta abilitata la fase di cross compilazione, non ci resta altro che trovare un modo per passare l'immagine dal nostro computer verso il raspberry in cui vogliamo che questa venga eseguita.\n\nOvviamente, ci sono diversi modi per farlo: il modo più semplice che ho trovato è quello di usare il progetto **dockehub** per condividere le immagini (utilissimo a meno che non volete creare delle immagini private) e **docker-compose** per il build e il deploy.\n\nCome avete visto se avete smanettato un po' con docker, la gestione da linea di comando di docker è un po' pesantuccia, ed ci troviamo spesso a dover scrivere comandi molto lunghi su shell. L'errore e i typos sono quindi un grosso problema che spesso ci costringono a riscrivere molte volte lo stesso comando. Docker-compose è un progetto che, sebbene porti tantissimi vantaggi nella gestione dei container, utilizzo spesso perchè semplifica enormemente la gestione da linea di comando di docker.\n\nVi ricordo che per installare docker-compose basta eseguire il comando:\n\n```bash\n$ sudo pip install docker-compose\n```\n\nIl concetto di questo tool è molto semplice: viene creato un nuovo file (chiamato `docker-compose.yml`) che contiene alcune informazioni del progetto docker che vogliamo creare (come il nome da dare all'immagine del container, la posizione dei Dockerfile, etc.), grazie a questo file, docker-compose semplifica le api dal shell di docker enormemente.\n\nVediamo quindi come creare un container che, in fase di lancio, eseguire un semplice script python di `hello-world` su archietettura ARM.\n\n### Costruiamo il Container Docker\n\nCreiamo una cartella `arm-docker-hello` e creiamo al suo interno i file `Dockerfile` e `docker-compose.yml`.\n\nCome visto su, scarichiamo il file `qemu-arm-static` e registriamo il file all'interno del nostro Dockerfile (se partite da un container già registrato, non è necessaria questa operazione). Inoltre, all'interno del Dockerfile, installiamo `python3` (sull'immagine `arm32v7/ubuntu:16.04`) non è installato di default:\n\n```\n# Dockerfile\n\n# ...\nRUN apt-get update\nRUN apt-get install python3 -y\n```\n\nQuindi, creiamo un file `hello.py` con il seguente contenuto:\n\n```python\n#!/usr/bin/env python3\n\nprint('Hello from Docker')\n```\n\nDiamogli i permessi di esecuzione:\n\n```bash\nchmod +x hello.py\n```\n\ne copiamo all'interno della del container.\n\nPer finire, utilizzamo l'istruzione `CMD` per dire a Docker di eseguire direttamente il file `/hello.py` quando viene chiamato con `run` (comando di default se nessun comando è specificato):\n\n```\n# Dockerfile\n\n# ...\n\nCOPY ./hello.py /hello.py\nCMD [\"/hello.py\"]\n```\n\nIl file `Dockerfile` è quindi\n\n```\n# Dockerfile\n\nFROM  arm32v7/ubuntu:16.04\nCOPY ./qemu-arm-static /usr/bin/qemu-arm-static\n\nRUN apt-get update\nRUN apt-get install python3 -y\n\nCOPY ./hello.py /hello.py\nCMD [\"/hello.py\"]\n```\n\n### Utilizzo di Docker-Compose\n\nSiamo pronti ad usare docker compose per buildare ed eseguire il container. Creiamo un nuovo file chiamato `docker-compose.yml` ed inseriamo il seguente codice all'interno:\n\n```\nversion: '3'\n\nservices:\n  arm-ubuntu:\n    build: .\n```\n\nQueste poche linee dicono che noi vogliamo creare un'immagine (in docker-compose sono chiamati **servizi**) che chiamiamo `arm-ubuntu` (attenzione, questo non è un tag docker, come vedremo dopo, ma solo un nome arbistrario che noi stiamo dando).\nDiamo anche informazioni a docker-compose che il `Dockerfile` per eseguire il build del container si trova nella cartella corrente (da qui `build: .`).\n\nA questo punto, possiamo eseguire il build con il comando\n\n```bash\ndocker-compose build arm-ubuntu\n```\n\ne, una volta conclusa questa fase, lanciare il container con il comando\n\n```bash\ndocker-compose run arm-ubuntu\n```\n\nSe poi vogliamo eseguire un comando diverso al nostro container, basta specificare questo comando, proprio come con docker. Ad esempio, per aprire la bash, digitiamo\n\n```bash\ndocker-compose run arm-ubuntu bash\n```\n\n![Docker Compose per compilare ed eseguire](./composerpi.png)\n\nCome potete vedere, a parte uno strano errore da qemu (`qemu: Unsupported syscall: 384`) l'immagine viene eseguita perfettamente. L'errore è dovuto al fatto che siamo comunque in un ambiente di emulazione.\n\n### Desploy sul Raspberry Pi con DockerHub\n\nFinita la fase di build e test del container, non ci resta che inviarlo al nostro Raspberry Pi.\nPer farlo, utilizziamo il progetto Dockerhub, che permette di condividere le vostre immagini tramite internet.\n\nPer prima cosa, se non lo avete già fatto, dovete iscrivervi in modo da avere un accesso ed un nome utente. Per farlo, basta accedere al sito [https://hub.docker.com/](https://hub.docker.com/) e seguire le istruzioni per creare un account. Prendete nota del vostro username (il mio è `ludusrusso`).\n\nUna volta loggati, dobbiamo creare una nuova repository cliccando sul tasto in alto a sinistra.\n\n![Dockerhub pagina iniziale](./dockerhub-main.png)\n\nDiamo un nome ed una descrizione alla nostra immagine, e quindi clicchiamo sul tasto `create`.\n\n![Dockerhub creare immagine](./dockerhub-create.png)\n\nA questo punto, otterremo un tag della nostra immagine (che ha la forma `<nome utente>/<nome immagine>`) che dovremmo usare per fare il deploy ed il download. Nel mio caso è `ludusrusso/arm-docker-hello`.\n\n![Dockerhub nuova immagine creata](./dockerhub-image.png)\n\nOra torniamo nel nostro terminale, per prima cosa dobbiamo loggarci su docker hub, per farlo, basta digitare il comando `docker login` su shell ed inserire nome utente e password.\n\n![Dockerhub Login](./dockerhub-login.png)\n\nOra, dobbiamo taggare la nostra immagine con il tag ottenuto da dockerhub. Per farlo, aggiungiamo la riga\n\n```\nimage: <tag immagine da dockerhub>\n```\n\ndentro il file `docker-compose-yml`. Che nel mio caso, diventa:\n\n```\nversion: '3'\n\nservices:\n  arm-ubuntu:\n    image: ludusrusso/arm-docker-hello\n    build: .\n```\n\nPer finire, buildiamo nuovamente l'immagine (in modo da inserire il tag all'interno di questa), e quindi eseguiamo il comando\n\n```bash\n$ docker-compose push\n```\n\n![Dockerhub Deploy](./dockerhub-deploy.png)\n\nQuesto effettuerà il deploy su dockerhub. Una volta finita al procedura (che potrà durare anche molto in base alla velocità della connessione internet), finalmente la nostra immagine sarà scaricabile da internet.\n\nA questo punto, non ci resta che accedere al nostro Raspberry Pi e verificare che tutto funzioni per il meglio. Per farlo, semplicemente eseguiamo l'immagine da docker (per ora non serve usare docker-compose) con il comando:\n\n```bash\n$ docker run <tag immagine da dockerhub>\n```\n\nCome vedrete, docker si accorge che l'immagine non esise in locale sul Raspberry e la scarica in automatico prima di eseguirla.\n\n![Dockerhub Download](./dockerhub-download.png)\n![Dockerhub Run](./dockerhub-run.png)\n\n## Conclusioni\n\nSi conclude qui questo tutorial, che sarà poi alla base del prossimo video (a breve sul mio canale YouTube) in cui vedremo come configurare un nuovo Raspberry Pi e usare Docker con ROS per iniziare a svilupparci delle applicazioni un po' più complesse.\n\nNell'attesa chiedo, come al soluto, quali sono le vostre impressioni in merito e cosa pensate di fare con questa tecnologia!\n\n## Update Agosto 2020\n\nNell'ultimo anno le cose si sono molto semplificate. In particolare Docker sta lavorando all'integrazione di immagini multi architettura che semplificano notevolmente quanto spiegato soprato.\n\nHo realizzato un video dove la nuova funzionalità viene descritta!\n\n<iframe width=\"100%\" height=\"400px\" src=\"https://www.youtube-nocookie.com/embed/bY3X3Sc5s9A\" frameborder=\"0\" allowfullscreen></iframe>\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-06-29-docker-raspberrypi/index.md",
    frontMatter: {
      path: "/2018/06/29/docker-raspberrypi/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "12 mins",
      published: "2018-06-29T00:00:00.000Z",
      publishedReadable: "29 Giu 2018",
      featured: false,
      tags: [
        "Docker",
        "Embedded Linux",
        "Raspberry",
        "Robot Open Source",
        "ROS",
      ],
      title: "Buildare e usare container Docker per Raspberry Pi",
      description:
        "In questa guida vediamo come buildare ed utilizzare Docker su Raspberry Pi (ed in generale sistemi Linux Embedded) per velocizzare la produzione di applicazioni Linux Embedded",
      href: "/2018/06/29/docker-raspberrypi/",
      image: "/content/blog/it/2018-06-29-docker-raspberrypi/main.jpg",
      imagePath: "/content/blog/it/2018-06-29-docker-raspberrypi",
    },
  },
  {
    content:
      '\nCiao! In questo (primo) tutorial vi spiegherò come interfacciare ROS con Dobot e scrivere una semplice applicazione per disegnare. Un grazie speciale va all\'azienda [Alumotion](http://www.alumotion.eu/), distributore italiano di Dobot, che ci ha donato il robot per progetti di ricerca e sviluppo su ROS (no no non li ho assolutamente messo pressione data la mia passione per la fabbricazione digitale :P ).\n\nPrima vediamo a grandi linee cos\'è, e perchè mi piace un sacco!\n\n![](./rosdobot.jpg)\n\n## Dobot\n\nDobot è un braccio robotico multifunzione prodotto dall\'azienda cinese Shenzhen Yuejiang Technology Co. L\'azienda naque nel 2015 a seguito di una campagna Kickstarter di grande successo (raccolsero più di 650 mila dollari). Da allora hanno già prodotto 5 modelli di robot diversi.\n\n<YouTube videoId="ggT4hz5tM_0" frameborder="0" allow="autoplay; encrypted-media" />\n\nDobot è un prodotto nato per l\'education concepito sia per chi vuole muovere i primi passi nel coding fino ad arrivare anche ai più esperti. Non richiede alcun assemblaggio da parte dell\'utente e nel kit ci sono un sacco di accessori per offrire funzionalità divertenti e che richiedono una precisione non banale come ad esempio: disegnare su carta, incidere al laser, stampare in 3D, posizionare piccoli oggetti. Si può programmare in Blockly (simil Scratch), in Python e da ora grazie al mio fantastico tutorial anche in ROS!\n\nTutto ciò ad un prezzo imbattibile (attorno ai 1500 Euro). Se volete altre informazioni vi consiglio di dare un\'occhiata [qui](http://www.dobot.it/prodotti/dobot-magician/). Personalmente credo che sia un braccio molto divertente, anche con solo 4 assi si possono fare delle cose carine. La cosa che mi ha stupito di più è che con un costo così basso si possano fare veramente, ed in modo davvero semplice, delle applicazioni che richiedono un minimo di precisione (disegnare). Per contro però devo dire che la community open source è gestita molto male e ci sono tantissimi problemi sia nel software che nella documentazione (inesistente).\n\n# ROS e Dobot: iniziamo\n\nCosa ti serve:\n\n- un computer con installato Ubuntu e ROS (io uso Kinetic su una VirtualBox Ubuntu da Mac)\n- un Dobot ;)\n\nPrima testiamo se funziona correttamente il robot e comunica via USB col computer.\nApri un terminale e controlla i dispositivi connessi alle USB con i comandi `lsusb ` e `ls /dev/tty*`.\n\n![](./terminal1.png)\n\nPoi inserisci nella presa USB il cavo di Dobot (acceso) e, se non hai problemi di driver, dovresti vedere QinHeng Electronics HL-340 USB-Serial adapter ed un nuovo device, nel mio caso /dev/ttyUSB0 digitando gli stessi comandi.\n\n![lsusb](./terminal2.png)\n\nOra installiamo il software _cutecom_ con ` sudo apt-get install cutecom` per testare il protocollo in seriale. Eseguilo da administratore con `sudo cutecom` . (questo è opzionale ma se non funzionasse ti aiuta a testare bene il protocollo di comunicazione)\n\n![cutecom](./cutecom.png)\n\nImposta in “Device” la porta USB corretta (nel mio caso è /dev/ttyUSB0) flagga “Hex Output” e seleziona nel menù a tendina in fondo “Hex Input”. Ora Premi su “Open Device” , se hai problemi potrebbe essere un problema di diritti sulla porta. Allora digita `sudo chmod 777 /dev/ttyUSB0` .\nOra digita nella casella di "input" `aa aa 02 14 00 ec ` a cui dovrebbe rispondere una stringa esadecimale e poi manda ancora `aa aa 03 1f 00 00 e1`, dovresti veder il DoBot muoversi!\n\nOk ora iniziamo ad usare veramente **ROS**!\nScarichiamo il pacchetto ROS Demo for DoBot Magician dal mio repository personale [qui](https://github.com/sgabello1/ros-dobot/tree/master). In realtà è quasi lo stesso del [sito ufficiale](https://www.dobot.cc/downloadcenter/dobot-magician.html?sub_cat=72#sub-download) però nel mio caso ci ha messo un sacco di tempo a scaricare e poi ho aggiunto due script per l\'applicazione finale.\n\nCrea un workspace in ROS (se non sai farlo è spiegato [qui](http://wiki.ros.org/catkin/Tutorials/create_a_workspace)). Copia il mio pacchetto in `catkin/src ` e compila con ` catkin_make` .\nOra fai partire\n\n`roscore`\n\nin un altro terminale (questo vale se la tua porta è ovviamente /dev/ttyUSB0)\n\n`rosrun dobot DobotServer /dev/ttyUSB0`\n\nin un altro terminale ancora il nodo che ho scritto\n\n`rosrun dobot DobotClient_topic `\n\ned infine in un altro terminale ancora un semplice nodo che pubblica solo i punti che dovrà seguire il Dobot.\n\n`rosrun dobot talker`\n\nE come risultato finale avremo questa fantastica spirale!\n\n<YouTube videoId="eXZgVXh3Phg" />\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-06-29- Dobot - ROS/index.md",
    frontMatter: {
      path: "/hbr/usare-il-braccio-robotico-dobot-con-ros/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "4 mins",
      published: "2018-06-29T00:00:00.000Z",
      publishedReadable: "29 Giu 2018",
      featured: false,
      tags: [],
      title: "Usare il braccio robotico Dobot con ROS",
      description: "Come usare il braccio robotico con Robot Operating System",
      href: "/hbr/usare-il-braccio-robotico-dobot-con-ros/",
      image: "/content/hbr/2018-06-29- Dobot - ROS/rosdobot.jpg",
      imagePath: "/content/hbr/2018-06-29- Dobot - ROS",
    },
  },
  {
    content:
      '\nLa **robotica di servizio** è il campo della robotica che sta entrando in modo sempre più forte nella nostra vita quotidiana.\n\nLa robotica di servizio studia e sviluppa robot in grado di muoversi, lavorare ed interagire con il mondo degli essere umani. È quindi la robotica che esce dalle fabbriche ed entra nella vita quotidiana di tutti noi.\n\nChe lo vogliamo o no, **la robotica sarà sempre più presente nei prossimi anni nel nostro posto di lavoro, nelle nostre case e in tutti gli ambienti in cui viviamo quotidianamente**. Dobbiamo quindi essere preparati al suo arrivo in modo attivo e partecipe, e non dobbiamo vederla come una minaccia alla nostra quotidianità.\n\nPer questo motivo, ho deciso di aprire una nuova rubrica su questo blog, in cui parlerò in modo semplice, e meno tecnico, di questo affascinante campo che rivoluzionerà la nostra vita. L\'intento è far capire come funziona questa tecnologia, quali sono i suoi punti di forza e quali i suoi limiti, e come varie aziende e startup in tutto il mondo si stanno preparando per accoglierla.\n\nIn questa rubrica, quindi, andremo ad affrontare le sfide tecnologiche, sociali, etiche e legali di questo mondo! Se vi interessa, cliccate sul pulsante in alto, oppure potete accedere alla rubrica [direttamente da qui](/robotica/).\n\n<a href="/robotica/" role="button" class="btn" > Accedi alla rubrica!</a>\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-06-11-pillole-robotica-servizio/index.md",
    frontMatter: {
      path: "/2018/06/11/pillole-robotica-servizio/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2018-06-11T00:00:00.000Z",
      publishedReadable: "11 Giu 2018",
      featured: false,
      tags: ["Robotica", "Robotica di Servizio", "Pillole di Robotica"],
      title: "Robotica di Servizio in Pillole",
      description:
        "Nasce una nuova rubrica sul mio blog, in cui cercherò di spiegare in modo semplice il mondo della robotica di servizio",
      href: "/2018/06/11/pillole-robotica-servizio/",
      image: "/content/blog/it/2018-06-11-pillole-robotica-servizio/main.jpg",
      imagePath: "/content/blog/it/2018-06-11-pillole-robotica-servizio",
    },
  },
  {
    content:
      "\nIn un [precedente Articolo](/2018/04/06/google-text-to-speech-per-generare-file-audio/) ho utilizzato le API messe a disposizione da Google per la sintesi vocale. In particolare, in quell'articolo abbiamo visto come usare gTTS per\ngenerare file vocali a partire da una stringa di testo.\n\nIn questo articolo, vediamo come utilizzare questa funzionalità per fare in modo che sia un bot Telegram ad\ninviare, tramite messaggio vocale, l'output delle API gTTS.\n\n## Configurare il tutto\n\nOrmai non vi sto a tediare sulla fase di configurazione. Ricordiamoci però di creare un ambiente virutale (in Python 3) e di installare i pacchetti `Telepot` e `gTTS`, come visto nei miei precedenti tutorial.\n\nPrima di cominciare, però, vi propongo una _best practice_ molto veloce per configurare il bot telegram (ed in particolare il Token), di cui non vi ho mai parlato ma che sto utilizzando molto.\n\nCreiamo, per inizializzare il bot, due file: `bot.py` che conterrà il nostro bot vero e proprio ed un file `config.py`, in cui andremo ad inserire tutte le informazioni di configurazione (nel caso di bot semplici, solo il TOKEN), in modo\nche queste siano facilmente reperibili.\n\nIl file di configurazione, quindi, avrà la seguente forma:\n\n```python\n\n# config.py\n\nTOKEN = \"*** inserisci il tuo token qui ***\"\n```\n\nA questo punto, nel bot principale, non dovremo far altro che importare `config` e usare `config.TOKEN`.\nQuesto semplifica di tanto la vita nel momento in cui il progetto diventa grande e servono altre variabili di configurazione, o quando volete tenere lo scheletro del vostro progetto ed utilizzarlo con diversi TOKEN.\n\n## Primo test: messaggio vocale statico\n\nPer prima cosa, implementiamo un semplice bot che sia in grado di inviare, come messaggio vocale, un file audio generato precedentemente da noi, come visto nel tutorial precedente. Nel mio caso, utilizzerò il file `saluti.mp3`.\n\nSpostiamo il file nella stessa cartella in cui si trova il robot. A questo punto, possiamo utilizzare il metodo `.sendVoice()` che `telepot` mette a disposizione, la cui funzione è molto simile al classico `.sendMessage()`, con l'unica differenza che il primo prende in ingresso un oggetto di tipo file invece che un stringa, ed invia un messaggio vocale con il contenuto di questo file.\n\nPer utilizzarlo, andiamo ad implementare un semplicissimo bot (riprendo l'esempio del mio [primo articolo sul tema](https://ludusrusso.cc/2017/04/27/implementiamo-un-bot-telegram-con-python/)), come di seguito:\n\n```python\n# file bot.py\n\nimport config\nimport telepot\nimport io\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n        bot.sendMessage(chat_id, 'Ma so mandare messaggi vocali!')\n        with open('saluti.mp3', 'rb') as file:\n            bot.sendVoice(chat_id, file)\n\n\nbot = telepot.Bot(config.TOKEN)\nbot.message_loop(on_chat_message)\n\nimport time\nwhile True:\n    time.sleep(10)\n```\n\nIn particolare, le linee di codice che contengono novità sono queste:\n\n```python\n# file bot.py\n\n# ...\ndef on_chat_message(msg):\n        # ...\n        with open('saluti.mp3', 'rb') as file:\n            bot.sendVoice(chat_id, file)\n\n# ...\n```\n\nQueste due linee aprono il file `saluti.mp3` e lo caricano il lettura nell'oggetto `file`, che poi viene inviato tramite\n`bot.sendVoice(chat_id, file)` all'utente.\n\nIl risultato è mostrato in figura:\n\n![Pirmo Messaggio Vocale](./simplemsg.png)\n\n## Generare messaggi dinamicamente\n\nA questo punto, non ci resta che generare messaggi vocali in modo dinamico, per rendere più interattivo il robot.\nPer farlo, dobbiamo sfruttare la libraria `gTTS` come [visto qui](/2018/04/06/google-text-to-speech-per-generare-file-audio/).\n\nIl modo più semplice per farlo è il seguente:\n\n1. Generare un file audio e salvarlo su disco,\n2. Leggere il file da disco ed inviarlo tramite `.sendVoice()`\n\nTuttavia in questo caso abbiamo un overhead non indifferente per la lettura e consequenziale scrittura su disco,\ninoltre, nel caso il bot venga lanciato in modalità multithread per la gestione di molti utenti, la gestione contemporanea di due (o più) utenti potrebbe creare problemi, in quanto andrebbero a scrivere contemporaneamente sullo stesso file.\nPer questo motivo, la soluzione migliore è quello di gestire il tutto in RAM.\n\nHo già discusso questo problema in alcuni miei precedenti posto:\n\n1. Nel post [Sviluppiamo un bot Telegram che legge i codici a barre degli alimenti](https://ludusrusso.cc/2018/01/31/telegram-opencv-barcode/) ho discusso il problema inverso (che si risolve allo stesso modo), in cui l'utente invia un file (in quel caso un'immagine) al bot, e questo deve processare l'immagine senza salvarla su disco.\n2. Nel mio posto [Implementiamo un bot Telegram in Python per leggere e creare QRCode](http://www.allafinedelpalo.it/implementiamo-un-bot-telegram-in-python-per-leggere-e-creare-qrcode/) ospitato nel blog **Alla Fine del Palo**, ho discusso di un problema simile per la creazione e l'invio di immagini da parte del bot verso l'utente.\n\nLa soluzione, come già visto, è sfruttare la libraria `io` di Python3, ed in particolare l'oggetto `BytesIO`, che non fa altro che emulare un file gestito completamente in memoria RAM, quindi come una normale variabile.\n\nPer farlo, implementiamo una funzione in grado di creare un file audio e salvarlo dentro una variabiale di tipo BytesIO:\n\n```python\n# ...\nimport io\nfrom gtts import gTTS\n\ndef generate_vocal_msg(text):\n    tts = gTTS(text=text, lang=\"it\")\n    vocal_file = io.BytesIO()\n    tts.write_to_fp(vocal_file)\n    vocal_file.seek(0)\n    return vocal_file\n\n# ...\n```\n\nCome vedete, questa funzione prende una stringa `text` e la converte in voce sintetizzata tramite la libraria `gtts`.\nLa novità è che, una volta ottenuto l'oggetto `tts`, sfruttiamo il [metodo `write_to_fp`](http://gtts.readthedocs.io/en/latest/module.html) per salvare i dati all'interno di un oggetto di tipo file. Questo oggetto è `vocal_file`, che è proprio un simil-file creato da `io.BytesIO`.\n\nPer ultimo, è nessario \"riavvolgere\" l'oggetto `vocal_file` create tramite il metodo `vocal_file.seek(0)`, in questo modo, chi lo leggerà lo vedrà dall'inizio, come se fosse stato appena aperto.\n\nA questo punto, possiamo utilizzare la funzione `generate_vocal_msg` per generare dinamicamente il nostro messaggio vocale. Nel semplice esempio di seguito, converto in vocale il messaggio che arriva dall'utente:\n\n```python\n# ...\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n        bot.sendMessage(chat_id, 'Ma so mandare messaggi vocali!')\n        bot.sendMessage(chat_id, 'Ecco, ti leggo cosa hai scritto:')\n        bot.sendVoice(chat_id, generate_vocal_msg(msg['text']))\n\n# ...\n```\n\nProviamo quindi il bot, vedrete che sarà in grado di \"leggere\" quello che gli scrivete! Provare per credere!!\n\n![Invio messaggio dinamicamente](./msgdinamico.png)\n\n## Conclusioni\n\nCome pensate possa essere utilizzata in modo utile questa capacità dei bot di generare messaggi vocali? Ditemelo nei commenti.\n\nIntanto, trovate sotto il codice completo che ho sviluppato!\n\n```python\n# file bot.py\n\nimport config\n\nimport telepot\nimport io\nfrom gtts import gTTS\n\n\ndef generate_vocal_msg(text):\n    vocal_file = io.BytesIO()\n    tts = gTTS(text=text, lang=\"it\")\n    tts.write_to_fp(vocal_file)\n    vocal_file.seek(0)\n    return vocal_file\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n        bot.sendMessage(chat_id, 'Ma so mandare messaggi vocali!')\n        bot.sendMessage(chat_id, 'Ecco, ti leggo cosa hai scritto:')\n        bot.sendVoice(chat_id, generate_vocal_msg(msg['text']))\n\n\nbot = telepot.Bot(config.TOKEN)\nbot.message_loop(on_chat_message)\n\nimport time\nwhile True:\n    time.sleep(10)\n```\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-05-17-bot-messaggi-vocali/index.md",
    frontMatter: {
      path: "/2018/05/17/bot-messaggi-vocali/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2018-05-17T00:00:00.000Z",
      publishedReadable: "17 Mag 2018",
      featured: false,
      tags: ["Python", "gtts", "text to speech", "Telegram", "Telepot"],
      title:
        "I chatbot possono Parlare? Sviluppiamo un bot telegram che manda messaggi vocali",
      description:
        "Usiamo le API di sintesi vocale di google per creare un bot in grado di mandare messaggi vocali",
      href: "/2018/05/17/bot-messaggi-vocali/",
      image: "/content/blog/it/2018-05-17-bot-messaggi-vocali/main.jpg",
      imagePath: "/content/blog/it/2018-05-17-bot-messaggi-vocali",
    },
  },
  {
    content:
      "\nAvete mai voluto controllare la voce del navigatore di google maps? Sapete che google vi permette\ndi sfruttare le sue API per la generazione di voce sintetica usando le GTTS (Google Text to Speech)?\nOra che lo sapete, vediamo come fruttare la libreria gtts in Python per generare file audio dal testo.\n\ngtts è una semplice libreria Python che wrappa le API web omonime, in grado di generare una traccia audio da una stringa di test.\n\n## Un piccolo esempio con gtts!\n\nPer installarlo, basta utilizzare il comando:\n\n```\n(env)$ pip install gtts\n```\n\ned anche l'utilizzo è molto banale: ecco sotto un semplicissimo programma che ho utilizzato per\ngenerare un file audio contente la stringa _\"un saluto da Ludovico!\"_:\n\n```python\nfrom gtts import gTTS\n\nTEXT = \"Un saluto da Ludovico!\"\n\ntts = gTTS(text=TEXT, lang=\"it\")\ntts.save(\"saluti.mp3\")\n```\n\nNon credo serva nemmeno spegare il codice, che è di una banalità assoluta!\nUna volta lanciato il programma, troverete un file nella cartella di lavoro chiamato `saluti.mp3`.\nEcco cosa viene fuori!\n\n<audio controls>\n  <source src=\"/assets/audio/saluti.mp3\" type=\"audio/ogg\" />\n  Il tuo browser non supporta gli elementi audio\n</audio>\n\n## Lingue e velocità\n\nLa libreria è veramente base e semplice da utilizzare! Quando creiamo la traccia, dobbiamo scegliere la lingua e la velocità di lettura.\n\nLa velocità di lettura può essere scelta tra _normale_ e _lenta_. La velocità _normale_ è quella di default, per generare un test con velocità di lettura lenta, basta aggiungere l'opzione `slow=True`, come nell'esempio sotto:\n\n```\ntts = gTTS(text=TEXT, lang=\"it\", slow=True)\n```\n\nChe genera questa traccia audio:\n\n<audio controls>\n  <source src=\"/assets/audio/saluti_lento.mp3\" type=\"audio/ogg\" />\n  Il tuo browser non supporta gli elementi audio\n</audio>\n\nPer la lingua, abbiamo un'ampia scelta: ecco tutte le lingue supportate\n\n```\n'af' : 'Afrikaans'\n'sq' : 'Albanian'\n'ar' : 'Arabic'\n'hy' : 'Armenian'\n'bn' : 'Bengali'\n'ca' : 'Catalan'\n'zh' : 'Chinese'\n'zh-cn' : 'Chinese (Mandarin/China)'\n'zh-tw' : 'Chinese (Mandarin/Taiwan)'\n'zh-yue' : 'Chinese (Cantonese)'\n'hr' : 'Croatian'\n'cs' : 'Czech'\n'da' : 'Danish'\n'nl' : 'Dutch'\n'en' : 'English'\n'en-au' : 'English (Australia)'\n'en-uk' : 'English (United Kingdom)'\n'en-us' : 'English (United States)'\n'eo' : 'Esperanto'\n'fi' : 'Finnish'\n'fr' : 'French'\n'de' : 'German'\n'el' : 'Greek'\n'hi' : 'Hindi'\n'hu' : 'Hungarian'\n'is' : 'Icelandic'\n'id' : 'Indonesian'\n'it' : 'Italian'\n'ja' : 'Japanese'\n'km' : 'Khmer (Cambodian)'\n'ko' : 'Korean'\n'la' : 'Latin'\n'lv' : 'Latvian'\n'mk' : 'Macedonian'\n'no' : 'Norwegian'\n'pl' : 'Polish'\n'pt' : 'Portuguese'\n'ro' : 'Romanian'\n'ru' : 'Russian'\n'sr' : 'Serbian'\n'si' : 'Sinhala'\n'sk' : 'Slovak'\n'es' : 'Spanish'\n'es-es' : 'Spanish (Spain)'\n'es-us' : 'Spanish (United States)'\n'sw' : 'Swahili'\n'sv' : 'Swedish'\n'ta' : 'Tamil'\n'th' : 'Thai'\n'tr' : 'Turkish'\n'uk' : 'Ukrainian'\n'vi' : 'Vietnamese'\n'cy' : 'Welsh'\n```\n\nProviamo ad esempio a generare un file in inglese:\n\n```\ntts = gTTS(text=\"Hello from Ludovico!\", lang=\"en\")\n```\n\n<audio controls>\n  <source src=\"/assets/audio/saluti_en.mp3\" type=\"audio/ogg\" />\n  Il tuo browser non supporta gli elementi audio\n</audio>\n\n## Conclusioni\n\nChe ne pensate di questa libreria? Come credete possa essere utilizzata in modo utile nei vostri progetti?\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-04-06-google-text-to-speech-per-generare-file-audio/index.md",
    frontMatter: {
      path: "/2018/04/06/google-text-to-speech-per-generare-file-audio/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2018-04-06T00:00:00.000Z",
      publishedReadable: "6 Apr 2018",
      featured: false,
      tags: ["Python", "gtts", "text to speech"],
      title:
        "Parliamo come GMaps: come creare file audio con gtts (Google Text to Speech) in Python",
      description:
        "gtts è una libreria in Python per sfruttare le API di Google Text to Speech per generare file audio dal testo",
      href: "/2018/04/06/google-text-to-speech-per-generare-file-audio/",
      image:
        "/content/blog/it/2018-04-06-google-text-to-speech-per-generare-file-audio/main.jpg",
      imagePath:
        "/content/blog/it/2018-04-06-google-text-to-speech-per-generare-file-audio",
    },
  },
  {
    content:
      "\nLe UI da terminale sono molto retrò, ma è sempre divertente sviluppare programmi che le utilizzano, e possono\nessere molto utili su progetti da adottare su un Raspberry Pi.\n\nIn questa guida, vi voglio introdurre alla libreria Python [`Asciimatics`](https://github.com/peterbrittain/asciimatics), un tool open source e multipiattaforma che sviluppare UI per terminale in modo semplice e veloce!\n\n## Primi test con la libreria\n\nPer prima cosa, installiamo la libreria, meglio se all'interno di un [ambiente virtuale](), con il comando\n\n```bash\n(env) pip install asciimatics\n```\n\nQuesto è abbastanza per utilizzare la libreria! Andiamo ad implementare ora un semplice esempio per vedere come funziona sviluppando uno screen automatico che gira su terminale.\n\nPrendendo spunto dal un esempio di test, ho realizzato questo semplice programma\n\n```python\nfrom asciimatics.effects import Cycle, Stars\nfrom asciimatics.renderers import FigletText\nfrom asciimatics.scene import Scene\nfrom asciimatics.screen import Screen\n\ndef demo(screen):\n    effects = [\n        Cycle(\n            screen,\n            FigletText(\"ludusrusso.cc\", font='big'),\n            int(screen.height / 2 - 8)),\n        Cycle(\n            screen,\n            FigletText(\"Impara asciimatics!\", font='small'),\n            int(screen.height / 2 + 3)),\n        Stars(screen, 500)\n    ]\n    screen.play([Scene(effects, 500)])\n\nScreen.wrapper(demo)\n```\n\nChe, una volta lanciato, genera questa bellissima animazione\n\n![Primo esempio](./1.gif)\n\nIl codice è anche molto semplice.\nPer prima cosa, creiamo una funzione `demo` che prende un oggetto chiamato `screen`. Questa funzione\nsi occuperà di renderizzare la nostra schermata, tramite la sua ultima riga: `screen.play([Scene(effects, 500)])`.\n\n`effects` non è altro che un vettore contenente i vari **effetti** che vogliamo aggiungere al nostro screen. In questo caso ne ho inseriti tre:\n\n- Il primo e il secondo sono un effetto `Cycle`, che non fa altro che ciclare il colore del testo che gli viene passato. Si noti che con `FigletText` possiamo utilizzare diversi [fliglet font](http://www.figlet.org/)! Fate un po' di prove.\n- Il terzo effetto è `Stars`, che non fa altro che disegnare `500` (o il numero che volete voi) stelle luccicanti sullo sfondo!\n\nPer finire, basta passare la funzione a `Screen.wrapper` per lanciare l'applicazione!\n\n## Conclusioni\n\nLa libreria è davvero divertente, e si possono anche fare alcune cose interessanti!\nVoi avete idee o suggermenti in che modo poterla usare? Se si, scrivetela nei commenti qui sotto!!\n\n## Aiutatemi\n\nVi chiedo un piccolo aiuto da parte di voi lettori: infatti, ho sempre meno tempo per mantere e migliorare questo blog, che al momento faccio senza nessuna retribuzione, e quindi nel tempo libero nel weekend.\nVi chiedo perciò di fare alcune, per aiutarmi a far crescere il blog per permettermi di dedicarci sempre più tempo:\n\n1. Iscrivetevi alla newsletter (trovate form nel footer di questo blog),\n2. Lasciate dei commenti sotto questo post (e sotto i vari post che ritenete utili). Vorrei sapere da voi come credete possa migliorare il blog, e se avete idee per futuri articoli o qualcosa che vorreste approndire, **questo è uno dei migliori modi con cui potete aiutarmi**!\n3. Mettete un Like alla mia [pagina facebook](https://www.facebook.com/ludusrusso.cc), aggiungetemi [su linkedin](https://www.linkedin.com/in/ludusrusso/) e seguitemi su [twitter](https://twitter.com/ludusrusso) e [github](https://github.com/ludusrusso).\n4. Condividete i miei post!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-04-04-python-scrivere-terminal-gui/index.md",
    frontMatter: {
      path: "/2018/04/04/python-scrivere-terminal-gui/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2018-04-04T00:00:00.000Z",
      publishedReadable: "4 Apr 2018",
      featured: false,
      tags: ["Python", "Asciimatics", "Terminal UI"],
      title: "Divertiamoci sviluppando UI da terminale con ASCIIMATICS",
      description:
        "Le UI da terminale fanno molto anni '80, però sono sempre diventerti da implementare. Oggi vi voglio introdurre ad una semplice libreria per creare questo tipo di applicazione.",
      href: "/2018/04/04/python-scrivere-terminal-gui/",
      image:
        "/content/blog/it/2018-04-04-python-scrivere-terminal-gui/main.png",
      imagePath: "/content/blog/it/2018-04-04-python-scrivere-terminal-gui",
    },
  },
  {
    content:
      "\nCiao a tutti, riprendo e concludo con questa terza parte la mia guida su come sviluppare API rest usando Flask e la filosofia di sviluppo TDD.\n\nNella [prima parte](/2017/10/04/tdd-flask-pytest-1/) ci siamo soffermati su sul setup dell'applicazione e lo sviluppo\ndei test, mentre nella [seconda parte](/2018/01/25/tdd-flask-pytest-2/) abbiamo visto come creare un semplice endpoint\ndi login in grado di generare un token JWT (JSON Web Token) univoco e crittograficamente firmato dal server.\n\nIn quest'ultima parte ci soffermeremo su come sfruttare il Token generato per autenticarsi all'interno di un endpoint protetto.\n\n## Sviluppo di un endpoint protetto `/protected` sfruttando JWT\n\nCome al solito, partiamo dai test. In questo caso vogliamo prima di tutto testare\nche l'endpoint `/protected` funzioni, e cioè che restituisca\n\n1. `401` (Unauthorized) se l'utente accede alla risorsa senza autenticarsi o con autenticazione errata\n2. `200` se l'utente è correttamente autenticato.\n\nPer autenticare una chiamata REST, sfrutteremo il campo `Authorization`,\ned in particolare lo setteremo a `Bearer <TOKEN>`, dove all'interno di `<TOKEN>` inseriremo\nil token con cui vogliamo autenticarci. Se ad esempio il token fosse `12345`, dovremmo inviare\nuna richiesta HTTP contenente nell'Header il seguente campo:\n\n```\nAuthorization: Bearer 12345\n```\n\nPer onore di cronata, **Bearer** sta per **portatore**, in questo modo diciamo al server \"Per favore, dai l'accesso al portatore di questo token\".\n\n### Iniziamo ad implementare i test\n\nIn pieno stile TTD, partiamo a scrivere un test e poi iniziamo subito a sviluppare il codice.\nIl primo test da implementare deve testare che l'accesso senza token all'endpoint `/protected`\nritorni `401`. Per farlo, il codice (da aggiungere al file `tests.py`) è molto banale:\n\n```python\n\n# tests.py\n\n# ...\n\ndef test_unauthorized_request_to_protected(client, app):\n    res = client.get('/protected')\n    assert res.status_code == 401\n```\n\nLanciando i test (con il comando `pytest tests.py`) otterremo il seguente errore\n\n```\n__________________________________________________ test_unauthorized_request_to_protected __________________________________________________\n\nclient = <TestClient <Flask 'app'>>, app = <Flask 'app'>\n\n    def test_unauthorized_request_to_protected(client, app):\n        res = client.get('/protected')\n>       assert res.status_code == 401\nE       assert 404 == 401\nE        +  where 404 = <Response streamed [404 NOT FOUND]>.status_code\n\ntests.py:80: AssertionError\n==================================================== 1 failed, 7 passed in 0.46 seconds ====================================================\n```\n\nIn quanto l'endpoint non esiste ancora, quindi Flask ritornerà, di default, l'errore `404`.\n\nRisolvere questo errore è molto banale, basta infatti implementare l'endpoint in modo che ritorni sempre\n`401` (in pieno stile TDD, ricordate di scrivere sempre il minimo codice che risolve l'errore attuale).\nAggiungiamo il nuovo endpoint al file `app.py`\n\n```python\n# app.py\n\ndef create_app():\n\n    # ...\n\n    @app.route('/protected')\n    @as_json\n    def protected():\n        return {}, 401\n```\n\ne rilanciamo i test, che questa volta si concluderanno senza errori.\n\n```\n=========================================================== test session starts ============================================================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 8 items\n\ntests.py ........\n\n========================================================= 8 passed in 0.36 seconds =========================================================\n```\n\nOvviamente l'endpoint ancora non funziona, dobbiamo infatti fare in modo che, nel caso\nil client fornisca un token valido, allora il serve gli permetta di accedere all'endpoint.\n\nSviluppiamo quindi altri due test che considerano i seguenti casi:\n\n1. Il client fornisce un token non valido -> `401`\n2. Il client fornisce un token valido -> `200`\n\n```python\n\n# tests.py\n\n# ...\n\ndef test_invalid_token_request_to_protected(client, app):\n    invalid_token = '12345'\n    headers = {\n        'Authorization': 'Bearer {}'.format(invalid_token)\n    }\n    res = client.get('/protected', headers=headers)\n    assert res.status_code == 401\n\ndef test_valid_token_request_to_protected(client, app):\n    valid_token = jwt.encode({'username':'username'}, app.config['SECRET_KEY']).decode('utf-8')\n    headers = {\n        'Authorization': 'Bearer {}'.format(valid_token)\n    }\n\n    res = client.get('/protected', headers=headers)\n    assert res.status_code == 200\n```\n\nI due test sono molto simili:\n\n1. generano un dizionario `headers` contentente un unico campo (`Authorization`) in cui è inserito un **Bearer Token**\n2. Inviano il dizionario con l'opzione `headers` in fase di richesta con il client.\n\nCome è possibile immaginare, una volta lanciati i test, il primo test appena scritto (`test_invalid_token_request_to_protected`) passerà senza problemi, mentre il secondo (`test_valid_token_request_to_protected`) fallirà:\n\n```\n================================================================= FAILURES =================================================================\n__________________________________________________ test_valid_token_request_to_protected ___________________________________________________\n\nclient = <TestClient <Flask 'app'>>, app = <Flask 'app'>\n\n    def test_valid_token_request_to_protected(client, app):\n        valid_token = jwt.encode({'username':'username'}, app.config['SECRET_KEY']).decode('utf-8')\n        headers = {\n            'Authorization': 'Bearer {}'.format(valid_token)\n        }\n\n        res = client.get('/protected', headers=headers)\n>       assert res.status_code == 200\nE       assert 401 == 200\nE        +  where 401 = <Response streamed [401 UNAUTHORIZED]>.status_code\n\ntests.py:97: AssertionError\n==================================================== 1 failed, 9 passed in 0.46 seconds ====================================================\n```\n\nQuesto è dovuto al fatto che l'endpoint sviluppata ritorna sempre `401`, indipendemente dall'header che gli inviamo.\n\nModifichiamo quindi il codice in modo da controllare il token ed agire di conseguenza.\n\nPer prima cosa, controlliamo che il campo `Authorization` esiste effettiamente nella richiesta.\nIn caso contrario ritorniamo `401`, altrimenti `200`.\n\nPer farlo, semplicemente accedo alla chiave `Authorization` dizionario `request.headers`. Se questa chiave non presente, l'eccezione `KeyError` viene generata. Devo quindi intercettare l'eccezione e ritornare `401` in caso\nsi verificasse.\n\n```python\n# app.py\n\ndef create_app():\n\n    # ...\n\n    @app.route('/protected')\n    @as_json\n    def protected():\n        try:\n            auth = request.headers['Authorization']\n        except KeyError:\n            return {}, 401\n        return {}, 200\n```\n\nA questo punto, la nuova versione dell'endpoint fa fallire solo il test `test_invalid_token_request_to_protected`.\nQuesto perchè non consideriamo ancora il caso in cui l'autorizzazione è effettivamente presente ma il token non è corretto.\n\nAggiustiamo quindi l'ultimo punto controllando il token presente nel campo. Per farlo, dobbiamo fare due cose:\n\n1. Controllare che il campo `Authorization` sia nella forma corretta,\n2. Controllare la firma del token.\n\nPer farlo, dobbiamo:\n\n1. Controllare che `auth` sia composto da due parole,\n2. Controllare che la prima parola di `auth` sia effettivamente `Bearer`,\n3. Testare il token con la funzione `jwt.decode` vista nel [precedente tutorial](/2018/01/25/tdd-flask-pytest-2/).\n\nSfruttiamo prima di tutto il metodo `.split()` delle stringhe in Python, che permette di generare una lista di stringhe separando la stringa di partenza in base agli spazi.\n\n```python\nauth = request.headers['Authorization'].split()\n```\n\nA questo punto, possiamo controllare che `auth` contenga due elementi e che il primo sia `Bearer` e, in caso contrario, ritornare `401`:\n\n```python\nif len(auth) != 2 or auth[0] != 'Bearer':\n    return {}, 401\n```\n\nPer finire, proviamo a decodificare (e testare) il token, e ritornare `401` nel caso in cui\nl'operazione non vada a buon fine (intercettando l'eccezione `jwt.exceptions.DecodeError`):\n\n```python\ntoken =  auth[1]\ntry:\n    data = jwt.decode(token, app.config['SECRET_KEY'])\nexcept jwt.exceptions.DecodeError:\n    return {}, 401\n```\n\nIl codice completo, così generato, sarà quindi il seguente:\n\n```python\n    @app.route('/protected')\n    @as_json\n    def protected():\n        try:\n            auth = request.headers['Authorization'].split()\n        except KeyError:\n            return {}, 401\n\n        if len(auth) != 2 or auth[0] != 'Bearer':\n            return {}, 401\n\n        token =  auth[1]\n        try:\n            data = jwt.decode(token, app.config['SECRET_KEY'])\n        except jwt.exceptions.DecodeError:\n            return {}, 401\n        return data, 200\n\n    return app\n```\n\nE finalmente, tutti i test passeranno:\n\n```\n======================================================== 10 passed in 0.38 seconds =========================================================\n(env) ➜  flask-tdd-tutorial pytest tests.py\n=========================================================== test session starts ============================================================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 10 items\n\ntests.py ..........\n\n======================================================== 10 passed in 0.35 seconds =========================================================\n```\n\n## Refactoring: mettiamo in ordine il tutto\n\nSiamo pronti per un'esteso refactoring (o meglio, riorganizzazione del codice),\nper mettere le cose in ordine e rendere il codice un po' più ordinato.\n\nIn particolare, faremo le seguenti operazioni:\n\n1. Spostiamo `FakeDB` in un'apposito file;\n2. Definiamo i vari endpoint creati al di fuori della funzione `create_app` per mezzo di un blueprint.\n\n### Riorganizziamo `FakeDB`\n\nLa prima cosa da fare, è quindi creare un nuovo file `fake_db.py` all'interno del quale inserire il codice\nche definisce la classe `FakeDB`:\n\n```python\n# fake_db.py\n\nclass FakeDB(object):\n    def __init__(self):\n        self._db = {}\n\n    def add_user(self, username, password, data={}):\n        data[\"username\"]=username\n        self._db[username] = (password, data)\n\n    def get_user(self, username):\n        return self._db[username][1]\n\n    def check_user(self, username, password):\n        try:\n            return self._db[username][0] == password\n        except KeyError:\n            return False\n```\n\nModifichiamo anche il file `app.py` rimuovendo la classe ed aggiungendo il seguente import:\n\n```python\nfrom fake_db import FakeDB\n```\n\nTutto questo non avrà nessun effetto sue test, che dovrebbero passare senza nessun problema!\n\n### Riorganizziamo gli endpoint sfruttando i Blueprint\n\nHo parlato dei Blueprint in [questo mio post su Flask](/2016/12/27/tutorial-flask/).\nQuesti sono un modo che permette di scrivere e raggruppare endpoint in modo separato\ndalla creazione dell'app stessa, e poi di attaccare questi endpoint all'app una volta\nche l'app viene creata. I vantaggi dei blueprint sono due:\n\n1. Scrivere codice più organizzato, in quanto possiamo distribuire i vari enpoint in file diversi ed al di fuori della funzione `init_app`.\n2. Sviluppare app modulari, e condividere porzioni di codice (blueprint) tra vari server senza dover reinventare la ruota.\n\nPer il momento, ci soffermeremo sul punto (1).\n\nQuello che vogliamo fare, quindi, è spostare i tre endpoint creati in un blueprint chiamato `main_bp`. Per farlo, creiamo un file `main_endpoints.py` e definiamo un blueprint al suo interno:\n\n```python\n# main_endpoints.py\n\nfrom flask import Blueprint\nmain_bp = Blueprint('main_bp', __name__)\n```\n\nAbiamo creato un blueprint chiamato `main_bp`, si noti che non c'è più nessun riferimento all'app che stiamo sviluppando (e mai ci sarà).\n\nA questo punto, tagliamo ed incolliamo i vari endpoint che si trovano nel file `app.py` e rimpiazziamo i route decorator da `@app.route()` a `@main_bp.route()`, in questo modo attacchiamo questi endpoint al blueprint `main_bp` invece che all'app principale. **State attenti a copiare anche i vari import**.\n\n```python\n# main_endpoints.py\n\nfrom flask import Blueprint, request\nfrom flask_json import as_json\nimport jwt\n\nmain_bp = Blueprint('main_bp', __name__)\n\n@main_bp.route('/')\n@as_json\ndef main():\n    return {}\n\n@main_bp.route('/login', methods=['POST'])\n@as_json\ndef login():\n    try:\n        username = request.get_json()['username']\n        password = request.get_json()['password']\n        if app.db.check_user(username, password):\n            token = jwt.encode({'username':username}, app.config['SECRET_KEY']).decode('utf-8')\n            return {'access_token': token}\n        else:\n            return {'error': 'invalid login'}, 401\n    except KeyError:\n        return {'error': 'invalid login'}, 401\n\n@main_bp.route('/protected')\n@as_json\ndef protected():\n    try:\n        auth = request.headers['Authorization'].split()\n    except KeyError:\n        return {}, 401\n\n    if len(auth) != 2 or auth[0] != 'Bearer':\n        return {}, 401\n\n    token =  auth[1]\n    try:\n        data = jwt.decode(token, app.config['SECRET_KEY'])\n    except jwt.exceptions.DecodeError:\n        return {}, 401\n    return data, 200\n```\n\nModifichiamo quindi la funzione `create_app` togliendo tutti gli endpoint (che ora sono deifniti nel blueprint) e registrando il blueprint in modo da poter attaccare all'app principale i vari endpoint:\n\n```python\n# app.py\n\nfrom flask import Flask\nfrom flask_json import FlaskJSON\nfrom fake_db import FakeDB\n\ndef create_app():\n    app = Flask(__name__)\n    FlaskJSON(app)\n    app.db = FakeDB()\n    app.config['SECRET_KEY'] = 'secret_ket'\n\n    from main_endpoints import main_bp\n    app.register_blueprint(main_bp)\n\n    return app\n```\n\nQuesto, in particolare, viene fatto con le due righe\n\n```python\n# app.py\n\ndef create_app():\n    # ...\n    from main_endpoints import main_bp\n    app.register_blueprint(main_bp)\n\n    # ...\n```\n\nPer finire, lanciamo i test per vedere se è tutto in ordine:\n\n```python\n    @main_bp.route('/protected')\n    @as_json\n    def protected():\n        try:\n            auth = request.headers['Authorization'].split()\n        except KeyError:\n            return {}, 401\n\n        if len(auth) != 2 or auth[0] != 'Bearer':\n            return {}, 401\n\n        token =  auth[1]\n        try:\n>           data = jwt.decode(token, app.config['SECRET_KEY'])\nE           NameError: name 'app' is not defined\n\nmain_endpoints.py:41: NameError\n==================================================== 4 failed, 6 passed in 1.17 seconds ====================================================\n```\n\nOps!!! Aiuto, vediamo una sfilza di errori che, fortunatamente, sono tutti riconducibili allo stesso errore:\nin varie parti del codice abbiamo utilizzato l'oggetto `app`, che (come detto sopra), non è più visibile nel Blueprint, quindi Python si lamenta.\n\nFortunatamente, Flask mette a disposizione un oggetto particolare, chiamato `current_app`, che si riferisce all'applicazione Flask corrente in cui sta girando il codice in esecuzione. Tramite questo oggetto, possiamo velocemente risolvere tutti gli errori semplicemente aggiunge un import all'inizio del file:\n\n```python\n# main_endpoints.py\n\nfrom flask import current_app as app\n\n# ...\n```\n\nQuesto risolve completamente i vari errori, ora i test passano senza nessun problema:\n\n```\n=========================================================== test session starts ============================================================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 10 items\n\ntests.py ..........\n\n======================================================== 10 passed in 0.38 seconds =========================================================\n```\n\n## Conclusioni - **Richiesta di aiuto!!**\n\nTi è piaciuta questa serie di tutorial? Al momento sto scrivendo una versione riveduta e corretta\ndella serie, che conterrà un bel po' di aggiunte rispetto alla serie che hai appena finito di leggere.\n\nPerò ho bisogno di un piccolo aiuto da parte di voi lettori: infatti, ho sempre meno tempo per mantere e migliorare questo blog, che al momento faccio senza nessuna retribuzione, e quindi nel tempo libero nel weekend.\nVi chiedo perciò di fare alcune, per aiutarmi a far crescere il blog per permettermi di dedicarci sempre più tempo:\n\n1. Iscrivetevi alla newsletter (trovate form nel footer di questo blog),\n2. Lasciate dei commenti sotto questo post (e sotto i vari post che ritenete utili). Vorrei sapere da voi come credete possa migliorare il blog, e se avete idee per futuri articoli o qualcosa che vorreste approndire, **questo è uno dei migliori modi con cui potete aiutarmi**!\n3. Mettete un Like alla mia [pagina facebook](https://www.facebook.com/ludusrusso.cc), aggiungetemi [su linkedin](https://www.linkedin.com/in/ludusrusso/) e seguitemi su [twitter](https://twitter.com/ludusrusso) e [github](https://github.com/ludusrusso).\n4. Condividete i miei post!\n\nIl mio è un piccolo esperimento per vedere se, insieme al vostro aiuto, posso riuscire ad aumentare le visite a questo blog, in caso affermativo, rilascerò la guida che sto scrivendo in PDF a tutti gli iscritti alla newsletter!\n\nAh dimenticavo, [qui](https://github.com/ludusrusso/flask-rest-tdd) trovate tutto il codice sviluppato!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-04-03-tdd-flask-pytest-3/index.md",
    frontMatter: {
      path: "/2018/04/03/tdd-flask-pytest-3/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "10 mins",
      published: "2018-04-03T00:00:00.000Z",
      publishedReadable: "3 Apr 2018",
      featured: false,
      tags: ["Python", "Test Driver Development", "Flask", "PyTest", "JWT"],
      title: "TDD con Flask e PyTest per lo sviluppo di API REST. Parte 3",
      description:
        "Tutorial su come usare il Test Driver Development (TDD) con Flask e PyTest per sviluppare delle semplici API REST",
      href: "/2018/04/03/tdd-flask-pytest-3/",
      image: "/content/blog/it/2018-04-03-tdd-flask-pytest-3/main.png",
      imagePath: "/content/blog/it/2018-04-03-tdd-flask-pytest-3",
    },
  },
  {
    content:
      "\nQuesto post serve a richiamare qualche costrutto base del linguaggio Python ed evidenziarne la sintassi che lo differenzia da altri linguaggi di programmazione. Procederò poi a descrivere quello che troverete nell'editor online della Piattaforma Cloud HBR e che vi sarà utile ricordare per evitare errori.\n\n# 1. Python: sintassi base\n\nPer avere un tutorial strutturato, da seguire qualora voleste imparare il linguaggio indipendentemente dalla piattaforma, [questo](http://www.html.it/guide/guida-python/) è un valido esempio. Per sperimentare, inoltre può tornare utile \"giocare\" con il nuovo linguaggio su un [compilatore online](https://repl.it/repls/ThreadbareBusyArrays), così da evitare la parte di installazione nel caso non foste poi interessati ad utilizzarlo sul vostro pc.\n\n## 1.1. Indentazione\n\nIn Python non utilizziamo parentesi per definire un blocco ma piuttosto il blocco è definito da opportuna indentazione: **il contenuto di ogni blocco deve rientrare di 4 spazi**.\n\nPer esempio:\n\n```python\ndef funzione1():\n    #contenuto funzione\n    if #condizone:\n        #fai qualcosa\n\ndef funzione2():\n    #contenuto funzione\n    while #condizone:\n        #fai qualcosa\n    #altro contenuto funzione\n```\n\n## 1.2. Apice singolo e virgolette\n\nIn Python le stringhe possono essere comprese sia tra apici singoli che tra virgolette:\n\n```python\nstringa = 'stringa'\n```\n\nè uguale a\n\n```python\nstringa = \"stringa\"\n```\n\n## 1.3. Istruzione **if**\n\nL'istruzione condizionale `if` non richiede l'uso di parentesi per definire la condizione da verificare. Se la condizione viene verificata, il contenuto del blocco viene eseguito:\n\n```python\nif x < 0:\n    #fai qualcosa\n```\n\n## 1.4. Ciclo **while**\n\nFinchè la condizione viene verificata, il contenuto del blocco viene eseguito ciclicamente; quando la condizione non si verifica, il programma esce dal ciclo.\n\n```python\nwhile x < 0:\n    #fai qualcosa\n```\n\n## 1.5. Ciclo **for**\n\nIl `for` di Python viene utilizzato in modo un po' diverso rispetto agli altri linguaggi di programmazione: infatti si può sfruttare la seguente forma per \"ciclare\" sugli elementi di una lista.\n\n```python\nelements = [1,3,5,7]\n# \"element\" assume, ad ogni ciclo, un valore all'interno della lista \"elements\":\nfor element in elements:\n    #fai qualcosa con element\n    #fai qualcos'altro\n```\n\nAl ciclo numero 1 quindi _element_ assumerà il valore 1, al ciclo 2 assumerà il valore 3 e così via.\n\n## 1.6. Funzioni\n\nCome avete potuto vedere nell'esempio per l'indentazione, una funzione python viene definita usando la parola chiave `def`:\n\n```python\ndef funzione(possible_argomento1, possibile_argomento2):\n    #contenuto della funzione\n```\n\n## 1.7. Istruzione **import**\n\nQuesta istruzione serve ad importare le librerie necessarie per chiamare specifiche funzioni o usare particolari oggetti. Per esempio:\n\n```python\nimport sys\nfrom gpiozero import LED\n...\n```\n\n# 2. Editor Piattaforma HBR\n\nL'editor per scrivere programmini da far girare sulla Raspberry tramite la piattaforma Cloud HBR, ideata da Ludovico e Gabriele, presenta la forma che dovrebbe risultare famigliare all'utente Arduino, ovvero la presenza delle funzioni `setup()` e `loop()`, che consente all'utente di definire un blocco di inizializzazione ed uno di esecuzione ciclica esattamente come nell'IDE Arduino. Anche in questo caso i programmi scritti nell'editor HBR vengono chiamati _sketch_.\n\n## 2.1. Classi e **self**\n\nLa parola chiave `class` definisce una classe e deve essere seguita dal nome che vogliamo dare alla classe stessa (con iniziale maiuscola). Il concetto di classi non sarà da capire a fondo per programmare sull'editor della piattaforma: vi basti sapere che il programma nello sketch deve essere definito come classe `Node` la quale riceve sempre l'argomento `dotbot_ros.DotbotNode` (la struttura, scheletro, di uno sketch viene in ogni caso automaticamente fornita alla creazione dello sketch stesso).\nPer evitare errori, ricordatevi di _anteporre `self.` a qualsiasi variabile definita in `setup()`, in modo tale da poter essere usata/processata in `loop()`_ o qualsiasi altra funzione vogliate creare.\n\nEcco un esempio di sketch:\n\n```python\nimport dotbot_ros\nfrom gpiozero import LED\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'blink'\n\n    def setup(self):\n        self.led = LED(5)\n        self.loop_rate = dotbot_ros.Rate(2)\n\n    def loop(self):\n        self.led.toggle()\n```\n\nPer maggiori informazioni su _self_ e classi Python date un occhio [qui](http://www.html.it/pag/15622/classi-in-python/).\n\n**Ciao!** :hibiscus:\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-03-08-python-e-sketches/index.md",
    frontMatter: {
      path: "/hbr/python-e-sketch-hbr/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "3 mins",
      published: "2018-03-08T00:00:00.000Z",
      publishedReadable: "8 Mar 2018",
      featured: false,
      tags: [],
      title: "Python e sketch HBR",
      description: "Sintassi base di Python e sketch HBR",
      href: "/hbr/python-e-sketch-hbr/",
      image: "/content/hbr/2018-03-08-python-e-sketches/py.png",
      imagePath: "/content/hbr/2018-03-08-python-e-sketches",
    },
  },
  {
    content:
      "\nLo avevo provato qualche tempo fa, quando era ancora alla seconda release alpha, e poi mi sono disinteressato al progetto e l'ho seguito da molto lontano. Ma finalmente, all'inizio di quest'anno, la prima release stabile, [ROS Ardent Apalone](https://github.com/ros2/ros2/wiki/Release-Ardent-Apalone) e io ho finalmente la possibilità di metterci le mani sopra!\n\n## Aspetta un momento, di cosa si parla? Non eravamo a ROS Lunar?\n\nImmagino che molti che non seguono assiduamente il mondo ROS stiano iniziando a farsi un po' di domande, perciò andiamo con ordine.\n\nROS nasce storicamente con un ben preciso obiettivo: **Fare Ricerca sulla Robotica**, o meglio, abilitare e semplificare la ricerca della robotica di servizio. La prima versione di ROS è nata quindi con l'università in testa, non l'industria, ed il progetto si è poi evoluto a partire da una base che aveva in mente questo obiettivo.\n\nProbabilmente gli stessi ideatori originali di ROS non immaginavano quello che ROS sarebbe diventato e cosa avrebbe rappresentato: un progetto di dimensioni planetarie che esce dal mondo puramente universitario e approda nel mondo industriale, dove standard di funzionamento, robustezza e sicurezza sono necesssari. Contemporaneamente, l'evoluzione della ricerca, il crescente interesse e l'enorme community di **Robot Developers** creatasi intorno a ROS hanno dato vita a nuovi casi d'uso, e ROS ha iniziato a mostrare i primi segni di immaturità. Le critiche su ROS fioccano, e sono più o meno le seguenti:\n\n- non è Robusto\n- non è Real Time\n- è complesso da apprendere\n- non usa protocolli e pattern adeguati\n- è un casino quando lavori con più di due robot\n- è basato su Python 2\n- ecc.\n\nE sono tutte critiche giustissime, che anche io, da sviluppatore ed entusiasta del progetto, noto ogni giorno.\n\nNel tempo, la community si è data da fare, e sono uscite varie patch che tentavano di risolvere i vari limiti che ROS ha:\n\n- Serve creare interfacce web per i robot? [Inventiamo ROSBridge](http://wiki.ros.org/rosbridge_suite).\n- Serve far comuncare ROS con microcontrollori? [Inventiamo ROSSerial](http://wiki.ros.org/rosserial).\n- Serve far lavorare insieme 20 robot ma evitare che se il master perde la connessione si rompa tutto? Inventiamo [Robot In Concert](http://wiki.ros.org/rocon).\n\nAd un certo punto, ci si è resi conto che era necessario un profondo ripensamento alla base di ROS, e è quindi nato ROS 2.0, che non è altro che una completa reimplementazione di ROS, partendo dalle stesse basi del progetto originale ma includendo le nuove tecnologie, i nuovi casi d'uso e dandogli un taglio più molto più robusto e industriale. Trovate qui un interessante articolo che [spiega nel dettaglio le motivazioni](http://design.ros2.org/articles/why_ros2.html).\n\nGuardate che bella l'architettura :D\n\n![ROS 2.0 Installazione](./ros_stack.png)\n\n## ROS 2.0 Ardent Apalone, primi test. Ha senso migrare?\n\nROS 2.0 è in fare di sviluppo da circa 2 anni e mezzo, e finalmente, come detto sopra, è stata rilasciata la prima release stabile.\n\nEd io non ho perso tempo per installarla.\n\n![ROS 2.0 Installazione](./install.png)\n\nIniziano ad esserci dentro un po' di chicche e carinerie varie:\n\n- Nativo su Python 3.0 (finally)\n- Supporto a molti linguaggi di programmazione, anche se la base è ancora C++ e Python\n- Linux RT\n- eccetera\n\nAl momento mi sono limitato a leggere la doc e iniziare ad installarlo sul mio PC (nel momento in cui scrivo sto aspettando il download dei vari pacchetti). Ecco alcune cose che ho capito..\n\nAl momento, ROS 2 include solo quello che in ROS è chiamato _core_, cioè l'insieme dei funzionamenti base che abilitano la comunicazione e la gestione dei pacchetti. Da ora in avanti seguirà la parte di migrazione e sapremo probabilmente solo tra qualche mese se sarà approvato ed utilizzato dalla community (la forza di ROS è la community, non ROS in se).\n\nAncora quindi non ha troppo senso iniziare a guardarlo, ma certamente io lo farò per interesse e per divertimento. Se il progetto prenderà veramente il posto per cui è nato, cioè una naturale evoluzione del ROS originale, è sicuramente un'ottimo momento per iniziare a contribuirci!\n\n:D\n\n## Video\n\nVi lascio con un video in cui spiego cosa ne penso e le prime impressioni a caldo dopo averlo provato!\n\n{% include youtube.html id=\"xi1TQMdXNWM\" %}\n\nLe repo citate nel video sono le seguenti:\n\n- [Docker ROS2](https://github.com/ludusrusso/docker_ros2_ament)\n- [Primi test](https://github.com/ludusrusso/ros2_tests)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-03-01-benvenuto-ros2/index.md",
    frontMatter: {
      path: "/hbr/benvenuto-a-ros-20/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2018-03-01T00:00:00.000Z",
      publishedReadable: "1 Mar 2018",
      featured: false,
      tags: [],
      title: "Benvenuto a ROS 2.0",
      description: "Primo contatto con ROS 2.0",
      href: "/hbr/benvenuto-a-ros-20/",
      image: "/content/hbr/2018-03-01-benvenuto-ros2/main.png",
      imagePath: "/content/hbr/2018-03-01-benvenuto-ros2",
    },
  },
  {
    content:
      "\nCiao a tutti! Oggi metterò insieme una serie di informazioni che ho raccolto mentre cercavo di creare un nuovo tipo di messaggio con ROS durante il mio progetto di tesi.\nQuesta potrebbe essere la vostra situazione nel caso aveste bisogno di un tipo di messaggio base con l'intento di semplificare la vostra applicazione: infatti alcuni [messaggi standard di ROS](http://wiki.ros.org/std_msgs/) sono fin troppo complessi per l'uso semplice che si vuol ottenere.\nSpero che questo post possa riassumere e accelerare la creazione di messaggi custom. Iniziamo!\n\n# Creare il file .msg\n\nAssumo che abbiate già il vostro workspace catkin (creato seguendo [questo tutorial](http://wiki.ros.org/catkin/Tutorials/create_a_workspace)) e che abbiate creato il vostro pacchetto ROS come spiegato [qui](http://wiki.ros.org/it/ROS/Tutorials/CreatingPackage#Creare_un_catkin_Package).\n\n> **RMK**: è buona abitudine creare un pacchetto specifico per la definizione di messaggi, e.g., create un package chiamato `custom_msgs`.\n\nPrima di tutto, dalla command line, entrate nella cartella del package, sfruttando il comando ROS `roscd`:\n\n```bash\nroscd custom_msgs\n```\n\nUna volta nella cartella, create una nuova cartella chiamata `msg`, tale che i messaggi custom contenuti in essa vengano riconosciuti auotmaticamente durante la compilazione del pacchetto:\n\n```bash\nmkdir msg\ncd msg\n```\n\nCreate il file di definizione del nuovo messaggio specificando direttamente il suo contenuto e salvandolo in un file con estensione `.msg`; nel mio caso, avevo bisogno di un semplice array di interi che ho chiamato `Servo_Array`.\n\n```bash\necho \"uint16[] data\" > msg/Servo_Array.msg\n```\n\nPer controllare se la definizione del messaggio è stata salvata correttamente, potete semplicemente fare un check del contenuto:\n\n```bash\ncat Servo_Array.msg\n```\n\n# \"Attivare\" la generazione del messaggio\n\nPer sollecitare la generazione dei nuovi tipo di messaggio durante la compilazione con catkin, dobbiamo modificare i file contenuti nel package `package.xml` e `CmakeLists.txt`:\n\n- Aprite `package.xml`, e assicuratevi che queste due linee siano presenti e **de-commentatele**:\n\n```xml\n<build_depend>message_generation</build_depend>\n<run_depend>message_runtime</run_depend>\n```\n\n- Aprite `CmakeLists.txt`, aggiungete `message_generation` alla lista dei `COMPONENTS`, così:\n\n```txt\nfind_package(catkin REQUIRED COMPONENTS\n   roscpp\n   rospy\n   std_msgs\n   message_generation\n)\n```\n\n- Esportare la dipendenza message runtime:\n\n```txt\ncatkin_package(\n  ...\n  CATKIN_DEPENDS message_runtime ...\n  ...)\n```\n\n- Quindi de-commentate le seguenti righe (rimuovete `#`) e rimpiazzate `Message*.msg` con il vostro file .msg (nel mio caso `Servo_Array.msg`):\n\n```txt\nadd_message_files(\n  FILES\n  Servo_Array.msg\n)\n```\n\n- Infine de-commentate queste righe:\n\n```txt\ngenerate_messages(\n  DEPENDENCIES\n  std_msgs\n)\n```\n\n> **NB**: se avete più di un messaggio custom da aggiungere, create i relativi file .msg e aggiungeteli ogni volta fche un file .msg deve essere aggiunto nel file `CmakeLists.txt` (come specificato sopra).\n\n# Re-building del package\n\nAdesso che abbiamo creato dei nuovi messaggi, dobbiamo fare di nuovo il make del pacchetto:\n\n# Nel vostro workspace catkin\n\n```bash\nroscd custom_msgs\ncd ../..\ncatkin_make\n```\n\n> **NB**: supponiamo che vogliate scrivere degli script Python all'interno di un package chiamato, per esempio, `my_package`: per importare il messaggio custom nel vostro script, avrete bisogno la seguente riga `from custom_msgs.msg import Motors_Array`. Notate che gli scripts Python sono solitamente contenuti in una cartella `my_package/scripts`.\n\nLa maggior parte delle informazioni in questo post sono state prese da [qui](http://wiki.ros.org/ROS/Tutorials/CreatingMsgAndSrv#Common_step_for_msg_and_srv).\n\n# Messaggi custom e Rosserial Arduino\n\nNel caso abbiate bisogno di usare il vostro messaggio cusotm nel nodo seriale su Arduino, dovete solo copiare il vostro package `custom_msgs` nella cartella `ros_lib` (_cartella_di_sketch_Arduino_/libraries/ros_lib/). Dopo aver ri-lanciato l'editor Arduino, potete riferirvi al nuovo messaggio nel vostro sketch con `#include <custom_msgs/Motors_Array.h>`.\n\n**Ciao!** :hibiscus:\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-02-26-ros-custom-messages/index.md",
    frontMatter: {
      path: "/hbr/come-creare-messaggi-custom-in-ros/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "3 mins",
      published: "2018-02-26T00:00:00.000Z",
      publishedReadable: "26 Feb 2018",
      featured: false,
      tags: [],
      title: "Come creare messaggi custom in ROS",
      description: "Creare nuovi tipi di messaggio ROS",
      href: "/hbr/come-creare-messaggi-custom-in-ros/",
      image: "/content/hbr/2018-02-26-ros-custom-messages/ros_custom.png",
      imagePath: "/content/hbr/2018-02-26-ros-custom-messages",
    },
  },
  {
    content:
      '\nIn occasione dell\'alternanza scuola-lavoro all\'ITIS Pininfarina di Torino, dove lo scopo è inventare applicazioni robotiche in ambito agricolo, stavo pensando di inventare qualcosa per risolvere il problema del rilevamento incendi. Allora mi è venuto in mente di implementare una semplice applicazione di visione artificiale che rilevi le sfumature di rosso e ci comunichi quando il robot "vede" una fiamma.\n\nIl problema ovviamente può essere affrontato in modo molto più complesso e con molti altri sensori (temperatura, gas, ecc), però per iniziare in modo low-cost e con poche righe di codice mi sembra un\'applicazione carina!\n\n![](./incendio.jpg)\n\n# 1. Ingredienti\n\nCi serve:\n\n- una Raspicam (io uso la V2)\n- un Raspberry Pi con l\'immagine HBrain sull\'SD\n\n# 2. Collegare la raspicam al Raspberry\n\nSeguite il tutorial scritto in precedenza che trovate [qui](http://hotblackrobotics.github.io/it/blog/2017/04/10/utilizzare-la-raspicam-in-streaming-con-la-piattaforma-cloud/).\n![Connessione Camera](./maxresdefault.jpg)\nUna volta che è tutto funzionante possiamo procedere con il codice. Andiamo nella sezione della piattaforma cloud adibita a creare nuovi "sketches" e iniziamo a scrivere un nodo!\n\n## 2.1 Rilevare il colore rosso - Il codice\n\nIl codice completo è qui sotto, copialo nello sketch, salva e premi "run".\n\n```python\nimport dotbot_ros\nimport cv2\nimport sys\nimport rospy\nimport numpy as np\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = \'fire_detection\'\n\n    def setup(self):\n        self.image_sub = dotbot_ros.Subscriber("/camera/image",Image,self.on_image)\n        self.image_pub = dotbot_ros.Publisher("image_back", Image)\n        self.img = None\n        self.bridge = CvBridge()\n        print "ci sono e sono vivo!"\n        sys.stdout.flush()\n\n    def on_image(self,data):\n\n        img = self.bridge.imgmsg_to_cv2(data, "bgr8")\n\n        # significa in RGB ROSSO\n        lower = np.array([17, 15, 100])\n        upper = np.array([50, 56, 200])\n\n        tol = 0\n        mask = cv2.inRange(img, lower, upper)\n        output = cv2.bitwise_and(img, img, mask = mask)\n        gray = cv2.cvtColor(output,cv2.COLOR_BGR2GRAY)\n\n        if (gray>tol).any():\n            print "Allarme Incendio !!!"\n        else:\n            print "---"\n\n        sys.stdout.flush()\n        self.image_pub.publish(self.bridge.cv2_to_imgmsg(gray, "mono8"))\n\n```\n\nSe è tutto ok, vedrai nella sezione "console" il nodo in esecuzione e facendo echo sui due topic "/camera/image" e "< nome-del-tuo-robot >/image_back" vedrai da una parte lo streaming dalla telecamera e dall\'altra l\'immagine solo se ha "qualcosa di rosso". NB: L\'immagine la vedrete con i colori invertiti probabilmente per un problema sul Raspberry e l\'immagine salta continuamnente da RGB a BGR e viceversa. Per questo ogni tanto il colore blu appare come rosso ;)\n\n# 3. Analizziamo meglio il codice\n\nA parte le prime righe dove si aggiungono i componenti Python necessari al programma, si instanzia una classe e si dichiara il nome del nodo come "fire_detection", vediamo in dettaglio il resto del codice.\n\nNella funzione setup, dichiariamo un _subscriber_ che si sottoscrive al topic **/camera/image**, con un tipo di messaggio **Image** e associa una funzione di callback di nome **on_image**. Questa funzione verrà richiamata ogni volta che nel topic viene pubblicato un messaggio di tipo **Image**. Nella riga sotto dichiariamo un _Publisher_ che ha l\'obiettivo di pubblicare l\'immagina processata. In questo modo così possiamo vedere l\'effetto del filtro colore che stiamo per applicare. Alla fine della funzione mettiamo un _print_ "ci sono e sono vivo!" per comunicare in console che il programma è in esecuzione correttamente.\n\n```python\n\ndef setup(self):\n    self.image_sub = dotbot_ros.Subscriber("/camera/image",Image,self.on_image)\n    self.image_pub = dotbot_ros.Publisher("image_back", Image)\n    self.img = None\n    self.bridge = CvBridge()\n    print "ci sono e sono vivo!"\n    sys.stdout.flush()\n\n```\n\nVediamo ora la funzione **on_image** dove accade il vero e proprio filtraggio.\n\n```python\ndef on_image(self,data):\n\n    #convertiamo l\'immagine da opencv nel formato idoneo a ROS\n    img = self.bridge.imgmsg_to_cv2(data, "bgr8")\n\n    # significa in RGB ROSSO\n    lower = np.array([17, 15, 100])\n    upper = np.array([50, 56, 200])\n```\n\nCon _lower_ e _upper_ definiamo le soglie di colore rosso minime e massime, Ovvero in BGR (Blue Green Red) il colore che andremo a filtrare da ogni frame della telecamera. Se sei curioso di sapere esattamente che colore è, [qui](https://www.w3schools.com/colors/colors_rgb.asp) c\'è un calcolatore RGB. NB: i colori nel codice Python sono in BGR quindi significa ad esempio per lower Blue = 17, Green = 15, Red = 100.\n\n```python\n    # tolleranza\n    tol = 0\n    # maschera per sogliare il colore rosso\n    mask = cv2.inRange(img, lower, upper)\n    # immagine output dove rimane solo il rosso e tutto il resto nero\n    output = cv2.bitwise_and(img, img, mask = mask)\n    #converto questa in bianco e nero\n    gray = cv2.cvtColor(output,cv2.COLOR_BGR2GRAY)\n\n    # se c\'è anche solo un pixel rosso mando un allarme!\n    if (gray>tol).any():\n        print "Allarme Incendio !!!"\n    else:\n        print "---"\n\n    sys.stdout.flush()\n\n    # pubblico l\'immagine processata su image_back\n    self.image_pub.publish(self.bridge.cv2_to_imgmsg(gray, "mono8"))\n```\n\nQui facciamo qualche operazione più complicata. Bisogna innanzitutto dire che un\'immagine è una matrice di numeri. Quindi in questo caso andiamo a definire una maschera _mask_, poi filtriamo nei range di colore definito e salviamo il risultato in un\'altra immagine di nome _output_. Dopo convertiamo questa in bianco e nero e salviamo in un\'altra immagine ancora di nome _gray_. Facciamo questa operazione perchè se la telecamera non vede niente di rosso (e nessun colore nel range definito prima) il nostro risultato sarà completamente nero, potete verificarlo in ROS console osservando il topic /image*back, il che significa che tutti i numeri della matrice sono 0 o praticamente 0.\nQuindi per capire in automatico se la telecamera "vede" una zona rossa basterà con *(gray>tol).any()_ andare a vedere se uno tra i tanti pixel dell\'immagine NON è nero. Ovvero si traduce nell\'osservare tutti gli elementi della matrice e vedere se ce n\'è uno che è maggiore di una piccola tolleranza (in questo caso tol = 0 quindi il sistema sarà parecchio sensibile).\nInfine con \\_self.image_pub.publish()_ pubblichiamo il risultato sultopic /image_back.\n\n# 4. Esercizi\n\nCollegate un LED al Raspberry o fate inviare tramite un bot Telegram un messaggio di allarme sul vostro cellulare.\n\nMigliorate l\'applicazione con tecniche più fini di riconoscimento immagini, non solo un pixel ma una regione minima di spazio che possa essere effettivamente una fiamma!\n\n**Ciao ciao!** :robot:\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-02-21-riconoscere-colori-con-opencv/index.md",
    frontMatter: {
      path: "/hbr/sviluppare-un-rilevatore-di-fiamma-con-la-visione-artificiale/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "5 mins",
      published: "2018-02-21T00:00:00.000Z",
      publishedReadable: "21 Feb 2018",
      featured: false,
      tags: [],
      title: "Sviluppare un rilevatore di fiamma con la visione artificiale",
      description:
        "Sviluppare un rilevatore di fiamma con la visione artificiale",
      href: "/hbr/sviluppare-un-rilevatore-di-fiamma-con-la-visione-artificiale/",
      image:
        "/content/hbr/2018-02-21-riconoscere-colori-con-opencv/incendio.jpg",
      imagePath: "/content/hbr/2018-02-21-riconoscere-colori-con-opencv",
    },
  },
  {
    content:
      "\nIn questo tutorial vedremo come collegare il manipolatore antropomorfo, siBOT, alla piattaforma HBR.\n\nsiBOT è l'insieme del design [EEZYBOT MK2](http://www.eezyrobots.it/eba_mk2.html), progetto italino Open Source, e del sistema di nodi ROS necessari a controllarlo. Ho utilizzato questo braccio per testare l'architettura sviluppata per il mio progetto di tesi, NTBD, di cui trovate maggiori informazioni in questo [post]({{ site.baseurl }}{% post_url /it/blog/2018-01-17-ntbd-guide-part-I %}).\n\n<p align=\"center\">\n    <image src=\"/assets/imgs/2018-01-17-ntbd/sibot.png\"  height=\"250\"/>\n</p>\nVedremo quali sono gli step necessari a collegare siBOT in Cloud per controllarlo da piattaforma HBR, sia nel **joint space** (invio degli angoli desiderati per i motori), sia nel **task space** (in questo caso invio posizioni desiderate nello spazio cartesiano che vengono convertite in angoli per i motori).\n\n# 1. Ingredienti\n\nCi serviranno:\n\n- 1 braccio siBOT (braccio EEZYBOT MK2 + nodo ROS Arduino)\n- 1 Raspberry Pi con l'immagine HBrain sull'SD\n\n# 2. Controllo nello spazio dei motori\n\n<p align=\"center\">\n    <image src=\"/assets/imgs/2018-01-17-ntbd/5_eezybotfrontservo.jpg\"  height=\"300\"/>\n</p>\nIl controllo più semplice è quello nello spazio dei motori: basterà infatti decidere quali valori vogliamo dare ai tre servo motori ed inviarli al robot.\nPossiamo definire una sequenza di configurazioni:\n```\nmotors_list = [m11,m21,m31,m12,m22,m32,...m1n,m2n,m3n]\n```\ne leggerla correttamente nel nostro sketch per inviare ciascuna sequenza in modo ciclico per far eseguire al robot una sorta di \"routine\".\n\n## 2.1 Generatore di valori servo desiderati - Sketch\n\nCreate un nuovo sketch e chiamatelo _motors_generator_sibot_. Il contenuto dovrà essere il seguente:\n\n```python\nimport dotbot_ros\nfrom std_msgs.msg import Int16MultiArray\nimport time\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'motors_generator'\n\n    def setup(self):\n        self.pub = dotbot_ros.Publisher('motors_nointerp', Int16MultiArray)\n        self.gripper = 25\n\n        motors_list = [90, 90, 90, 180, 100, 30, 0, 140, 60]\n        self.gripp_list = ['open','closed','open']\n        n = 3\n        self.m_list = [motors_list[i:i+n] for i in range(0, len(motors_list), n)]\n        self.loop_rate = dotbot_ros.Rate(0.33)\n\n    def loop(self):\n        for indx, motors_seq in enumerate(self.m_list):\n            seq = Int16MultiArray()\n            if self.gripp_list[indx] == 'open':\n                self.gripper = 100\n            else:\n                self.gripper = 25\n            seq.data = [m for m in motors_seq, self.gripper]\n            self.pub.publish(seq)\n            time.sleep(3)\n```\n\n## 2.2 Generatore di valori servo desiderati - Sketch con commenti\n\nQui di seguito riporto il codice commentato. Come potete vedere, la struttura è quella utilizzata finora per i nodi ROS su HBrain: vengono definite le funzioni setup() e loop(), con l'aggiunta di una funzione di callback.\n\n```python\nimport dotbot_ros\nfrom std_msgs.msg import Int16MultiArray\nimport time\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'motors_generator'\n\n    def setup(self):\n    # Definiamo un publisherper pubblicare le sequenze di motori\n        self.pub = dotbot_ros.Publisher('motors_nointerp', Int16MultiArray)\n    # Inizializziamo il valore del gripper a chiuso\n        self.gripper = 25\n    # Sequenza di angoli desiderati (da leggere 3 alla volta)\n        motors_list = [90, 90, 90, 180, 100, 30, 0, 140, 60]\n    # Sequenza di configurazioni desiderate per il gripper\n        self.gripp_list = ['open','closed','open']\n    # Come detto, prendiamo i valori in gruppi da n elementi\n        n = 3\n    # Il seguente codice ritorna una lista di liste da 3 elementi:\n    # [[motor_seq1], [motor_seq2],...[motor_seqn]]\n        self.m_list = [motors_list[i:i+n] for i in range(0, len(motors_list), n)]\n        self.loop_rate = dotbot_ros.Rate(0.33)\n\n    def loop(self):\n    # Durante il ciclo for nella lista di liste, salvo anche l'indice\n    # di ogni elemento così da poter ciclare nella lista di valori per il gripper\n        for indx, motors_seq in enumerate(self.m_list):\n            seq = Int16MultiArray()\n            if self.gripp_list[indx] == 'open':\n                self.gripper = 100\n            else:\n                self.gripper = 25\n            seq.data = [m for m in motors_seq, self.gripper]\n    # Pubblichiamo sul topic definito da pub la sequenza di motori,\n    # unione degli angoli dei miniservo dei giunti e il valore per il gripper.\n            self.pub.publish(seq)\n            time.sleep(3)\n```\n\n# 3. Controllo della posizione dell'End Effector\n\nAbbiamo visto come controllare i valori dei motori di siBOT, ma spesso nella robotica industriale l'obbiettivo è controllare la posizione e l'orientamento dell'**End Effector** (**EE**) che in questo caso corrisponde al giunto della pinza (gripper).\n\n<p align=\"center\">\n    <image src=\"/assets/imgs/2018-02-07-sibot-cloud/5_trigoreal.jpeg\"  height=\"300\"/>\n</p>\nPer poter ottenere la posizione desiderata è necessario manipolare questa informazione e trasformarla in valori per i motori del braccio robotico, i quali sono l'unico modo per muovere il robot stesso. Questa operazione si chiama **cinematica inversa** e tramite calcoli, analitici o numerici, consente di trovare il valore dei motori corrispondenti ad una certa posizione dell'EE. Notate che in questo caso, possiamo definire solo la posizione desiderata (non l'orientamento) dal momento che la pinza non ruota per configurazione fisica del braccio.\nAnche in questo caso definiamo una sequenza di posizioni desiderate che vorremmo l'EE del braccio raggiungesse.\n\n## 3.1 Generatore di posizioni EE - Sketch\n\nCreate un nuovo sketch e chiamatelo _positions_generator_sibot_. Il contenuto dovrà essere il seguente:\n\n```python\nimport dotbot_ros\nfrom geometry_msgs.msg import Point\nfrom std_msgs.msg import String\nimport time\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'position_generator'\n\n    def setup(self):\n        self.pub = dotbot_ros.Publisher('desired_position_nointerp', Point)\n        self.pubG = dotbot_ros.Publisher('gripper_value', String)\n\n        desPos = [150, 0, 235, 130, 50, 140, 130, -30, 90]\n        self.gripp_list = ['open','closed','open']\n        n = 3\n        self.desP = [desPos[i:i+n] for i in range(0, len(desPos), n)]\n        self.loop_rate = dotbot_ros.Rate(0.33)\n\n    def loop(self):\n        for indx,pos in enumerate(self.desP):\n            self.pubG.publish(self.gripp_list[indx])\n            des_pos =  Point(*pos)\n            self.pub.publish(des_pos)\n            time.sleep(3)\n```\n\n## 3.2 Generatore di posizioni EE desiderate - Sketch con commenti\n\nCome potete notare, nel caso delle posizioni desiderate non abbiamo la funzione di callback all'arrivo di messaggi sul topic in cui viene specificato lo stato della pinza (gripper_value): questa funzione di callback verrà infatti definita nel nodo per la cinematica inversa in cui vengono pubblicati i valori dei servo-motori insieme al valore per il gripper sull'apposito topic.\n\n```python\nimport dotbot_ros\nfrom geometry_msgs.msg import Point\nimport time\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'position_generator'\n\n    def setup(self):\n    # Definiamo un publisher per pubblicare la sequenza di posizioni\n    # per l'EE ed uno per il valore del gripper\n        self.pub = dotbot_ros.Publisher('desired_position_nointerp', Point)\n        self.pubG = dotbot_ros.Publisher('gripper_value', String)\n    # Posizioni in coordinate cartesiane espresse in millimetri\n    # (da leggere [x1,y1,z1,x2,y2,z2...xn,yn,zn])\n        desPos = [150, 0, 235, 130, 50, 140, 130, -30, 90]\n    # Sequenza di configurazioni desiderate per il gripper\n        self.gripp_list = ['open','closed','open']\n    # Come detto, prendiamo i valori in gruppi da n elementi\n        n = 3\n    # Il seguente codice ritorna una lista di liste da 3 elementi. Ogni lista\n    # è una posizione in coordinate Cartesiane:\n    # [[pos1], [pos2],...[posn]]\n        self.desP = [desPos[i:i+n] for i in range(0, len(desPos), n)]\n        self.loop_rate = dotbot_ros.Rate(0.33)\n\n    def loop(self):\n    # Durante il ciclo for nella lista di liste, salvo anche l'indice\n    # di ogni elemento così da poter ciclare nella lista di valori per il gripper\n        for indx,pos in enumerate(self.desP):\n    # Pubblichiamo sul topic gripper_value la stringa per definire se la pinza\n    # debba essere aperta o chiusa in quella configurazione\n            self.pubG.publish(self.gripp_list[indx])\n            des_pos =  Point(*pos)\n    # Pubblichiamo sul topic definito da pub la posizione desiderata, come messaggio Point\n            self.pub.publish(des_pos)\n            time.sleep(5)\n```\n\n## 3.3 Nodo di cinematica inversa - Sketch\n\nUna volta che le posizioni desiderate verranno pubblicate, sarà necessario convertirle nei valori dei servo corrispondenti. Esistono molte soluzioni a seconda della complessità del problema (per esempio i gradi di libertà, Degrees Of Freedom) ma quella calcolata da me è di tipo geometrico, ancora possibile visti i 3 DOF del braccio.\nCreate un nuovo sketch e chiamatelo _IK_sibot_. Il contenuto dovrà essere il seguente:\n\n```python\nimport dotbot_ros\nimport math\nfrom std_msgs.msg import Int16MultiArray\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Point\nfrom sys import stdout\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'IK'\n\n    def setup(self):\n        dotbot_ros.Subscriber(\"desired_position\", Point, self.callback)\n        dotbot_ros.Subscriber(\"gripper_value\", String, self.gripper_callback)\n        self.pub = dotbot_ros.Publisher('motors', Int16MultiArray)\n        self.gripper = 25\n\n    def hipo(self,x,y):\n        return math.sqrt(x*x + y*y)\n\n    def lawOfCosines(self,a,b,c):\n        rate = (a*a + b*b - c*c) / (2 * a * b)\n        if abs(rate) > 1:\n            if max(rate,0) == 0:\n                rate = -1\n            if max(rate,0) == rate:\n                rate = 1\n        return math.acos(rate)\n\n    def deg(self,rad):\n        return rad * 180 / math.pi\n\n    def gripper_callback(self, msg):\n        if msg.data == \"open\":\n            self.gripper = 100\n        else:\n            self.gripper = 25\n\n    def callback(self,data):\n        L0 = 50\n        L1 = 35\n        L2 = 150\n        L3 = 150\n        cartP = {'xEE':data.x, 'yEE': data.y, 'zEE': data.z}\n\n        L = L0 + L1\n        cylP = {'theta': math.atan(cartP['yEE']/cartP['xEE']), 'r':self.hipo(cartP['xEE'], cartP['yEE']), 'zhat':cartP['zEE']-L}\n        zhat = cylP['zhat']\n        rho = self.hipo(cylP['r'], zhat)\n\n        M1 = 2*cylP['theta'] + math.pi/2\n        M2 = math.atan(zhat/cylP['r']) + self.lawOfCosines(L2,rho,L3)\n        M3 = M2 + self.lawOfCosines(L2,L3,rho) - math.pi/2\n        angles = [M1,math.pi - M2,M3]\n        values = Int16MultiArray()\n        values.data = [self.deg(angle) for angle in angles]\n        values.data.append(self.gripper)\n\n        if values.data[0] > 180:\n            values.data[0] = 180\n            print \" motor 1 has been saturated!\"\n        if values.data[1] > 145:\n            values.data[1] = 145\n            print \" motor 2 has been saturated!\"\n        if values.data[1] < 55:\n            values.data[1] = 55\n            print \" motor 2 has been saturated!\"\n        if values.data[2] > 110:\n            values.data[2] = 110\n            print \" motor 3 has been saturated!\"\n        if values.data[2] < 20:\n            values.data[2] = 20\n            print \" motor 3 has been saturated!\"\n        stdout.flush()\n        self.pub.publish(values)\n```\n\n## 3.4 Nodo di cinematica inversa - Sketch con commenti\n\n```python\nimport dotbot_ros\nimport math\nfrom std_msgs.msg import Int16MultiArray\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Point\nfrom sys import stdout\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'IK'\n\n    def setup(self):\n        dotbot_ros.Subscriber(\"desired_position\", Point, self.callback)\n        dotbot_ros.Subscriber(\"gripper_value\", String, self.gripper_callback)\n        self.pub = dotbot_ros.Publisher('motors', Int16MultiArray)\n        self.gripper = 25\n\n# Qui vengono definite alcune funzioni utili a risolvere la cinematica inversa\n    def hipo(self,x,y):\n        return math.sqrt(x*x + y*y)\n\n    def lawOfCosines(self,a,b,c):\n        rate = (a*a + b*b - c*c) / (2 * a * b)\n        if abs(rate) > 1:\n            if max(rate,0) == 0:\n                rate = -1\n            if max(rate,0) == rate:\n                rate = 1\n        return math.acos(rate)\n\n    def deg(self,rad):\n        return rad * 180 / math.pi\n# Funzione di callback per impostare il valore del servo della pinza\n# a seconda della stringa pubblicata su gripper_value\n    def gripper_callback(self, msg):\n        if msg.data == \"open\":\n            self.gripper = 100\n        else:\n            self.gripper = 25\n# Funzione di callback, chiamata alla ricezione della posizione desiderata\n# sull'apposito topic, in cui vengono calcolati i valori per i servo ed uniti al valore del gripper\n    def callback(self,data):\n        L0 = 50\n        L1 = 35\n        L2 = 150\n        L3 = 150\n# Posizione desiderata estrapolata dal messaggio di tipo Point\n        cartP = {'xEE':data.x, 'yEE': data.y, 'zEE': data.z}\n        L = L0 + L1\n# Posizione desiderata in coordinate cilindriche\n        cylP = {'theta': math.atan(cartP['yEE']/cartP['xEE']), 'r':self.hipo(cartP['xEE'], cartP['yEE']), 'zhat':cartP['zEE']-L}\n        zhat = cylP['zhat']\n        rho = self.hipo(cylP['r'], zhat)\n\n        M1 = 2*cylP['theta'] + math.pi/2\n        M2 = math.atan(zhat/cylP['r']) + self.lawOfCosines(L2,rho,L3)\n        M3 = M2 + self.lawOfCosines(L2,L3,rho) - math.pi/2\n\n        angles = [M1,math.pi - M2,M3]\n        values = Int16MultiArray()\n        values.data = [self.deg(angle) for angle in angles]\n        values.data.append(self.gripper)\n# Limitiamo i valori dei motori ai limiti definiti dalla struttura fisica del robot\n        if values.data[0] > 180:\n            values.data[0] = 180\n            print \" motor 1 has been saturated!\"\n        if values.data[1] > 145:\n            values.data[1] = 145\n            print \" motor 2 has been saturated!\"\n        if values.data[1] < 55:\n            values.data[1] = 55\n            print \" motor 2 has been saturated!\"\n        if values.data[2] > 110:\n            values.data[2] = 110\n            print \" motor 3 has been saturated!\"\n        if values.data[2] < 20:\n            values.data[2] = 20\n            print \" motor 3 has been saturated!\"\n        stdout.flush()\n# Pubblichiamo sul topic definito da pub la sequenza di motori,\n# unione degli angoli dei miniservo dei giunti e il valore per il gripper.\n        self.pub.publish(values)\n```\n\n# 4. Interpolazione\n\nI nodi per controllare il manipolatore sono pronti però manca ancora un nodo che renda i movimenti da una configurazione all'altra più fluidi: un nodo di interpolazione. Per mantenere il tutto semplice assumiamo che non ci siano ostacoli da evitare ed implementiamo un'interpolazione di tipo lineare. Implementiamo quindi un nodo di path planning molto semplice.\n\n## 4.1 Nodo di path planning - Sketch con commenti\n\nProcederò direttamente a riportare il codice commentato. Copiate questo codice in uno sketch chiamato _linear_interp_sibot_.\n\n```python\nimport dotbot_ros\nimport math\nfrom geometry_msgs.msg import Point\nfrom std_msgs.msg import Int16MultiArray\nimport time\n\nclass Node(dotbot_ros.DotbotNode):\n    node_name = 'interpolator'\n\n    def setup(self):\n# Definiamo i publisher e subscriber\n        self.pub = dotbot_ros.Publisher('desired_position', Point)\n        self.pubM = dotbot_ros.Publisher('motors', Int16MultiArray)\n        dotbot_ros.Subscriber(\"desired_position_nointerp\", Point, self.callback)\n        dotbot_ros.Subscriber(\"motors_nointerp\", Int16MultiArray, self.motors_callback)\n        self.i = 0\n        self.pointA = Point()\n        self.pointB = Point()\n        self.motorA = Int16MultiArray()\n        self.motorB = Int16MultiArray()\n# Qui vengono alcune funzioni utili al calcolo dei punti di interpolazione\n    def coord_distance_AB(self,a,b):\n        d = Point()\n        d.x = abs(b.x-a.x)\n        d.y = abs(b.y-a.y)\n        d.z = abs(b.z-a.z)\n        return d\n\n    def values_distance_AB(self,a,b):\n        d = Int16MultiArray()\n        d.data.append(abs(b.data[0]-a.data[0]))\n        d.data.append(abs(b.data[1]-a.data[1]))\n        d.data.append(abs(b.data[2]-a.data[2]))\n        return d\n\n# Funzione di callback chiamata alla ricezione di una sequenza di valori per i motori\n# Legge la sequenza corrente poi la paragona a quella precedente per calcolare i valori intermedi\n# in 20 steps (N=20)\n    def motors_callback(self,data):\n        N = 20\n        self.i += 1\n        if self.i == 1:\n            self.motorA = data\n            self.pubM.publish(self.motorA)\n        else:\n            self.motorB = data\n            d = self.values_distance_AB(self.motorA, self.motorB)\n            if d.data[0] == 0 and d.data[1] == 0 and d.data[2] == 0 and d.data[3] == 0 :\n                self.motorA = self.motorB\n                self.pubM.publish(self.motorA)\n            else:\n                for self.i in range(1,N+1):\n                    M = Int16MultiArray()\n                    if self.motorA.data[0] < self.motorB.data[0]:\n                        M.data.append(self.motorA.data[0] + d.data[0]/N)\n                    else:\n                        M.data.append(self.motorA.data[0] - d.data[0]/N)\n                    if self.motorA.data[1] < self.motorB.data[1]:\n                        M.data.append(self.motorA.data[1] + d.data[1]/N)\n                    else:\n                        M.data.append(self.motorA.data[1] - d.data[1]/N)\n                    if self.motorA.data[2] < self.motorB.data[2]:\n                        M.data.append(self.motorA.data[2] + d.data[2]/N)\n                    else:\n                        M.data.append(self.motorA.data[2] - d.data[2]/N)\n\n                    M.data.append(self.motorB.data[3])\n\n                    self.pubM.publish(M)\n                    self.motorA = M\n                    self.i += 1\n                    time.sleep(0.05)\n# Funzione di callback chiamata alla ricezione di una nuova posizione per l'EE\n# Legge la posizione corrente poi la paragona a quella precedente per calcolare i valori intermedi\n# in 20 steps (N=20)\n    def callback(self,data):\n        N = 20\n        self.i += 1\n        if self.i == 1:\n            self.pointA = data\n            self.pub.publish(self.pointA)\n        else:\n            self.pointB = data\n            d = self.coord_distance_AB(self.pointA, self.pointB)\n            if d.x == 0 and d.y == 0 and d.z == 0:\n                self.pointA = self.pointB\n                self.pub.publish(self.pointA)\n            else:\n                for self.i in range(1,N+1):\n\n                    P = Point()\n\n                    if self.pointA.x < self.pointB.x:\n                        P.x = self.pointA.x + d.x/N\n                    else:\n                        P.x = self.pointA.x - d.x/N\n\n                    if self.pointA.y < self.pointB.y:\n                        P.y = self.pointA.y + d.y/N\n                    else:\n                        P.y = self.pointA.y - d.y/N\n\n                    if self.pointA.z < self.pointB.z:\n                        P.z = self.pointA.z + d.z/N\n                    else:\n                        P.z = self.pointA.z - d.z/N\n                    self.pub.publish(P)\n                    self.pointA = P\n                    self.i += 1\n                    time.sleep(0.05)\n```\n\nNOTA: i valori per i servo possono essere solo interi, l'interpolazione quindi genera valori che possono essere diversi da quelli desiderati.\n\n# 5. Sketch Arduino\n\nPer poter controllare il manipolatore è necessario controllarne i motori con una scheda Arduino su cui verrà eseguito un nodo ROS seriale che leggerà i messaggi sui topic da noi specificati.\nCaricate sulla vostra scheda Arduino il seguente sketch:\n\n```c++\n/*\n * siBOT servo control\n */\n#include <Servo.h>\n#include <ros.h>\n#include <std_msgs/Int16MultiArray.h>\n#define USE_USBCON\n\nros::NodeHandle  nh;\n\nServo servo1, servo2, servo3, servo4;\n\n// Funzione di callback (quando una nuova sequenza di motori viene pubblicata\n// scrivi gli angoli sui rispettivi pin)\nvoid motors_cb( const std_msgs::Int16MultiArray& angles_msg){\n\n  servo1.write(angles_msg.data[0]);\n  servo2.write(angles_msg.data[1]);\n  servo3.write(angles_msg.data[2]);\n  servo4.write(angles_msg.data[3]);\n\n}\n\n// Definizione del subscriber. Notate che il topic è specifico al robot su cui stanno\n// eseguendo i nodi ROS (/hotbot/ in questo caso)\nros::Subscriber<std_msgs::Int16MultiArray> sub(\"/hotbot/motors\",motors_cb);\n\nvoid setup(){\n\n  nh.initNode();\n  nh.subscribe(sub);\n\n  servo1.attach(2); //attach it to pin 2\n  servo2.attach(3);\n  servo3.attach(4);\n  servo4.attach(5);\n}\n\nvoid loop(){\n  nh.spinOnce();\n  delay(1);\n}\n```\n\n# 6. Avvio di Rosserial e run dei nodi\n\nAffinchè il nodo seriale che esegue sulla scheda Arduino venga reso noto al sistema ROS, un nodo python seriale apposito deve essere lanciato. Per fare ciò attraverso la piattaforma, bisogna aprire questo [link](http://cloud.hotblackrobotics.com/cloud/webgui/camera) e cliccare su \"Apri Manager Robot\". Una volta aperta la pagina, dove compare \"rosserial\" cliccare su start per avviare il nodo seriale.\n\nUna volta lanciato il nodo seriale, non ci resta che runnare i nodi necessari al controllo del robot, a seconda del controllo scelto:\n\n- Controllo nello spazio dei motori: motors_generator_sibot, linear_interp_sibot\n- Controllo della posizione dell'EE: positions_generator_sibot, IK_sibot, linear_interp_sibot\n\n# 7. Esercizi\n\n- Scrivere uno sketch chiamato _set_motors_sibot_ che invii una sequenza per i motori ad ogni esecuzione di loop().\n- Scrivere uno sketch chiamato _set_position_sibot_ che invii una posizione per l'EE ad ogni esecuzione di loop().\n\n**Hint**: sfruttate il codice fornito e modificatelo per renderlo più semplice ed usarlo come base per pubblicare sui topic giusti. Inoltre, per fare in modo che l'interpolazione venga eseguita basta runnare lo sketch _linear_interp_sibot_ oltre allo sketch che avrete creato.\n\n**Ciao ciao!** :hibiscus:\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-02-14-sibot-cloud/index.md",
    frontMatter: {
      path: "/hbr/controllare-sibot-dalla-piattaforma-hbr/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "12 mins",
      published: "2018-02-14T00:00:00.000Z",
      publishedReadable: "14 Feb 2018",
      featured: false,
      tags: [],
      title: "Controllare siBOT dalla piattaforma HBR",
      description:
        "Come controllare il manipolatore siBOT utilizzando la piattaforma HBR",
      href: "/hbr/controllare-sibot-dalla-piattaforma-hbr/",
      image: "/content/hbr/2018-02-14-sibot-cloud/cover.png",
      imagePath: "/content/hbr/2018-02-14-sibot-cloud",
    },
  },
  {
    content:
      "\nQualche giorno fa, ho sviluppato un [breve articolo](/2018/01/22/opencv-barcode-reader/) che spiega come implementare\nun sistema in grado di leggere ed analizzare i codici a barre per alimenti\nutilizzando **OpenCV** e la libreria **zbar**, ovviamente in Python.\n\nIn questa guida, voglio estendere il codice implementato nel tutorial precedente\ned integrarlo ad un bot Telegram, in modo che questo sia in grado di leggere le\ninformazioni dal codice a barre ed rispondere all'utente con queste info.\n\n## Vediamo come fare\n\nPer prima cosa, come sempre, dobbiamo creare un [ambiente virtuale](/2017/11/06/virtualenv/) ed installare\npython e le varie dipendenze...\nDobbiamo installare le varie librerie viste nel tutorial precedente più la libreria `telepot`\nper gestire Telegram.\nQuesta volta non la faccio lunga:\n\n```bash\n$ mkdir barcode-telegram\n$ cd barcode-telegram\n$ virtualenv -ppython3 env\n$ source env/bin/activate\n(env)$ pip install telepot pyzbar opencv-python requests\n```\n\nSiamo pronti per iniziare. Ovviamente, partiamo dal codice già implementato nel tutorial\nprecedente. Creiamo un file `bot_barcode.py` ed implementiamo il seguente codice:\n\n```python\nfrom pyzbar.pyzbar import decode\nimport cv2\nimport requests\n\ndef get_barcode_info(img):\n    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    barcodes = decode(gray_img)\n\n    if len(barcodes) == 1:\n        code = barcodes[0].data\n        url = \"https://it.openfoodfacts.org/api/v0/product/{}.json\".format(code)\n        data = requests.get(url).json()\n        if data[\"status\"] == 1:\n            product = data[\"product\"]\n            brand = product[\"brands\"]\n            return \"produttore: {}    nome: {}\".format(product[\"brands\"], product[\"product_name\"])\n        else:\n            return \"Prodotto non trovato!\"\n    else:\n        return \"Codice a barre non trovato!\"\n```\n\nLa funzione `get_barcode_info`, come già spieato in precedenza, riceve un'immagine\nOpenCV e ritorna la stringa contenente le informazioni trovate!\n\nPrecedentemente avevamo impresso le immagini all'interno dell'immagine stessa con\nOpenCV. Questa volta, semplicemente facciamo ritornare queste informazioni a Telegram.\n\nImpostiamo quindi il bot Telegram, implementando il seguente codice:\n\n```python\n# ...\nimport telepot\n\ndef get_barcode_info(img):\n  #...\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n\nTOKEN = '*** inserisci il tuo token qui  ***'\n\nbot = telepot.Bot(TOKEN)\nbot.message_loop(on_chat_message)\n\nprint 'Listening ...'\n\nimport time\nwhile 1:\n    time.sleep(10)\n```\n\nLeggete [questo mio articolo](/2017/04/27/implementiamo-un-bot-telegram-con-python/)\nse non sapete cosa fa il codice implementato su!\n\n### Leggere le immagini da Telegram\n\nPer unire il tutto ci manca un pezzo.. Come facciamo a leggere l'immagine da Telegram\ne passarla alla funzione `get_barcode_info`?\n\nFortunatamente, `Telepot` è già in grado di gestire le immagini. Sfortunatamente\nmette a disposizione un unico metodo che permette di scaricare l'immagine come file su\ndisco.\n\n#### Leggere l'immagine come file\n\nPer leggere l'immagine, il modo più semplice che ho trovato consiste nel salvare\nl'immagine come file e poi leggerla da OpenCV. Questo metodo non è molto efficace\nma funzione, e sarà il punto di partenza per testare il nostro progetto.\n\nPer prima cosa dobbiamo controllare che il `content_type`\nsia di tipo `photo`. Nel caso, possiamo scaricare l'immagine con il comando\n`bot.download_file(msg['photo'][-1]['file_id'], 'image.png')` e a questo punto\nla possiamo leggere il file `image.png` con il comando `cv2.imread`.\n\n```python\nif content_type == 'photo':\n    bot.download_file(msg['photo'][-1]['file_id'], 'image.png')\n    img = cv2.imread('image.png')\n```\n\nFatto questo, basta passare la foto `img` a `get_barcode_info()` e mandare\nla stringa ottenuta come riposta.\n\n```python\n    data = get_barcode_info(img)\n    bot.sendMessage(chat_id, data)\n```\n\nHo notato che il tempo di risposta del bot è lento, quindi per non bloccare\nl'utente aggiungiamo una risposta di \"Attendi\" prima di analizzare la foto.\n\nGestiamo inoltre il caso in cui l'utente invia un dato che non è un'immagine con una\nsemplice risposta automatica.\n\nIl codice completo per la funzione `handle` è quindi il seguente\n\n```python\ndef handle(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'photo':\n        bot.download_file(msg['photo'][-1]['file_id'], 'image.png')\n        img = cv2.imread('image.png')\n        bot.sendMessage(chat_id, \"Sto cercando...\")\n        data = get_barcode_info(img)\n        bot.sendMessage(chat_id, data)\n    else:\n      bot.sendMessage(chat_id, \"Inviami una foto contenente un codice a barre!\")\n```\n\nSiamo pronti per testare il bot. Avviamo il programma\n\n```bash\n(env)$ python bot-barcode.py\n```\n\nE iniziamo a comunicare con il bot. Se tutto funziona, dovrebbe essere in grado di\nrispondere correttamente, come segue!\n\n![Bot Telegram Legge i Codici a Barre](./telegram.png)\n\n#### Evitare di salvare l'immagine su file\n\nIl salvataggio dell'immagine su file e poi il ricaricamento di qeusta in memoria\nnon è molto efficiente in quanto spreca tempo (di lettura e scrittura) e risorse (Hard Disk).\nLitigandoci un po', ho però\ntrovato una soluzione efficace che sfrutta il modulo nativo di Python3 `io.BytesIO`,\nche essenzialmente simula un file caricato in memoria RAM (quindi che non viene veramente\nsalvato su disco). Quello che dobbiamo, è creare un file `io.BytesIO`, salvare\nl'immagine su questo file e poi leggerla con OpenCV. Il tutto è dato da queste linee di codice:\n\n```python\n    raw_img = io.BytesIO()\n    bot.download_file(msg['photo'][-1]['file_id'], raw_img)\n    file_bytes = np.fromstring(raw_img.getvalue(), dtype=np.uint8)\n    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n```\n\nChe richiedono di importare le seguenti librerie\n\n```python\nimport io\nimport numpy as np\n```\n\nLa funzione modificata diventa la seguente\n\n```python\ndef handle(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'photo':\n        raw_img = io.BytesIO()\n        bot.download_file(msg['photo'][-1]['file_id'], raw_img)\n        file_bytes = np.fromstring(raw_img.getvalue(), dtype=np.uint8)\n        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n        bot.sendMessage(chat_id, \"Sto cercando...\")\n        data = get_barcode_info(img)\n        bot.sendMessage(chat_id, data)\n    else:\n      bot.sendMessage(chat_id, \"Inviami una foto contenente un codice a barre!\")\n```\n\nProvate a lanciare il codice. Noterete che è molto più veloce di quello precedente!\n\n## Codice completo\n\nQui trovate il codice completo sviluppato in questo articolo\n\n```python\nfrom pyzbar.pyzbar import decode\nimport requests\nimport telepot\nimport cv2\nimport numpy as np\nimport io\n\ndef get_barcode_info(img):\n    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    barcodes = decode(gray_img)\n\n    if len(barcodes) == 1:\n        code = barcodes[0].data\n        url = \"https://it.openfoodfacts.org/api/v0/product/{}.json\".format(code)\n        data = requests.get(url).json()\n        if data[\"status\"] == 1:\n            product = data[\"product\"]\n            brand = product[\"brands\"]\n            return \"produttore: {}    nome: {}\".format(product[\"brands\"], product[\"product_name\"])\n        else:\n            return \"Prodotto non trovato!\"\n    else:\n        return \"Codice a barre non trovato!\"\n\n\ndef handle(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'photo':\n        raw_img = io.BytesIO()\n        bot.download_file(msg['photo'][-1]['file_id'], raw_img)\n        file_bytes = np.fromstring(raw_img.getvalue(), dtype=np.uint8)\n        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n        bot.sendMessage(chat_id, \"Sto cercando...\")\n        data = get_barcode_info(img)\n        bot.sendMessage(chat_id, data)\n    else:\n      bot.sendMessage(chat_id, \"Inviami una foto contenente un codice a barre!\")\n\nTOKEN = '*** inserisci il tuo token qui  ***'\n\nbot = telepot.Bot(TOKEN)\nbot.message_loop(handle)\n\nprint('Listening ...')\n\nimport time\nwhile 1:\n    time.sleep(10)\n```\n\n## Conclusioni\n\nQuesto progetto mi è veramente piaciuto e l'ho trovato super divertente. In realtà,\ncon questo tutorial voglio inaugurare una serie di articoli che sfruttano Telegram\ne la Computer Vision (con OpenCV) per sviluppare bot in grado di fare Image Processing.\n\nSe qualcuno ha possibili applicazioni per queste tecnologie, me lo dica sotto nei commenti, potremmo\nfarla diventare un tutorial!!\n\nA presto.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-01-31-telegram-opencv-barcode/index.md",
    frontMatter: {
      path: "/2018/01/31/telegram-opencv-barcode/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2018-01-31T00:00:00.000Z",
      publishedReadable: "31 Gen 2018",
      featured: false,
      tags: ["Python", "Telegram", "OpenCV", "Barcode"],
      title:
        "Sviluppiamo un bot Telegram che legge i codici a barre degli alimenti",
      description:
        "Implementiamo un bot Telegram in grado di leggere ed analizzare le immagini per la lettura ed interpretazione dei codici a barre",
      href: "/2018/01/31/telegram-opencv-barcode/",
      image: "/content/blog/it/2018-01-31-telegram-opencv-barcode/main.jpg",
      imagePath: "/content/blog/it/2018-01-31-telegram-opencv-barcode",
    },
  },
  {
    content:
      '\nEhilà!\n\nQuesto post ha l\'obbiettivo di fornire un esempio in codice Python per inviare una posa _goal_ (posizione ed orientamento desiderati) ad un robot, nel mio caso un robot [TurtleBot3](http://wiki.ros.org/Robots/TurtleBot) simulato, sfruttando la [ROS Navigation Stack](http://wiki.ros.org/navigation). Solitamente, ad un robot autonomo mobile viene richiesto di raggiungere un\'ubicazione desiderata. Per fare ciò, deve avere alcune informazioni e combinarle tra loro: avere una mappa dell\'ambiente in cui si trova, percepire ciò che lo circonda, localizzare se\' stesso e pianificare i propri movimenti. La ROS Navigation Stack assume il ruolo di "guidare" la base mobile a muoversi verso quell\'obbiettivo, evitando eventuali ostacoli e mettendo insieme tutte le informazioni a disposizione.\nUsando codice, l\'utente può inviare alla navigation stack una posa desiderata da far assumere al robot. Per scrivere il nodo correttamente, ho seguito il [tutorial per il nodo C++ "Sending Goals to the Navigation Stack"](http://wiki.ros.org/navigation/Tutorials/SendingSimpleGoals), quindi il mio scopo è quello di darvi un equivalente per il nodo Python.\n\n**Nota**: Uso ROS Kinetic. Assumerò che il lettore abbia conoscenze a proposito di [Nodi ROS](http://wiki.ros.org/Nodes), [Topics](http://wiki.ros.org/Topics), [Messaggi](http://wiki.ros.org/msg) e [Actions](http://wiki.ros.org/actionlib#Overview). Alcune informazioni a proposito di queste ultime verranno date durante la descrizione delle librerie.\n\n# 1. La libreria **_actionlib_**\n\nLa ROS navigation stack è basata sulle ROS Actions: infatti le Actions sono la scelta migliore nei casi in cui un nodo voglia inviare una richiesta ad un altro nodo e riceverà una risposta dopo un tempo relativamente lungo. Per evitare che l\'utente si chieda che cosa stia succedendo e se tutto stia andando come desiderato o meno, le Actions implementano un meccanismo di _feedback_, il quale permette all\'utente di ricevere informazioni di tanto in tanto. Le Actions sono basate sul paradigma Client-Server: la [libreria **actionlib**](http://wiki.ros.org/actionlib#Client-Server_Interaction) fornisce gli strumenti e un\'interfaccia per creare un Action Server che esegua le richieste di goal inviate dal Client. Gli elementi principali del meccanismo delle ROS actions sono: _goal_, _result_, e _feedback_. Ognuno di essi è specificato da un tipo di Messaggio ROS, contenuto in un _action definition file_, con estensione "_.action_".\n\nPer maggiori informazioni fate riferimento alla [descrizione dettagliata di actionlib](http://wiki.ros.org/actionlib/DetailedDescription).\n\n# 2. Il nodo MoveBase\n\nIl [nodo ROS move_base](http://wiki.ros.org/move_base), è il componente più importante della navigation stack il quale permette di configurare, runnare ed interagire con quest\'ultima. Il nodo move*base implementa un \\_SimpleActionServer*, un action server con la restrizione di ricevere un solo goal alla volta, che riceve goals in messaggi di tipo [_geometry_msgs/PoseStamped_](http://docs.ros.org/api/geometry_msgs/html/msg/PoseStamped.html). Per comunicare con questo nodo, viene usata l\'interfaccia SimpleActionClient. Il nodo move_base cerca di raggiungere la posa desiderata combinando un motion planner globale ed uno locale per portare a termine il task di navigazione il quale include evitare ostacoli.\n\n<p align="center">\n    <image src="/assets/imgs/2018-01-29-goal/movebase.png"/>\n</p>\n\\n\n# 3. Creazione del Nodo - Codice\nEcco qui il codice dell\'intero nodo senza commenti. Per i commenti andate alla [Sezione 4](#4-creazione-del-nodo---codice-e-commenti).\n\n```python\n#!/usr/bin/env python\n# license removed for brevity\n\nimport rospy\nimport actionlib\nfrom move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\n\ndef movebase_client():\n\n    client = actionlib.SimpleActionClient(\'move_base\',MoveBaseAction)\n    client.wait_for_server()\n\n    goal = MoveBaseGoal()\n    goal.target_pose.header.frame_id = "map"\n    goal.target_pose.header.stamp = rospy.Time.now()\n    goal.target_pose.pose.position.x = 0.5\n    goal.target_pose.pose.orientation.w = 1.0\n\n    client.send_goal(goal)\n    wait = client.wait_for_result()\n    if not wait:\n        rospy.logerr("Action server not available!")\n        rospy.signal_shutdown("Action server not available!")\n    else:\n        return client.get_result()\n\nif __name__ == \'__main__\':\n    try:\n        rospy.init_node(\'movebase_client_py\')\n        result = movebase_client()\n        if result:\n            rospy.loginfo("Goal execution done!")\n    except rospy.ROSInterruptException:\n        rospy.loginfo("Navigation test finished.")\n```\n\n# 4. Creazione del Nodo - Codice e commenti\n\nEcco qui il codice completo di commenti. L\'intero codice del nodo senza commenti è dato nella [Sezione 3](#3-creazione-del-nodo---codice).\n\n```python\n#!/usr/bin/env python\n# license removed for brevity\n\nimport rospy\n\n# Importa il SimpleActionClient\nimport actionlib\n# Importa il file .action ed i messaggi usati dalla move base action\nfrom move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\n\ndef movebase_client():\n\n   # Crea un action client chiamato "move_base" con action definition file "MoveBaseAction"\n    client = actionlib.SimpleActionClient(\'move_base\',MoveBaseAction)\n\n   # Aspetta che l\'action si sia avviato ed abbia iniziato ad essere ricettivo per i goal\n    client.wait_for_server()\n\n   # Crea un nuovo goal con il costruttore MoveBaseGoal\n    goal = MoveBaseGoal()\n    goal.target_pose.header.frame_id = "map"\n    goal.target_pose.header.stamp = rospy.Time.now()\n   # Muovere di 0.5 metri avanti lungo l\'asse x del sistema di riferimento della mappa\n    goal.target_pose.pose.position.x = 0.5\n    goal.target_pose.pose.orientation.w = 1.0\n\n   # Invia il goal all\'action server.\n    client.send_goal(goal)\n   # Aspetta che il server finisca di eseguire la richiesta\n    wait = client.wait_for_result()\n   # Se il risultato non arriva, assumiamo che il Server non sia disponibile\n    if not wait:\n        rospy.logerr("Action server not available!")\n        rospy.signal_shutdown("Action server not available!")\n    else:\n    # Restituisce il risultato dell\'esecuzione dell\'action\n        return client.get_result()\n\n# Se il nodo Python viene eseguito come processo principale (eseguito direttamente)\nif __name__ == \'__main__\':\n    try:\n       # Inizializza un nodo rospy per permettere al SimpleActionClient di interagire in ROS\n        rospy.init_node(\'movebase_client_py\')\n        result = movebase_client()\n        if result:\n            rospy.loginfo("Goal execution done!")\n    except rospy.ROSInterruptException:\n        rospy.loginfo("Navigation test finished.")\n```\n\nAbbiamo finito! Questo è un semplice esempio di nodo Python per inviare una posa desideata alla navigation stack per muovere un robot mobile. Come potete notare, per motivi di semplicità, essendo questo un tutorial base, non vengono sfruttati i meccanismi di feedback propri delle Actions ed il risultato non è indicativo del reale status del goal. Per avere un esempio più completo, vi consiglio la lettura del post ["Inviare una sequenza di Goals alla ROS NavStack usando Python"]({{ site.baseurl }}{% post_url /it/blog/2018-01-29-seq-goals-py %}).\n\n**Grazie per l\'attenzione e a presto!** :hibiscus:\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-01-29-action-client-py/index.md",
    frontMatter: {
      path: "/hbr/inviare-goals-alla-navigation-stack-versione-nodo-ros-python/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "4 mins",
      published: "2018-01-29T00:00:00.000Z",
      publishedReadable: "29 Gen 2018",
      featured: false,
      tags: [],
      title: "Inviare Goals alla Navigation Stack - versione nodo ROS Python",
      description:
        "Inviare un goal all ROS navigation stack utilizzando un nodo Python",
      href: "/hbr/inviare-goals-alla-navigation-stack-versione-nodo-ros-python/",
      image: "/content/hbr/2018-01-29-action-client-py/cover.png",
      imagePath: "/content/hbr/2018-01-29-action-client-py",
    },
  },
  {
    content:
      '\n![cover](./coverpost.png)\n\nCiao a tutti!\n\nSe avete letto il mio post, ["Inviare Goals alla Navigation Stack - versione nodo ROS Python"]({{ site.baseurl }}{% post_url /it/blog/2018-01-29-action-client-py %}), adesso dovreste essere in grado di inviare un singlo goal ad un robot mobile usando un nodo python. Che ne dite, invece, di inviare una _sequenza_ di pose desiderate? In questo post vi fornirò un esempio per inviare diverse pose desiderate (posizioni cartesiane + orientamento espresso con i quaternioni) per una base mobile alla [ROS Navigation Stack](http://wiki.ros.org/navigation). Questo tutorial è sviluppato scegliendo come base mobile il robot TurtleBot 3 simulato, ma il nodo python è valido per qualunque robot scelto. Prima farò una panoramica sulla soluzione adattata e poi verrà spiegato il codice.\n\n**Nota**: Uso ROS Kinetic. Assumerò che il lettore abbia conoscenze a proposito di [Nodi ROS](http://wiki.ros.org/Nodes), [Topics](http://wiki.ros.org/Topics), [Messaggi](http://wiki.ros.org/msg), [Actions](http://wiki.ros.org/actionlib#Overview) e Parametri ROS [ROS Parameters](http://wiki.ros.org/Parameter%20Server). La lettura del [post]() citato prima e relativa documentazione ROS è consigliata.\n\n# 1. Download del progetto Github e del pacchetto turtlebot3\n\nPer poter lavorare con il mio esempio, clonate il progetto github, che potete trovare [qui](https://github.com/FiorellaSibona/turtlebot3_nav), nella vostra location preferita.\n\nInoltre servirà il pacchetto ROS turtlebot3 per eseguire la simulazione. Per ROS kinetic:\n\n```bash\n sudo apt-get install ros-kinetic-turtlebot3-*\n```\n\n# 2. Goals come parametri ROS\n\nL\'idea è quella di salvare come parametri ROS la sequenza di pose desiderate da far processare all\'Action Server ed eseguire al nostro robot mobile. Una volta che i dati sono salvati sul ROS Parameter Server, possono essere facilmente recuperati e confezionati successivamente in messaggi ROS predefiniti di tipo Goal tramite il nodo Python, in modo tale che possano essere correttamente interpretati ed eseguiti dall\'Action Server.\n\nSalvare i goal come parametri, consente all\'utente di modificare solo il launch file, in cui i parametri sono settati, senza alcuna modifica al codice del nodo.\n\n# 3. Launch files\n\nil launch fil [**movebase_seq.launch**](https://github.com/FiorellaSibona/turtlebot3_nav/blob/devel/catkin_ws/src/simple_navigation_goals/launch/movebase_seq.launch) è molto semplice e, come anticipato, ha il ruolo di settare le positioni e orientamenti desiderati da far assumere alla base mobile. Come potete vedere, il nodo, contenuto nel pacchetto "simple*navigation_goals" e con nome del file specificato nell\'argomento \\_type*, è lanciato con alcuni [_parametri ROS privati_](http://wiki.ros.org/Parameter%20Server#Private_Parameters) specificati nel [tag <_rosparam_>](http://wiki.ros.org/rosparam). Notate che i parametri privati dovranno essere chiamati come _nome_name/nome_parametro_.\n\nPrima viene definita la sequenza di posizioni desiderata nel sistema di riferimento Cartesiano. La lista _p_seq_, per esempio, avendo _n_ punti, deve essere interpretata nel seguente modo:\n\n```\np_seq = [x1,y1,z1,x2,y2,z2,...xn,yn,zn]\n```\n\nDopo viene specificata la sequenza di angoli di impabardata (yaw angles) desiderati, espressi in gradi. Infatti, essendo il movimento del robot mobile sul piano xy, possiamo avere una variazione di orientamento solo attorno all\'asse z del sistema di riferimento della mappa. Sicuramente il nostro robot non può inclinarsi entrando nel pavimento!\n\n<p align="center">\n    <image src="/assets/imgs/2018-01-29-goal/rpy.png" />\n</p>\n\\n\nGli angoli vanno specificati in gradi per mantenere l\'inserimento dati semplice e verranno convertiti in radianti nel nodo. Più dettaglia saranno dati nelle sezioni seguenti.\n\nIl launch file [**gazebo_navigation_rviz.launch**](https://github.com/FiorellaSibona/turtlebot3_nav/blob/devel/catkin_ws/src/simple_navigation_goals/launch/gazebo_navigation_rviz.launch), setta e lancia i nodi necessari alla visualizzazione del Turtlebot simulato con la mappa che ho ottenuto usando la funzionalità di mapping fornita dal pacchetto turtlebot3_slam (il quale sfrutta [gmapping](http://wiki.ros.org/gmapping)).\n\nLa cartella _launch_ contiene anche una copia di alcuni file di launch che normalmente lanceremmo così come sono dal pacchetto turtlebot3 package, ma ho avuto bisogno di fare alcune modifiche per specificare la mia mappa e la mia configurazione di rviz (file contenuti nella cartella [/config](https://github.com/FiorellaSibona/turtlebot3_nav/tree/devel/catkin_ws/src/simple_navigation_goals/config)), per darvi in mano un esempio funzionante e già impostato.\n\n# 4. Nodo Python - Codice\n\nHo usato [questo codice](https://github.com/pirobot/ros-by-example/blob/master/rbx_vol_1/rbx1_nav/nodes/move_base_square.py) come riferimento.\n\nQui c\'è il codice completo senza commenti.Per i commenti guarda la [Sezione 5](#5-nodo-python---codice-e-commenti).\n\n```python\n#!/usr/bin/env python\n# license removed for brevity\n__author__ = \'fiorellasibona\'\nimport rospy\nimport math\n\nimport actionlib\nfrom move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\nfrom actionlib_msgs.msg import GoalStatus\nfrom geometry_msgs.msg import Pose, Point, Quaternion\nfrom tf.transformations import quaternion_from_euler\n\nclass MoveBaseSeq():\n\n    def __init__(self):\n\n        rospy.init_node(\'move_base_sequence\')\n        points_seq = rospy.get_param(\'move_base_seq/p_seq\')\n        yaweulerangles_seq = rospy.get_param(\'move_base_seq/yea_seq\')\n        quat_seq = list()\n        self.pose_seq = list()\n        self.goal_cnt = 0\n        for yawangle in yaweulerangles_seq:\n            quat_seq.append(Quaternion(*(quaternion_from_euler(0, 0, yawangle*math.pi/180, axes=\'sxyz\'))))\n        n = 3\n        points = [points_seq[i:i+n] for i in range(0, len(points_seq), n)]\n        for point in points:\n            self.pose_seq.append(Pose(Point(*point),quat_seq[n-3]))\n            n += 1\n        self.client = actionlib.SimpleActionClient(\'move_base\',MoveBaseAction)\n        rospy.loginfo("Waiting for move_base action server...")\n        wait = self.client.wait_for_server(rospy.Duration(5.0))\n        if not wait:\n            rospy.logerr("Action server not available!")\n            rospy.signal_shutdown("Action server not available!")\n            return\n        rospy.loginfo("Connected to move base server")\n        rospy.loginfo("Starting goals achievements ...")\n        self.movebase_client()\n\n    def active_cb(self):\n        rospy.loginfo("Goal pose "+str(self.goal_cnt+1)+" is now being processed by the Action Server...")\n\n    def feedback_cb(self, feedback):\n        rospy.loginfo("Feedback for goal pose "+str(self.goal_cnt+1)+" received")\n\n    def done_cb(self, status, result):\n        self.goal_cnt += 1\n        if status == 2:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" received a cancel request after it started executing, completed execution!")\n\n        if status == 3:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" reached")\n            if self.goal_cnt< len(self.pose_seq):\n                next_goal = MoveBaseGoal()\n                next_goal.target_pose.header.frame_id = "map"\n                next_goal.target_pose.header.stamp = rospy.Time.now()\n                next_goal.target_pose.pose = self.pose_seq[self.goal_cnt]\n                rospy.loginfo("Sending goal pose "+str(self.goal_cnt+1)+" to Action Server")\n                rospy.loginfo(str(self.pose_seq[self.goal_cnt]))\n                self.client.send_goal(next_goal, self.done_cb, self.active_cb, self.feedback_cb)\n            else:\n                rospy.loginfo("Final goal pose reached!")\n                rospy.signal_shutdown("Final goal pose reached!")\n                return\n\n        if status == 4:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" was aborted by the Action Server")\n            rospy.signal_shutdown("Goal pose "+str(self.goal_cnt)+" aborted, shutting down!")\n            return\n\n        if status == 5:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" has been rejected by the Action Server")\n            rospy.signal_shutdown("Goal pose "+str(self.goal_cnt)+" rejected, shutting down!")\n            return\n\n        if status == 8:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" received a cancel request before it started executing, successfully cancelled!")\n\n    def movebase_client(self):\n        goal = MoveBaseGoal()\n        goal.target_pose.header.frame_id = "map"\n        goal.target_pose.header.stamp = rospy.Time.now()\n        goal.target_pose.pose = self.pose_seq[self.goal_cnt]\n        rospy.loginfo("Sending goal pose "+str(self.goal_cnt+1)+" to Action Server")\n        rospy.loginfo(str(self.pose_seq[self.goal_cnt]))\n        self.client.send_goal(goal, self.done_cb, self.active_cb, self.feedback_cb)\n        rospy.spin()\n\nif __name__ == \'__main__\':\n    try:\n        MoveBaseSeq()\n    except rospy.ROSInterruptException:\n        rospy.loginfo("Navigation finished.")\n\n```\n\n# 5. Nodo Python - Codice e commenti\n\nQui viene dato il codice completo di commenti. Per il codice senza commenti, guarda la [Sezione 4](#4-nodo-python---codice).\n\n```python\n#!/usr/bin/env python\n# license removed for brevity\n__author__ = \'fiorellasibona\'\nimport rospy\nimport math\n\nimport actionlib\nfrom move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\nfrom actionlib_msgs.msg import GoalStatus\nfrom geometry_msgs.msg import Pose, Point, Quaternion\nfrom tf.transformations import quaternion_from_euler\n\n\nclass MoveBaseSeq():\n\n    def __init__(self):\n\n        rospy.init_node(\'move_base_sequence\')\n        points_seq = rospy.get_param(\'move_base_seq/p_seq\')\n        # Sono necessari solo gli angoli di imbardata (no rotazioni attorno agli assi x e y) in gradi:\n        yaweulerangles_seq = rospy.get_param(\'move_base_seq/yea_seq\')\n        # Lista dei quaternioni desiderati:\n        quat_seq = list()\n        # Lista delle pose desiderate:\n        self.pose_seq = list()\n        self.goal_cnt = 0\n        for yawangle in yaweulerangles_seq:\n            # Spacchettamento della lista di quaternioni e passaggio dei valori al costruttore del messaggio Quaternion\n            quat_seq.append(Quaternion(*(quaternion_from_euler(0, 0, yawangle*math.pi/180, axes=\'sxyz\'))))\n        n = 3\n        # Restituisce una lista di liste[[point1], [point2],...[pointn]]\n        points = [points_seq[i:i+n] for i in range(0, len(points_seq), n)]\n        for point in points:\n            #Sfrutta la variabile n per ciclare in quat_seq\n            self.pose_seq.append(Pose(Point(*point),quat_seq[n-3]))\n            n += 1\n        #Crea un action client\n        self.client = actionlib.SimpleActionClient(\'move_base\',MoveBaseAction)\n        rospy.loginfo("Waiting for move_base action server...")\n        wait = self.client.wait_for_server(rospy.Duration(5.0))\n        if not wait:\n            rospy.logerr("Action server not available!")\n            rospy.signal_shutdown("Action server not available!")\n            return\n        rospy.loginfo("Connected to move base server")\n        rospy.loginfo("Starting goals achievements ...")\n        self.movebase_client()\n\n    def active_cb(self):\n        rospy.loginfo("Goal pose "+str(self.goal_cnt+1)+" is now being processed by the Action Server...")\n\n    def feedback_cb(self, feedback):\n        #Per stampare la posa corrente ad ogni feedback:\n        #rospy.loginfo("Feedback for goal "+str(self.goal_cnt)+": "+str(feedback))\n        rospy.loginfo("Feedback for goal pose "+str(self.goal_cnt+1)+" received")\n\n    def done_cb(self, status, result):\n        self.goal_cnt += 1\n    # Riferimento per i valori dello goal status: http://docs.ros.org/diamondback/api/actionlib_msgs/html/msg/GoalStatus.html\n        if status == 2:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" received a cancel request after it started executing, completed execution!")\n\n        if status == 3:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" reached")\n            if self.goal_cnt< len(self.pose_seq):\n                next_goal = MoveBaseGoal()\n                next_goal.target_pose.header.frame_id = "map"\n                next_goal.target_pose.header.stamp = rospy.Time.now()\n                next_goal.target_pose.pose = self.pose_seq[self.goal_cnt]\n                rospy.loginfo("Sending goal pose "+str(self.goal_cnt+1)+" to Action Server")\n                rospy.loginfo(str(self.pose_seq[self.goal_cnt]))\n                self.client.send_goal(next_goal, self.done_cb, self.active_cb, self.feedback_cb)\n            else:\n                rospy.loginfo("Final goal pose reached!")\n                rospy.signal_shutdown("Final goal pose reached!")\n                return\n\n        if status == 4:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" was aborted by the Action Server")\n            rospy.signal_shutdown("Goal pose "+str(self.goal_cnt)+" aborted, shutting down!")\n            return\n\n        if status == 5:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" has been rejected by the Action Server")\n            rospy.signal_shutdown("Goal pose "+str(self.goal_cnt)+" rejected, shutting down!")\n            return\n\n        if status == 8:\n            rospy.loginfo("Goal pose "+str(self.goal_cnt)+" received a cancel request before it started executing, successfully cancelled!")\n\n    def movebase_client(self):\n        goal = MoveBaseGoal()\n        goal.target_pose.header.frame_id = "map"\n        goal.target_pose.header.stamp = rospy.Time.now()\n        goal.target_pose.pose = self.pose_seq[self.goal_cnt]\n        rospy.loginfo("Sending goal pose "+str(self.goal_cnt+1)+" to Action Server")\n        rospy.loginfo(str(self.pose_seq[self.goal_cnt]))\n        self.client.send_goal(goal, self.done_cb, self.active_cb, self.feedback_cb)\n        rospy.spin()\n\nif __name__ == \'__main__\':\n    try:\n        MoveBaseSeq()\n    except rospy.ROSInterruptException:\n        rospy.loginfo("Navigation finished.")\n```\n\n- Notate che l\'operatore Pyhton [\\*](https://docs.python.org/2/tutorial/controlflow.html#unpacking-argument-lists) è qui utilizzato come operatore di "spacchettamento", cioè estrae i valori della lista.\n\n- Per ulteriori informazioni riguardo la funzione _quaternion_from_euler_, guardate [qui](https://www.lfd.uci.edu/~gohlke/code/transformations.py.html) and [here](https://answers.ros.org/question/53688/euler-angle-convention-in-tf/).\n\n- Notate che il nodo Python è stato definito come classe per semplificare il codice in caso di uso futuro.\n\n# 6. Setup e simulazione\n\nAdesso che avete capito tutto della mia soluzione (si spera!), dovete solo eseguire i file di launch e vedrete il turtlebot muoversi verso le pose desiderate!\n\n## 6.1. Settare il modello per Turtlebot\n\nPer evitare l\'errore a proposito del modello ogni volta che un nodo del pacchetto turtlebot3 viene lanciato, vi suggerito di eseguire questo comando:\n\n```bash\necho "export TURTLEBOT3_MODEL=burger" >> ~/.bashrc\n```\n\n## 6.2. Lanciare Gazebo e Rviz\n\nRicordate sempre di _runnare_ i file di setup di ROS e di catkin. Quindi eseguite:\n\n```bash\nroslaunch simple_navigation_goals gazebo_navigation_rviz.launch\n```\n\nIl launch file [gazebo_navigation_rviz.launch](https://github.com/FiorellaSibona/turtlebot3_nav/blob/devel/catkin_ws/src/simple_navigation_goals/launch/gazebo_navigation_rviz.launch) avvia Gazebo e Rviz insieme ai nodi di navigazione.\n\n<p align="center">\n    <image src="/assets/imgs/2018-01-29-goal/6.2.0.png"  height="250"/>\n    <image src="/assets/imgs/2018-01-29-goal/6.2.1.png"  height="250" />\n</p>\n\n## 6.3. Settare la posa corrente di Turtlebot\n\nPer eseguire tutti gli step per spostarsi alle pose desiderate, il turtlebot ha bisogno di sapere (almeno approssimativamente) dove si trova sulla mappa. Per fare ciò, in Rviz, premete il bottone **2D Pose Estimate**, cliccate poi nella posizione approssimativa dove viene visualizzato il turtlebot in Gazebo e, prima di rilasciare, settate anche il suo orientamento.\n\n<p align="center">\n    <image src="/assets/imgs/2018-01-29-goal/6.3.2.png"  height="30"/>\n</p>\n<p align="center">\n    <image src="/assets/imgs/2018-01-29-goal/6.2.1.png"  height="250"/>\n    <image src="/assets/imgs/2018-01-29-goal/6.3.0.png"  height="250" />\n</p>\n<p align="center">\n    <image src="/assets/imgs/2018-01-29-goal/6.2.1.png"  height="250"/>\n    <image src="/assets/imgs/2018-01-29-goal/6.3.1.png"  height="250"/>\n</p>\n\n## 6.4. Lanciare il nodo movebase_seq e caricare i parametri\n\nIn un nuovo terminale eseguire il seguente comando:\n\n```bash\nroslaunch simple_navigation_goals movebase_seq.launch\n```\n\nLa pianificaione di navigazione può necessitare di alcuni istanti ma dovreste vedere il turtlebot andare verso le pose desiderate definite nel launch file.\nIl percorso _verde_ è quello calcolato dal global planner mentre quello _blu_ è il path calcolato dal local planner il quale cambia frequentemente, a seconda della percezione del robot di ciò che lo circonda, nel tempo.\n\n<p align="center">\n    <image src="/assets/imgs/2018-01-29-goal/6.4.0.png"  height="250"/>\n    <image src="/assets/imgs/2018-01-29-goal/6.4.1.png"  height="250"/>\n</p>\n\nSul terminale dovreste vedere alcune informazioni a proposito di come sta procedendo l\'esecuzione del goal corrente.\n\nAdesso dovreste avere un esempio funzionante per inviare una sequenza di pose alla navigation stack sul vostro robot.\n\n**A presto!** :hibiscus:\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-01-29-seq-goals-py/index.md",
    frontMatter: {
      path: "/hbr/inviare-una-sequenza-di-goals-alla-ros-navstack-usando-python/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "8 mins",
      published: "2018-01-29T00:00:00.000Z",
      publishedReadable: "29 Gen 2018",
      featured: false,
      tags: [],
      title: "Inviare una sequenza di Goals alla ROS NavStack usando Python",
      description:
        "Inviare una sequenza di pose desiderate alla ROS Navigation Stack usando un nodo Python",
      href: "/hbr/inviare-una-sequenza-di-goals-alla-ros-navstack-usando-python/",
      image: "/content/hbr/2018-01-29-seq-goals-py/cover_seq_ita.png",
      imagePath: "/content/hbr/2018-01-29-seq-goals-py",
    },
  },
  {
    content:
      "\nPer varie ragioni e problemi lavorativi, scrivo questo tutorial con molto\nritardo nella tabella di marcia (circa 2 mesi).\nMa finalmente ho trovato il tempo per riprenderlo!\n\n#### Perciò...\n\nBenvenuti nella seconda parte del mio articolo su TDD e Flask per lo sviluppo di REST API.\nNella prima parte, abbiamo visto come impostare il nostro ambiente di test e\nabbiamo sviluppato una semplicissima app che risponde con 200 all'endpoint `/`.\n\nIn questa parte vedremo come definire sviluppare l'autenticazione utilizzando\nil protocollo JWT (JSON Web Token), sempre adottando il TDD.\n\nCome detto nel tutorial precedente, l'idea è di utilizzare meno framework possibile,\nanche per far capire al meglio il funzionamento dell'autenticazione in Flask.\n\nPartiamo subito!!\n\n## Rispondere in JSON\n\nCome detto la volta scorsa, vogliamo che la nostra app risponda come API JSON, e non\ndirettamente in html. Attualmente infatti, l'app risponde automaticamente in HTML, in quanto\nè il comportamento standard di Flask.\n\nVediamo come cambiare questo comportamento tramite approccio TDD.\nScriviamo quindi un test che testa il fatto che l'app risponda tramite JSON. Per farlo,\nimplementiamo il seguente codice nel file `tests.py`:\n\n```python\ndef test_app_returns_json(client):\n    res = client.get('/')\n    assert res.headers['Content-Type'] == 'application/json'\n```\n\nIl codice non fa altro che leggere l'header della risposta di una chiamata all'app e verificare\nil parametro `Content-Type`, che indica il tipo di dato con cui è codificata la risposta.\nNel caso di codice html, ci aspettiamo che questo sia `text/html`, ma noi vogliamo che\nquesto diventi `application/json`.\n\nLanciamo il test, e, come ci aspettiamo, l'ultimo test scritto genera un'eccezione:\n\n```\n(env)\n=================================== FAILURES ===================================\n____________________________ test_app_returns_json _____________________________\n\nclient = <FlaskClient <Flask 'app'>>\n\n    def test_app_returns_json(client):\n        res = client.get('/')\n>       assert res.headers['Content-Type'] == 'application/json'\nE       AssertionError: assert 'text/html; charset=utf-8' == 'application/json'\nE         - text/html; charset=utf-8\nE         + application/json\n\ntests.py:18: AssertionError\n```\n\nChe ci informa che il contenuto della riposta è di tipo `text/html` e non `application/json`.\n\nSiamo autorizzati, quindi, a modificare il codice.\n\nApriamo il file `app.py` ed iniziamo a modificare il codice implementato.\nIn particolare, per realizzare un'app in grado di rispondere con API JSON, utilizzeremo\nl'estensione `Flask-JSON`, che fa proprio il lavoro che serve a noi.\n\nInstalliamo il pacchetto con il comando `pip install flask-json` e modifichiamo il codice.\n\n1. Per prima cosa, dobbiamo importare `FlaskJSON` e `as_json` dalla libreria `flask_json`.\n\n```python\nfrom flask_json import FlaskJSON, as_json\n```\n\n2. Inizializzamo l'app con l'oggetto `FlaskJSON`della funzione `create_app`.\n\n```python\n#...\ndef create_app():\n    app = Flask(__name__)\n    FlaskJSON(app)\n    # ...\n```\n\n3. Fatto questo, possiamo utilizzare il decoratore `@as_json` sulla funzione `main`,\n   che trasforma in json quello che viene ritornato dalla funzione (a\n   patto che sia un dizionario o una lista e, in generale, un oggetto serializzabile) e\n   trasforma la risposta in risposta json.\n\n```python\n# ...\n@app.route('/')\n@as_json\ndef main():\n    return {}\n#...\n```\n\nSi noti che al momento la funzione `main()` ritorna un dizionario vuoto. Non ci interessa\n(non c'è un test apposito) cosa ritorni questa funziona, l'unica cosa che ci interessa è che\nsia un oggetto serializzabile.\n\nRilanciamo il test, che questa volta dovrebbe passare senza nessun grosso problema.\n\n```\n(env)$ pytest tests.py\n=========================================================== test session starts ===========================================================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 2 items\n\ntests.py ..\n```\n\nPer ora, saltiamo la parte di _refactoring_, e concludiamo qui il secondo ciclo red-green-refactor.\n\nCome vedete, sono andato più spedito dell'altra volta! Stiamo iniziando ad imparare!! :D\n\n## Autenticazione con JWT\n\nSiamo finalmente arrivati a fare cose interessanti. Adesso il codice si inspessisce e\nsi complica un pochettino, perchè vogliamo sviluppare il sistema di autenticazione utilizzando la tecnologie JWT.\n\nVi ho parlato di JWT e Flask in un mio [precedente tutorial](/2017/06/12/gestire-l-autenticazione-in-flask-con-flask-jwt-extended/), in cui\nho spiegato lo scopo ed il funzionamento della tecnologia ed implementato un semplice\nsistema di autenticazione con il pacchetto [Flask-JWT-extended](http://flask-jwt-extended.readthedocs.io/en/latest/).\n\nPer la spiegazione tecnica su JWT vi rimando al mio precedente tutorial,\nma per completezza di questo, vi rispiego qui sotto brevemente che problema\nrisolve e come si usa.\n\n### Come funziona JWT\n\nEssenzialmente, JWT è uno standard aperto evita il problema di dover continuamente\nmandare `username` e `password` ad una webapp che utilizza JSON.\nIn modo da evitare i rischi che questi vengano intercettati da potenziali hacker.\nPer fare questo, creeremo un endpoint `/login` nella nostra piattaforma, che risponde\nad una _post request_ contenente _username_ e _password_ dell'utente che si vuole registrare.\n\nNel caso in cui le informazioni risultino corrette, il metodo ritornerà un token\nJWT che codifica, in modo univoco e con firma crittografata, l'utente stesso.\nQuesto token potrà essere poi usato per accede ai vari URL protetti come autenticazione,\nsenza che l'utente debba nuovamente rinviare la propria password. Il token JWT\navrà al proprio interno anche una _data di scadenza_, dopo la quale non sarà più\nvalido e l'utente dovrà nuovamente inserire le credenziali per richiederne uno nuovo.\n\nSi noti che le informazioni contenute all'interno del token non sono crittografate,\nsono cioè accessibili a chiunque acceda al token stesso. Il token però è firmato\ndigitalmente, ciò vuol dire che le informazioni non possono essere modificate da\nun malintenzionato.\n\nIn questo tutorial, non utilizzeremo direttamente `Flask-JWT-extended`, ma\nimplementeremo il sistema completo di autenticazione noi stessi. Useremo la libreria [pyjwt](https://pyjwt.readthedocs.io/en/latest/) che implementa lo standard JWT in Python.\n\n### Il database\n\nOvviamente, l'autenticazione richiede un database. Per il momento non complichiamoci\nla vita implementandolo, ma sviluppiamo un semplice modulo db che tiene in memoria\nle informazioni che normalmente sarebbero contenute nel database.\n\nPer farlo, implementiamolo come semplice dizionario nella forma `{\"username\": (info, password)}`\nall'interno di un oggetto `FakeDB` che permette di:\n\n1. Aggiungere utenti con il medoto `db.add_user(username, password, info={})`,\n2. Recuperare le info di un utente con il metodo `db.get_user(username)`,\n3. Controllare che la password sia corretta con un metodo `db.verify_user(username, password)`.\n\nCome sempre, prima di implementare il codice, scriviamo delle funzioni per testare\nil nostro modulo nel file `tests.py`:\n\n```python\n#...\nfrom app import FakeDB\n\n#...\n@pytest.fixture\ndef db():\n    return FakeDB()\n\ndef test_db_get_user(db):\n    db.add_user(\"test@test.com\", \"password\", {\"name\": \"test\"})\n    user = db.get_user(\"test@test.com\")\n    assert user[\"username\"] == \"test@test.com\"\n    assert user[\"name\"] == \"test\"\n\ndef test_db_get_not_known_user(db):\n    with pytest.raises(KeyError):\n        user = db.get_user(\"nouser@test.com\")\n\ndef test_db_password_check(db):\n    db.add_user(\"test@test.com\", \"password\", {\"name\": \"test\"})\n    assert db.check_user(\"test@test.com\", \"password\") == True\n    assert db.check_user(\"test@test.com\", \"wrong\") == False\n    assert db.check_user(\"nouser@test.com\", \"password\") == False\n```\n\nIl codice implementato è abbastanza semplice.\n\n1. Per prima cosa, importiamo il modulo `FakeDB` da `app`.\n2. Definiamo la nuova **fixture** che crea un oggetto `FakeDB` e lo ritorna.\n\n```python\n@pytest.fixture\ndef db():\n    return FakeDB()\n```\n\n3. A quanto punto, definiamo tre test.\n\n- `test_db_get_user` e `test_db_password_check` sono banali, in quanto testano che le\n  informazioni di un utente vengano effettivamente rilasciate corrette e che il password_check\n  funzioni bene.\n- `test_db_get_not_known_user` è nuova, ed in particolare testa un'eccezione. In particolare,\n  il context aperto da `with pytest.raises(KeyError)` fallisce solo se il codice\n  al suo interno non rilascia l'eccezione `KeyError`. In altre parole, testiamo che, se si fa la get\n  di un utente che non è inserito nel database, questo generi l'eccezione `KeyError`.\n\nLanciamo il test:\n\n```\ntests.py:3: in <module>\n    from app import FakeDB\nE   ImportError: cannot import name 'FakeDB'\n```\n\nChe fallisce perchè non è definito l'oggetto `FakeDB`. Definiamolo quindi in\n`app.py` con lo scheletro dei metodi da implementare:\n\n```python\nclass FakeDB(object):\n    def __init__(self):\n        pass\n\n    def add_user(self, username, password, data={}):\n        pass\n\n    def get_user(self, username):\n        return {}\n\n    def check_user(self, username, password):\n        return True\n```\n\nE rilanciamo il test:\n\n```\n================================================================ FAILURES =================================================================\n____________________________________________________________ test_db_get_user _____________________________________________________________\n\ndb = <app.FakeDB object at 0x10524e748>\n\n    def test_db_get_user(db):\n        db.add_user(\"test@test.com\", \"password\", {\"name\": \"test\"})\n        user = db.get_user(\"test@test.com\")\n>       assert user[\"username\"] == \"test@test.com\"\nE       KeyError: 'username'\n\ntests.py:28: KeyError\n_______________________________________________________ test_db_get_not_known_user ________________________________________________________\n\ndb = <app.FakeDB object at 0x1051dfdd8>\n\n    def test_db_get_not_known_user(db):\n        with pytest.raises(KeyError):\n>           user = db.get_user(\"nouser@test.com\")\nE           Failed: DID NOT RAISE <class 'KeyError'>\n\ntests.py:33: Failed\n_________________________________________________________ test_db_password_check __________________________________________________________\n\ndb = <app.FakeDB object at 0x1052757b8>\n\n    def test_db_password_check(db):\n        db.add_user(\"test@test.com\", \"password\", {\"name\": \"test\"})\n        assert db.check_user(\"test@test.com\", \"password\") == True\n>       assert db.check_user(\"test@test.com\", \"wrong\") == False\nE       AssertionError: assert True == False\nE        +  where True = <bound method FakeDB.check_user of <app.FakeDB object at 0x1052757b8>>('test@test.com', 'wrong')\nE        +    where <bound method FakeDB.check_user of <app.FakeDB object at 0x1052757b8>> = <app.FakeDB object at 0x1052757b8>.check_user\n\ntests.py:38: AssertionError\n=================================================== 3 failed, 2 passed in 0.43 seconds ====================================================\n```\n\nCome vedete, abbiamo tre errori, perché nessuno dei tre test scritti passa.\nA questo punto, iniziamo a risolverli uno alla volta. Partiamo da `test_db_get_user`, che fallisce\nperchè la funzione `get_user()` ritorna sempre `{}` (non salviamo nessun dato infatti).\n\nModifichiamo `FakeDB` per salvare i dati e ritornare i dati corretti:\n\n```python\nclass FakeDB(object):\n    def __init__(self):\n        self._db = {}\n\n    def add_user(self, username, password, data={}):\n        data[\"username\"]=username\n        self._db[username] = (password, data)\n\n    def get_user(self, username):\n        return self._db[username][1]\n\n    #...\n```\n\nIl codice è molto facile e banale. Per prima cosa, creiamo un db interno `self._db`\nquando creiamo l'oggetto, quindi nel metodo `__init__`.\n\n```\ndef __init__(self):\n    self._db = {}\n```\n\nA questo punto, implementiamo `add_user` in modo che salvi `password` e `data` all'interno di una tupla.\nMa prima, inseriamo il campo `username` nel dizionario `data`:\n\n```python\ndef add_user(self, username, password, data={}):\n    data[\"username\"]=username\n    self._db[username] = (password, data)\n```\n\nPer finire, implementiamo `get_user` in modo da ritornare il campo `data` (secondo elemento della tupla):\n\n```python\ndef get_user(self, username):\n    return self._db[username][1]\n```\n\nE rilanciamo il test. Noterete una cosa inaspettata:\n\n```\n================================================================ FAILURES =================================================================\n_________________________________________________________ test_db_password_check __________________________________________________________\n\ndb = <app.FakeDB object at 0x103d8b358>\n\n    def test_db_password_check(db):\n        db.add_user(\"test@test.com\", \"password\", {\"name\": \"test\"})\n        assert db.check_user(\"test@test.com\", \"password\") == True\n>       assert db.check_user(\"test@test.com\", \"wrong\") == False\nE       AssertionError: assert True == False\nE        +  where True = <bound method FakeDB.check_user of <app.FakeDB object at 0x103d8b358>>('test@test.com', 'wrong')\nE        +    where <bound method FakeDB.check_user of <app.FakeDB object at 0x103d8b358>> = <app.FakeDB object at 0x103d8b358>.check_user\n\ntests.py:38: AssertionError\n=================================================== 1 failed, 4 passed in 0.43 seconds ====================================================\n```\n\nSia `test_db_get_user` che `test_db_get_not_known_user` si risolvono. Questo perchè\nl'eccezione `KeyError` viene rilasciata da un dizionario quando si accede con una chiave\nche non esiste.\n\nCi manca di risolvere l'ultimo errore, che si fa implementando la funzione `check_user`\ncome segue:\n\n```python\n#...\ndef check_user(self, username, password):\n    try:\n        return self._db[username][0] == password\n    except KeyError:\n        return False\n```\n\nQuesta funzione, semplicemente ritorna il valore di `self._db[username][0] == password`\n(che vale `True`) solo se l'uguaglianza è verificata. Se viene generata l'eccezione `KeyError` (cioè se stiamo cercando di accedere con un username che non esiste), viene ritornato `False`.\n\nLanciamo nuovamente il test, che questa volta non fallirà.\n\n```\n=========================================================== test session starts ===========================================================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 5 items\n\ntests.py .....\n\n======================================================== 5 passed in 0.37 seconds =========================================================\n```\n\nPerfetto, non serve ancora fare refactoring, quindi possiamo andare avanti\ncon l'implementazione dell'endpoint `/login`.\n\n### L'endpoint `/login`\n\nIniziamo finalmente a costruire il nostro endpoint `/login` e, come al solito, partiamo dai test.\n\nIn particolare, dobbiamo verificare le seguenti condizioni:\n\n1. Se vengono mandati dati corretti, `/login` ritorna un token JWT valido, contenente lo username dell'utente.\n2. Se i dati di autenticazione sono sbagliati, `/login` ritorna l'errore `Unauthorized 401` (in questo caso non sono sicurissimo che l'errore sia corretto, ma per ora lasciamo così.. Se qualcuno conosce http meglio di me lo scriva nei commenti :D).\n\nPrima di iniziare, una piccola nota: purtroppo, il `test_client` di `Flask` non gestisce\nautomaticamente le chiamate `JSON`. Questo vuol dire che per inviare un dato JSON solitamente\ndobbiamo scrivere codice del tipo:\n\n```python\nimport JSON\n\nres = post('/test_function', data=json.dumps(dict(foo='bar')), content_type='application/json')\ndata = JSON.loads(res.data)\n```\n\nIl che risulta un po' fastidioso, quando si scrive tanto codice di questo tipo.\nFortunatamente ho trovato [un'elegante soluzione](https://stackoverflow.com/questions/28836893/how-to-send-requests-with-jsons-in-unit-tests) che permette di avere delle API molto più belle:\n\n```python\nres = post('/test_function', json=dict(foo='bar'))\ndata = res.json\n```\n\nPer attuarla, dobbiamo modificare la funzione _fixture_ `app()`, nel file `tests.py` come segue:\n\n```python\n#...\n\nfrom flask import Flask, Response as BaseResponse, json\nfrom flask.testing import FlaskClient\nfrom werkzeug.utils import cached_property\n\n@pytest.fixture\ndef app():\n    class Response(BaseResponse):\n        @cached_property\n        def json(self):\n            return json.loads(self.data)\n\n\n    class TestClient(FlaskClient):\n        def open(self, *args, **kwargs):\n            if 'json' in kwargs:\n                kwargs['data'] = json.dumps(kwargs.pop('json'))\n                kwargs['content_type'] = 'application/json'\n            return super(TestClient, self).open(*args, **kwargs)\n\n    app = create_app()\n    app.response_class = Response\n    app.test_client_class = TestClient\n    app.testing = True\n    return app\n#...\n```\n\nE a questo punto, possiamo iniziare ad implementare due test:\n\nIl primo test controlla l'inserimento di un user name errato:\n\n```python\ndef test_invalid_login(client):\n    res = client.post('/login', json={'username': 'nouser', 'password': 'no password'})\n    assert res.status_code == 401\n    assert res.json['error'] == 'Login Error'\n```\n\nNotate che in questo caso non controllo i vari casi possibili, come l'inserimento\ndi password sbagliata per username corretto, perchè questo controllo è fatto già dai test\nprecedenti.\n\nIl secondo test definisce il comportamento per l'inserimento di un utente corretto.\n\n```python\nimport jwt\n\ndef test_correct_login(client, app):\n    username = \"test@test.com\"\n    password =  \"password\"\n    app.db.add_user(username, password, {\"name\": \"test\"})\n    res = client.post('/login', json={'username': username, 'password': password})\n    assert res.status_code == 200\n    assert \"access_token\" in res.json\n    token = res.json[\"access_token\"]\n    data = wt.decode(token, verify=False)\n    assert data['username'] == username\n\n```\n\nQuesto test è un po' più lungo, perché dobbiamo controllare che le informazioni\ndello username sono correttamente inserite nel token.\nUna volta ottenuto il token JWT da un login corretto, infatti, controlliamo che\nil campo `username` decodificato nel token è corretto.\n\nNotate che invochiamo la funzione `decode` con il parametro `verify=False`. Questo\nviene fatto perchè non ci interessa verificare che la firma digitale sia corretta (nel caso,\nci servirebbe la chiave segreta di cifratura), ma solo che il dato sia corretto.\n\nRicordiamo di installare `pyjwt` con il comando\n\n```bash\n(env) pip install pyjwt\n```\n\nCome ci aspettiamo, entrambi i test falliscono quando lanciamo `pytest`.\n\n```\n================================================================ FAILURES =================================================================\n___________________________________________________________ test_invalid_login ____________________________________________________________\n\nclient = <TestClient <Flask 'app'>>\n\n    def test_invalid_login(client):\n        res = client.post('/login', json={'username': 'nouser', 'password': 'no password'})\n>       assert res.status_code == 401\nE       assert 404 == 401\nE        +  where 404 = <Response streamed [404 NOT FOUND]>.status_code\n\ntests.py:63: AssertionError\n___________________________________________________________ test_correct_login ____________________________________________________________\n\nclient = <TestClient <Flask 'app'>>, app = <Flask 'app'>\n\n    def test_correct_login(client, app):\n        username = \"test@test.com\"\n        password =  \"password\"\n>       app.db.add_user(username, password, {\"name\": \"test\"})\nE       AttributeError: 'Flask' object has no attribute 'db'\n\ntests.py:69: AttributeError\n=================================================== 2 failed, 5 passed in 0.65 seconds ====================================================\n```\n\nMa andiamo con\nordine e risolviamoli uno alla volta. Il test `test_invalid_login` è facile da risolvere,\nbasta implementare uno stupido endpoint che ritorna sempre il codice `401` (lo so,\nla funzione non sarà corretta anche se risolve il test, ma ricordiamoci il mantra TDD: _scrivere sempre il minimo codice possibile per risolvere il test_).\n\n```python\ndef create_app():\n\n    # ...\n    @app.route('/login', methods=['POST'])\n    @as_json\n    def login():\n        return {'error': 'invalid login'}, 401\n\n    return app\n```\n\nPerfetto, questo codice risolve il primo errore, ora possiamo dedicarci al secondo.\n\n```\n================================================================ FAILURES =================================================================\n___________________________________________________________ test_correct_login ____________________________________________________________\n\nclient = <TestClient <Flask 'app'>>, app = <Flask 'app'>\n\n    def test_correct_login(client, app):\n        username = \"test@test.com\"\n        password =  \"password\"\n>       app.db.add_user(username, password, {\"name\": \"test\"})\nE       AttributeError: 'Flask' object has no attribute 'db'\n\ntests.py:69: AttributeError\n=================================================== 1 failed, 6 passed in 0.60 seconds ====================================================\n```\n\nIntanto, il codice termina perchè non esiste l'oggetto `app.db`. Questo deriva da\nfatto che il `db` non viene creato. Risolviamo modificando la funzione `create_app()`:\n\n```python\ndef create_app():\n    app = Flask(__name__)\n    FlaskJSON(app)\n    app.db = FakeDB()\n```\n\nRilanciando il test, otteniamo il seguente errore:\n\n```\n___________________________________________________________ test_correct_login ____________________________________________________________\n\nclient = <TestClient <Flask 'app'>>, app = <Flask 'app'>\n\n    def test_correct_login(client, app):\n        username = \"test@test.com\"\n        password =  \"password\"\n        app.db.add_user(username, password, {\"name\": \"test\"})\n        res = client.post('/login', json={'username': username, 'password': password})\n>       assert res.status_code == 200\nE       assert 401 == 200\nE        +  where 401 = <Response streamed [401 UNAUTHORIZED]>.status_code\n\ntests.py:71: AssertionError\n=================================================== 1 failed, 6 passed in 0.38 seconds ====================================================\n```\n\nOra l'endpoint viene correttamente chiamato, ma (ovviamente), il codice di ritorno è `401`.\nDobbiamo scrivere altro codice per gestire i casi in cui l'utente è effettivamente trovato.\n\nPer farlo, reimplementiamo la funzione `login`:\n\n```python\nfrom flask import Flask, request\n#...\nimport jwt\n\ndef create_app():\n    app = Flask(__name__)\n    #...\n    app.config['SECRET_KEY'] = 'secret_ket'\n\n    #...\n    @app.route('/login', methods=['POST'])\n    @as_json\n    def login():\n        try:\n            username = request.get_json()['username']\n            password = request.get_json()['password']\n            if app.db.check_user(username, password):\n                token = jwt.encode({'username':username}, app.config['SECRET_KEY']).decode('utf-8')\n                return {'access_token': token}\n            else:\n                return {'error': 'invalid login'}, 401\n        except KeyError:\n            return {'error': 'invalid login'}, 401\n```\n\nCome vedete, il codice si è un po' complicato.\nPer prima cosa, abbiamo settato la configurazione `SECRET_KEY` per l'app (`app.config['SECRET_KEY'] = 'secret_ket'`).\nQuesto perchè, per rendere sicura la firma digitale, dobbiamo utilizzare una secret key che solo la nostra app conosce.\nAl momento va bene questa, ma in produzione dovremmo generare una chiava veramente sicura.\n\nA questo punto, la funzione `login` accede a `username` e `password` della richiesta, e\ncontrolla che siano corretti con il metodo `db.check_user`. In caso affermativo, viene generato il `token` con il metodo `jwt.encode` e ritornato tale codice.\n\nIn caso nome utente/password non siano corretti, viene ritornato l'errore `401`. Tale errore è anche ritornato se si verifica l'eccezione `KeyError`, che può essere generata dall'accesso ai parametri `username`/`password` della richiesta, oppure dalla funzione `db.check_user`.\n\nLanciamo il test e controlliamo che non ci siano più errori:\n\n```\n$ pytest tests.py\n=========================================================== test session starts ===========================================================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 7 items\n\ntests.py .......\n\n======================================================== 7 passed in 0.57 seconds =========================================================\n```\n\nDi nuovo, al momento non serve fare refactoring, quindi concludiamo qui il ciclo.\n\n## Fine seconda Parte\n\nBene, siamo arrivati alla fine di questa seconda parte.\nFinalmente abbiamo implementato un sistema di login.\nTale soluzione sarà poi usata nei miei prossimi progetti come sistema di login principale.\nNella prossima parte, vedremo come usare il token che abbiamo ottenuto per\nabilitare l'utente ad accedere ad API private!\n\nCome sempre, segnalatemi qui sotto eventuali errori, e fatemi sapere cosa ne pensate\ndi questo tutorial!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-01-25-tdd-flask-pytest-2/index.md",
    frontMatter: {
      path: "/2018/01/25/tdd-flask-pytest-2/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "13 mins",
      published: "2018-01-25T00:00:00.000Z",
      publishedReadable: "25 Gen 2018",
      featured: false,
      tags: ["Python", "Test Driver Development", "Flask", "PyTest", "JWT"],
      title: "TDD con Flask e PyTest per lo sviluppo di API REST. Parte 2",
      description:
        "Tutorial su come usare il Test Driver Development (TDD) con Flask e PyTest per sviluppare delle semplici API REST",
      href: "/2018/01/25/tdd-flask-pytest-2/",
      image: "/content/blog/it/2018-01-25-tdd-flask-pytest-2/tdd-python-2.png",
      imagePath: "/content/blog/it/2018-01-25-tdd-flask-pytest-2",
    },
  },
  {
    content:
      '\n![](./main.png)\n\nNell\'ultimo weekend si è tenuto l\'evento [**Hackability@Barilla**](http://www.hackability.it/hackabilitybarilla/), l\'ultimo\ndei tanti eventi organizzati dall\'associazione Hackability, di cui faccio parte,\nche legano il mondo del making e della disabilità.\n\nCome membro del team Hackability, ho partecipato all\'evento come _mentor_, con lo scopo di\naiutare i vari tavoli di lavoro a completare i propri concept e prototipi durante\ni due giorni iniziali dell\'evento.\n\nTra i vari progetti dei partecipanti, uno di questi aveva il problema di riuscire\nad estrarre informazioni a partire dai codici a barre degli alimenti (le scatole della pasta\nBarilla, ad esempio), e tradurre queste informazioni in Braille. Non voglio entrare\nnel dettaglio del progetto e dell\'idea (che non è mia), ma voglio prendere spunto\nda questo mini progetto per scrivere questo tutorial.\n\n## Cosa Faremo?\n\nLo scopo del tutorial è, quindi, riuscire ad estrarre delle informazioni (metadati) di\nalimenti a partire dal codice a barre presente sulla scatola. In particolare, useremo\nla libreria [**OpenCV**](https://opencv.org/) per gestire la cattura delle immagini (sia da file che direttamente da\nfotocamera come video stream), e la libreria [**zbar**](http://zbar.sourceforge.net/) per la lettura dei codici a barre.\n\nUna volta letto il codice a barre dalle immagini, useremo un servizio molto interessante\ntrovato su internet, chiamato [Open Food Facts](https://world.openfoodfacts.org/), che mette\na disposizione in database ben fornito (anche se non si trovato tutti i prodotti), con una ricerca\nproprio da codice identificato letto da barcode.\n\nMa andiamo con ordine.\n\n## Lettura del codice a barre con **zbar**\n\n**zbar** è una libreria multipiattaforma che permette in modo veloce la lettura dei\ncodici a barre delle immagini. Per usarla in Python, dobbiamo installare sia la libreria\noriginale (**zbar**) che i wrapper di tale libreria in python (**pyzbar**).\n\nPer installare la libreria, in base al sistema operativo, dobbiamo usare i seguenti comandi.\n\n#### Mac OS\n\n```bash\nbrew install zbar\n```\n\n#### Linux\n\n```bash\nsudo apt-get install libzbar0\n```\n\nSu Windows, la libreria viene automaticamente installata tramite **pyzbar**.\n\nA questo punto, installiamo **pyzbar** all\'interno di un nuovo [ambiente virtuale](https://ludusrusso.cc/2017/11/06/virtualenv/)\n\n```bash\n(env)$ pip install pyzbar\n```\n\nSimilmente, installiamo **OpenCV** per la gestione delle immagini, usando il comando\n\n```bash\n(env)$ pip install opencv-python\n```\n\nA questo punto, siamo pronti per iniziare a scrivere il codice.\n\n### Leggere il codice a barre da un\'immagine salvata su file\n\nIl più semplice programma che possiamo fare sarà in grado di leggere il codice a barre\npresente all\'interno di un\'immagine salvata su file. Creiamo un nuovo file, chiamato\n`barreader.py` ed iniziamo ad implementare il seguente codice.\n\n```python\nfrom pyzbar.pyzbar import decode\nimport cv2\n\nfilename = "img.jpg"\nimg = cv2.imread(filename)\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nbarcodes = decode(gray_img)\nprint(barcodes)\n```\n\nQuesto programma esegue le seguenti operazioni:\n\n1. importiamo il modulo `decode` di `pyzbar` ed il modulo `cv2` (cioè OpenCV).\n\n```python\nfrom pyzbar.pyzbar import decode\nimport cv2\n```\n\n2. leggiamo l\'immagine contenuta nel file `img.jpg` (salvandola nella variabile `img`) e la convertiamo in scala di grigi usando il comando `cv2.cvtColor`.\n\n```python\nfilename = "img.jpg"\nimg = cv2.imread(filename)\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n```\n\n3. leggiamo i codici a barre contenuti nell\'immagine e stampiano a scermo le info lette.\n\n```python\nbarcodes = decode(gray_img)\nprint(barcodes)\n```\n\nSi noti che `barcodes` contiene una lista con tutti i codici a barre trovati all\'interno\ndell\'immagine.\n\nProvando il codice sull\'immagine di sotto (che potete scaricare e testare voi stessi),\ndovreste ottenere il seguente risultato:\n\n```bash\n(env)$ python barreader.py\n[Decoded(data=b\'8076809531191\', type=\'EAN13\')]\n```\n\n![Primo Codice a barre](./img.jpg)\n\n### Ricavare le informazioni dal codice a barre sfruttando **Open Food Facts**\n\nA partire dal codice a barre letto, possiamo ottenere le informazioni dell\'alimento\nandando sul sito [world.openfoodfacts.org](https://world.openfoodfacts.org/) ed inserendo\nil codice (nel mio caso `8076809531191`) all\'interno della barra di ricerca (si veda la figura sotto).\n\n![Ricerca su Open Food Facts](./food.png)\n\nLa cosa interessante, è che il sito mette a disposizione delle web API per ricevere le\ninformazioni contenute nel loro database in formato JSON, quindi facilmente leggibile da\nun programma in Python.\n\nPer accedere alle informazioni in formato JSON, basta costruire il seguente URL:\n`https://it.openfoodfacts.org/api/v0/product/<INSERIRE CODICE DA CERCARE>.json`\n\ndove il codice da cerca va inserito alla fine dell\'URL prima del `.json`. Ad esempio, nel nostro caso, l\'url sarà:\n`https://it.openfoodfacts.org/api/v0/product/8076800105735.json`\n\nInserendo l\'URL ricavato all\'interno del browser (o di un programma di test API come [insomnia](https://insomnia.rest/)), otterremo veramente tante informazioni legate al prodotto in questione.\n\n![Esempio di info JSON restituita da Open Food Facts](./foodapi.png)\n\nLe informazioni contenute sono, ad esempio, il produttore, gli ingredienti, gli allergeni, il nome\ndel prodotto, ecc. Vi riporto un estratto delle info contenute qui sotto:\n\n```json\n{\n  "status": 1,\n  "product": {\n    "...": "...",\n    "nutriments": {\n      "saturated-fat_value": "0.5",\n      "proteins_value": "13",\n      "proteins_100g": "13",\n      "carbohydrates": 65.7,\n      "...": "..."\n    },\n    "allergens_tags": ["en:gluten"],\n    "brands": "Barilla",\n    "product_name": "Fusilli Integrali",\n    "...": "..."\n  },\n  "...": "..."\n}\n```\n\nSi noti che, nel caso in cui non venga trovato nessun elemento nel database, otterremo il\nseguente json:\n\n```json\n{\n  "status": 0,\n  "status_verbose": "product not found",\n  "code": "34983423424930242342"\n}\n```\n\nBasta quindi controllare il valore di `status` per vedere se è stato trovato qualcosa.\n\n### Leggere le info di **Open Food Facts** da Python con **requests**\n\nPer leggere queste informazioni da Python, possiamo sfruttare la libreria [**requests**](http://docs.python-requests.org/en/master/). Ma prima di tutto, dobbiamo\ninstallarla usando il comando\n\n```bash\n(env)$ pip install requests\n```\n\nA questo punto, dobbiamo semplicemente costruire l\'url di ricerca ed usare `requests.get`\nper leggere i dati.\n\n1. Importiamo la libreria ` requests`` con il comando `:\n\n```python\nfrom pyzbar.pyzbar import decode\nimport cv2\nimport requests\n...\n```\n\n2. Una volta elaborata l\'immagine, accediamo al primo elemento della lista `barcodes` (supponiamo che ci sia sempre e solo un codice a barre nelle foto) e costruiamo l\'url usando il metodo `format` di string\n\n```python\n# ...\nbarcodes = decode(gray_img)\ncode = barcodes[0].data\nurl = "https://it.openfoodfacts.org/api/v0/product/{}.json".format(code)\n# ...\n```\n\n3. A questo punto, usando `requests` possiamo fare una query verso il database, controllare\n   che il prodotto sia stato trovato (sfruttando il campo status) e stampare a video alcune informazioni\n\n```python\n# ...\ndata = requests.get(url).json()\nif data["status"] == 1:\n    product = data["product"]\n    brand = product["brands"]\n    print("produttore:", product["brands"])\n    print("nome:", product["product_name"])\n# ...\n```\n\nDi sotto, il codice completo, arricchito di vari `if` - `else` per gestire i possibili errori:\n\n- Codice a barre non trovato nell\'immagine\n- Prodotto non trovato nel database\n\n```python\nfrom pyzbar.pyzbar import decode\nimport cv2\nimport requests\n\nfilename = "img.jpg"\nimg = cv2.imread(filename)\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nbarcodes = decode(gray_img)\n\nif len(barcodes) == 1:\n    code = barcodes[0].data\n    url = "https://it.openfoodfacts.org/api/v0/product/{}.json".format(code)\n    data = requests.get(url).json()\n    if data["status"] == 1:\n        product = data["product"]\n        brand = product["brands"]\n        print("produttore:", product["brands"])\n        print("nome:", product["product_name"])\n    else:\n        print("Prodotto non trovato!")\nelse:\n    print("Codice a barre non trovato!")\n```\n\nLanciando il programma, otterremo questo risultato:\n\n```bash\n(env)$ python barreader.py\nProduttore: Barilla\nNome: Fusilli Integrali\n```\n\n### Leggere il codice direttamente da webcam del computer\n\nPer finire, vediamo come ricavare queste informazioni direttamente da webcam del\ncomputer, invece che da file immagine.\n\nFortunatamente, OpenCV mette a disposizione un metodo molto semplice per leggere\nlo streaming video proveniente da una webcam. Per farlo, infatti, basta utilizzare\nl\'oggetto `cv2.VideoCapture` nel seguente modo:\n\n```python\ncap = cv2.VideoCapture(0)\nwhile(True):\n  ret, frame = cap.read()\n```\n\nIn questo modo, abbiamo creato un ciclo infinito che legge l\'immagine dalla webcam\ne la salva nella variabile `frame`. Il numero inserito all\'interno del comando\n`cv2.VideoCapture(0)` rappresenta l\'id della webcam da utilizzare. Se il computer è dotato di una\nsola webcam, questa avrà id `0` (come nel nostro caso). Se ne abbiamo 2, possiamo accedere ad una o\nall\'altra utilizzando `cv2.VideoCapture(0)` e `cv2.VideoCapture(1)`, e così via.\n\nSolitamente, viene anche comodo visualizzare l\'immagine appena letta a video.\nQuesto si fa usando il seguente codice:\n\n```python\ncap = cv2.VideoCapture(0)\nwhile(True):\n  ret, frame = cap.read()\n  cv2.imshow(\'Codice a Barre\', frame)\n  code = cv2.waitKey(30)\n  if code == ord(\'q\'):\n      break\n```\n\nIn particolare, la funzione `cv2.imshow(\'Codice a Barre\', frame)` crea una finestra (chiamata `Codice a Barre`)\nin cui viene mostrata l\'immagine contenuta nella variabile `frame`.\n\nLa funzione `cv2.imshow` deve sempre essere accompagnata dalla funzione `cv2.waitKey(time)`.\nQuest\'ultima fa in modo che le finestre OpenCV vengano effettivamente renderizzate (senza non si vedrebbe niente), e blocca il programma per un tempo (in millisecondi) pari alla variabile che gli viene\npassata. La funzione ritorna normalmente `-1`, a meno che non venga premuto un tasto sulla tastiera. In questo caso, ritorna il codice ASCII corrispondente al tasto premuto.\n\nLe ultime due righe del ciclo controllano che sia stato premuto il tasto `q` da tastiera, e, in caso positivo, terminano il ciclo while.\n\n```python\nif code == ord(\'q\'):\n    break\n```\n\nLanciando il codice su, quindi, dovrebbe aprirsi una finestra che mostra la vostra telecamera,\ncome in figura sotto:\n\n![Finestra OpenCV](./opencv.png)\n\n### Mettiamo tutto insieme\n\nA questo punto, non ci resta che mettere tutto insieme per leggere i dati del codice\na barre contenuto in frame.\n\nPer prima cosa, modifichiamo il codice che legge le info del codice a barre implementato sopra\nin modo che diventi una funzione, che prende l\'immagine da analizzare e restituisce il testo.\n\n```python\ndef get_barcode_info(img):\n    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    barcodes = decode(gray_img)\n\n    if len(barcodes) == 1:\n        code = barcodes[0].data\n        url = "https://it.openfoodfacts.org/api/v0/product/{}.json".format(code)\n        data = requests.get(url).json()\n        if data["status"] == 1:\n            product = data["product"]\n            brand = product["brands"]\n            return "produttore: {}    nome: {}".format(product["brands"], product["product_name"])\n        else:\n            return "Prodotto non trovato!"\n    else:\n        return "Codice a barre non trovato!"\n```\n\nCome vedete, il codice non è cambiato molto. La più grande differenza è che, adesso, invece\ndi stampare a video le informazioni vengono ritornate come stringa.\n\nA questo punto, non ci resta che passare la variabile `frame` alla funzione appena sviluppata,\nricavare le informazioni e stamparle sull\'immagine.\n\n```python\nwhile(True):\n  ret, frame = cap.read()\n  info = get_barcode_info(frame)\n  # ...\n```\n\nPer fare questo, usiamo la funzione `cv2.putText()` di OpenCV, che prende, nell\'ordine,\ni seguenti parametri:\n\n1. L\'immagine in cui inserire il testo `frame`,\n2. Il testo da inserire `info`,\n3. La posizione (in pixel), in cui inserire il testo `(100, 20)`,\n4. Il font `cv2.FONT_HERSHEY_SIMPLEX`,\n5. La dimensione del testo `1`,\n6. Il colore in RGB (nel mio caso ho scelto verde) `(0,255,0)`,\n7. Lo spessore della linea `2`.\n\nIl codice da inserire sarà quindi:\n\n```python\n  cv2.putText(frame, info, (30,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n```\n\nA questo punto, possiamo visualizzare l\'immagine `frame e concludere il programma`.\n\n```python\ncap = cv2.VideoCapture(0)\nwhile(True):\n  ret, frame = cap.read()\n  info = get_barcode_info(frame)\n  cv2.putText(frame, info, (30,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n\n  cv2.imshow(\'Codice a Barre\', frame)\n  code = cv2.waitKey(30)\n  if code == ord(\'q\'):\n      break\n```\n\nLanciandolo, dovremmo ottenere dei risultati come sotto:\n\n![Nessun codice a barre trovate](./nobar.png)\n\n![Codice a barre trovate](./readbar.png)\n\nPer concludere, vi riporto il codice completo sviluppato in questo Tutorial.\n\n```python\nfrom pyzbar.pyzbar import decode\nimport cv2\nimport requests\n\ndef get_barcode_info(img):\n    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    barcodes = decode(gray_img)\n\n    if len(barcodes) == 1:\n        code = barcodes[0].data\n        url = "https://it.openfoodfacts.org/api/v0/product/{}.json".format(code)\n        data = requests.get(url).json()\n        if data["status"] == 1:\n            product = data["product"]\n            brand = product["brands"]\n            return "produttore: {}    nome: {}".format(product["brands"], product["product_name"])\n        else:\n            return "Prodotto non trovato!"\n    else:\n        return "Codice a barre non trovato!"\n\ncap = cv2.VideoCapture(0)\nwhile(True):\n  ret, frame = cap.read()\n  info = get_barcode_info(frame)\n  cv2.putText(frame, info, (30,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n\n  cv2.imshow(\'Codice a Barre\', frame)\n  code = cv2.waitKey(30)\n  if code == ord(\'q\'):\n      break\n```\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2018-01-22-opencv-barcode-reader/index.md",
    frontMatter: {
      path: "/2018/01/22/opencv-barcode-reader/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "9 mins",
      published: "2018-01-22T00:00:00.000Z",
      publishedReadable: "22 Gen 2018",
      featured: false,
      tags: ["Python", "Barcode", "OpenCV"],
      title: "Leggere i codici a barre con OpenCV e zbar in Python",
      description:
        "Come usare Python per leggere i codici a barre degli alimenti e ricavarne alcune informazioni utili",
      href: "/2018/01/22/opencv-barcode-reader/",
      image: "/content/blog/it/2018-01-22-opencv-barcode-reader/main.png",
      imagePath: "/content/blog/it/2018-01-22-opencv-barcode-reader",
    },
  },
  {
    content:
      "\n![docker_arm_intel](./Processor_ARM.png)\n\nCiao a tutti!\n\nMai avuto il dubbio su come compilare Immagini [Docker](https://www.docker.com/) per ARM direttamente sul vostro PC? Io ho dovuto faticare per scoprire come farlo, per buildare la versione ARM dell'architettura sviluppata per il mio lavoro di tesi, NTBD (trilogia di post a proposito [qui]()).\n\nLa seguente è una guida veloce su come configurare la vostra macchina Intel per poter compilare Immagini Docker eseguibili su host con processori ARM, sfruttando [QEMU](https://www.qemu.org/).\n\n**Nota**: in questo tutorial assumerò che il lettore conosca Docker. Per una panoramica a proposito di Docker date un'occhiata al mio post, \"[Docker, questo sconosciuto!]()\". Questa guida darà consigli su come compilare l'Immagine Docker per una **Raspberry Pi** su un **host Ubuntu**.\n\n# 1. Cos'è QEMU ed installazione di QEMU\n\nQEMU (Quick EMUlator) è un hosted hypervisor, cioè un hypervisor eseguito su un sistema operativo esattamente come altri programmi, il quale fornisce virtualizzazione hardware. QEMU emula le CPU di diverse archietture, per esempio x86, PPC, ARM and SPARC. Permette di eseguire eseguibili non nativi, emulando l'escuzione nativa e, come richiesto in questo caso, di eseguire operazioni di cross-building.\n\nDal momento che uso un host Ubuntu, questi sono i comandi per installare i pacchetti _qemu_, _qemu-user-static_ e _binfmt-support_ da linea di comando:\n\n```bash\n sudo apt update\n sudo apt install -y qemu qemu-user-static qemu-user binfmt-support\n```\n\nIl package _qemu-user-static_ fornisce eseguibili QEMU buildati staticamente, cioè eseguibili che non hanno dependencies.\n\n# 2. QEMU ed Immagini Docker\n\nPer ottenere un'Immagine Docker che possa essere correttamente _buildata_ ed eseguita su un host ARM, è necessario avere un'Immagine base provvista dell'eseguibile qemu richiesto, _qemu-arm-static_ in questo caso. Ci sono un po' di Immagini pronte complete di questo eseguibile:\n\n- [Hypriot rpi-alpine Image](https://hub.docker.com/r/hypriot/rpi-alpine/)\n- [Resin rpi-raspbian Image](https://hub.docker.com/r/resin/rpi-raspbian/)\n- [Resin raspberry-pi-alpine-node:slim Image](https://hub.docker.com/r/resin/raspberry-pi-alpine-node/).\n\nIn ogni caso è possibile usare un'Immagine \"semplice\" per Raspberry e poi copiare nel contenitore il binary che puoi trovare in _/usr/bin/_, dopo aver scaricato i pacchetti di QEMU (vedi [step 1](#1-cosè-qemu-ed-installazione-di-qemu)).\n\nSupponiamo che partiate dall'Immagine Docker \"ufficiale\" per Ubuntu su piattaforme ARMv7(armhf), disponibile [qui](https://hub.docker.com/r/armv7/armhf-ubuntu/), e che abbiate fatto una copia dell'eseguibile di cui abbiamo bisogno, _qemu-arm-static_, nel vostro build context (cartella contenente il Dockerfile, i.e. \".\"). Le prime righe del vostro Dockerfile saranno:\n\n```Dockerfile\nFROM armv7/armhf-ubuntu:16.04\n\nCOPY ./qemu-arm-static /usr/bin/qemu-arm-static\n```\n\nNel mio caso, per l'[Immagine Base di NTBD](https://github.com/HotBlackRobotics/ntbd/blob/devel/NTBD_base/Dockerfile.rpi3), ho usato come immagine di partenza l'[Immagine HotBlack Robotics hbrobotics/ros-base:rpi3](https://hub.docker.com/r/hbrobotics/ros-base/), basata sull'Immagine \"ufficiale\" per ARM citata sopra, con installato ROS Kinetic. Ho quindi copiato il binary ARM di QEMU, ottenendo:\n\n```Dockerfile\nFROM  hbrobotics/ros-base:rpi3\n\nCOPY ./qemu-arm-static /usr/bin/qemu-arm-static\n```\n\nQuindi completate il vostro Dockerfile con tutti i layers necessari.\n\n# 3. Registrare QEMU sul build agent\n\nPer registrare QEMU sul build agent, c'è un'Immagine Docker apposita, quindi eseguite semplicemente il seguente comando nella command line:\n\n```bash\ndocker run --rm --privileged multiarch/qemu-user-static:register --reset\n```\n\n# 4. Build dell'Immagine\n\nAdesso siete pronti per _buildare_ la vostra immagine. Usate il solito comando _docker build_. Nel mio caso, avendo un nome specifico per il Dockerfile, il comando è:\n\n```bash\ndocker build -f ./Dockerfile.rpi3 -t ntbd/base:rpi3 .\n```\n\nEcco fatto! La vostra Immagine Docker dovrebbe essere pronta per essere _pushata_ sulla vostra repository Docker Hub e alla fine scaricata e caricata sulla vostra Raspberry Pi.\n\nGrazie, per la maggior parte delle informazioni, a [Hypriot](https://blog.hypriot.com/post/setup-simple-ci-pipeline-for-arm-images/).\n\\n\n**A presto!** :hibiscus:\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-01-22-docker-images-arm/index.md",
    frontMatter: {
      path: "/hbr/come-compilare-immagini-docker-per-arm-su-host-intel/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "3 mins",
      published: "2018-01-22T00:00:00.000Z",
      publishedReadable: "22 Gen 2018",
      featured: true,
      tags: [],
      title: "Come compilare Immagini Docker per ARM su host Intel",
      description: "Buildare Immagini Docker per host ARM su Intel",
      href: "/hbr/come-compilare-immagini-docker-per-arm-su-host-intel/",
      image:
        "/content/hbr/2018-01-22-docker-images-arm/Processor_ARM_anteprima.png",
      imagePath: "/content/hbr/2018-01-22-docker-images-arm",
    },
  },
  {
    content:
      "\n![docker logo](./docker-facebook.png)\n\nCiao a tutti!\nOggi vorrei parlarvi di una tecnologia che sta acquistando sempre più importanza, nel mondo dei developers ed anche in quello aziendale: [Docker](https://www.docker.com).\n\n### Indice\n\n# 1. Cos'è un contenitore?\n\nAlcuni di voi penseranno \"Bhè chiaro! Una scatola, dove mettere qualcosa, per trasportarlo in modo compatto\". Vi dirò che questo vostro pensiero ha senso, andiamo a vedere perchè: il concetto di contenitore è apparso per la prima volta con la tecnologia dei Linux Containers [LXC](https://linuxcontainers.org/it/http://assemble.io), cioè un metodo di virtualizzazione a livello di sistema operativo che permette di eseguire molteplici sistemi Linux, chiamati _containers_, i quali sono isolati e condividono lo stesso Kernel Linux. Nel 2008 è stata rilasciata la versione 2.6.24 del Kernel Linux, la quale permetteva, per la prima volta, l'isolamento di risorse su hardware condiviso senza il bisogno delle Virtual Machines, il metodo di virtualizzazione più utilizzato fino ad allora.\n\n## 1.1. Contenitori Linux vs. Macchine Virtuali\n\n- _Virtualizzazione_: come anticipato, i Linux Containers (LCs) forniscono virtualizzazione a livello di sistema operativo, mentre le Virtual Machines offrono la virtualizzazione dell'hardware.\n- _Guest OS_: i LCs non necessitano di ulteriori layers al di sopra del sistema operativo Host. Invece, le VMs, per poter essere eseguite, richiedono che la copia completa di un sistema operativo Guest venga installata.\n  La maggior parte degli esempi di Docker Container, per lo sviluppo di applicazioni, sono basati sull'installazione di nuovo software su, per esempio, Ubuntu, il quale non è realmente installato ma è rappresentato da contenuti del Filesystem necessari affinchè l'applicazione possa essere eseguita.\n  • _Prestazioni e peso_: considerate le osservazioni di cui sopra, i LCs sono leggeri e veloci mentre le VMs presentano un considerevole overhead all'avvio dovuto a tutti gli step che l'avvio di un sistema operativo completo comporta.\n  • _Hypervisor_ : i LCs possono essere eseguiti contemporaneamente e l'isolamento tra le risorse di ognuno è garantinto dalla divisione delle risorse del sistema operativo in gruppi separati. Al contrario, affinchè diverse macchine virtuali possano essere eseguite contemporaneament, è necessario un Hypervisor (conosciuto anche come Virtual Machine Monitor, VMM), ulteriore strato sopra il sistema operativo Host.\n  Le seguenti immagini riportano le differenze a livello di layers tra i LCs e le VMs.\n\n<p align=\"center\">\n    <image src=\"/assets/imgs/2018-01-18-docker/4_dockerVM1.png\"  height=\"250\"/>\n    <image src=\"/assets/imgs/2018-01-18-docker/4_dockerVM2.png\"  height=\"250\"/>\n</p>\n\n## 1.2. Container Docker\n\nI contenitori sono diventati popolari con la nascita di Docker, grazie alla facilità di utilizzo fornita dalla API ad alto livello. Docker permette ai developers di _impacchettare_ ed isolare le proprie applicazioni, favorendo la _modularità_ e la _portabilità_ di queste ultime. Infatti, il software \"_containerizzato_\" eseguirà sempre nello stesso modo, indipendentemente dall'ambiente in cui si trova, con l'unico requisito che il sistema operativo Host sia compatibile con Docker. L'unica pecca dei container è che sono _meno sicuri_ delle VMs poichè l'isolamento in queste ultime è reale e robusto mentre nei containers l'isolamento può essere violato a causa delle condivisione di risorse. Per questo motivo le applicazioni Cloud e IoT, per adesso, sono containerizzate ed installate su VMs.\nLa tecnologia di _containereizzazione_ insieme alle procedure standard fornite, definiscono il _Docker Engine_, un'applicazione client-server con i seguenti componenti:\n\n- Un processo persistente o daemon, chiamato _dockerd_, il quale gestisce containers ed immagini;\n- una API [REST](https://spring.io/understanding/REST) che specifica le interfacce utilizzate dai programmi per comunicare col daemon, per dirgli cosa fare;\n- una interfaccia da linea di comando, usata dall'utente per interagire con il Docker Engine per eseguire e gestire in generale containers ed immagini.\n\n# 2. Concetti chiave per lavorare con Docker\n\nDopo avervi annoiato con un po' di concetti teorici, passiamo alla parte divertente: qualche pillola utile per utilizzare Docker, lavorarci e capire cosa succede!\n\n## 2.1. Immagine Docker e Contenitore Docker\n\nI concetti di Docker Image e Docker Container, per un nuovo utente, possono essere motivo di confusione: un' _Immagine Docker_ è un eseguibile stand-alone che incapsula tutte le risorse neccessarie per eserguirlo, per esempio, codice, librerie, codice runtime, impostazioni e strumenti di sistema. Un'Immagine Docker che viene eseguita è chiamata _Docker Container_: possono \"_runnare_\" vari containers basati sulla stessa immagine.\n\n## 2.2. Dockerfile\n\nUna Immagine Docker viene costruita a partire da una \"pila\" di strati definiti in un file chiamato _Dockerfile_. La tipica Immagine è definita partendo dall'immagine di un sistema operativo di base su cui viene installato software e vengono eseguite operazioni, che possono essere definite utilizzando linguaggio BASH e seguendo un certa [sintassi](https://docs.docker.com/engine/reference/builder/).\nVediamo un esempio breve di Dockerfile:\n\n```Dockerfile\n# Pull dell'immagine di base\nFROM ubuntu:16.04\nSHELL [\"/bin/bash\",\"-c\"]\n# Installazione di software\nRUN apt-get update && \\\n    apt-get -y upgrade && \\\n    apt-get install ...\n# Copia di file dall'Host al Container\nCOPY /source/path/del/file/locale/ /destination/path/nel/contenitore\n# Copia e definizione di un file di operazioni da eseguire all'avvio, i.e., entrypoint\nCOPY /path/locale/entrypoint.sh\nENTRYPOINT [\"/entrypoint.sh\"]\n```\n\nIl file che viene eseguito all'avvio può contenere operazioni di copia dall'Host al container, escuzione di altri script BASH ecc. Nel seguente file di esempio, utilizzato per un contenitore su cui è installato ROS, vengono eseguiti dei file di setup, viene avviato un server [nginx](https://nginx.org/en/) e un launch file ROS.\n\n```bash\n!/usr/bin/env bash\nset -e\necho \"export TERM=xterm\" >> ~/.bashrc\n# Setup dell'ambiente ROS\nsource /opt/ros/kinetic/setup.bash\nsource /catkin_ws/devel/setup.bash\n\n# Avvia nginx\nservice nginx start\n\n# Launch dei nodi ROS\nroslaunch ntbd_core NTBD_launch.launch\nexec \"$@\"\n```\n\nDocker fa il _build_ delle immagini sfruttando un utilissimo sistema di caching che permette di velocizzare questo processo ogni qualvolta i layer non siano stati modificati.\nPer \"_buildare_\" un'Immagine, bisogna usare il comando:\n\n```bash\n docker build -t nometag .\n```\n\nQuesto comando cercherà (di default) il file chiamato Dockerfile nel path specificato, nell'esempio '' . '', ovvero la cartella corrente. E' possibile dare un nome identificativo alla Immagine creata (opzione -t) oppure definire un altro file per il build (opzione -f, per esempio, docker build -f ./mioDockerfile).\n\n## 2.3. Build context, cos'è?\n\nIl build context è la cartella contenente il Dockerfile per la creazione di un'Immagine. Quando si deve copiare un file dall'Host al container il path relativo deve riferirsi a questa cartella, per esempio:\n\n```Dockerfile\nCOPY ./src/file/da/copiare /path/file/nel/container\n```\n\nIn questo caso il file si trova nella cartella _src_ contenuta nella cartella contenente il _Dockerfile_.\n\n## 2.4. COPY: usare con cautela!\n\nMi raccomando usate COPY nel Dockerfile solo nel momento in cui il file che volete copiare è alla sua versione finale: infatti il comando COPY creerà uno dei \"layers\" che compone la vostra immagine, quindi, nel caso che il file venisse modificato, il build dell'immagine Docker ripartirebbe da quel layer, senza sfruttare l'uso della cache dell'immagine già \"_buildata_\".\n\n<p align=\"center\">\n    <image src=\"/assets/imgs/2018-01-18-docker/4_dockerdev.png\"  height=\"400\"/>\n</p>\n\\n\n Quando la vostra applicazione è ancora in fase di sviluppo, il consiglio è quindi quello di eseguire la copia dei file necessari (programmi in development) all'interno del file di entrypoint in modo tale che l'Immagine non venga re-buildata ogni volta che i file cambiano. Ovviamente, essendo eseguito all'avvio del contenitore, il tempo di boot sarà maggiore.\n\nPer ulteriori informazioni, consultare l'Appendice di questo [post]().\n\n## 2.5. Docker Compose\n\n[Docker Compose](https://docs.docker.com/compose/overview/) è un tool per definire e _runnare_ applicazioni multi-container tramite la configurazione definita in un file [YAML](http://yaml.org/). Trovo, però, che l'utilizzo di questo tool sia molto utile anche solo per eseguire un solo container perchè ti permette di usare un semplice comando, i.e.,\n`docker-compose up`, il quale estrapola le informazioni di configurazione (mapping di porte, volumi, tag), per default, da un file chiamato _docker-compose.yml_ ed esegue il container con tutte le relative opzioni.\nEcco un esempio di un file _docker-compose.yml _:\n\n```yaml\nservice_name:\n  image: ntbd/manipulator:intel\n  container_name: ntbd_manipulator_intel\n  ports:\n    - \"80:80\"\n  privileged: true\n  devices:\n    - \"/dev/ttyACM0:/dev/ttyACM0\"\n  volumes:\n    - /tmp/.X11-unix:/tmp/.X11-unix:ro\n  environment:\n    - DISPLAY=$DISPLAY\n```\n\n# 3. Comandi utili\n\nVi lascio alla sperimentazione con Docker con alcuni comandi da command line, utili per la gestione di Immagini e Contenitori:\n\n- Visualizzare i contenitori che sono attualmente eseguiti o _stoppati_:\n\n```bash\n docker ps -a -q\n```\n\n- Visualizzare tutte le Immagini Docker create:\n\n```bash\n docker images\n```\n\n- Fermare tutti i container attualmente eseguiti:\n\n```bash\n docker stop $(docker ps -a -q)\n```\n\n- Rimuovere un container:\n\n```bash\ndocker rm ID_container\n```\n\n- Rimuovere tutti i container:\n\n```bash\ndocker rm $(docker ps -a -q)\n```\n\n- Rimuovere un'immagine:\n\n```bash\ndocker rmi ID_immagine\n```\n\n- Rimuovere tutte le immagini senza tag:\n\n```bash\ndocker rmi $(docker images | grep \"^<none>\" | awk \"{print $3}\")\n```\n\n# 4. Perchè Docker?\n\nSicuramente Docker ha molti altri vantaggi che scoprirò e scoprirete, ma mi sento di consigliarlo per i seguenti motivi:\n\n1. **Portabilità**: le vostre applicazioni potranno essere _dockerizzate_ ed eseguite su ogni macchina su cui ci sia installato Docker perchè avranno tutto ciò che serve per essere eseguite senza problemi. Un contenitore è proprio una scatola per portare le vostre applicazioni dove volete!\n\n**Nota**: _un'Immagine buildata con una macchina che ha un certo processore potrà essere eseguita su macchine con lo stesso processore (per esempio, Intel su Intel, ARM su ARM)_. 2. **Sperimentazione**: a me Docker ha dato la possibilità di provare ad installare o eseguire qualsiasi cosa, senza avere il pensiero di corrompere l'intero sistema. Una volta che il contenitore è eseguito, tutte le modifiche fatte al run-time verranno eliminate allo stop del contenitore stesso, senza lasciare traccia delle modifiche apportate al sistema. Questo è, secondo me, utilissimo anche per chi è alle prese con nuovi sistemi operativi e vuole provare, per capire come funziona! 3. **Tracking del lavoro fatto**: il sistema Docker di definire l'immagine uno strato alla volta, permette di avere un file che ci dice tutto su come l'immagine è stata costruita e ci permette di eliminare uno strato nel caso che non ci soddisfi. La consultazione del Dockerfile permette di trovare subito eventuali errori o step fondamentali dimenticati (per esempio, il download di un pacchetto) ed avere un quadro generale dei vari step implementati.\n\n**Buon Docker a tutti!**\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-01-18-docker-this-stranger/index.md",
    frontMatter: {
      path: "/hbr/docker-questo-sconosciuto/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "8 mins",
      published: "2018-01-18T00:00:00.000Z",
      publishedReadable: "18 Gen 2018",
      featured: false,
      tags: [],
      title: "Docker, questo sconosciuto!",
      description: "Perchè utilizzare Docker e la mia esperienza",
      href: "/hbr/docker-questo-sconosciuto/",
      image: "/content/hbr/2018-01-18-docker-this-stranger/docker-facebook.png",
      imagePath: "/content/hbr/2018-01-18-docker-this-stranger",
    },
  },
  {
    content:
      "\r\nCiao a tutti! Sono di nuovo io, Fiorella e, con questo post, vorrei presentarvi il lavoro svolto per la mia Tesi di Laurea Magistrale in Ingegneria Meccatronica conseguita al Politecnico di Torino, \"_Development of a Standard Architecture\r\nto enable Fast Software Prototyping\r\nfor Robot Arms_\", e fornirvi una guida step by step il più possibile chiara (si spera!) per poter utilizzare e ri-utilizzare l'architettura sviluppata, chiamata NTBD.\r\nNella prima parte vi presento l'architettura proposta così come la troverete esplorando il [progetto su github](https://github.com/HotBlackRobotics/ntbd/tree/06f5af9c35c814ff039fc60e410531724c96a11c). Nel secondo post invece ci sarà un tutorial su come utilizzare l'architettura integrata ad un braccio robotico Open-Source da me scelto, avendo a disposizione un PC con processore Intel (oppure un host con processore ARM). Infine nel terzo articolo spiegherò come poter sfruttare NTBD utilizzando un braccio a scelta diverso da quello presentato, evidenziandone i limiti.\r\n\r\n# Parte I: una panoramica\r\n\r\n## Motivazioni\r\n\r\nL'idea della mia tesi è nata dall'osservazione che nell'ambito della prototipazione rapida, l'hardware ha sempre avuto dei validi rappresentanti, per esempio le schede Open-Source [Arduino](http://www.arduino.org/) e [RaspBerry Pi](https://www.raspberrypi.org/); per quanto riguarda la Robotica, esistono innumerevoli progetti Open-Source per la costruzione di robot, muniti di istruzioni, indicazioni sull'opportuno hardware per il controllo, pezzi necessari alla costruzione (i quali possono essere stampati in 3D) e lista di minuteria necessaria.\r\nPer quanto riguarda invece il software, non c'è a disposizione un'architettura standard su cui costruire in modo semplice la propria applicazione robotica. Ecco che entra in scena **NTBD**, pensata per lo sviluppo di applicazioni con bracci robotici.\r\n\r\n## NTBD: Name To Be Decided\r\n\r\nEbbene sì, ecco il nome tanto ricercato in tutta la sua gloria! Dopo pomeriggi passati a scegliere un nome che fosse accattivante e cool questo è il risultato...\r\n\r\n![enter image description here](./giphy.gif)\r\n\r\nSono però dell'idea che l'importante sia il contenuto.\r\nA proposito di contenuto, adesso procederò a darvi una veloce panoramica top-down su NTBD.\r\n\r\n## NTBD - Livello Concettuale\r\n\r\n![ntbd-conceptual](./4_architect.png)\r\n\r\nL'architettura è composta da vari elementi tra cui troviamo dei componenti astratti, ovvero componenti generici che possono essere implementati dall'utente. Ecco il significato di ogni componente astratto:\r\n\r\n- **IK & FK** implementano cinematica inversa (Inverse Kinematics) e cinematica diretta (Forward Kinematics) per l'end effector del braccio robotico.\r\n- **URDF**: è un file ([Universal Robot Description Format](http://wiki.ros.org/urdf)) che descrive la struttura cinematica del braccio per definirne il modello per la simulazione.\r\n- **P2V**: qui vengono convertiti ed adattati gli angoli dei giunti del braccio per ottenere i valori corrispondenti per muovere conformemente il modello in simulazione.\r\n- **Motor Values**: in questo elemento vengono uniti, in un unico array, i valori dei giunti e della pinza del braccio, se presente.\r\n- **HW**: questo componente rappresenta l'hardware utilizzato per il controllo del manipolatore, in questo caso una scheda Arduino.\r\n\r\nI seguenti sono invece i componenti che sono indipendenti dalla struttura del manipolatore scelto:\r\n\r\n- **Position Limiter**: questo elemento serve a limitare la posizione che si desidera raggiungere determinata dai limiti inferiori e superiori della coordinate Cartesiane x,y,z.\r\n- **Path Planner**: ho scelto, per questioni di semplicità, di pianificare il percorso dell'end effector in modo lineare, assumendo che non ci siano ostacoli.\r\n- **Values Limiter**: anche i valori dei motori devono essere limitati per evitare danni o comportamenti inattesi.\r\n- **Rosserial**: questo elemento rappresenta l'importanza del tool [Rosserial](http://wiki.ros.org/rosserial) necessario per stabilire una connessione seriale con la scheda di prototipazione rapida scelta per il controllo.\r\n- **Rosbridge**: questo componente rappresenta il tool di ROS [Rosbridge](http://wiki.ros.org/rosbridge_suite), che permette di simulare il nostro braccio robotico tramite l'integrazione di ROS con il mondo Web utilizzando una libreria JavaScript, [roslibjs](http://wiki.ros.org/roslibjs).\r\n\r\n## NTBD - Livello Docker\r\n\r\nL'architettura è portabile grazie alla sua definizione all'interno di un contenitore [Docker](https://www.docker.com/) il quale ne consente l'esecuzione dei componenti sempre uguale a se' stessa, con l'unico requisito di un sistema compatibile con Docker.\r\nChi ha qualche concetto base di Docker, saprà bene che un'applicazione Docker viene sviluppata partendo da un'immagine base che solitamente corrisponde all'immagine di un sistema operativo. Nel mio caso l'immagine di partenza è Ubuntu 16.04 su cui è pre-installato ROS Kinetic Kame (decima distribuzione di ROS, 2016) ottenuti dal [github di HotBlack Robotics](https://github.com/HotBlackRobotics/docker-ros-base). Come possibile vedere dalla [repository NTBD](https://hub.docker.com/u/hbrobotics/) su [Docker Hub](https://docs.docker.com/docker-hub/) ci sono due _layer_ che compongono l'archiettura, _base_ e _manipulator_. La prima contiene gli elementi dell'architettura comuni a tutti i bracci robotici (Position Limiter, Path Planner, Values Limiter, Rosserial e Rosbridge); su quest'ultima è costruita la seconda immagine in cui vengono implementati i componenti astratti, analizzati prima.\r\n\r\n## NTBD - Livello ROS\r\n\r\nI componenti presentati precedentemente sono stati implementati in [ROS](http://www.ros.org/), Robot Operating System, come nodi Python. Assumo che il lettore conosca le dinamiche base del framework ROS così da non dilungarmi in spiegazioni ulteriori e procedere all'elenco e relativa spiegazione di [nodi](http://wiki.ros.org/Nodes) e [topics](http://wiki.ros.org/Topics) di questa architettura.\r\n\r\nIn Figura vediamo i nodi e i topics coinvolti nelle dinamiche di NTBD.\r\n![ntbd-ros](./4_archrosgraph.png)\r\n\r\n<!--Per meglio individuare il ruolo di ogni nodo e topic, li suddividerò in categorie di attinenza.\r\n Nodi e Topic per il controllo del robot -->\r\n\r\nLa tabella riportata qui sotto presenta i topics e i relativi tipi di [messaggi ROS](http://wiki.ros.org/Messages).\r\n\r\n**Note**:\r\n\r\n- Motors_Array è un tipo custom, creato per rendere più chiaro il contenuto del messaggio stesso ed avere una struttura semplice.\r\n- il tipo di messaggio di _/girpper_value_ dipende dall'implementazione dell'utente.\r\n\r\n| Topic                      | ROS Message Type                                                                       |\r\n| :------------------------- | :------------------------------------------------------------------------------------- |\r\n| /desired_position_nolim    | [geometry_msgs/Point](http://docs.ros.org/api/geometry_msgs/html/msg/Point.html)       |\r\n| /desired_position_nointerp | geometry_msgs/Point                                                                    |\r\n| /desired_position          | geometry_msgs/Point                                                                    |\r\n| /motors_nogripper          | Motors_Array                                                                           |\r\n| /gripper_value             | [std_msgs/String](http://docs.ros.org/api/std_msgs/html/msg/String.html)               |\r\n| /motors_nolim              | Motors_Array                                                                           |\r\n| /motors                    | Motors_Array                                                                           |\r\n| /actual_position           | geometry_msgs/Point                                                                    |\r\n| /joint_states              | [sensor_msgs/JointState](http://docs.ros.org/api/sensor_msgs/html/msg/JointState.html) |\r\n\r\n- Topic **desired_position_nolim**: la posizione desiderata viene pubblicata su questo topic come messaggio di tipo Point.\r\n- Nodo **/position_limiter**: qui i valori che cadono al di fuori dei limiti (che sono definiti come [parametri ROS](http://wiki.ros.org/Parameter%20Server#Parameters)), vengono saturati in modo tale da evitare errori dovuti a posizioni non raggiungibili.\r\n- Topic **/desired_position_nointerp**: le posizioni \"filtrate\" dal nodo _/position_limiter_ vengono pubblicate su questo topic.\r\n- Nodo **/path_planner**: lo scopo di questo nodo è quello di calcolare l'interpolazione lineare tra due posizioni consecutive pubblicate su _/desired_position_nointerp_.\r\n- Topic **/desired_position**: qui viene pubblicata la sequenza di punti nello spazio calcolata dal nodo di path planning.\r\n- Nodo **/IK**: la posizione desiderata viene qui convertita in valori per i motori (angoli , nel caso dei servo-motori).\r\n- Topic **/motors_nogripper**: i valori ottenuti in _/IK_ sono pubblicati qui.\r\n- Topic **/gripper_value**: fornisce in output il valore desiderato per la pinza del braccio, in questo caso la pinza può essere aperta o chiusa.\r\n- Nodo **/motors_values**: qui i valori dei motori e della pinza vengono uniti in un unico vettore di dati.\r\n- Topic **/motors_nolim**: l'insieme di tutti i valori desiderati viene pubblicato su questo topic.\r\n- Nodo **/motors_limiter**: questo nodo legge i valori dei motori e, se necessario li limita confrontandoli con i valori limite definiti come parametri ROS. Questo nodo è fondamentale nel caso che l'utente voglia comandare il robot direttamente nello spazio dei giunti.\r\n- Topic **/motors**: i valori limitati sono finalmente disponibili su questo topic.\r\n- Nodo Rosserial **/init_serial_node**: questo nodo, che corrisponde al nodo [_/serial_node_](http://wiki.ros.org/rosserial_python#serial_node.py), consente di stabilire una connessione tra il nodo seriale caricato sull'hardware (in questo caso Arduino) e il sistema ROS sul computer. Infatti i valori dei motori vengono letti dall'apposito topic e processati dalla scheda per muovere i servo.\r\n- Nodo **/FK**: i valori dei motori possono essere utilizzati per il calcolo della cinematica diretta per ottenere la posizione reale, che può essere diversa da quella desiderata a causa dei limiti fisici.\r\n- Topic **/actual_position** la posizione raggiunta viene pubblicata su questo topic.\r\n\r\nPer quanto riguarda la simulazione del robot su una pagina web, ho dovuto rendere disponibili su un server il file URDF del braccio e il file HTML dell'applicazione. La soluzione è stata quella di tirare su un server, all'interno dell'ambiente containerizzato, utilizzando [_nginx_](https://www.nginx.com/resources/glossary/nginx/), un web server Open-Source che può essere utilizzato per fornire sulla rete contenuti HTTP. Per visualizzare la simulazione sul browser del sistema operativo host è bastato mappare la porta 80 del contenitore su una porta a scelta, per esempio 1234 dell'host (nella versione definitiva la porta 80 è mappata alla porta standard dell'host ovvero la porta 80).\r\nLa cartella root di default di nginx (/var/www/html) contiene il documento HTML, dove avvengono le interazioni tra Rosbridge e ROS e la descrizione URDF del robot necessaria al rendering di quest'ultimo.\r\n\r\n![ntbd-simulation](./4_sim.png)\r\n\r\nRipartendo da dove eravamo rimasti per la descrizione a livello ROS, i seguenti sono i nodi e topics coinvolti nella simulazione del nostro braccio:\r\n\r\n- Nodo **/physical_2_visual** : questo nodo fa parte dei componenti astratti, dipendente quindi dal braccio scelto. Si tratta di un nodo di conversione che mappa i valori fisici forniti dal topic _/motors_ ai valori corrispondenti in visualizzazione.\r\n- Topic **/joint_states**: qui vengono pubblicati i valori dei joint in visualizzazione.\r\n  Da qui in avanti, la gestione dei messaggi su topic ed i nodi è quella tipica di ROS per i dati 3D: i valori dei joint sono passati al topic [**/robot_state_publisher**](http://wiki.ros.org/robot_state_publisher) che fornisce in output messagi di tipo [_geometry_msgs/Transform_](http://docs.ros.org/jade/api/geometry_msgs/html/msg/Transform.html) sfruttando il package [_tf2_](http://wiki.ros.org/tf2) di ROS, il quale consente all'utente di tener traccia dei sistemi di coordinate nel tempo. A questo punto, queste informazioni vengono rese note a Rosbridge; dal momento che i nodi e topic coinvolti in questa parte sono abbastanza standard, non mi dilungherò oltre.\r\n  ![graph-simulation](./5_rosbr.png)\r\n\r\nCollegandoci quindi \"a noi stessi\" dal browser, sulla porta definita potremo vedere il modello del braccio muoversi insieme al braccio fisico.\r\nLa connessione Rosbridge viene iniziata sulla porta di default 9090 sulla quale un altro computer può interagire con il sistema ROS pubblicando sui topics e iscrivendosi ad essi.\r\n\r\n# Parte II: tutorial\r\n\r\nInquesta parte spiegherò come riprodurre il progetto, completo di integrazione del braccio robotico con l'architettura NTBD, introdotta nella [Parte I](#parte-i-una-panoramica).\r\n\r\n## Ingredienti\r\n\r\nCi serviranno:\r\n\r\n- 1 braccio EEZYBOT MK2 stampato in 3D, completo di servo-motori (3 mini-servo, 1 micro-servo)\r\n- 1 scheda Arduino (nel mio caso ho usato una Mega ADK 2560)\r\n- 1 pc con processore Intel su cui installare Docker\r\n- 1 controller [Leap Motion](https://www.leapmotion.com/) per una delle applicazioni robotiche implementate\r\n- 1 Alimentatore esterno da 2A-7.5V\r\n- 1 Breadboard\r\n- Jumper q.b.\r\n\r\n**Nota:** Questo tutorial si riferisce all'Immagine Docker per host Intel ma è disponibile anche l'**Immagine ARM** (può essere eseguita su Raspberry 3). Per ottenere la versione ARM, quando un comando è necessario o un documento è citato, è sufficiente \\*sostituire la parola **intel** con **rpi3\\***.\r\n\r\n## 1. Stampare il Braccio Robotico\r\n\r\nIl braccio robotico da me scelto è [EEZYbotARM MK2](http://www.eezyrobots.it/eba_mk2.html), progetto open source italiano di Carlo Franciscone, Design Engineer e Maker.\r\n\r\nSeguendo le istruzioni presenti su [_Thingiverse_](https://www.thingiverse.com/thing:1454048) ed [_Instructables_](http://www.instructables.com/id/EEZYbotARM-Mk2-3D-Printed-Robot/) relativi a questo progetto, ho completato con successo la stampa 3D ed il montaggio del braccio robotico.\r\nIl software per la stampa che ho utilizzato è [Cura](https://ultimaker.com/en/products/ultimaker-cura-software) con parametri configurati per stampare con una [DeltaWASP](http://www.wasproject.it/w/stampa-3d/).\r\n![3d printing](./5_piece1.jpg)\r\nPer la stampante DeltaWASP scaricate il seguente [profilo](http://www.personalfab.it/en/downloads-2/download-info/profili-cura/) e caricatelo seguendo la seguente [guida](https://ultimaker.com/en/resources/52032-manage-profiles).\r\n\r\nDi seguito i parametri più significativi utilizzati per stampare i pezzi, per migliorarne la definizione:\r\n\r\n| Parametro               |                                                                                         Valore                                                                                          |\r\n| :---------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\r\n| Infill                  | 30-100%. Vi consiglierei di stampare con infill del 30% le parti del braccio sottoposte a poco sforzo mentre le parti meccaniche più piccole sono state stampate con il 100% di infill. |\r\n| Printing Temperature    |                                                                                        200-210°C                                                                                        |\r\n| Build Plate Temperature |                                                                                          40°C                                                                                           |\r\n| Filament Diameter       |                                                                                         1.8 mm                                                                                          |\r\n| Print Speed             |                                                                                         60 mm/s                                                                                         |\r\n| Infill Speed            |                                                                                         80 mm/s                                                                                         |\r\n| Travel Speed            |                                                                                        150 mm/s                                                                                         |\r\n| Support                 |                                                                                         Enabled                                                                                         |\r\n| Platform Adhesion       |                                                                                         Enabled                                                                                         |\r\n\r\n\\n\r\nQuesto è il risultato:\r\n\r\n![eezybot lateral](./5_eezybotlateral.jpg)\r\n\r\n## 2. Scaricare lo sketch per Arduino\r\n\r\nSulla pagina github di NTBD troverete lo sketch [myServoControl_ntbd.ino](https://github.com/HotBlackRobotics/ntbd/blob/devel/myServoControl_ntbd.ino) da caricare sulla scheda Arduino. Nel mio caso ho usato una Arduino Mega ADK 2560.\r\n![arduino](./5_mega.jpeg)\r\n\r\n## 3. Scaricare Docker\r\n\r\nPer Ubuntu usare questo [link](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#uninstall-old-versions).\r\n\r\n## 4. Scaricare le Immagini Docker\r\n\r\nA questo punto per scaricare le immagini di NBTD basterà eseguire i seguenti comandi nella vostra _command line_, per ottenerle da [Docker Hub](https://docs.docker.com/docker-hub/), usando il comando [_docker pull_](https://docs.docker.com/engine/reference/commandline/pull/):\r\n\r\n```\r\ndocker pull hbrobotics/ntbd_base:intel\r\n```\r\n\r\n```\r\ndocker pull hbrobotics/ntbd_manipulator:intel\r\n```\r\n\r\n## 5. Collegamenti\r\n\r\nCome possibile vedere dallo sketch, i servomotori, numerati come in figura, sono collegati all'Arduino come riportato in tabella.\r\n\r\n![servo](./5_eezybotfrontservo.jpg)\r\n\r\n| Servo | Pin Arduino |\r\n| :---: | :---------: |\r\n|   1   |      2      |\r\n|   2   |      3      |\r\n|   3   |      4      |\r\n|   4   |      5      |\r\n\r\n\\n\r\nPer muovere tutti i servomotori contemporaneamente senza sovraccaricare la scheda, colleghiamola ad un alimentatore esterno a 2 A e 7.5 V.\r\nColleghiamo su una breadboard i mini-servo con V+ collegato al pin _Vin_ di Arduino e V- collegato ad uno qualsiasi dei pin _GND_ (ground) della scheda.\r\n\r\nPer evitare di surriscaldare il micro-servo, lo colleghiamo il suo V+ al pin da 5V dell'Arduino e V- ad un pin GND.\r\n\r\n**ATTENZIONE:** controllate sempre che il ground sia comune a tutti i motori (GND breadboard = GND arduino).\r\n\r\nColleghiamo l'Arduino e il controller Leap Motion al computer tramite USB.\r\n\r\n![leap](./5_leapmotion.jpg)\r\n\r\nPer installare correttamente i driver per Leap Motion su Ubuntu 16.04, seguite questa [guida](https://support.leapmotion.com/hc/en-us/articles/223782608-Linux-Installation) insieme a questa piccola [modifica](https://forums.leapmotion.com/t/tip-ubuntu-systemd-and-leapd/2118).\r\n\r\n## 6. Avviare il Container Docker\r\n\r\nAdesso che tutti i dispositivi esterni sono collegati, scaricate il [file .yaml](https://github.com/HotBlackRobotics/ntbd/blob/devel/docker-compose.hbr_ntbd_intel.yml) per l'immagine ntbd_manipulator:intel, che è quella che vogliamo avviare. Per avviare il container (dove è presente l'applicazione Web), basta eseguire il seguente comando nella cartella contenente il file .yaml, sfruttando il tool [Docker Compose](https://docs.docker.com/compose/overview/):\r\n\r\n```\r\ndocker-compose -f docker-compose.hbr_ntbd_intel.yml up\r\n```\r\n\r\n## 7. WebApp per NTBD e siBOT\r\n\r\nL'insieme di NTBD e il braccio EEZYBOT controllato da ROS è quello che ho voluto chiamare **siBOT**.\r\n![sibot](./sibot.png)\r\n\r\nUna volta che il contenitore è stato avviato, apriamo una pagina Browser e connettiamoci all'indirizzo di loopback, _localhost_, per collegarci al nostro stesso computer: infatti il server dell'applicazione è sul nostro pc. Avendo chiamato il file HTML \"index.html\", connettendoci al nostro indirizzo IP sulla porta default 80 (come ci aspettiamo, avendo mappato la porta 80 del container a quella 80 dell'host) la _homepage_ dell'indirizzo sarà proprio la nostra WebApp per NTBD-Visualizer, provvista di link all'applicazione con Leap Motion.\r\n\r\n![webapp](./5_ntbdviz.png)\r\n\r\n## 8. Giocare con le WebApps\r\n\r\n### Simulazione con NTBD - Visualizer\r\n\r\nA questo punto avrete a disposizione l'applicazione, dalla quale potete impostare una posizione desiderata nello spazio, muovendo gli sliders per le coordinate Cartesiane; Premendo il bottone **Execute** vedrete il modello del braccio muoversi insieme al braccio fisico.\r\n\r\n**Nota**: i valori di input inseriti dall'utente tramite la WebApp NTBD - Visualizer, sono utilizzati per il controllo sia del modello in simulatione che del braccio fisico.\r\n\r\n### Controllo con Leap Motion\r\n\r\nNel caso si volesse utilizzare la seconda applicazione sviluppata, basterà premere sul link \"_NTBD Leap Motion WebApp_\" il quale aprirà una nuova pagina. Tenendo selezionata questa nuova finestra/scheda, vedremo che, posizionando la mano davanti al dispositivo Leap Motion, le posizioni nello spazio vengono interpretate ed inviate al robot fisico che riprodurrà i movimenti della mano.\r\n![leapspace](./5_leapref.png)\r\n\r\n**Nota**: per aprire e chiudere la pinza, semplicemente aprite e chiudete la mano!\r\n\r\n# Parte III: integrazione con altri manipolatori\r\n\r\nPer adattare l'archiettura NTBD ad un manipolatore diverso da EEZYBOT, è necessario ridefinire i componenti astratti dell'archiettura. Inoltre assumiamo che la scheda utilizzata per il controllo dei motori sia una scheda Arduino.\r\nI componenti astratti sono implementati nell'Immagine Docker _ntbd_manipulator_ e, come spiegato nella [\"Parte I: una panoramica\"](#parte-i-una-panoramica), dipendono dal braccio robotico scelto e vanno quindi modificati conformemente alla struttura scelta.\r\n\r\n**Note**:\r\n\r\n- Suggerisco di leggere la [Parte I](#parte-i-una-panoramica) e la [Parte II](#parte-ii-tutorial) per capire cosa deve essere modificato per integrare un manipolatore con NTBD e come connettere i dispositivi esterni per il controllo e per le WebApps.\r\n- Per poter fare il build delle Immagini Docker è necessario [installare Docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#uninstall-old-versions). In questo tutorial assumo che il lettore abbia delle conoscenze su come sviluppare applicazioni in Docker. Per consigli sulla fase development, leggere l'[appendice](#appendice-docker-prod-vs-docker-devel).\r\n\r\n## 1. Modificare i componenti astratti di NTBD\r\n\r\nSarà necessario scaricare il [progetto NTBD da github](https://github.com/HotBlackRobotics/ntbd) in modo tale da modificare i seguenti file prima di fare il build della nuova Immagine _ntbd_manipulator_:\r\n\r\n- [_joint_names_sibot_urdf.yaml_](https://github.com/HotBlackRobotics/ntbd/blob/devel/NTBD_manipulator/NTBD_abstract_nodes/manipulator_urdf/config/joint_names_sibot_urdf.yaml): in questo file sono definiti i nomi dei joint del braccio robotico, utili per lo scambio di messaggi ROS. Questa definizione è utile, per esempio, nel nodo [physical_2_visual](https://github.com/HotBlackRobotics/ntbd/blob/devel/NTBD_manipulator/NTBD_abstract_nodes/physical_2_visual), che deve quindi essere modificato di conseguenza.\r\n- [_/meshes/_](https://github.com/HotBlackRobotics/ntbd/tree/devel/NTBD_manipulator/NTBD_abstract_nodes/manipulator_urdf/meshes): questa cartella contiene le [meshes](https://it.wikipedia.org/wiki/Mesh_poligonale) per la visualizzazione del braccio robotico scelto, in formato [_STL_](<https://it.wikipedia.org/wiki/STL_(formato_di_file)>).\r\n- [siBOT_noEE.urdf](https://github.com/HotBlackRobotics/ntbd/blob/devel/NTBD_manipulator/NTBD_abstract_nodes/manipulator_urdf/urdf/siBOT_noEE.urdf): questo file deve contenere la definizione [URDF](http://sdk.rethinkrobotics.com/wiki/URDF) del nuovo manipolatore; può quindi essere rinominato a piacere con l'unico accorgimento di cambiare il nome anche nel launch file [NTBD_launch.launch](https://github.com/HotBlackRobotics/ntbd/blob/devel/NTBD_manipulator/launch/NTBD_launch.launch).\r\n- [index.html](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/NTBD_abstract_nodes/web/index.html) e [ntbd_lm.html](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/NTBD_abstract_nodes/web/ntbd_lm.html) definiscono le applicazioni Web e devono essere modificati a seconda della nuova configurazione (per esempio, con i nuovi limiti).\r\n- [IK](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/NTBD_abstract_nodes/IK), [FK](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/NTBD_abstract_nodes/FK), [motor_values](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/NTBD_abstract_nodes/motors_values) e [physical_2_visual](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/NTBD_abstract_nodes/physical_2_visual): questi file sono tutti dipendenti dalla scelta del braccio robotico; per ulteriori informazioni riguardo al loro ruolo .\r\n- [_NTBD_launch.launch_](https://github.com/HotBlackRobotics/ntbd/blob/devel/NTBD_manipulator/launch/NTBD_launch.launch): questo file deve essere modificato per modificare i parametri ROS dei limiti per le [coordinate della posizione](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/launch/NTBD_launch.launch#L16) e per i [motori](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/launch/NTBD_launch.launch#L24).\r\n- [myServoControl_ntbd.ino](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/myServoControl_ntbd.ino): ovviamente, cambiando il manipolatore, cambia la configurazione fisica del braccio (numero e tipo di motori) e di conseguenza lo sketch caricato sulla scheda Arduino.\r\n\r\n**Nota**:\r\n\r\n- il package ROS [_manipulator_urdf_](https://github.com/HotBlackRobotics/ntbd/tree/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/NTBD_abstract_nodes/manipulator_urdf), che contiene tutte le info necessarie per utilizzare la definizione URDF del robot, può essere prodotto automaticamente partendo dall'assembly del robot, utilizzando il tool [SolidWorks to URDF Exporter](http://wiki.ros.org/sw_urdf_exporter/Tutorials/Export%20an%20Assembly).\r\n- Nel caso si voglia modificare il nome di un file bisogna tener sempre conto del fatto che questo file potrebbe essere \"chiamato\" in qualche altro file e quindi quest'ultimo dovrebbe essere modificato di conseguenza. Il consiglio è quindi quello di _evitare di rinominare i file_ affinchè non ci siano intoppi.\r\n\r\n## 2. Fare il build della nuova immagine\r\n\r\nUna volta modificati i file necessari, è ora di \"buildare\" la nuova immagine. Entrare nella cartella [NTBD_manipulator](https://github.com/HotBlackRobotics/ntbd/tree/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator) in cui è contenuto il file [Dockerfile.intel](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/Dockerfile.intel) ed eseguire il seguente comando.\r\n\r\n```\r\ndocker build -t ntbd/manipulator:intel .\r\n```\r\n\r\n## 3. Avviare il nuovo contenitore\r\n\r\nDopo aver collegato tutti i dispositivi esterni, basterà quindi avviare il contenitore eseguendo:\r\n\r\n```\r\ndocker-compose -f docker-compose.intel.yml up\r\n```\r\n\r\nche sfrutta il tool [Docker Compose](https://docs.docker.com/compose/overview/) con configurazione specificata nel file [docker-compose.intel.yml](https://github.com/HotBlackRobotics/ntbd/blob/06f5af9c35c814ff039fc60e410531724c96a11c/NTBD_manipulator/docker-compose.intel.yml).\r\n\r\nL'integrazione di un nuovo braccio finisce qua, per informazioni a proposito dell'utilizzo delle WebApp implementate, vedi il [Post Parte II: tutorial](#parte-ii-tutorial).\r\n\r\n## Appendice: Docker prod vs Docker devel\r\n\r\nQuando si lavora con Docker conviene, per motivi di organizzazione e ordine, usare un'Immagine per lo sviluppo (Development Image) ed una per la produzione (Production Image). Quest'ultima è la versione finale dell'applicazioe Docker, pronta per la distribuzione, mentre la prima è usata durante lo sviluppo dell'applicazione. Viene \"buildata\" un'immagine comune sulla quale si vanno a sviluppare la versione Prod e la versione Dev e, con qualche accorgimento, si può sfruttare al meglio il sistema di caching per la fase di _build_ dell'immagine. Infatti, se i file modificati sono ancora in fase di debug, ad ogni build i layer, anche se già buildati in precedenza, vengono ri-buildati.\r\n\r\n![docker](./4_dockerdev.png)\r\n\r\nPer la fase di sviluppo è quindi consigliato avere tutti i file non ancora definitivi in una cartella condivisa tra l'host e il container: tramite uno script bash, eseguito all'avvio del contenitore, i file vengono copiati nel container.\r\nQuesto, chiaramente, aumenta il tempo di avvio ma evita che l'immagine venga re-buildata ogni volta che un file viene modificato. L'Immagine Prod, che nel caso di ntbd è quella resa [disponibile su Docker Hub](https://hub.docker.com/r/hbrobotics/ntbd_manipulator/), copia i file definitivi dal _building context_ (la cartella in cui sono contenute tutte le risorse necessarie all'esecuzione del container) al container, dal momento che tutti file, a questo punto, dovrebbero essere alla loro versione finale.\r\n\r\nDi seguito un esempio di building context:\r\n\r\n![buildingcontext](./building-context.png)\r\n\r\nQui invece riporto il contenuto del file bash NTBD_devel_entrypoint.sh usato per la versione devel:\r\n\r\n```bash\r\n#!/usr/bin/env bash\r\nset -e\r\necho \"export TERM=xterm\" >> ~/.bashrc\r\necho \". /opt/ros/kinetic/setup.bash\" >> ~/.bashrc\r\necho \". /catkin_ws/devel/setup.bash\" >> ~/.bashrc\r\n# Source form host:\r\n# NTBD_core scripts & launch\r\ncp /src/IK /catkin_ws/src/ntbd_core/scripts/IK\r\ncp /src/physical_2_visual /catkin_ws/src/ntbd_core/scripts/physical_2_visual\r\ncp /src/FK /catkin_ws/src/ntbd_core/scripts/FK\r\ncp /src/motors_values /catkin_ws/src/ntbd_core/scripts/motors_values\r\n# Make scripts executable to be used as nodes!\r\ncd /catkin_ws/src/ntbd_core/scripts/\r\nchmod +x IK && chmod +x physical_2_visual && chmod +x FK && chmod +x motors_values\r\n\r\ncp /src/NTBD_launch.launch /catkin_ws/src/ntbd_core/launch/NTBD_launch.launch\r\n\r\n# NTBD_urdf\r\ncp -rf /src/manipulator_urdf/ /catkin_ws/src/manipulator_urdf/\r\n# setup ros3djs config (comprehends nginx config)\r\ncp -rf /src/manipulator_urdf/ /var/www/html/manipulator_urdf/\r\ncp /src/NTBD_viz.html /var/www/html/NTBD_viz.html\r\n\r\ncp /src/ntbd_lm.html /var/www/html/ntbd_lm.html\r\n\r\ncp -rf /src/ros3djs/roswebconsole/ /var/www/html/roswebconsole/\r\n\r\nsource /catkin_ws/devel/setup.bash\r\ncd /catkin_ws/ && catkin_make\r\n\r\n# setup ros environment\r\n source /opt/ros/kinetic/setup.bash\r\n source /catkin_ws/devel/setup.bash\r\n\r\n# start nginx\r\nservice nginx start\r\n\r\n# Launch my ROS nodes and ros3djs URDF visualization\r\nroslaunch ntbd_core NTBD_launch.launch\r\n\r\nexec \"$@\"\r\n```\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2018-01-17-ntbd-guide-part-I/index.md",
    frontMatter: {
      path: "/hbr/ntbd-guida-step-by-step/",
      author: {
        id: "fiorellazza",
        name: "Fiorella Sibona",
        bio: "Aspiring roboticist",
        profile: "/imgs/authors/fiorellazza.jpg",
      },
      readTime: "16 mins",
      published: "2018-01-17T00:00:00.000Z",
      publishedReadable: "17 Gen 2018",
      featured: false,
      tags: [],
      title: "NTBD: guida step by step",
      description:
        "Cos'è e come utilizzare NTBD step by step, primo articolo della serie",
      href: "/hbr/ntbd-guida-step-by-step/",
      image: "/content/hbr/2018-01-17-ntbd-guide-part-I/sibot.png",
      imagePath: "/content/hbr/2018-01-17-ntbd-guide-part-I",
    },
  },
  {
    content:
      "\nNegli ultimi anni il dibattito sulla robotica si è molto acceso ed è diventato comune anche tra l'opinione pubblica.\nI robot creano nelle persone sentimenti contrastanti, sia di interesse verso questa tecnologia ma anche di paura\nper il nostro futuro.\n\nLe paure sono da una parte causate da un grosso filone della fantascienza che racconta mondi in cui i robot prendono\nil sopravvento sull'uomo come nuova specie dominante del pianeta, ma dall'altro dalla paura (a mio avviso non tanto concreta) dell'innovazione che distruggerà tantissimi posti di lavoro nel futuro prossimo.\n\nIn questo post non voglio addentrarmi troppo in queste discussioni (anche se certamente dedicherò alcuni post futuri su questa rubrica a discorsi etici, morali e sociologici della robotica), ma voglio invece iniziare ad intraprendere un discorso con voi su cosa è la robotica, e cosa dobbiamo aspettarci da questa scienza nel prossimo futuro!\n\n## Cosa è un robot?\n\nPer preparaci al meglio, cerchiamo prima di tutto di rispondere alla domanda \"cosa è un **robot**?\"! Come fa notare la professoressa Carrozza nel suo libro [**I Robot e Noi**](https://amzn.to/2sVkCOt), cercando di rispodnere a questa domanda ci troviamo di fronte ad un grande **paradosso**, in cui per noi risulta molto facile riconoscere un robot vedendolo, ma altrettanto difficile darne una definizione\nomnicomprensiva che permetta, in modo semplice e schematico, di definire questa classe di macchine.\n\nI robot, infatti, hanno differenti forme e funzioni, e vanno da Robot Industriali, enormi macchine meccaniche in grado di spostare anche oggetti pesantissimi, passando per droni e robot su ruote, fino ai semplici sistemi educativi che, da qualche tempo, vanno molto di moda nelle scuole.\n\n![alcuni esempi di robot](./robots.png)\n\nI robot, quindi, hanno diverse forme, dimensioni, funzioni e scopi nel nostro mondo, e diventa sempre più complesso darne una definizione che accontenta tutti! Nel mio piccolo, piace definire i robot secondo un paio di parametri che accomunano\nquasi tutti i robot con cui ho lavorato: la **multifunzionalità**, l'**autonomia** e la **programmabilità**. Secondo la mia definizione, infatti, i robot sono **macchine multifunzionali**, progettati cioè per compiere una vasta gamma di compiti più o meno complessi, in grado di **agire in modo (semi)autonomo** attraverso dell'intelligenza gestida da un **programma software**.\n\nAnalizziamo un po' meglio questi aspetti insieme.\n\n##### I robot sono macchine multifunzionali\n\nCioè progettati per compiere azioni diverse in base alle necessità. Un braccio robotico industriale, ad esempio, è progettato per muoversi con grande precisione, velocità e destrezza. In questo modo, è in grado di compiere vari tipi di operazioni dal prendere e spostare gli oggetti, ad eseguire lavori come la saldatura, montare pezzi, etc. Similmente, un drone è progettato per volare in modo snello e veloce, e questo gli permette di compiere operazioni di ripresa e monitoraggio o di spostare piccoli oggetti in modo autonomo e veloce.\n\n##### I robot sono macchine (semi)autonome\n\nCioè in grado di prendere decisioni, anche complesse, in base alle necessità, con diversi gradi di interazione con una persona umana.\nL'autonomia nei robot varia in base alle situzione ed alla applicazione. Si passa da robot con un bassissimo grado di autonomia, specialmente in applicazioni industriali di manifattura o robot a controllo remoto, fino a robot completamente autonomi, come ad esempio robot per l'esplorazione spaziale o i robot di servizio moderno, passando per diversi gradi intermedi.\n\n##### I robot sono programmabili\n\nL'intelligenza del robot è demandata ad un programma più o meno complesso che gira sui computer o microcontrollori a bordo del robot.\nData l'elevata multifunzionalità dei robot, questi programmi devono essere sviluppati da tecnici ed ingegneri esperti con linguaggi di programmazione moderni.\n\n## La Robotica: La scienza per studiare i robot\n\nI robot sono quindi sistemi complessi sotto diversi punti di vista. Progettare e costruire robot non è semplice, ma spesso si considera la **robotica** come una semplice branca dell'ingegneria.\n\nIn realtà, lo studio e lo sviluppo dei robot è una **scienza** a tutti gli effetti, che ha come particolare caratterica quella di far confluire al suo interno diversi saperi delle classiche scienze tradizionali (matematica, ingegneria, biologia, fisica, neuroscienze, etc.) e scienze umane (in particolar modo la fisolofia e l'etica). La robotica è una scienza particolare, non settoriale spesso associata al concetto di **multidisciplinarietà**, ma recentemente definita dalla prof.ssa Carrozza come scienza **antidisciplinare**, nel senso che lo scienziato robotico deve padroneggiare diversi campi del sapere, in contratto con i classici approcci multidisciplinari in cui diversi esperti, padroni di una determinata disciplina, lavorano insieme ma mantenendo separate le loro competenze.\n\nLo studio della robotica come scienza, infatti, è influenzato ed influenza diverse scienze. Pensate, ad esempio, che lo studio dei movimenti di un robot umanoide ha permesso di comprendere meglio la biomeccanica nel movimento degli animali ed esseri umani.\n\nNel mio piccolo, capisco e mi ci ritrovo nel mondo dell'antidisciplinarietà come ingegnere robotico, che è stato fortemente presente nella mia carriera da studente. Fin dall'inizio ero deciso ad intraprendere degli studi nel mondo della robotica, tanto da aver studiato **meccatronica** presso il **Politecnico di Torino**, un corso di studi già di per se multidisciplinare.\nMa la mia scelta di andare sempre più in direzione della robotica mi ha spesso portato allo stravolgimento del mio corso di studi, in modo da aggiungere corsi (non previsti) legati più al mondo dell'informatica e dello sviluppo software.\nÈ un fatto i miei studi si siano spostati sempre di più verso lo studio di algoritmi di intelligenza artificiale e visione artificiale, non presenti nel corso di Meccatronica standard.\n\nProprio a causa di questa natura antidisciplinare, esistono diversi campi applicativi della robotica, spesso molto diversi tra di loro. Di seguito vi riporto un elenco di alcune delle applicazioni moderne della robotica, che verranno poi riprese ed esplose nei prossimi post di questa rubrica:\n\n1. Robotica Industriale\n2. Robotica per l'esplorazione spaziale\n3. Robotica per la Chirurgia\n4. Biorobotica e Neurorobotica\n5. Robotica Educativa\n6. Robotica di Servizio\n7. Robotica collaborativa\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/robotics/001-introduzione-robotica/index.md",
    frontMatter: {
      path: "/robotica/001-introduzione-robotica/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2018-01-10T00:00:00.000Z",
      publishedReadable: "10 Gen 2018",
      featured: false,
      tags: [],
      title: "La robotica: la scienza che sta rivoluzionando il mondo",
      description:
        "Iniziamo insieme un viaggio alla scoperta dei robot e della robotica!",
      href: "/robotica/001-introduzione-robotica/",
      image: "/content/robotics/001-introduzione-robotica/robots.png",
      imagePath: "/content/robotics/001-introduzione-robotica",
    },
  },
  {
    content:
      "\nQuesto post riprende in parte un post scritto tempo fa per la community Rokers, che adesso purtroppo non è più online per il poco tempo che io, Gabriele e Basilio avevamo per dedicarci.\n\nEssendo il post (almeno secondo me) veramente ben fatto, mi dispiaceva che non fosse più pubblicato. Ho quindi deciso di riesumarlo e megliorlarlo.\n\n![Robotica Illustrazione](./maxresdefault.jpg)\n\n## La Robotica di Servizio\n\nPartiamo dal concetto di **Robotica di Servizio**.\nQuando si parla di Robotica, si pensa principalmente a tre differenti aspetti:\n\n![Service Robotics](./service.png)\n\n- La robotica industriale, che è quel campo della robotica a cui tecnologicamente e realisticamente siamo più abituati. E il prof. Basilio Bona, su questo argomento, vi sta già tediando abbastanza :D\n- La robotica nella fantascienza, in cui solitamente si parla di Robot Umanoidi non tanto distinguibili dagli essere umani (e che molto spesso tentano di distruggere la razza umana)!\n- La robotica educativa/hobbistica, che ha invaso le scuole e i Fablab negli ultimi anni, in cui vediamo piccoli robottini con pochissima autonomia, realizzati per scopi didattici o per puro divertimento.\n\nTuttavia, negli ultimi anni, un nuovo campo di applicazione della robotica sta sempre più prendendo piede, sia dal punto di vista della ricerca, ma anche con applicazioni reali sul mercato: si tratta della **robotica di servizio**. Questo campo della robotica riunisce tutte quelle tecnologie robotiche pensate per aiutare gli essere umani a svolgere compiti nel loro quotidiano.\n\nOra, definire esattamente cosa è la robotica di servizio è molto difficile, in quanto esistono tantissime applicazioni pratiche molto diverse tra di loro (e con hardware molto diversi). Tuttavia, cercherò di dare la mia personalissima definizione (che non comprende tutte le definizione e/o i campi di applicazione, come è ovvio che sia):\n\n> Un **sistema robotico** di **servizio** è un sistema robotico in grado di aiutare gli esseri umani a svolgere un certo compito in modo **(semi)autonomo**, **senza essere programmato** dall'utente.\n\nDal mio personalissimo punto di vista, un sistema robotico (ho scelto appositamente questo termine _sistema robotico_, e non _robot_) di servizio deve avere una specifica caratteristica per essere definito tale:\n\n- Non necessitare di una programmazione dell'utente per svolgere il suo lavoro.\n\nQuesto è infatti ciò che distingue, sia da un punto di vista tecnologico che da un punto di vista applicativo, un sistema di robotica di servizio dai classici sistemi di robotica industriale. In quest'ultimo caso, infatti, l'utente del robot (l'utilizzatore), è anche colui che programma il robot, al contrario, nella robotica di servizio è il costruttore del robot (o chi lo vende) a doverlo programmare, mentre l'utente è un puro utilizzatore passivo del sistema.\n\nApplicativamente, infatti, un utente non deve essere \"esperto\" in robotica per poter usare il sistema. Pensate per esempio al Roomba (o ai vari robot per pulire i pavimenti): il loro utilizzo è quasi come quello di un'applicazione per uno smartphone: apri la scatola, accendi, fine. Il robot, con le dovute limitazioni, è quasi completamente autonomo nel pulire i pavimenti.\n\nIl problema è tecnologico: infatti sviluppare un robot con un alto grado di autonomia risulta essere molto complesso.\nLimitiamoci al caso specifico di robot su ruote: i programmatori non possono fare \"assunzioni\" su cosa succederà intorno al robot, come avviene invece nei robot industriali. Il robot deve essere autonomo, sicuro e deve durare, e questo implica che questa debba essere in grado di eseguire alcuni compiti complessi, che sono (principalmente) quelli che trovate qui sotto:\n\n- **mapping**: Il robot deve essere in grado di costruire una \"mappa\" (cioè un modello matematico) dell'ambiente in cui si trova.\n- **localization** Il robot deve essere in grado di determinare la propria posizione all'interno dell'ambiente (utilizzando la mappa di cui sopra).\n- **path planning** Il robot deve essere in grado di pianificare una traiettoria da seguire per raggiungere un punto specifico della mappa.\n- **path following** Il robot deve essere in grado di seguire una traiettoria pianificata nel punto sopra, considerando la possibilità di trovare ostacoli non previsti come persone in movimento o oggetti non presenti in fase di costruzione della mappa.\n\n![navigazione robotica](./navigazione.png)\n\nQueste 4 capacità vengono solitamente raggruppate sotto il noto problema del **robot navigation**, problema ancora tecnologicamente aperto e non completamente risolto.\n\nSi noti inoltre che le 4 capacità sopra citate sono anch'esse non ben definite, e dipendono molto dalla specifica applicazione. Per un robot che si muove in esterno le prime due sono quasi gratuite: basta sfruttare un qualsiasi servizio che fornisce mappe terrestri e dei GPS (anche se ci sarebbe un grosso discorso da fare sulla precisione degli stessi); ma il **path following** diventa molto delicato. Al contrario, in un robot che si muove all'interno di un edificio, **mapping** e **localizzazione** spesso sono problemi che devono essere risolti contemporaneamente (il robot mentre costruisce la mappa deve sapere la posizione di se stesso nella mappa in costruzione): in questo caso, si parla di un noto e importante problema nella robotica chiamato **SLAM** (_Simultaneous Localization and Mapping_).\n\nA tale complessità, si aggiungono altri problemi quando si sviluppano le applicazioni robotiche:\n\n- Interazione con la persona\n- Limiti di batteria\n- Costo dell'hardware e del software\n\nCapite quindi che, per un ingegnere robotico (come me), il tutto è un grosso problema. E alla base di tutto questo c'è il progetto ROS.\n\n## ROS: The Robot Operating System\n\n![ROS illustrazione](./FAIYQBVH3M6BTPR.MEDIUM.jpg)\n\n> Why ROS? Because creating truly robust, general-purpose robot software is hard. From the robot's perspective, problems that seem trivial to humans often vary wildly between instances of tasks and environments. Dealing with these variations is so hard that no single individual, laboratory, or institution can hope to do it on their own. \\[[ros.org/about-ros/](http://www.ros.org/about-ros/)\\]\n\nProvo a tradurre:\n\n> Perché ROS? Perché sviluppare software robusti e _general-purpose_ per robot è difficile. Dal punto di vista di un robot, problemi che sembrano banali agli essere umani spesso variano molto per le funzioni e gli ambienti. Affrontare queste variazioni è così difficile che nessun singolo individuo, laboratorio o istituto possa sperare di farlo da solo.\n\nLa volontà e l'intuizione degli ideatori di ROS era quindi quella di fornire un ecosistema per spingere vari gruppi di ricerca in tutto il mondo a collaborare per risolvere questi problemi tanto complessi unendo le forze.\n\nDopo circa 10 anni dalla prima versione realizzata di ROS, posso certamente affermare che lo scopo principale (quello di creare una community a livello mondiale), è stato realizzato, ed infatti, all'interno del mondo ROS, è possibile trovare pacchetti che risolvono (o tentano di risolvere, in quanto la tecnologia ancora non è perfetta) praticamente tutti i problemi tecnologici legati alla robotica di servizio.\n\n### Ma quindi, cosa cavolo è 'sto ROS???\n\nMi aspetto che chi è riuscito a leggere questo articolo fino a qui si sia fatto questa domanda. Vediamo di capire esattamente cosa è. Ma prima sfatiamo un mito: a dispetto del nome, ROS **non è un sistema operativo per robot**. ROS, invece, è:\n\n- Un framework per lo sviluppo di applicazione robotiche (connesse).\n- Un set di Librerie, strumenti di sviluppo e convenzioni che forniscono una base tecnologica robusta da cui partire per lo sviluppo di tali applicazioni.\n- Una grossissima community di ricercatori, scienziati e appassionati di tutto il mondo.\n\nROS è quindi una grossissima ed importantissima fonte per chiunque voglia iniziare a sviluppare applicazioni robotiche. Si basa su Linux (in particolare Ubuntu e Debian), ma è possibile installarlo su una vasta quantità di macchine.\n\nDal punto di vista tecnico, tra le caratteristiche più importanti di questo progetto, le più interessanti (secondo me, poi qualcuno potrebbe non essere d'accordo), sono le seguenti:\n\n- Astrazione dell'hardware;\n- Sistemi Multimacchina.\n\nROS permette di _Astrarre l'hardware_, cioè fa sì che gli sviluppatori non debbano pensare troppo al sistema reale su cui la propria applicazione deve girare. Il tutto ha alcuni svantaggi di performarce, ma certamente enormi vantaggi sul piano applicativo: un esempio è il seguente, il sistema di telecontrollo di un robot in ROS funziona, senza problemi, sia per controllare Robot su ruote che per controllare Robot umanoidi, e con alcune accortezze, permette di controllare droni.\nIn altre parole, grazie a ROS, sotto opportune limitazioni, possiamo sviluppare applicazioni generiche e farle girare su sistemi robotici di vario tipo, un po' come fanno gli sviluppatori per Android, che quando sviluppano l'app per cellulare, non stanno a chiedersi se poi quest'app sarà scaricata su un Samsung, su un Nexus o un One Plus.\n\nInoltre, ROS permette di sviluppare sistemi _Multimacchina_, in cui l'intelligenza non è centralizzata su un unico computer (di solito sul robot), ma può essere distribuita (tramite una rete di comunicazione), tra più computer connessi tra di loro. Il bello è che il tutto è trasparente allo sviluppatore e al codice. Io, sviluppatore, posso implementare un Nodo ROS (cioè un programma ROS), e poi decidere se farlo girare sul robot o su una macchina remota, senza dover cambiare una riga del codice originale.\n\nQueste due caratteristiche di ROS, aprono la strada ad un grandissimo cambio di paradigma, avvenuto negli ultimi temi, nel mondo della robotica di servizio: la **Cloud Robotics**.\n\n## Cloud Robotics: anche i robot usano DropBox\n\n![Cloud Robotics Illustrazione](./Cloud-Robotics-and-Automation-Illustration-Goldberg-Aug-2014-lo-res.jpg)\n\nNel 2010, James Kuffner fece un ragionamento molto semplice ma anche disruptive:\n\n> i robot sono (essenzialmente) computer con delle ruote, i computer trovano un enorme beneficio nell'essere connessi ad internet: che succede se attacco un robot ad internet?\n\nDa questa semplice considerazione, che per certi versi ho banalizzato, ma spero che renda l'idea, è nato quindi il paradigma della **Cloud Robotics**, o **Robotica in Cloud**.\n\nBadate bene, l'idea di connettere robot a internet è arrivata molto prima: tralasciando tutta la letteratura fantascientifica, già dagli anni '80 riusciamo a trovare lavori di vario tipo che prevedono di connettere e controllare Robot tramite internet. Lo stesso progetto [**RoboEarth**](http://roboearth.ethz.ch/), che è ampiamente riconosciuto come il primo progetto di ricerca ad applicare fortemente il concetto di Cloud Robotics, è nato nel 2009 (quindi un anno prima la presentazione di Kuffner). Tuttavia, a James Kuffner, va riconosciuto il merito di aver formalizzato sotto un unico cappello ed aver trovato un nome a questo nuovo approccio alla robotica.\n\nMa perché la **Cloud Robotics** è fortemente legata alla robotica di servizio? La risposta è molto semplice: sebbene questo paradigma sia molto trasversale nel mondo della robotica, e venga applicato benissimo anche nel mondo della robotica industriale, nel mondo della robotica di servizio risulta essere non tanto un miglioramento o potenziamento di una tecnologia già matura, ma il vero abilitatore di una tecnologia che, come spiegato prima, ancora non è completamente matura.\n\nIl perché è presto detto: come spiegato precedentemente, gli algoritmi necessari a far funzionare bene un robot di servizio sono molto complessi, e quindi richiedono enormi quantità di calcolo (e di storage, nel caso di algoritmi per la visione artificiale). Questo vuol dire che un robot autonomo deve avere un grosso computer a bordo per poter funzionare. Questa cosa ha tre svantaggi:\n\n- L'ingombro e il peso (un server molto potente non è certo piccolo),\n- Il consumo energetico,\n- Il costo.\n\nCapite bene, quindi, che mettere un server decente su un robot di servizio ne aumenta il costo, il peso e le dimensioni, e ne riduce l'autonomia della batteria.\n\nCon l'approccio della Cloud Robotics, invece, queste limitazioni sono virtualmente superate: il robot può \"delegare\" parte della sua intelligenza ad un server in Cloud, spedendo al server i dati dei propri sensori, che vengono elaborati e trasformati in comandi per gli attuatori, che tornano indietro al robot.\n\nRicordo che, quando inizia il mio percorso di dottorato in TIM, si vedeva la **Cloud Robotics** come un sistema composto da un robot stupido, che non era altro che un insieme di sensori e attuatori, con una sim 4G al suo interno. Ovviamente questa visione è troppo semplicistica ed irrealizzabile, specialmente perché alcune funzionalità del robot, per quanto complesse, è bene che siano eseguite all'interno del robot stesso. Prendiamo, ad esempio, un semplice algoritmo per evitare gli ostacoli, se proviamo a mettere \"in Cloud\" questo algoritmo, sono sicuro al 100% che al primo malfunzionamento o ritardo di internet il robot va a sbattere da qualche parte :D\nTuttavia, esistono un'ampia classe di funzionalità di sistema robotico autonomo, che non necessitano di stringenti limiti temporali per funzionare bene. Gli algoritmi di **Mapping**, **SLAM** e **Path Planning** rientrano in questa categoria, e sono anche tra i più esosi in termini di risorse computazionali.\n\nSpero, a questo punto, di aver fatto capire come mai sopra parlavo di **sistema robotico** e non di **robot**. Infatti, spesso questi tipi di robot non sono a se stanti, ma connessi ad internet, e parte del loro \"cervello\" viene spostata su un server in cloud, lasciando sul robot stesso, alcune funzionalità di base necessarie alla sicurezza nel caso che la connessione internet venga persa.\n\n## Conclusioni\n\nCosa ne pensate di queste tecnologie? Siete interessati ad approfondire alcuni concetti? Scrivendo questo post, ho trascurato tantissimi aspetti di cui avrei voluto parlare ma (per questioni di lunghezza, e perchè volevo evitare di tediarvi troppo, ho preferito non evidenziare, almeno per il momento). Scrivetemi cosa ne pensate!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/robotics/002-introduzione-robotica-servizio/index.md",
    frontMatter: {
      path: "/robotica/002-introduzione-robotica-servizio",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "10 mins",
      published: "2018-01-10T00:00:00.000Z",
      publishedReadable: "10 Gen 2018",
      featured: false,
      tags: [],
      title: "Robotica di Servizio, ROS e Cloud Robotics",
      description:
        "Iniziamo insieme un viaggio alla scoperta dei robot e della robotica!",
      href: "/robotica/002-introduzione-robotica-servizio",
      image:
        "/content/robotics/002-introduzione-robotica-servizio/maxresdefault.jpg",
      imagePath: "/content/robotics/002-introduzione-robotica-servizio",
    },
  },
  {
    content:
      '\nCiao a tutti,\ncome chi segue questo blog sa già, da poche settimane, grazie ad alune richieste dalla\ncommunity [Rokers](https://rokers.io/),\nabbiamo fatto partire un corso youtube che introduce e spiega le basi di ROS.\n\nIl corso sta proseguendo, ma la parte introduttiva, che è stata conclusa, è disponibile\nda vedere completamente.\n\nQui sotto, trovate la parte introduttiva del corso, ormai completa, in cui spieghiamo\nquali sono gli scopi e le finalità di ROS, e forniamo una veloce panoramica\ndelle funzioni base.\n\nSe volete ricevere informazioni sulla pubblicazione dei video, e discuterne,\npotete iscrivervi al gruppo facebook [Robot Developers Italiani](https://www.facebook.com/groups/493163691070528/)\n\n### Introduzione a ROS e alla Robotica di Servizio\n\n{% include youtube.html id="ZcZC_LT916g" %}\n\n### Installazione di ROS su Linux Ubuntu\n\n{% include youtube.html id="Bk1h7rTMh7U" nav=True %}\n\n### Utilizzo base di ROS\n\n{% include youtube.html id="Gxx3iWTuc_U" %}\n\n### Ispezionare ROSGraph con RQT\n\n{% include youtube.html id="OFZzIRBf4LQ" %}\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-12-13-corso-web-ros-introduzione/index.md",
    frontMatter: {
      path: "/hbr/video-corso-ros-rokers-completati-i-video-di-introduzione/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-12-13T00:00:00.000Z",
      publishedReadable: "13 Dic 2017",
      featured: false,
      tags: [],
      title: "Video Corso ROS Rokers - Completati i video di Introduzione",
      description:
        "Sono disponibili online i video tutorial del corso di ROS partito dalla community Rokers",
      href: "/hbr/video-corso-ros-rokers-completati-i-video-di-introduzione/",
      image: "/content/hbr/2017-12-13-corso-web-ros-introduzione/main.png",
      imagePath: "/content/hbr/2017-12-13-corso-web-ros-introduzione",
    },
  },
  {
    content:
      "\r\n![ROS+Raspberry Logo](./FPNU31FHBNXVG6G.jpg)\r\n\r\nCiao a tutti, torniamo con questo primo tutorial per installare ed utilizzare [ROS](http://www.ros.org/) (the Robot Operating System) su Raspberry Pi.\r\n\r\n## ROS: Il Sistema Operativo dei robot\r\n\r\nPrima di installarlo ed utilizzarlo, cerchiamo di capire cosa è, quali sono le sue finalità e perchè è diventato un standard di fatto a livello accademico e perchè molte aziende lo stanno iniziando ad adottare.\r\n\r\n### Cosa è ROS?\r\n\r\nSecondo il sito ufficiale, ROS è un framework per la programmazione Robot orientato alla creazione di Sistemi Robotici distribuiti che interagiscono con l'ambiente umano. È quindi un framework per lo sviluppo di applicazione Robotiche di servizio. È chiamato _OS_, in modo leggermente improprio, perchè offre le stesse funzionalità che normalmente offre un sistema operativo, ma in ambiente multi macchina e multi robot.\r\n\r\n### Perchè ROS?\r\n\r\nPerchè sviluppare applicazioni robotiche di servizio è difficile! ROS è quindi nato per essere modulare e per favorire la collaborazione tra gruppi di ricerca interessati a temi diversi. Facciamo un esempio del sistema di complessità di un'applicazione robotica reale.\r\n\r\nUsando ROS, diveri gruppi di ricerca posso creare moduli sulla loro expertize tecnica, e poi condividere tra loro i module ed integrarli con altri moduli per costruire l'applicazione.\r\n\r\nQuesta caratteristica ha fatto si che ROS sia diventato in poco tempo uno standard utilizzato da praticamente tutti i gruppi di ricerca accademici che si interessano alla robotica di servizio. E ultimamente anche molte aziende si sono avvicinate a questa tecnologica. In italia citiamo **TIM** che dal 2013 si interessa di queste tematiche.\r\n\r\n### ROS e HotBlack Robotics\r\n\r\nNoi di **HBRobotics** siamo esperti di ROS, in quanto lo abbiamo utilizzato per anni durante il nostro percorso di Ph.D. al Politecnico di Torino. Quando abbiamo fondato questa società abbiamo deciso di fondare su ROS tutta la nostra tecnologica, e dato che ROS ci ha dato tanto, vogliamo anche contribuire al suo sviluppo e alla sua diffusione anche sul suolo Italiano.\r\n\r\n## ROS su Raspberry Pi\r\n\r\nQuando è stato presentato il primo **Raspberry PI**, molti utilizzatori di ROS (tra cui il sottoscritto, _maker_ da prima di conoscere la parola \"_maker_\") hanno capito le potenzialità di questo piccolo computer nell'ambito della robotica di servizio. Finalmente esisteva un piccolo computer a bassissimo costo in grado di supportare ROS e quindi di alimentarne la diffusione non solo in ambito accademico e industriale ma anche a livello hobbistico. Purtroppo le prime procedure per l'installazione di ROS su questa macchina erano molto complicate e lente, in quanto era necessario compilare l'intero sistema operativo su Debian, che non supportava ufficialmente. Ricordo ancora la prima volta che riuscii ad installare ROS sul primo Raspberry Pi Model B dopo un mese di tentativi (ammetto che quell'esperienza fu altamente istruttiva in quanto, a fuoria di risolvere errori e dipendenze, imparai tantissimo di Linux).\r\n\r\nAi tempi spuntavano online varie SD già pronte con ROS installato sopra. Il problema era che, ogni volta che serviva installare un nuovo pacchetto ROS, bisognava ricompilare tutto dall'inizio, cosa che dopo un po' diventava infattibile.\r\n\r\nAd ogni modo, i tempi sono cambiati e adesso è molto facile, con qualche trucchetto, installare ROS su un Raspberry Pi senza troppi problemi.\r\n\r\n### Cosa Serve?\r\n\r\nEcco i materiali che servono:\r\n\r\n- Un Raspberry Pi (consiglio caldamente Raspberry Pi 3 Model B, o almeno il 2 Model B, non ho mai provato questa procedura sul Raspberry Pi 1).\r\n- Una SD con sopra Raspbian. Trovate l'ultima versione [qui](https://www.raspberrypi.org/downloads/raspbian/).\r\n- Un po' di pazienza :D\r\n\r\n### Cosa Faremo?\r\n\r\nLo scopo del tutorial è quello di installare ROS e iniziare ad utilizzarlo!\r\n\r\n## Installiamo ROS\r\n\r\nAccediamo al Raspberry ed apriamo il terminale.\r\n\r\nPer prima cosa, è importante aggiornare tutti i pacchetti all'ultima versione, la procedura potrebbe richiedere un po' di tempo, nella mia prova ci ha messo più di 30 minuti per completare l'installazione!\r\n\r\n```bash\r\nsudo apt-get update\r\nsudo apt-get upgrade\r\n```\r\n\r\nUna volta lanciato, digitiamo i seguenti comandi\r\n\r\n```bash\r\nsudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu trusty main\" > /etc/apt/sources.list.d/ros-latest.list'\r\nsudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 421C365BD9FF1F717815A3895523BAEEB01FA116\r\nsudo apt-get update\r\nsudo apt-get install ros-indigo-ros-base\r\n```\r\n\r\nInseriamo la password quando serve e procediamo selezionando sempre `Y` (yes) durante la fasi di installazione.\r\nAnche questa procedura è un po' lenta, dovuta al fatto che sono tantissimi i moduli da installare e la poca potenza del raspberry!\r\n\r\nUna volta installato, dobbiamo abilitare ROS all'avvio di ogni shell, in modo da avere tutti i comandi principali attivi. Si fa con il seguente comando\r\n\r\n```bash\r\necho \"source /opt/ros/indigo/setup.bash\" >> ~/.bashrc\r\n```\r\n\r\n## Utilizzo di TurtleSim\r\n\r\nTurtle Sim è un modulo ROS sviluppato per imparare ad utilizzarlo. È in particolare una suite di sperimentazione che permette di controllare tramite ROS una tartaruga virtuale Robotica.\r\n\r\n### Installazione di TurtleSim\r\n\r\nPer installare il modulo, utilizziamo il comando\r\n\r\n```bash\r\nsudo apt-get install ros-indigo-turtlesim\r\n```\r\n\r\nA questo punto siamo pronti a muovere i primi passi. Ma prima di tutto è necessario **Chiudere la Shell**.\r\n\r\n### Utilizzo di TurtleSim\r\n\r\nA questo punto iniziamo a divertirci. È importante, prima di tutto, dobbiamo aprire un po' di shell contemporaneamente (è la prassi quando si utilizza ROS, quindi abitutevi al disordine).\r\n\r\nNella prima shell, digitiamo il comando\r\n\r\n```bash\r\nroscore\r\n```\r\n\r\nche lancia il cuore di ROS, ed è necessario per inizializzare una rete ROS.\r\n\r\n![roscore ROS shell](./roscore.png)\r\n\r\nDovreste vedere un output del tipo\r\n\r\n```shell\r\n\r\n... logging to /home/pi/.ros/log/e3e26302-d999-11e6-94cd-b827ebf7d5f2/roslaunch-raspberrypi-10902.log\r\nChecking log directory for disk usage. This may take awhile.\r\nPress Ctrl-C to interrupt\r\nDone checking log file disk usage. Usage is <1GB.\r\n\r\nstarted roslaunch server http://raspberrypi:45912/\r\nros_comm version 1.11.20\r\n\r\n\r\nSUMMARY\r\n========\r\n\r\nPARAMETERS\r\n * /rosdistro: indigo\r\n * /rosversion: 1.11.20\r\n\r\nNODES\r\n\r\nauto-starting new master\r\nprocess[master]: started with pid [10914]\r\nROS_MASTER_URI=http://raspberrypi:11311/\r\n\r\nsetting /run_id to e3e26302-d999-11e6-94cd-b827ebf7d5f2\r\nprocess[rosout-1]: started with pid [10927]\r\nstarted core service [/rosout]\r\n\r\n```\r\n\r\nLasciate questa shell aperta e, in una seconda shell, lanciamo il simulatore della nostra bellissima tartaruga\r\n\r\n```\r\nrosrun turtlesim turtlesim_node\r\n```\r\n\r\nche aprirà una finestra grafica in cui viene visualizzata una tartaruga stilizzata in grafica 2D. In realtà la tartaruga è un robot ROS simulato, a cui possiamo mandare comandi di velocità tramite ROS\r\n\r\n![ROS TurtleSim Finestra](./turtlesim.png)\r\n\r\nA questo punto, non ci resta che lanciare un terzo nodo per mandare comandi di velocità alla tartaruga. Questo nodo si lancia (di nuovo su una shell distinta) con\r\n\r\n```bash\r\nrosrun turtlesim turtle_teleop_key\r\n```\r\n\r\n![Shell ROS teleop](./teleop.png)\r\n\r\nQuesta volta non usciamo dalla shell ma, lasciandola attiva, premiamo le frecce della tastiera. Se tutto funziona, dovreste vedere la vostra tartaruga muoversi in accordo con i comandi impartiti.\r\n\r\nQuesta è lo screen sul mio Raspberry Pi quando tutto è in funzione.\r\n\r\n![Screen ROS Raspberry Pi](./screen_rasp.jpg)\r\n\r\n## Conclusioni\r\n\r\nIn questo tutorial abbiamo visto come installare ed utilizzare ROS su Raspberry Pi. Seguiranno altri tutorial per approfondire l'argomento!\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-12-11-installiamo-ros-su-raspberry-pi/index.md",
    frontMatter: {
      path: "/hbr/installiamo-ros-su-raspberry-pi/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2017-12-11T00:00:00.000Z",
      publishedReadable: "11 Dic 2017",
      featured: false,
      tags: [],
      title: "Installiamo ROS su Raspberry Pi",
      description: "Un breve tutorial su come utilizzare ROS sul Raspberry Pi",
      href: "/hbr/installiamo-ros-su-raspberry-pi/",
      image:
        "/content/hbr/2017-12-11-installiamo-ros-su-raspberry-pi/FPNU31FHBNXVG6G.jpg",
      imagePath: "/content/hbr/2017-12-11-installiamo-ros-su-raspberry-pi",
    },
  },
  {
    content:
      "\nCiao a tutti,\nCome sapete, da domani 1 Dicembre fino a domenica 3 Dicembre a Roma si terrà l'edizione 2017 della Maker Faire Europe. Il più grande evento di Making Europeo che si tiene annualmente nella nostra capitale.\n\nCome ogni anno, io sarò presente con i miei progetti e con i miei amici per mostrare ai presenti su cosa stiamo lavorando.\n\nQuest'anno abbiamo applicato come **Rokers**, (che si trova al Pav. 6 B.01) la community di robot makers tutta italiana fondata da me, Gabriele e Michele Maffucci pochi mesi fa.\n\nMa non solo, io, Gabriele e Michele fare anche due talk incentrati sul mondo della robotica e sul mondo del lavoro per gli sviluppatori robotici.\n\nSe volete più informazioni, trovate tutto a [questo link](https://rokers.io/makers/educativa/2017/11/28/Rokers-alla-maker-faire-rome-programma.html)!\n\n![DotBot](./dotbot.png)\n\n![Parloma](./parloma.jpg)\n\nFatemi sapere nei commenti se qualcuno riesce a passare, noi vi aspettiamo!\n\nA presto,\nLudovico\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-11-24-maker-faire-2017/index.md",
    frontMatter: {
      path: "/2017/11/24/maker-faire-2017/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-11-24T00:00:00.000Z",
      publishedReadable: "24 Nov 2017",
      featured: false,
      tags: ["Maker Faire", "Rokers", "HotBlack Robotics"],
      title: "Maker Faire 2017",
      description: "Ci vediamo alla Maker Faire, pav.6 B.01",
      href: "/2017/11/24/maker-faire-2017/",
      image: "/content/blog/it/2017-11-24-maker-faire-2017/dotbot.png",
      imagePath: "/content/blog/it/2017-11-24-maker-faire-2017",
    },
  },
  {
    content:
      "\nCiao a tutti,\nscrivo un breve post per due motivi.\n\nIl primo, per informavi che nel mio lavoro con [HotBlack Robotics](http://hotblackrobotics.com) sto portando avanti un video corso su come utilizzare ROS (Robot Operating System) completamente in italiano.\n\n![Corso ROS](./main.jpg)\n\nSe volete seguire il corso, o comunque ricevere più informazioni a riguardo, iscrivetevi al gruppo facebook appositamente creato, chiamato [robot developers italiani](https://www.facebook.com/groups/493163691070528/?ref=bookmarks) oppure alla newsletter che trovate al fondo di [questo articolo](https://hotblackrobotics.github.io/2017/11/20/slide-del-nostro-intervento-al-politecnico-di-torino-su-ros/).\n\nIl secondo motivo, meno importante ma anche interessante, è perché sto testando un nuovo metodo per pubblicare automaticamente i contenuti che posto su Jekyll sui vari social networks. Vi farò sapere se questo tentativo funziona.\n\nA presto,\nLudovico\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-11-24-videocorso-web-ros/index.md",
    frontMatter: {
      path: "/2017/11/24/videocorso-web-ros/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-11-24T00:00:00.000Z",
      publishedReadable: "24 Nov 2017",
      featured: false,
      tags: ["ROS", "YouTube"],
      title: "Un Video Corso di ROS",
      description: "Il mio video corso su come utilizzare ROS è disponibile",
      href: "/2017/11/24/videocorso-web-ros/",
      image: "/content/blog/it/2017-11-24-videocorso-web-ros/main.jpg",
      imagePath: "/content/blog/it/2017-11-24-videocorso-web-ros",
    },
  },
  {
    content:
      "\nCome sapete, da un po' di tempo (2 anni) mi sto dedicando alla creazione di una\nstart up in Robotica. In questo articolo, vi riporto la storia di [HotBlack Robotics](http://www.hotblackrobotics.com/),\n[scritta qualche mese](http://mars42.org/blog/2017/1/4/hotblack-robotics-story) fa da Gabriele (il mio socio e CEO della Startup) e tradotta\ndall'inglese da me.\n\n![Team HotBlack Robotics](./team.png)\n\nVi lascio alle parole di Gabriele.\n\n## _Autore: Gabriele Ermacora, Ph.D., CEO & Co-Founder, HotBlack Robotics_\n\nLa storia di [HotBlack Robotics](http://www.hotblackrobotics.com/) inizia nel 2011, quando TIM decise di investire in Ricerca e Sviluppo (R&D) sui nuovi trend tecnologici: Internet of Things e Cloud Robotics.\nDato che l'idea sembrava interessante, nel 2012 TIM decise di collaborare a stretto contatto con le più prestigiose università italiane. Così fondarono nuovi laboratori all'interno del mondo accademico. Questi laboratori si chiamano Joint Open Lab (JOL) e l'idea su cui si fondano è quella di creare team eterogenei di persone con background molto diverso tra di loro, sia ricercatori accademici che impiegati TIM, e farli lavorare insieme all'interno di progetti di innovazione molto ambiziosi.\nIl laboratorio dove ho svolto il mio Dottorato (_ed anche il mio, nota di Ludovico_) è il JOL CRAB (Connected Robotics Application laB). La visione su cui è nato questo laboratorio è quella di costruire una piattaforma di Cloud Robotics e trovare nuovi mercati per generare valore utilizzando questa tecnologia. Il laboratorio sviluppò diversi test case per mostrare le potenzialità della piattaforma:\n\n- robot per il monitoraggio energetico di data centers,\n- gestione di UAV all'interno di Smart Cities,\n- robotica per education ed intrattenimento,\n- robotica per agricoltura.\n\nInoltre, uno degli scopi principali del lab è quello di creare startup in modo da testare ed accelerare il processo di _go to market_. Così, il 23 Giugno 2015, io e il mio collega Ludovico Orlando Russo (_che sarei io, nota di Ludovico_) decidemmo di fondare una startup con la stessa visione del laboratorio e portare i nostri risultati scientifici nel market: così abbiamo fondato [**HotBlack Robotics**](http://www.hotblackrobotics.com/).\n\nAbbiamo deciso di partire dal progetto più maturo creato dal CRAB: un robot per il monitoraggio energetico all'interno di Data Center. Il risultato fu che lo spostamento dal mondo scientifico a quello imprenditoriale fu molto doloroso e pieno di problemi che non ci aspettavamo.\n\n![Robot per il monitoraggio termico nel data center](./robot.png)\n\nI data center sprecano tantissima energia elettrica, a causa del fatto che necessitano di alimentare e raffreddare continuamente i server. Ci sono varie soluzioni per aumentare l'efficienza energetica, e una delle più usate consiste in una rete di sensori distribuita e densa, i cui costi di installazione e manutenzione sono molto alti. L'idea era questa: perché rimpiazzare gli innumerevoli sensori fissi con un singolo sensore in grado di muoversi in autonomia all'interno del data center? Così sviluppammo un robot, dotato di sensori ambientali, in grado di muoversi autonomamente e collezionare misure dell'intero data center. Funzionava perfettamente dopo 4 anni di sviluppo, utilizzava tutti gli algoritmi allo stato dell'arte ed era decisamente robusto.\nCosì decidemmo di lanciare il sistema sul mercato, considerando anche di avere alcuni possibili clienti all'interno di TIM. Cosa avevamo dimenticato? Era una soluzione tecnologica in cerca di un problema, cosa molto pericolosa nel mondo del business.\n\nFortunatamente, abbiamo avuto la possibilità di imparare ed applicare la metodologia Lean Startup in modo molto scientifico. Così intervistammo 31 manager di data center, chiedendo loro come gestivano l'infrastruttura per avere miglio insight sul mercato. Scoprimmo che il mercato dei data center è così composto:\n\n- Nei **Servizi di Housing**, i clienti pagano per uno spazio fisico. Mettono i server di loro proprietà negli spazzi affittati e il provider garantisce deve garantire che questi server siano in condizioni di funzionamento ottimali.\n- Nei **Servizi di Hosting**, i clienti pagano per avere accesso a server e data storage remoti.\n- I **Servizi Cloud** funzionano come i precedenti, ma i clienti pagano solo per le risorse effettivamente utilizzate, quindi sono molto più flessibili.\n- I **data center ad utilizzo interno** sono data center sviluppati all'interno delle aziende che non voglio (o non possono) appoggiarsi a servizi esterni. Quindi questi data center sono solo ad uso interno, non creano il valore dell'azienda, ma ne sono solo una piccola parte.\n- I **Servizi di Audi** sono servizi che valutano l'efficienza di un data center e cercano di migliorarla.\n\nCosì identificammo il nostro valore competitivo e trovammo il miglior mercato di conseguenza. La nostra soluzione era perfetta per il monitoraggio fisico di server in ambiente molto dinamico, in cui il consumo energetico è considerato un grosso problema. Scoprimmo che i clienti dei provider di servizi di hosting o cloud non erano molto interessati al servizio, non avendo un hardware fisico da monitorare.\n\nI servizi di Housing sembravano potenziali clienti all'inizio. Sfortunatamente scoprimmo che la maggior parte di questi progettava e costruiva nuove infrastrutture sempre più avanzate a livello di efficienza energetica. Così ci spostammo verso i data center ad uso interno. Questi ultimi erano interessanti perché, non essendo direttamente produttori del valore nell'azienda, sono visti sempre come un costo. Per approfondire, intervistammo Fabio Borri, CTO di General Electrics. Ci disse che in realtà la principale causa degli alti costi non è il consumo energetico in sé, ma l'infrastruttura e il team di supporto. In fatti, loro si stavano spostando verso un data center centralizzato realizzato con le stesse tecnologia stato dell'arte sull'efficienza energetica.\n\nRimanevano solo i servizi di audit. Un potenziale cliente interessato ci disse che l'interesse principale era la dinamicità del sistema. Così pensammo che questo poteva essere il mercato giusto. Sfortunatamente, scoprimmo presto che si trattava di un mercato troppo piccolo per un business. Inoltre, necessitavamo di avere esperienza e skill in questo specifico settore, cosa che era completamente in disaccordo con la nostra visione. Scoprimmo di essere fuori da qualsiasi mercato, con tanti prototipi sviluppati e nessuno interessato ad usare quello che avevamo costruito.\n\nNon ci arrendemmo, ma usammo questa esperienza come una buona lezione da cui imparare per creare qualcosa di nuovo e migliore.\n\nCi focalizzammo sulle nostre features e skill principali. Con una piattaforma di cloud robotics potevamo:\n\n1.  rendere lo sviluppo di applicazioni robotiche più semplice ed accessibile a tutti,\n2.  creare una community di **Sviluppatori Robotici** sfruttando internet,\n3.  separare lo sviluppo software da quello hardware, e monetizzare solo con la piattaforma Cloud, invece di sviluppare noi stessi i servizi.\n\nCosì finalmente, con la stessa strategia, abbiamo iniziare a creare un mercato per maker e robotics enthusiasts.\n\n![Schema di funzionamento della piattaforma di HotBlack Robotics](./api.png)\n\nAdesso la piattaforma è accessibile dal sito [hotblackrobotics.com](http://hotblackrobotics.com) e aiuta gli utenti ad usare i robot e a scrivere software in modo semplice. La piattaforma è anche un tool online educativo e di intrattenimento che aiuta chiunque voglia autocostruire un robot a farlo in modo semplice grazie al Cloud. Abbiamo sviluppato alcune funzionalità come riconoscimento vocale e riconoscimento facciale. Stiamo creando una community interno alla piattaforma, e ci sono molte altre cose in arrivo.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-11-06-hotblack-robotics/index.md",
    frontMatter: {
      path: "/2017/11/06/hotblack-robotics/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2017-11-06T00:00:00.000Z",
      publishedReadable: "6 Nov 2017",
      featured: false,
      tags: ["HotBlack Robotics", "Robotica"],
      title: "Da Ph.D. ad Imprenditori. Ecco la storia di HotBlack Robotics",
      description:
        "La vera storia di HotBlack Robotics, aka la mia Startup. Scritta dal mio socio Gabriele Ermacora",
      href: "/2017/11/06/hotblack-robotics/",
      image: "/content/blog/it/2017-11-06-hotblack-robotics/team.png",
      imagePath: "/content/blog/it/2017-11-06-hotblack-robotics",
    },
  },
  {
    content:
      "\nHo deciso di riesumare un vecchio articolo (uno dei primi) che avevo scritto sul\nmio blog, e che si era perso durante la migrazione. Leggengolo, l'ho anche corretto\ned aggiornato un po'!\n\n![Virtualenv in Python](./main.png)\n\nOggi l'amico Michele (come dice lui) ha avuto problemi nell'installare alcuni componenti Python sul proprio Mac, per questo motivo ho deciso di scrivere questo tutorial, che presenta\nuna soluzione ad uno dei problemi classici dello sviluppo software: come faccio ad\nevitare conflitti su diversi progetti che utilizzano librerie diverse?\n\nSpesso infatti, quando si sperimenta con qualsiasi linguaggio di programmazione, ci si ritrova a dover utilizzare librerie diverse che hanno dipendenze in conflitto tra di loro.\nMolti linguaggi hanno trovato diverse soluzioni per evitare il conflitto dei pacchetti.\nIn Python, è stata sviluppata una soluzione molto elegante basata sui virtualenv.\n\n## Virtualenv in Python\n\nI Virtualenv (ambienti virtuali, appunto) sono un modo semplice per creare progetti Python isolati, in cui installare diverse librerie che non andranno in conflitto con altre librerie in altri ambienti.\n\nDa un po' di anni (da quando li ho scoperti), ho preso l'abitudine di utilizzare un virtualenv per ogni progetto su cui lavoro, in modo da avere tutto preciso ed ordinato nei miei millemila progetti.\n\n## Installiamo virtualenv\n\nPer installare virtualenv sulla proprima macchina, basta digitare su un terminale il comando\n\n```\n$ sudo pip install virtualenv\n```\n\ne inserire la password.\n\nTale procuderura richiede solo l'installazione di `pip`, che solitamente è già installato\nnelle ultime versioni di Python.\n\n## Creiamo un Virtualenv\n\nUtilizzare virtualenv è molto semplice.\nSupponiamo di voler iniziare un nuovo progetto su un blog, sviluppato in python ed in particolare per mezzo di **Flask**.\n\nPer prima cosa, nella nostra cartella di sviluppo principale, creiamo una nuova\ncartella (`blog`) in cui lavorare per il progetto.\n\n```bash\n$ mkdir blog\n$ cd blog\n```\n\nA questo punto, creiamo l'ambiente virtuale, utilizzando il comando\n\n```\n$ virtualenv <nome ambiente virtuale>\n```\n\nche, nel caso specifico, sarà\n\n```\n$ virtualenv env\n```\n\n> Il nome dell'ambiente virtuale può essere quello che preferiamo, tuttavia solitamente il nome standard che si da è appunto `env`.\n\nDopo l'esecuzione del programma, troverete una nuova directory chiamata `env` nella directory `blog`.\n\n## Attiviamo un ambiente virtuale\n\nUna volta creato l'ambiente virtuale, prima di utilizzarlo bisogna attivarlo.\nPer farlo, basta fare il _source_ del file `env/bin/activate`, che viene creato\nall'interno della cartella **env**.\n\nCioè, da shell, lanciamo il comando\n\n```\n$ source env/bin/activate\n```\n\nA questo punto, su ogni riga del prompt dei comandi, apparirà la scritta `(env)` prima della solita stringa del prompt. Questo indica che l'ambiente è attivo. Possiamo quindi installare nuove librerie python (ulizzando pip), che esisteranno solo all'interno del nostro ambiente virtuale. In questo caso, non è necessario utilizzare il comando `sudo`, perchè ci troviamo all'interno di una cartella privata.\n\n```sh\n(env)$ pip install flask\n```\n\nOra flask sarà installato all'interno del nostro ambiente virtuale.\n\n![Esempio Shell](./shell.png)\n\n## Lavoriamo all'interno dell'ambiente virtuale\n\nUna volta attivato l'ambiente ed installate le librerie, siamo abbastanza liberi su come muoverci per iniziare un progetto. Lavorate come volete voi. Quello che si fa abitualmente è\ncreare il nostro progetto direttamente nella cartella principale `blog`, ricordandoci\ndi ignorare, ad esmepio tramite `gitignore`, la cartella env.\n\n## Chiudiamo l'ambiente virtuale\n\nPer chiudere un ambiente virtuale, basta digirare il comando\n\n```\n(env)$ deactivate\n```\n\nVedrete che la stringa `(env)` sparirà dal vostro prompt.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-11-06-virtualenv/index.md",
    frontMatter: {
      path: "/2017/11/06/virtualenv/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2017-11-06T00:00:00.000Z",
      publishedReadable: "6 Nov 2017",
      featured: false,
      tags: ["Python", "Virtualenv"],
      title: "Virtualenv: gestiamo meglio le dipendenze in Python",
      description: "A cosa servono e come si utilizzano i virtualenv Python",
      href: "/2017/11/06/virtualenv/",
      image: "/content/blog/it/2017-11-06-virtualenv/main.png",
      imagePath: "/content/blog/it/2017-11-06-virtualenv",
    },
  },
  {
    content:
      "\nSo che molti programmatori preferiscono imparare da autodidatta, e che\nsolitamente le informazioni che imparano arrivano da internet, navigando tra\nvarie risorse online come blog e documentazione ufficiale.\nTuttavia, io trovo veramente utile, una volta superato lo scoglio iniziale in\ncui le risorse online\nsono le migliori, approfondire utilizzando risorse a pagamento (tra cui libri) in\ncui le informazioni che ci servono vengono riportate in modo organico e sono\npiù fruibili e comprensibili.\n\n![Python Libri Copertina](./main.jpg)\n\nInoltre, sono in generare un patito della lettura, e ho scoperto che leggere libri tecnici,\nse sono scritti bene, diventa piacevole.\n\nIn questo post vi voglio consigliare alcuni libri su Python che ho letto negli ultimi due anni e\nda cui ho imparato molte delle cose che conosco.\nLa lista è in ordine casuale, non c'è un libro preferito al momento.\nSono tutti libri che ritengo ottime\nrisorse per approfondire molti concetti del linguaggio.\n\nInoltre, tutti i libri che riporto qui sono in inglese. So che molte delle persone\nche mi seguono apprezzano il mio blog principalmente per fatto che scrivo in italiano, tuttavia\nogni buon programmatore di dovrà scontrare con la lingua inglese se vuole intraprendere\nquesta carriera.\n\n- [Flask Web Development: Developing Web Applications with Python](http://amzn.to/2zauw1q)\n- [Test-Driven Development With Python](http://amzn.to/2zbOqJy)\n- [Fluent Python](http://amzn.to/2zfpAdv)\n- [Learning Python](http://amzn.to/2iXwfCY)\n- [The Clean Coder: A Code of Conduct for Professional Programmers](http://amzn.to/2zcn9qp)\n\n## Flask Web Development: Developing Web Applications with Python\n\n<AmazonAffiliationLink src=\"//rcm-eu.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=ludusrusso-21&o=29&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=1449372627&linkId=78204e2f826d85185dac4023e5e8269b\"/>\n\n[Flask Web Development: Developing Web Applications with Python](http://amzn.to/2zauw1q)\nè il secondo\nlibro su Python che ho leggo. Parto da questo per un motivo specifico: è stato il\nlibro che mi ha spinto ad iniziare questo blog, in quanto al suo interno è presentato\nlo sviluppo di un blog interamente scritto in _Flask_.\n\nChi mi segue da un po' di tempo ricorderà la prima versione di questo blog implementata\nproprio in _Flask_, insieme ad una [guida](/2016/12/27/tutorial-flask/) che prende spunto\nproprio da questo libro.\n\nIl libro richiede una conoscenza almeno base di Python, e si incentra principalmente\nsull'utilizzo di _Flask_ come libreria per sviluppare applicazioni Web. Tuttavia, per chi\nnon vuole spendere soldi per il libro ma comunque è interessato all'argomento, consiglio\nil blog di [Miguel Gringberg](https://blog.miguelgrinberg.com/), autore del libro,\nall'interno del quale trovate tanti spunti interessanti più un'intera guida, [Flask Mega Tutorial](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world)\nche è una vera e propria versione preliminare del libro.\n\n## Test-Driven Development with Python\n\n<AmazonAffiliationLink src=\"//rcm-eu.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=ludusrusso-21&o=29&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=1491958707&linkId=cc18d2d51e02cfac42ea5bfcd276cb35\" />\n\n[Test-Driven Development With Python](http://amzn.to/2zbOqJy) è l'ultimo libro su\nPython da me letto (notare la data di uscita della seconda edizione, che è Agosto 2017).\n\nHo comprato questo libro principalmente per il mio interesse verso la filosofia del [Test Driven Development](/2017/10/03/tdd-intro/), e ne ho apprezzato molto la prima parte,\nin cui ci si addentra principalmente sull'utilizzo pratico di questo modello di programmazione.\n\nLa seconda parte, che si specializza di più sulla programmazione e\nlo sviluppo di applicazioni web in Django, l'ho ritenuta invece meno interessante... Ma questo\nè forse dovuto al fatto che sono un patito di Flask, un \"concorrente\" di Django.\n\n## Fluent Python\n\n<AmazonAffiliationLink src=\"//rcm-eu.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=ludusrusso-21&o=29&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=1491946008&linkId=90ef440b9d7f7c1826779c634b9c83bb\" />\n\n[Fluent Python](http://amzn.to/2zfpAdv) è probabilmente uno dei libri più interessanti\ne ben scritti su Python da me letti, risulta anche essere uno dei best seller\nsu questa categoria.\n\nL'unico problema, almeno nel mio caso, è averlo scoperto e letto nel momento sbagliato: quando\navevo raggiunto una conoscenza delle dinamiche e dell'implementazione Python\nabbastanza profonda da trovare il libro poco utile nella mia formazione. Nonostante\nquesto, lo reputo uno strumento veramente interessante, e spesso lo consulto per\napprofondire l'utilizzo di alcune strutture dati che non uso spesso.\n\nIl libro parte spiegando il funzionamento del _Python Data Model_, cioè l'implementazione\ndella filosofia di Python. Il libro quindi continua facendo interessanti esempi\nsu come implementare codice python pulito e \"_Pythonico_\", sfruttando tutte le\nfunzionalità e i pattern che questo linguaggio mette a disposizione.\n\nLo considero un libro intermedio, pensato per qualcuno che già conosce Python ma\nvuole approfondire l'utilizzo di tale linguaggio.\n\n## Learning Python\n\n<AmazonAffiliationLink src=\"//rcm-eu.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=ludusrusso-21&o=29&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=1449355730&linkId=051066c07f60c2a5d4a14d6deba8164b\" />\n\n[Learning Python](http://amzn.to/2iXwfCY), di cui esiste anche una [versione italiana](http://amzn.to/2zahocJ) è un libro introduttivo su Python molto molto voluminoso (conta circa 1500 pagina, sembra di leggere un romanzo di Ken Follett).\nNon ho mai comprato questo libro, ma l'ho consultato\ntempo fa perché è stato comprato dal professor Basilio Bona, che lo teneva gelosamente\nin ufficio.\n\nNonostante sia un libro introduttivo sul Python, si concentra principalmente sugli\naspetti teorici della programmazione, scavalcando quelli pratici, e portando pochi esempi\ninteressanti. Lo reputo un ottimo libro per imparare a programmare in generale, quindi\nse non conoscete nessun linguaggio di programmazione e siete veramente alle prime armi,\nallora è un ottimo libro per voi!\n\nIn caso contrario, se conoscete già un altro linguaggio di programmazione,vi consiglio\ndi seguire la filosofia del _Learning by Doing_, cioè imparare\nfacendo, e poi approfondire in seguito. Se volete quindi iniziare ad imparare Python,\npartite da un progetto, e poi approfondite con libri di livello intermedio!\n\n## Bonus: The Clean Coder\n\n<AmazonAffiliationLink src=\"//rcm-eu.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=ludusrusso-21&o=29&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=0137081073&linkId=613e89eb704d545df166a47d5e7e59bb\" />\n\n[The Clean Coder: A Code of Conduct for Professional Programmers](http://amzn.to/2zcn9qp) è\nil quinto libro (dei 4 + 1)\nche mi sento di consigliare. Non è un libro su Python, e non è un libro sulla programmazione.. È un libro che da spunti e consigli molto interessanti sul cosa fa e come deve comportarsi\nun _professional coder_. In questo libro, l'autore rende disponibile al lettore una serie\ndi conoscenze e lezioni imparate dai suoi errori dopo anni di esperienza come programmatore.\nHo apprezzato veramente tanto alcuni capitoli legati all'idea dei [Coding Kata](http://codekata.com/), della gestione del tempo e dell'importanza di dire \"**no!**\". È considerato uno dei libri che bisogna leggere nel momento in cui si entra nel mondo del lavoro in questo settore.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-11-02-libri-python/index.md",
    frontMatter: {
      path: "/2017/11/02/libri-python/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2017-11-02T00:00:00.000Z",
      publishedReadable: "2 Nov 2017",
      featured: false,
      tags: ["Python", "Libri"],
      title: "4 (+1) Libri su Python (in Inglese) da cui imparare",
      description:
        "Una lista di libri su Python (in Inglese) da cui ho imparato a programmare",
      href: "/2017/11/02/libri-python/",
      image: "/content/blog/it/2017-11-02-libri-python/main.jpg",
      imagePath: "/content/blog/it/2017-11-02-libri-python",
    },
  },
  {
    content:
      '\r\nHey! Se sei finito qui è perchè probabilmente ti interessa avere qualche info in più. Se vuoi sapere:\r\n\r\n**a) info sul come fare l\'applicazione robotica per controllare in remoto un robot tramite un bot in Telegram**\r\n\r\n**b) chi sono i "tizi" di HotBlack Robotics e perchè abbiamo concepito tutto ciò**\r\n\r\n## Il robot che vedi alla mostra di Cesena\r\n\r\n{% include youtube.html id="9lyAfzyFcQQ" %}\r\n\r\n## Il tutorial per rifare questo robot e l\'applicazione a casa tua\r\n\r\nSe hai dei problemi con questo tutorial o anche solo vuoi fare 4 chiacchiere scrivimi a ermacora.gabriele@gmail.com !!\r\n\r\n{% include youtube.html id="E9NX3vx4WSw" %}\r\n\r\n## RECAP: come fare questa applicazione robotica a casa tua\r\n\r\nIl tutorial per costruire questo robot controllabile da remoto è semplice e consiste in **18** semplici passaggi.\r\n\r\n**Cosa ti serve**\r\n\r\nIl robot DotBot che uso è open source e puoi costruirtelo a casa. Il tutorial dettagliato per stampare la meccanica in 3D, le schede elettroniche e come farlo lo trovi [qui](http://hotblackrobotics.github.io/blog/posts/2017-02-08-dotbot-tutorial-hardware).\r\n\r\nSe però non hai ancora tempo di costruirti tutto il robot puoi già partire solo con:\r\n\r\n- [Raspberry Pi 3](https://www.raspberrypi.org/products/raspberry-pi-3-model-b/)\r\n- [RaspiCam](https://www.raspberrypi.org/products/camera-module-v2/)\r\n- [Una SD Kingstone da 4 GB](https://www.amazon.it/Kingston-SDC4-4GB-MicroSDHC-Adattatore/dp/B000VX6XL6)\r\n- Un alimentatore da cellulare Android per alimentare il Raspberry o un [power bank](https://www.amazon.it/RAVPower-Caricabatterie-Tecnologia-Universale-Smartphone/dp/B00YA01MC6/ref=sr_1_13?ie=UTF8&qid=1509721259&sr=8-13&keywords=ravpower+power+bank)\r\n\r\n**NB: potete prendere ovviamente altri componenti purchè le specifiche di funzionamento siano rispettate.**\r\n\r\n**NB2: occhio alle batterie scariche! Succede ogni tanto che se non alimentato bene il robot o non si connette o non fa streaming dalla camera o non si muove!**\r\n\r\n**Partiamo**\r\n\r\n1. vai sul sito [hotblackrobotics.github.io](http://hotblackrobotics.github.io/)\r\n\r\n2. Dopo aver visto il mio (fantastico) breve video accedi in piattaforma. In alto a destra premendo ["Registrati"](http://hotblackrobotics.github.io/register) ti registri.\r\n\r\n3. Una volta autenticato/a ci sarà un altro (ancora più fantastico) video. Vai sotto e clicca su [**Tutorial**](http://hotblackrobotics.github.io/blog/posts/supporto-tecnico)\r\n\r\n4. Clicca sulla scritta arancione **["03-Scaricare HBrain - Immagine SD"](http://hotblackrobotics.github.io/blog/posts/2017-03-24-immagine-sd-per-la-cloud-e-configurazione)** e scarica l\'immagine che va masterizzata sulla SD da inserire dentro il Raspberry Pi 3\r\n\r\n5. Scarica l\'immagine ed il programma per masterizzare [Etcher](https://etcher.io/). Masterizza sulla SD!\r\n\r\n6. Collega il tuo raspberry ad un cavo Ethernet e collegalo al tuo router di casa\r\n\r\n7. Accendi il Raspberry e dopo un po\' (30 secondi - 1 minuto) [cerca il robot dalla piattaforma cloud](http://hotblackrobotics.github.io/cloud/index)\r\n\r\n8. Ad un certo punto apparirà un robot che si chiama **hotbot**! Premi "connect".\r\n\r\n9. Ora vai su ["Skecthes"](http://hotblackrobotics.github.io/cloud/sketch/). Vai al fondo della pagina dove c\'è scritto "Examples". Troverai un esempio che si chiama "Mufantbot".Premi "clone"!\r\n\r\n10. Adesso il programmino è andato in "programs". Ora premi il bottone "Edit". Vedrai che si apre il codice.\r\n\r\n11. Crea il tuo bot Telegram seguendo il [tutorial qui](http://hotblackrobotics.github.io/blog/posts/2017-02-16-tutorial-sviluppiamo-un-bot-telegram-in-ros). Segui tutti i passaggi fino a "Creazione del nostro programma" siccome tu il programma lo copi da me ;)\r\n\r\n12. Vai nel codice e dove c\'è scritto TOKEN a riga 18 sostituisci "il_tuo_token" con il tuo token.\r\n\r\n13. Ora inserisci la telecamera per il Raspberry (RaspiCam). La attivi andando su "Apps" sulla barra in alto e selezionando [RaspiCam](http://hotblackrobotics.github.io/cloud/webgui/camera)\r\n\r\n14. Ora da questa pagina premi il pulsante ["Apri Manager Robot"](http://192.168.0.101:9001/).\r\n\r\n15. Si apre la schermata con diversi processi e vai a schiacciare "start" su "ros_name". Aspetta 30 secondi.\r\n\r\n16. Ora torna su RaspiCam (pagina di prima) e premi start camera. Il LED sulla camera si accende ed inizia lo streaming video.\r\n\r\n17. Ora torna sul tuo programmino e premi "RUN". Cerca su Telegram il tuo bot, con il nome che gli hai dato.\r\n\r\n18)Appena avvii la chat dovrebbe darti segni di vita!\r\n\r\n## HOTBLACK ROBOTICS\r\n\r\nHotBlack Robotics è una startup innovativa che offre una piattaforma di cloud robotics per facilitare la creazione di servizi e applicazioni robotiche. Il cuore della piattaforma è la community di **robot developers** in grado di inventare, sviluppare e condividere applicazioni e progetti robotici in modo facile e customizzzato.\r\n\r\nGli elementi chiave della piattaforma sono quindi i contenuti ovvero progetti hardware, software, i servizi, i processi, le metodologie e le esperienze da condividere on-line per favorire la condivisione tra gli utilizzatori della piattaforma (robot developers e end-users).\r\n\r\nPerchè facciamo questo? Perchè crediamo fermamente che la condivisione open source di contenuti di robotica in una piattaforma cloud possa generare presto nuovi servizi robotici e creare nuovi business. Inoltre crediamo che i nuovi servizi robotici che si andranno a creare andranno a risolvere problemi specifici e customizzati nel mercato (customizzazione di massa).\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-10-31-un-robot-al-museo-mufant-e-hotblack-robotics/index.md",
    frontMatter: {
      path: "/hbr/un-robot-al-museo-mufant-e-hotblack-robotics/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "4 mins",
      published: "2017-10-31T09:55:34.000Z",
      publishedReadable: "31 Ott 2017",
      featured: false,
      tags: [],
      title: "Un robot al museo - MuFant e HotBlack Robotics",
      description: "",
      href: "/hbr/un-robot-al-museo-mufant-e-hotblack-robotics/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-10-31-un-robot-al-museo-mufant-e-hotblack-robotics",
    },
  },
  {
    content:
      "\n[Parloma](http://parloma.github.io) è un progetto di ricerca su cui lavoro ormai da anni, sin dal periodo\nin cui, durante la laurea Magistrale, ho avuto l'onore ed il piacere di essere selezionato\ncome studente presso l'Alta Scuola Politecnica (ASP).\n\n![Foto PARLOMA demo 2](./main.jpg)\n\nL'ASP è un progetto congiunto tra Politecnico di Torino e di Politecnico Milano che ha lo scopo di\nselezionare e formare alcuni studenti di entrambe le università su tematiche\ninterdisciplinari. Devo dire che partecipare all'ASP mi ha aperto gli occhi, facendomi\ncapire che non è solo il mondo ingegneristico ad essere degno di nota (pensiero\ncondiviso da molti ingegneri), ma lo sono tutte le professionalità come ingegneri, designer e architetti\nsenza le quali noi ingegneri non potremmo sopravvivere.\n\nL'ASP è stata genericamente un'esperienza veramente formativa, con i suoi pro e i suoi contro.\nTuttavia, all'interno di questo percorso, la cosa che mi ha aiutato di più in assoluto\ne che ha influenzato le mie scelta di continuare nel mondo della ricerca e dell'innovazione,\nè stato certamente il progetto **PARLOMA**.\n\nMa andiamo per ordine, voglio raccontarvi la storia e il mio coinvolgimento nel progetto,\nnon solamente il progetto in se'.\n\n## I progetti dell'Alta Scuola Politecnica\n\nIl percorso dell'ASP si divide in due parti:\n\n- un percorso didattico di 6 _school_ intensive, della durata di 1 settimana, incentrate su un argomento multidisciplinare, che prendono luogo durante i due anni scolastici di laurea magistrale.\n- un progetto innovato, da portare avanti in team, che si conclude in una presentazione finale ed in un report conclusivo, che è decisamente equivalente ad una tesi di laurea, se non fosse per il fatto che, per fortuna, deve essere svolto in team.\n\nQui vi voglio parlare del progetto, che nel mio caso era, appunto, il progetto PARLOMA.\n\n## Come è nata l'idea di PARLOMA?\n\nL'idea del progetto venne a Carlo Geraci, un professore e linguista\ndell'Ecole Normale de Paris, la cui ricerca è incentrata sulla Lingua dei Segni.\nCarlo, covava da parecchi l'idea di sviluppare un dispositivo che\naiutasse persone sordocieche a comunicare a distanza attraverso la loro \"lingua mandre\",\nchiamata Lingua dei Segni Tattile (LSt). Come vi spiegherò più avanti, il loro modo di comunicare (o uno dei tanti, ma per alcuni il più naturale), è una versione modificata della Lingua dei Segni che usa però il tatto, anzichè la vista, per capire le informazioni contenute nei movimenti.\nLa LSt ha però un problema molto grosso: non è possibile trasmetterla in remoto.. Mentre esistono soluzioni come il Skype per persone che comunicano con la LS standard, non esiste\nun'alternativa che possa remotizzare questo tipo di comunicazione.\n\nCarlo aveva in mente l'idea dagli anni 2000, ma solo negli anni 2010/2011\nè riuscito ad iniziare a renderla concreta, grazie al prof. Paolo Prinetto, un professore\ndel Politecnico di Torino con cui Carlo aveva iniziato una collaborazione.\n\nPaolo è una persona molto aperta alle idee, anche le più stravaganti (e vi assicuro che a me ne\nvengono tante, e lui mi da sempre ascolto). Quando Carlo gli parlò della sua idea, lui pensò di\nproporla come progetto presso l'Alta Scuola Politecnica. Tramite due suoi dottorandi,\nGabriele Tiotto e Marco Indaco, il progetto venne presentato a noi nuovi studenti,\ne venne formato il Team Parloma dell'Ottavo Ciclo ASP.\n\nPiccola nota: il nome Parloma è stato trovato proprio da Paolo: _parloma_ è una parola del dialetto\npiemontese, che vuol dire _parliamo_.\n\n## Il Team PARLOMA\n\nIl team Parloma dell'ASP è nato come il team sfigato, eravamo in 6, e diventammo in 5\ndopo poche ore di inizio lavori.. Il sesto ragazzo, mai conosciuto, non si presentò\nil primo giorno, e venne istantaneamente espulso (le regole dell'ASP sono un po' severe).\n\nEravamo il team con meno membri, a parte uno, da 6 persone, tutti gli altri team\nerano composti da 10 - 12 persone.\n\nMa avevamo la fortuna di essere pochi, e quindi evitare dispersioni, e di avere\ndei tutors molto molto bravi, disponibili, e che credevano veramente nel progetto.\n\nIl team era composto dalle seguenti persone:\n\n- Chiara, capo progetto, rappresentante degli studenti (lato Torino) e capo di tutto in generale. Ingegneressa (si dice?) biomedica\n- Alice, anche lei ingegneressa biomedica, anche lei lato Torino,\n- Giuseppe, infomatico, sempre Torino,\n- Io, Meccatronico, di nuovo Torino,\n- Giorgio, ingegnere Fisico, l'unico di Milano, quello che doveva farsi tutti i viaggi!\n\nAh si, eravamo anche il gruppo più asimettrico (credo) dell'ASP.\nQui sotto trovate una bella foto che ci ritrae\n\n![Team Parloma ASP](./parloma_asp.jpg)\n\nAd ogni modo, i primi tempi passarono abbastanza velocemente, ci prendemmo un po' di tempo\nper capire e studiare il problema (un argomento un bel po' delicato), per distruggere\nle idee iniziali che avevamo e pensare ad alternative, per cercare di capire\nperché queste persone non possono usare il Braille per comunicare (e no, non possono,\ne ve lo spiegherò tra poco).\n\nDurante il primo anno di lavoro, abbiamo principalmente concepito e definito il progetto\nda un punto di vista funzionale. Ho imparato, durante questo periodo, che noi ingegneri\ne comunque tecnologi, facciamo l'errore di confondere la tecnologia con la soluzione.\nUna lezione che poi mi sono portato avanti nel mio lavoro da imprenditore, e che adesso\nposso riassumere con la seguente frase: _all'utente non frega niente della tua soluzione_.\n\nPer questo motivo, vorrei parlare prima di tutto degli utenti, e poi del progetto.\n\n## La sordocecità e la Lingua dei Segni Tattile\n\nLa sordocecità è una disabilità multisensoriale. Le persone affette da questa disabilità\nhanno perso, completamente o in parte, l'uso sia della vista che dell'udito.\nEssendo una disabilità che affligge più di un senso, il modo in cui la persona affetta\nsi relaziona con la sua disabilità dipende tantissimo dalla sua storia.\n\nUna persona normodotata, diventata sordocieca a causa di un incidente o per la vecchia,\nha dei bisogni e delle necessità molto diverse da quella di una persona nata sordocieca,\no di una persona sorda che poi è diventata sordocieca in seguito.\n\nUno dei problemi principali delle persone sordocieche è, ovviamente, la comunicazione.\nQueste persone vivono in uno stato quasi totale di isolamento, ed hanno solo il tatto per comunicare\ntra di loro. Ovviamente, modi di comunicare basati sul tatto sono molti, il più\nconosciuto probabilmente è l'alfabeto braille, che non è un linguaggio, ma una trasposizione\ntattile della lingua scritta... In altre parole, per capire il braille bisogna saper leggere,\nla qualcosa cosa necessita, essendo il nostro alfabeto baso sulla lingua parlata,\nil saper parlare, ed il conoscere il concetto di fonema...\n\nEd è qui che arriviamo al punto cruciale del nostro discorso, necessario per capire\nbene la disabilità: chi nasce sordo, non avendo mai sentito, difficilmente riesce\na comprendere un concetto tanto lontano dalla sua condizione come i fonemi.. Questo è\nil motivo per cui molte persone sorde non parlano (non perché sono muti, come molti erroneamente credono, ma perché, non avendo mai sentito, non riescono a modulare la loro voce).\n\nEd ecco un'informazione che a me ha stupito tanto: molte persone sorde non sanno leggere,\nper lo stesso motivo per cui non sanno parlare.. Non conoscono il concetto di fonema!\nMolti infatti pensano che le Lingua dei Segni non siano altro che una trasposizione\na gesti delle lingue parlate, come lo è il braille... In realtà questo è sbagliatissimo:\nuna lingua dei segni è una lingua a tutti gli effetti, che si sviluppa in modo indipendente\ndalle lingue parlate (solitamente in una comunità sorda) nello stesso territorio, che ha una sua grammatica ed una sua sintassi e che è basata non su fonemi (come nel caso della lingua parlata) ma sui segni. Le lingue dei segni\nsono molto differenti dalle lingua parlata, vi copio un [estratto da Wikipedia](https://it.wikipedia.org/wiki/Lingua_dei_segni) che fa capire bene questo concetto:\n\n> \"_I verbi ad esempio non si coniugano in base al tempo, ma devono concordare sia con il soggetto (come in italiano) sia con l'oggetto dell'azione, come avviene in basco. Esistono forme pronominali numeriche per indicare \"noi due, voi due\" (come il duale del greco antico) e addirittura \"noi cinque, voi quattro, loro tre\". La concordanza di verbi, aggettivi e nomi non è basata sul genere (maschile e femminile come in italiano) ma sulla posizione nello spazio in cui il segno viene realizzato. Esistono diverse forme per il plurale \"normale\" e il plurale distributivo, distinzione sconosciute alle lingue europee, ma note in lingue oceaniche. Il tono della voce è sostituito dall'espressione del viso: c'è un'espressione per le domande dirette («Vieni?», «studi matematica?») una per domande complesse («quando vieni?», «cosa studi?», «Perché piangi?») una per gli imperativi («Vieni!», «Studia!») e altre per indicare le frasi relative («il libro che ho comprato, la ragazza con cui parlavi»)_\"\n\nCapito questo concetto, torniamo ai sordociechi: esiste una malattia congenita molto\ngrave, chiamata [Sindrome di Usher](https://www.legadelfilodoro.it/chi-aiutiamo/sordocecita-e-sindromi/sindromi/sindrome-di-usher), che porta le persone a diventare sordocieche, ed è una delle cause principali di sordociecità.\n\nNon mi voglio dilungare troppo nella malattia, ma alcune persone affette nascono sorde, ma la malattia porta alla diminuzione progressiva ma molto lenta del campo visivo, che si completa in età adulta. Queste persone, quindi, si trovano a vivere in una condizione da sordo, solitamente imparano\nla lingua dei segni della comunità di cui fanno parte, e col tempo, quando la ciecità diventa severa,\niniziano a sviluppare un modo di comunicare che rimpiazza il tatto alla vista, chiamato Lingua dei Segni Tattile (LSt).\n\nL'utente primario del progetto Parloma è quindi quello di supportare queste persone,\nche per la loro storia, difficilmente potranno imparare ad usare sistemi di comunicazione basati su Braille o simili alternative.\n\n## Il progetto Parloma\n\nIl primo anno di lavoro in Alta Scuola Politecnica, si è incentrato principalmente, come detto\nprima, sul capire i bisogni dei nostri utenti (e chi fossero questi utenti) e definire\nun'architettura generale del progetto. L'architettura è poi rimasta più o meno invariata da allora,\ne l'ho riportata qui sotto.\n\n![Architettura Parloma](./parloma_arch.png)\n\nLo scopo del progetto è quello di permettere a due persone di comunicare utilizzando la Lingua dei Segni tattile, di cui almeno uno dei due sordocieco. Entrambi devono conoscere la lingua dei segni, e la sua versione tattile. Quindi, come molti credono inizialmente, il sistema non è un traduttore, ma un vero\ne proprio telefono, che acquisisce il mezzo nel quale il messaggio è contenuto, lo trasmette tramite internet e lo riproduce senza interpretarlo.\n\nIl sistema è composto da tre parti, o blocchi:\n\n- Blocco di Input, che si occupa di eseguire algoritmi di Hand Tracking per digitalizzare i movimenti della mano e del braccio,\n- Blocco di Trasmissione, che si occupa di trasmettere queste informazioni tramite internet,\n- Blocco di Output, che si occupa di riprodurre, tramite una mano robotica, il segno inviato.\n\nLa cosa interessante è che, nonostante in questi 6 anni di sviluppo molte cose siano cambiate,\nmolto spesso abbiamo dovuto ricominciare dall'inizio e alcune situazioni al contorno\nsiano diverse, l'architettura generale è ancora lì, e non si tocca!\n\n## Sviluppo tecnico, mani robotiche e tanto altro\n\nLa maggior parte del lavoro tecnico sul progetto è stata fatta durante il secondo anno dell'ASP, in cui\niniziammo a smanettare col codice e ad implementare i primi algoritmi di Hand Tracking basati\nsu telecamere standard.\n\nDevo ammettere che ai tempi avevamo un po' sopravvalutato le nostre capacità, e le capacità in generale\ndella tecnologia di visione per eseguire algoritmi di hand tracking. Ci rendemmo conto ad\nun certo punto che una semplice telecamere non fornisce abbastanza informazioni\nper eseguire un algoritmo di hand tracking fine e che serviva qualcosa di più per lo\nsviluppo.\n\nFortunatamente, abbiamo avuto l'occasione di incontrare un gruppo di ricerca del CNR,\ned in particolare un ragazzo (Daniele) che allora stava lavorando ad un sistema di\nHand Tracking basato telecamere 3D, ed in particolare la tecnologia del Microsoft Kinect.\nDaniele ci diede una mano enorme nello sviluppo del primo prototipo di hand tracking,\nlavorando con lui al sistema, riuscimmo a tirare su un algoritmo funzionante in grado di\ncapire come è posizionata una mano nello spazio... Il problema era che il risultato ottenuto,\nseppure funzionante, era ancora troppo poco preciso. Decidemmo quindi di sviluppare\nun classificatore, in grado di individuare il segno statico (_handshape_) che la mano\nstava eseguendo, in modo da migliorarne il funzionamento. Questo è stato il mio primo\nserio contributo al progetto.\n\nCome è ovvio, questa soluzione limita tantissimo il risultato richiesto, ma era un\nbuon inizio ed una buona base di partenza per fare una demo e per mostrare la tecnologia.\n\nL'altro nostro problema era la necessità di avere accesso ad una mano robotica.\nAndammo a chiedere aiuto ad un partner ufficiale del progetto, l'istituto di Bio Robotica\ndel Sant'Anna di Pisa. Loro ci misero a disposizione un prototipo di mano robotica su\ncui stavano lavorando, con l'unica condizione di farci andare a lavorare direttamente\nnel loro laboratorio. Così, pochi giorni dopo la laurea, io e Giuseppe passammo qualche mese\na fare avanti e indietro tra Torino e Pisa, per lavorare alla mano robotica e preparare\nuna demo per la presentazione finale ASP, che era schedulata per dicembre 2013.\n\nQuel periodo fu abbastanza impegnativo ma anche divertente. È stato figo essere ufficialmente\nall'interno di un istituto tanto prestigioso (con tanto di tesserino), ed è stato\nmolto interessante lavorare su una vera mano robotica.\n\nCosì passammo quel periodo al lavoro sul far funzionare la mano, che aveva tantissimi\nproblemi: spesso non funzionava (ci diedero un prototipo che non usavano, che giustamente\nnon era molto messo bene lato hardware).\n\nIo e Giuseppe implementammo un sistema di\ncontrollo della mano in Python (la mia prima esperienza con questo linguaggio), e\nin qualche settimana, grazie ad un Raspberry Pi, siamo riusciti a sviluppare un sistema\nche, dopo aver riconosciuto i segni tramite il nostro algoritmo, li avia al Rasperry Pi\nconesso alla mano, che si occupa di controllarlo in modo adeguato.\n\nChiara e Alice si occuparono del rivestimento della mano: dai primi test fatti con\nuna persona sordocieca, era emerso il fatto che la forma della mano non era\nfacilmente riconoscibile al tatto: c'era, ad esempio, una sporgenza metallica sul\npalmo che molte volte veniva scambiata per il pollice chiuso.\n\nAgli inizi di dicembre, comunque, eravamo pronti con la demo per i primi test.\nTrovate il primo video dimostrativo da noi realizzato qui:\n\n<div class=\"embed-responsive embed-responsive-16by9\">\n  <iframe class=\"embed-responsive-item\" src=\"https://www.youtube-nocookie.com/embed/6MGJb_GqauU?rel=0\"></iframe>\n</div>\n\nChe poi venne presentato, a metà Dicembre 2013, come lavoro finale presso l'Alta Scuola\nPolitecnica.\n\n<div class=\"embed-responsive embed-responsive-16by9\">\n  <iframe class=\"embed-responsive-item\" src=\"https://www.youtube-nocookie.com/embed/TRvEjpxtARM?rel=0\"></iframe>\n</div>\n\nAd oggi, cosa di cui vado molto fiero, questo progetto è considerato uno dei migliori progetti\nusciti dall'ASP, e spesso viene citato nella opening delle nuovi cicli!\n\n## Mani stampante in 3D\n\nDalla fine dell'ASP, anche se con un po' di rimorso, il progetto è andato in secondo\npieno ed il suo sviluppo è stato messo sempre più in secondo piano, anche se ho\navuto la fortuna, durante il mio percorso di Dottorato, di poterci comunque dedicare un po'\ndi tempo.\n\nA Gennaio 2014, io e Giueppe avevamo appena iniziato il PhD. Io con Telecom Italia\nsu una tencologia chiamata _Cloud Robotics_. Giuseppe, insieme al gruppo di Paolo e Marco,\nera invece incentrato sulle tecnologie assistive. Parloma era li in mezzo, quindi\nentrambe le cose, oppure ne' una ne' l'altra (dipende dai punti di vista). Ad ogni modo,\nnon ricordo esattamente in che periodo, un mio carissimo amico, Andrea, stava per\nintraprendere il percorso di Tesi di chiusura della laurea Magistrale, e chiese a me\nse avevo dei consigli da dargli. Andrea si stava dedicando, da qualche anno, alla\nstampa 3D, tanto che, parlando con lui mi venne un'idea molto interessante: al posto\ndi utilizzare come mano robotica una mano progettata per altri scopi (la mano di Pisa è una\nprotesi), cerchiamo di utilizzare la tencologia della stampa 3D, e il mondo dell'Open Source,\nper progettarnarne una a basso costo ed orientata allo riproduzione di segni della lingua\ndei segni.\n\nAndrea partì subito con molto interesse e voglia, decidemmo di usare, come base di\npartenza, la mano sviluppata da un designer francese per il suo progetto [InMoov](http://inmoov.fr/),\ne in poco tempo Andrea riuscì a ricreare in casa la mano robotica di InMoov.\n\nA quel punto, proponemmo a lui un progetto più ambizioso: realizzare una mano robotica,\na partire da quella di InMoov, che fosse in grado di realizzare più gesti nella lingua\ndei segni di quelli che InMoov (e comunque tutte le altre mani robotiche in commercio)\npotesse fare.\n\nAndrea fu bravissimo: in pochi mesì riuscì a mettere altri 3 motori all'interno della mano,\nriprogettare il sistema di tendini ed aggiungere molle all'iterno della mano robotica robotica,\nin modo da rendere più efficiente il controllo delle dita.\n\nLa nuova mano ha tre gradi di libertà rispetto alle precedenti: può ad esempio,\nincrociare indice e medio (gesto molto importante nelle lingue dei segni).\n\n![Confronto PARLOMA InMoov](./confronto_inmoov.jpg)\n\nIn questo periodo, io mi occupai di sviluppare la parte di elettronica e di controllo\ndella nuova mano, e di integrare il tutto con ROS.\nAd ogni modo, Andrea ottenne punteggio pieno sulla tesi e la presentazione, ma\nvolle andare avanti. Alla fine della tesi, abbiamo creato un secondo video demo\nche mostra i nostri avanzamenti (e che vede me come attore principale).\n\n<div class=\"embed-responsive embed-responsive-16by9\">\n  <iframe class=\"embed-responsive-item\" src=\"https://www.youtube-nocookie.com/embed/EJ5-uBt7rHs?rel=0\"></iframe>\n</div>\nTra le cose più belle che sono successe dopo il [rilascio Open Source](https://www.thingiverse.com/thing:701446) della mano,\nè stata quella di essere contattati da Elena dell'Antonia, una ragazza di Treviso\nche ha realizzato un gioco didattico per aiutare i bambini ad apprendere la Lingua\ndei Segni Italiana, utilizzando la mano progettata da Andrea. Il progetto si chiama\n[MANIpolare per comunicare con l'alfabeto LIS](http://manipolarepercomunicare.com/),\ned è veramente interessante.. Dategli un'occhiata.\n\n![Manipolare per Comunicare](./manipolare-comunicare.jpg)\n\nConclusa la tesi, come noi, continua a supportare il progetto\nproponendo miglioramenti, sempre legati alla meccanica, con lo scopo rendere la\nnostra mano, sempre più simile alla mano umana.\n\nAiutato da altre persone e tesisti, un'altra idea interessantissima su cui ha lavorato\nè stata quella di utilizzare una struttura meccanica nota in ingegneria navale, chiamata\n\"_spalla del pinguino imperatore_\", utilizzata come propulsore nella robotica navale. Il\nnome deriva dal fatto che imita il funzionamento della spalla dei pinguini che, attaccata\nall'ala, gli permette di nuotare in modo molto veloce. Andrea pensò di realizzare\nuna versione miniaturizzata di questa struttura da usare come polso della mano.\n\nQui sotto potete vedere le immagini scattate con la mano e il polso in funzione.\n\n![Segni fatti dalla mano](./hands.png)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-10-31-parloma/index.md",
    frontMatter: {
      path: "/2017/10/31/parloma/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "14 mins",
      published: "2017-10-31T00:00:00.000Z",
      publishedReadable: "31 Ott 2017",
      featured: false,
      tags: ["PARLOMA"],
      title: "PARLOMA",
      description: "Un sistema di comunicazione remota per Sordociechi",
      href: "/2017/10/31/parloma/",
      image: "/content/blog/it/2017-10-31-parloma/main.jpg",
      imagePath: "/content/blog/it/2017-10-31-parloma",
    },
  },
  {
    content:
      "\nDato il grande interesse riscontrato sul [mio precedente post](/2017/04/27/implementiamo-un-bot-telegram-con-python/) riguardo lo sviluppo\ndi bot Telegram usando **Python** e la libreria **telepot**, ho deciso di continuare\na scrivere post riguardo questo argomento.\n\nIn questo post vedremo come gestire meglio, usando Telepot, i comandi e i possibili\nmessaggi che arrivano dall'utente, fruttando alcune funzionalità interessanti di Python.\n\n![ChatBot Telegram](./main.jpeg)\n\n## Comandi in Telegram\n\nIn Telegram, un comando è semplicemente una parola che inizia con il carattere `/`.\nI comandi vengono automaticamente riconosciuti dalla Chat Telegram e evidenziati in blu\nchiaro, e la chat stessa permette di re-inviarli semplicemente cliccandoci sopra.\n\nAd ogni modo, accedere ai comandi con Telegram è molto semplice, dobbiamo semplicemente\ntrattarli come se tutte le normali righe di test, ed avendo già visto come accedere\nal messaggio inviato dagli utenti, il tutto risulta essere molto ma molto semplice.\n\n## Rispondere a comandi Telegram con il nostro Bot\n\nRiprendiamo il codice sviluppato nel precedente post, che, per semplicità, riporto quindi in basso:\n\n```python\nimport telepot\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        name = msg[\"from\"][\"first_name\"]\n        txt = msg['text']\n        bot.sendMessage(chat_id, 'ciao %s, sono un bot molto stupido!'%name)\n        bot.sendMessage(chat_id, 'ho ricevuto questo: %s'%txt)\n\nTOKEN = '*** inserisci il tuo token qui  ***'\n\nbot = telepot.Bot(TOKEN)\nbot.message_loop(on_chat_message)\n\nprint 'Listening ...'\n\nimport time\nwhile 1:\n    time.sleep(10)\n```\n\nIl nostro scopo, a questo punto, è accedere al testo del messaggio e controllare\nse al suo interno c'è un comando specifico, e nel caso elaborare tale comando.\n\nAbbiamo già visto come accedere al test del messaggio, operazione che facciamo con\nquesta riga di codice: `txt = msg['text']`. Per controllare che all'interno del testo\nesista un comando specifico (ma si noti che il tutto funziona anche con una qualsiasi parola),\npossiamo sfruttare l'operatore `in` di Python.\n\n`in`, applicato alle stringhe, ritorna `True` se la stringa a sinistra dell'operatore\nè contenuta all'interno della stringa a destra di esso.\n\nFacciamo un esempio:\n\n- `\"ciao\" in \"ciao mondo\"` ritorna `True`,\n- `\"Ehy\" in \"ciao mondo\"` ritorna `False`\n\nAbbinare quindi `in` a dei costrutti `if` - `elif` ci permette di rispondere in modo\ndifferente in base ai comandi ricevuti.\n\nRiscriviamo quindi la funzione `on_chat_message` come segue:\n\n```python\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        name = msg[\"from\"][\"first_name\"]\n        txt = msg['text']\n        if '/start' in txt:\n            bot.sendMessage(chat_id, 'ciao {}, sono un bot molto stupido!'.format(name))\n        elif '/hey' in txt:\n            bot.sendMessage(chat_id, 'Heylà')\n        else:\n            bot.sendMessage(chat_id, 'Mi spiace {}, non capisco'.format(name))\n```\n\nSemplice vero?\n\nAggiungiamo un comando (solitamente `/help`) che risponde con la lista dei comandi\nche il bot comprende:\n\n```python\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        name = msg[\"from\"][\"first_name\"]\n        txt = msg['text']\n        if '/start' in txt:\n            bot.sendMessage(chat_id, 'ciao {}, sono un bot molto stupido!'.format(name))\n        elif '/hey' in txt:\n            bot.sendMessage(chat_id, 'Heylà')\n        elif '/help' in txt:\n            bot.sendMessage(chat_id, 'Ecco i comandi che capisco:\\n - /start\\n - /hey')\n        else:\n            bot.sendMessage(chat_id, 'Mi spiace {}, non capisco\\nUsa /help per sapere cosa posso fare!'.format(name))\n```\n\nLanciando questo bot, otterremo come risultato quanto segue:\n\n![Esempio Telegram 1](./esempio1.png)\n\nChe, come vedete, migliora di molto l'usabilità del nostro bot.\n\n## Gestire messaggi che iniziano con un comando\n\nIl codice di sopra funziona, ma ha un problema: risponde a qualsiasi frase contenente\nun comando specifico, anche se questo non è all'inizio del messaggio..\n\nAd esempio, una messaggio del tipo \"Che succede se scrivo /start\" è equivalente, per il\nbot, al messaggio \"/start\".\n\nTuttavia, molto spesso, quello che vogliamo fare è controllare che il messaggio inizi\ncon il comando dato, non che lo contenga.\n\nPer fortuna, possiamo usare il metodo `.startswith()` del tipo `str` Python, che controlla,\nappunto, se una stringa inizia con una stringa che viene passata come parametro.\n\nPossiamo quindi riscrivere il codice precedente come segue:\n\n```python\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        name = msg[\"from\"][\"first_name\"]\n        txt = msg['text']\n        if txt.startswith('/start'):\n            bot.sendMessage(chat_id, 'ciao {}, sono un bot molto stupido!'.format(name))\n        elif txt.startswith('/hey'):\n            bot.sendMessage(chat_id, 'Heylà')\n        elif txt.startswith('/help'):\n            bot.sendMessage(chat_id, 'Ecco i comandi che capisco:\\n - /start\\n - /hey')\n        else:\n            bot.sendMessage(chat_id, 'Mi spiace {}, non capisco\\nUsa /help per sapere cosa posso fare!'.format(name))\n```\n\nIn modo da risolvere il problema di cui sopra.\n\n## Comandi con parametri\n\nOk, iniziamo ora a creare esempi un po' più reali della semplice risposta a comandi\npre impostati: utilizziamo i comandi con parametri...\n\nI parametri non sono altro che informazioni aggiuntive che vengono date a dei comandi,\nin modo da aumentarne la loro possibilità! Vi proporrò due esempi, il primo, molto semplice,\nper far capire l'utilizzo dei parametri a livello di codice. Il secondo, più interessante,\nli utilizzerà per gestire un'applicazione reale e utile, e lo troverete nel prossimo post.\n\n### Un semplice comando com parametri: somma e media di numeri\n\nL'esempio banale (ma solo per l'applicazione, non per il codice) è presto detto:\nvogliamo implementare un nuovo comando (chiamato `/conti`) che permette di calcolare\nsomma e media dei numeri che gli vengono passati come parametri. Il comportamento è questo:\n\n- `/conti` (senza parametri) ritorna l'help della funzione.\n- `/conti <serie di numeri>` calcola la media e la somma dei numeri che gli vengono passati, vi porto giù un paio di esempi reali:\n- `/conti 1 2 3` risponde: `somma: 6, media 2`\n- `/conti 1 2 3 2 1` risponde: `somma: 9, media 1.8`\n\nVediamo come implementare questa funzione.\n\nPer prima cosa, il mio consiglio è sviluppare una funzione, che riceve una serie di numeri\ne ritorna la loro somma e la loro media.\n\nLa funzione è semplicemente implementabile come segue, giocando con alcune magie\nche può fare Python :D\n\n```python\ndef conti(*args):\n    return sum(args), sum(args)/len(args)\n```\n\n> L'operatore `*`, messo davanti all'argomento di una funzione, dice di passare\n> alla funzione stessa tutti gli argomenti come tupla. `args` è quindi una tupla contenente\n> tutti i valori dati alla funzione.\n\nPer testare questa funzione, ho anche scritto un semplicissimo test automatico (si veda [questo articolo](/2017/10/03/tdd-intro/) se volete approfondire sui test):\n\n```python\ndef test_conti():\n    assert (6, 2) == conti(1,2,3)\n    assert (9, 1.8) == conti(1,2,3,2,1)\n    assert (1, 1) == conti(1)\n    assert (2, 1) == conti(1,1)\n```\n\nBene, a questo punto non dobbiamo far altro che utilizzare questa funzione all'interno\ndel nostro bot, ma c'è un problema: come tradurre il messaggio che abbiamo ricevuto in\nparametri e comando?\n\nCi sono vari modi di farlo (del resto il messaggio è una stringa). Il modo più semplice,\nanche se forse non perfetto, che mi è venuto in mente è quello di usare il metodo `split()`\ndelle stringhe e di eliminare il primo elemento del risultato (che è il nome del comando stesso).\nLa lista rimanente conterrà (come stringhe) i parametri passati con il comando stesso.\n\nAndiamo quindi ad implementare la gestione del nostro comando.\n\n```python\n#...\nelif txt.startswith('/conti'):\n    params = txt.split()[1:]\n    if len(params) == 0:\n        bot.sendMessage(chat_id, 'Uso: /help <parametri>.. Calcola la somma e la media dei numeri')\n    else:\n        try:\n            params = [float(param) for param in params]\n            somma, media = conti(*params)\n            bot.sendMessage(chat_id, 'Somma: {}, media {}'.format(somma, media))\n        except:\n            bot.sendMessage(chat_id, 'Errore nei parametri, non hai inserito numeri!')\n#...\n```\n\n#### Vediamo di capire il codice implementato:\n\nLa prima operazione che eseguiamo è `params = txt.split()[1:]`, in questo modo,\ndividiamo la stringa `txt`, quindi l'intero comando passato, in una lista di stringhe.\nLa sintassi `[1:]` serve a prendere tutti gli elementi della stringa a partire del secondo\nelemento. Quindi escludendo il primo elemento, che è il comando stesso.\n\nFacciamo degli esempi:\n\n- Se `text = \"/conti 1 2 3\"`, allora, `params = [\"1\", \"2\", \"3\"]`.\n- Se `text = \"/conti\"`, allora, `params = []`.\n\nSi noti che i parametri non vengono automaticamente convertiti in numeri, ma sono ancora\nstringhe.\n\nDopo aver ottenuto i parametri, facciamo un check per vedere se effettivamente abbiamo\npassato dei parametri, e, nel caso in cui la lista di parametri sia vuota, inviamo via\nmessaggio l'help del comando:\n\n```python\nif len(params) == 0:\n    bot.sendMessage(chat_id, 'Uso: /help <parametri>.. Calcola la somma e la media dei numeri')\n```\n\nSuperato questo check, dobbiamo trasformare i parametri in numeri, applicare la funzione\n`conti` sui parametri, e ritornare il risultato:\n\n```python\n    params = [float(param) for param in params]\n    somma, media = conti(*params)\n    bot.sendMessage(chat_id, 'Somma: {}, media {}'.format(somma, media))\n```\n\nPer ultima cosa, ho inserito le righe sopra all'interno di un costrutto `try` - `except`,\nin modo da intercettare errori dovuti dall'inserimento di parametri non numerici.\n\nSe la conversione dei parametri da stringe a numeri, fatta nella riga `params = [float(param) for param in params]` non va a buon fine, un'eccezione viene generata ed intercettata da una linea di codice\nche invia un messaggio di errore all'utente.\n\n```python\ntry:\n    params = [float(param) for param in params]\n    somma, media = conti(*params)\n    bot.sendMessage(chat_id, 'Somma: {}, media {}'.format(somma, media))\nexcept:\n    bot.sendMessage(chat_id, 'Errore nei parametri, non hai inserito numeri!')\n```\n\nFatto!\n\nLanciando il bot, il nuovo comando funziona perfettamente!\n\n![Esempio Telegram 2](./esempio2.png)\n\nAbbiamo implementato il primo comando complesso in grado di gestire diversi parametri.\nPer ultima cosa, aggiungiamo il comando all'help. Vediamo quindi il codice completo...\n\n```python\nimport telepot\n\nTOKEN = '*** inserisci il tuo token qui  ***'\n\ndef conti(*args):\n    return sum(args), sum(args)/len(args)\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        name = msg[\"from\"][\"first_name\"]\n        txt = msg['text']\n        if txt.startswith('/start'):\n            bot.sendMessage(chat_id, 'ciao {}, sono un bot molto stupido!'.format(name))\n        elif txt.startswith('/hey'):\n            bot.sendMessage(chat_id, 'Heylà')\n        elif txt.startswith('/help'):\n            bot.sendMessage(chat_id, 'Ecco i comandi che capisco:\\n - /start\\n - /hey\\n - /conti')\n        elif txt.startswith('/conti'):\n            params = txt.split()[1:]\n            if len(params) == 0:\n                bot.sendMessage(chat_id, 'Uso: /conti <parametri>.. Calcola la somma e la media dei numeri')\n            else:\n                try:\n                    params = [float(param) for param in params]\n                    somma, media = conti(*params)\n                    bot.sendMessage(chat_id, 'Somma: {}, media {}'.format(somma, media))\n                except:\n                    bot.sendMessage(chat_id, 'Errore nei parametri, non hai inserito numeri!')\n        else:\n            bot.sendMessage(chat_id, 'Mi spiace {}, non capisco\\nUsa /help per sapere cosa posso fare!'.format(name))\n\nif __name__ == '__main__':\n    bot = telepot.Bot(TOKEN)\n    bot.message_loop(on_chat_message)\n\n    print('Listening ...')\n\n    import time\n    while 1:\n        time.sleep(10)\n```\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-10-29-bot-telegram-telepot-2/index.md",
    frontMatter: {
      path: "/2017/10/29/bot-telegram-telepot-2/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "8 mins",
      published: "2017-10-29T00:00:00.000Z",
      publishedReadable: "29 Ott 2017",
      featured: false,
      tags: ["Python", "Tutorial", "Telegram"],
      title: "Implementiamo un bot Telegram con Python - I Comandi",
      description: "Vediamo come gestire i comandi del nostro bot in Telegram",
      href: "/2017/10/29/bot-telegram-telepot-2/",
      image: "/content/blog/it/2017-10-29-bot-telegram-telepot-2/main.jpeg",
      imagePath: "/content/blog/it/2017-10-29-bot-telegram-telepot-2",
    },
  },
  {
    content:
      '\r\n![Time Plot](./betasting.png)\r\n\r\n<a href="https://goo.gl/forms/p7bFtHkbPwUAAydY2?utm_source=openapi&utm_medium=form&utm_campaign=api&utm_content=dc" class="btn btn-lg btn-info"> Accedi al Beta Testing delle HBR Cloud API</a>\r\n\r\nTra il 2014 e il 2015, abbiamo sviluppato un progetto chiamato Robot@CED, un sistema robotico in Cluod che permetteva di monitorare automaticamente un ambiente CED (Data Center) utilizzando un robot in grado di muoversi autonomamente nell\'ambiente e dotato di sensori ambientali (temperatura e umidità).\r\n\r\nRobot@CED è stata l\'idea iniziale da cui è nato HotBlack Robotics attorno alla quale abbiamo sviluppato le nostre competenze sulla Cloud Robotics e la nostra tecnologia.\r\n\r\nOggi annunciamo ufficialmente che un altro tassello di Robot@CED rientra ufficialmente a far parte di HRB, e sarà messo a disposizione dei nostri utenti per permettere lo sviluppo di applicazioni di Cloud Robotics: stiamo sviluppando le **HBR Cloud API**.\r\n\r\n### HBR Cloud API\r\n\r\nLe nostre API sono le stesse utilizzate all\'interno di Robot@CED, migliorate dopo due anni di esperienza di Cloud e messe a disposizione degli utenti. Essenzialmente, esse erano alla base del sistema di raccolta dati del robot: infatti permettono di salvare in Cloud e organizzare una mole di dati ambientali in base alla loro posizione ed al loro instante di cattura. In futuro, queste **API** si evolveranno includendo sempre di più funzionalità legate al mondo della navigazione autonoma, come il **calcolo automatico della traiettoria**, il **mapping** ecc.\r\n\r\n### Accedi al programma di Beta Testing\r\n\r\nSei interessato ad aiutarci a sviluppare e migliorare queste API? Accedi al programma di betatesting cliccando qui\r\n\r\n<a href="https://goo.gl/forms/p7bFtHkbPwUAAydY2?utm_source=openapi&utm_medium=form&utm_campaign=api&utm_content=dc" class="btn btn-lg btn-info"> Accedi al Beta Testing delle HBR Cloud API</a>\r\n\r\nNon appena saremo pronti, ti forniremo un accesso da Beta Tester, un tutorial di utilizzo e tutte le informazioni necessarie per utilizzarle al meglio!\r\n\r\n## Esempio: Robot@CED\r\n\r\nVediamo come noi le abbiamo utilizzate all\'interno del Data Center del Politecnico di Torino per effettuare monitoraggio ambientale.\r\n\r\nCome detto, il robot da noi sviluppato è in grado di muoversi autonomamente nell\'ambiente, e di raggiungere qualsiasi punto del data center in modo sicuro (cioè evitando eventuali ostacoli).\r\n\r\nIl data center del Politecnico di Torino è un piccolo data center composto da 16 rec (armadi di server) disposti su due file, che creano 3 corridoi. Abbiamo programmato il robot in modo da raggiungere 9 Way Point (WP) disposti come in figura sottostante (i cerchi).\r\n\r\n![Data Center Layout](./dclayout.png)\r\n\r\nAl raggiungimento di ogni Way Point, il robot esegue le misure di temperatura e umidità e le salva nella piattaforma di Cloud Robotics sfruttando le HBR Cloud API.\r\n\r\nIl risultato è una serie di misure geolocalizzate, o una serie storica di misure per ogni way point. In figura, i plot di temperature e umidità su 3 giorni dei dati raccolti per due waypoint specifici.\r\n\r\n![Time Plot](./plot.png)\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-10-07-annunciamo-il-programma-di-beta-testing-di-hbr-cloud-api/index.md",
    frontMatter: {
      path: "/hbr/annunciamo-il-programma-di-beta-testing-di-hbr-cloud-api/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-10-07T08:13:27.000Z",
      publishedReadable: "7 Ott 2017",
      featured: false,
      tags: [],
      title: "Annunciamo il programma di Beta Testing di HBR Cloud API",
      description: "",
      href: "/hbr/annunciamo-il-programma-di-beta-testing-di-hbr-cloud-api/",
      image:
        "/content/hbr/2017-10-07-annunciamo-il-programma-di-beta-testing-di-hbr-cloud-api/betasting.png",
      imagePath:
        "/content/hbr/2017-10-07-annunciamo-il-programma-di-beta-testing-di-hbr-cloud-api",
    },
  },
  {
    content:
      "\nNel mio [precedente articolo](/2017/10/03/tdd-intro/) vi ho parlato di TDD e del\nperchè lo trovo estremamente utile come metodologia di sviluppo.\n\nTra l'altro, grazie ad alcuni feedback che ho ricevuto, ho scoperto che tra alcuni\nGuru dell'informatica questa metodologia sta iniziando ad essere chiamata **Test Driven Design**,\ninvece che **Test Drived Development**. Questo perché si vuole mettere l'accento\nsul fatto che il TDD aiuta a sviluppare codice migliore, quindi è una metodologia\ndi design (progettazione), piuttosto che di development (sviluppo).\n\nAd ogni modo, indipendentemente da come la vogliamo chiamare, voglio farvi vedere,\nin questo post ed in quelli che ne seguiranno, come può essere applicata nello sviluppo\ndi codice reale.\n\n## Un caso pratico: sviluppiamo delle API in Flask usando il TDD\n\nDiamoci un obiettivo: recemente ho iniziato a sviluppare API Rest, e mi sono reso conto\n(in modo completamente inaspettato), che la cosa mi diverte parecchio.\n\nQui vi propongo quindi come sviluppare una semplice app Flask che ci permette di comunicare tramite API REST (in json).\nPer semplicità, l'app al momento permetterà solamente di eseguire il Login\n(utilizzando una tecnologia chiamata JWT) ed esporrà 3 **end point**:\n\n- `/login`: per loggarsi;\n- `/protected`: a cui si potrà accedere solo se loggati;\n- `/`: a cui si potrà accedere senza nessuna identificazione.\n\n### Alcune note\n\nNonostante questa applicazione possa sembrare semplice, in realtà essa è la base\ndi un grosso progetto che sto sviluppando per hobby,\nchiamato **Flask-IoT**. L'idea di questo progetto è quella di sviluppare un\nserver IoT basato su Flask che permetta a dispositivi connessi (Raspberry Pi in primis),\ndi inviare dati ad un database.\n\nInoltre, nonostante la disponibilità di estensioni di Flask molto che potrebbero essere\nutili per lo sviluppo di questa applicazione, la mia idea è di svilupparla senza usare troppi\nframework già pronti, in piena filosofia _Flask_, che da al programmatore la piena libertà di\nscelta nello sviluppo. Ovviamente questo non mi impedirà di usare framework semplici e molto utili (come [Flask-JSON](http://flask.pocoo.org/docs/0.12/api/)), tuttavia, dopo aver provato un po' di esensioni Flask\nper lo sviluppo di API Rest ([Flask-RESTFul](https://flask-restful.readthedocs.io/en/latest/), [Flask-RESTPlus](http://flask-restplus.readthedocs.io/en/stable/),\n[Flask-Potion](https://pypi.python.org/pypi/Flask-Potion)), mi sono sempre trovato\nnella condizione di dover aggirare dei limiti imposti da questi framework, finchè non ho\ndeciso di sviluppare tutto da me (cosa molto facile in Flask).\n\nPer ultimo, utilizzerò [**PyTest**](https://docs.pytest.org/en/latest/) come framework per lo sviluppo dei test.\n\n### Iniziamo: Setup dell'ambiente di sviluppo\n\nAl solito, da terminale, iniziamo a creare la cartella di lavoro con l'ambiente\nvirtuale:\n\n```\n$ mkdir flask-tdd-tutorial && cd flask-tdd-tutorial\n$ virtualenv -ppython3 env\n$ source env/bin/activate\n```\n\nNotare il parametro `-ppython3` che forza l'ambiente virtuale ad utilizzare Python 3.\n\n### Implementiamo il primo test\n\nRicordate il mantra del TDD? **Mai sviluppare se non si ha un test che fallisce**.\nQuesto vale anche quando si inizia lo sviluppo dell'app: scriviamo prima i test!\n\nCreiamo un file `test.py` ed iniziamo ad implementare il test.\n\n```python\n# file test.py\n\nfrom app import create_app\n\ndef test_app_runs():\n    app = create_app()\n    client = app.test_client()\n    res = client.get('/')\n    assert res.status_code == 200\n```\n\nCome vedete, il test non è altro che una semplice funzione (il cui come inizia con `test_`),\nche fa le seguenti operazioni:\n\n1. Crea un'app _Flask_ tramite una funzione chiamata `create_app()` (importata dal modulo `app`);\n2. Crea un client di test (funzione implementata da Flask) utilizzando il comando `app.test_client()`;\n3. Fa una richiesta all'url `/` del nostro server\n4. Verifica, tramite il comando `assert`, che il codice di ritorno della risposta sia `200` (vuol dire _tutto ok!_).\n\nVedete come, nell'implementare il test, abbiamo già dato alcuni vincoli (o linee guida)\nnello sviluppo vero e proprio? Vediamoli tutti insieme:\n\n1. La nostra applicazione viene sviluppata in un modulo chiamato `app`\n2. L'applicazione viene creata da una funzione chiamata `create_app()`\n\n- Questo è uno dei pattern di sviluppo suggeriti da Flask!\n\n3. L'url `/` (quindi principale) deve ritornare qualcosa senza errori (`status_code` deve essere `200`).\n\nTramite queste poche righe di codice abbiamo quindi già definito (a grandi linee), la struttura\ned il comportamento del nostro server!\n\n### Il comando `assert`\n\nVorrei prendere un po' di tempo per spiegare per bene cosa vuol dire il comando `assert`:\nquesto è una speciale keyword id Python (e di molti altri linguaggi) utilizzata\nper generare Errori (o **Eccezioni**). Un eccezione, per chi non lo sapesse, è un errore\nche viene generato da un programma quando succede qualcosa che non va, come ad esempio\nil tentativo di dividere un numero per zero.\nIn particolare `assert` funziona in modo molto simile a `if`. Viene chiamata insieme ad\nuna condizione, e genera errore nel caso tale condizione sia `False`.\n\nIn **PyTest**, `assert` è utilizzata come condizione di verifica di esecuzione del test.\nQuindi, se tutti gli `assert` (sì, possono essercene più di uno, anche se in TDD\nconsiglia un solo assert a test!) all'interno di un test passano, allora il test è considerato\npassato, altrimenti fallisce.\n\n### Lanciamo il primo test\n\nOk, chiusa questa parantesi che serve a far capire il codice, partiamo!\nPer lanciare il test, dobbiamo prima di tutto installare il pacchetto _pytest_.\nUtilizziamo il comando `pip`\n\n```\n(env)$ pip install pytest\n```\n\ne quindi lanciare il comando `pytest test.py`\n\n```bash\n(env)$ pytest tests.py\n============================= test session starts ==============================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 0 items / 1 errors\n\n==================================== ERRORS ====================================\n___________________________ ERROR collecting test.py ___________________________\nImportError while importing test module '/Users/ludus/develop/github/flask-tdd-tutorial/test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ntest.py:3: in <module>\n    from app import create_app\nE   ModuleNotFoundError: No module named 'app'\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 errors during collection !!!!!!!!!!!!!!!!!!!!\n=========================== 1 error in 0.13 seconds ============================\n```\n\nIl primo test è fallito! Dobbiamo essere contenti: possiamo iniziare a sviluppare.\nVediamo gli errori che vengono generati, e cerchiamo di risolverli nel modo più\nbanale possibile.\n\nIl primo errore lo abbiamo su `from app import create_app`,\ncausato dal fatto che non esiste un modulo `app` (`ImportError: No module named app`).\n\nRisolviamolo: creiamo un file `app.py` e rilanciamo il test.\n\n```\n(env)$ pytest tests.py\n============================= test session starts ==============================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 0 items / 1 errors\n\n==================================== ERRORS ====================================\n___________________________ ERROR collecting test.py ___________________________\nImportError while importing test module '/Users/ludus/develop/github/flask-tdd-tutorial/test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ntest.py:3: in <module>\n    from app import create_app\nE   ImportError: cannot import name 'create_app'\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 errors during collection !!!!!!!!!!!!!!!!!!!!\n=========================== 1 error in 0.13 seconds ============================\n```\n\nAdesso otteniamo l'errore `cannot import name create_app`:\nperché il nostro modulo non definisce la funzione `create_app`.\n\nAggiustiamolo definendo la versione `create_app` nel modo più stupido possibile:\n\n```\n# file app.py\n\ndef create_app():\n    pass\n```\n\nSi esatto, so già che avrò altri errori oltre a questo, ma l'idea del TDD è\nproprio questa: risolviamo un errore alla volta (nel modo più semplice possibile).\n\nLanciamo il test:\n\n```\n(env)$ pytest tests.py\n============================= test session starts ==============================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 1 item\n\ntest.py F\n\n=================================== FAILURES ===================================\n________________________________ test_app_runs _________________________________\n\n    def test_app_runs():\n        app = create_app()\n>       client = app.test_client()\nE       AttributeError: 'NoneType' object has no attribute 'test_client'\n\ntest.py:7: AttributeError\n=========================== 1 failed in 0.03 seconds ===========================\n```\n\nOk, le cose migliorano: il test si lamenta dal fatto che la variabile `app` è\nnon definita, e quindi non possiamo chiamare la funzione `app.test_client()`.\nRisolviamolo facendo tornare alla funzione `create_app` un qualcosa di più\ninteressante (magari un'app Flask?).\n\n```python\n# file app.py\n\nfrom flask import Flask\n\ndef create_app():\n    app = Flask(__name__)\n    return app\n```\n\nE rilanciamo il test:\n\n```\n(env)$ pytest tests.py\n============================= test session starts ==============================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 0 items / 1 errors\n\n==================================== ERRORS ====================================\n___________________________ ERROR collecting test.py ___________________________\nImportError while importing test module '/Users/ludus/develop/github/flask-tdd-tutorial/test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ntest.py:3: in <module>\n    from app import create_app\napp.py:3: in <module>\n    from flask import Flask\nE   ModuleNotFoundError: No module named 'flask'\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 errors during collection !!!!!!!!!!!!!!!!!!!!\n=========================== 1 error in 0.13 seconds ============================\n```\n\nBene, nuovo errore, super semplice da risolvere: `No module named 'flask'`,\nrisolviamolo installando **Flask**\n\n```\n$ pip install Flask\n```\n\nE via di nuovo con il test.\n\n```\n(env)$ pytest tests.py\n============================= test session starts ==============================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 1 item\n\ntest.py F\n\n=================================== FAILURES ===================================\n________________________________ test_app_runs _________________________________\n\n    def test_app_runs():\n        app = create_app()\n        client = app.test_client()\n        res = client.get('/')\n>       assert res.status_code == 200\nE       assert 404 == 200\nE        +  where 404 = <Response streamed [404 NOT FOUND]>.status_code\n\ntest.py:9: AssertionError\n=========================== 1 failed in 0.38 seconds ===========================\n```\n\nOk, le cose migliorano.\nIl test ha raggiunto il primo `assert`.\nIn particolare, l'url `/` ritorna un errore _404 (not found)_ invece che il codice di successo (200).\nIl modo migliore per risolverlo? Definiamo una route su `/`.\n\n```python\n# file app.py\n\nfrom flask import Flask\n\ndef create_app():\n\n    app = Flask(__name__)\n\n    @app.route('/')\n    def index():\n        return ''\n\n    return app\n```\n\nCodice un po' brutto vero? Personalmente non adoro definire una `route` dentro `create_app`,\nma non preoccupiamoci ora. Notare che la funzione ritorna una stringa vuota:\nattualmente stiamo risolvendo l'errore 404, non il messaggio nella risposta HTML.\n\nLanciamo il test...\n\n```\n(env)$ pytest tests.py\n============================= test session starts ==============================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 1 item\n\ntest.py .\n\n=========================== 1 passed in 0.30 seconds ===========================\n```\n\nEvviva! Il test è passato. Abbiamo concluso la seconda fase del ciclo (green).\nAl momento potremmo fare il refactoring del codice, ma è ancora troppo acerbo\nper preoccuparcene... Però possiamo migliorare i test!\n\n## Fixture e le magie di PyTest\n\nCome potete immaginare vedendo la funzione di test, è molto probabile che gli\noggetti `app` e `client` debbano essere creati in ogni test che implementiamo.\n\nIn particolare, è un'esigenza comune dover eseguire del codice ogni volta che\nun test viene eseguito (ricordatevi che un test è ogni funzione).\nFortunatamente **pyTest** ha una funzionalità molto molto utile chiamata **fixture**.\n\nEssenzialmente, una **fixture** è una funzione che viene chiamata all'inizio di\nogni test, il cui valore di ritorno viene passato automatica alle funzioni\nche lo richiedono.\n\nImplementare una fixture è semplicissimo: basta decorare una funzione.\n\nPartiamo dall'inizio:\nè molto probabile che ogni nostro test che implementeremo utilizzerà l'oggetto `app`.\nPossiamo quindi farlo diventare una fixture, implementando la seguente funzione:\n\n```python\nimport pytest\n\n@pytest.fixture\ndef app():\n    _app = create_app()\n    return _app\n```\n\nPer non fare confusioni, ho chiamato la funzione `app`, mentre l'oggetto che questa\nfunzione ritorna `_app`. Capirete dopo perché questa differenza.\n\nAdesso viene il bello delle fixture: ogni funzione di test che avrà come argomento\n`app` (nome della funzione), chiamerà automaticamente questa fixture, e il valore di\nritorno della fixture sarà passato all'argomento della funzione di test.\n\nNei test Flask, avremo molto spesso bisogno anche della variabile `client`,\ncreiamo quindi una fixture anche per questo:\n\n```python\n@pytest.fixture\ndef client(app):\n    _client = app.test_client()\n    return _client\n```\n\nSi noti che questa seconda fixture implementata dipende dalla precedente, perchè\nriceve un parametro chiamato (appunto) `app`.\n\nOk, ora possiamo reimplementare la vecchia funzione `test_app_runs` come segue:\n\n```python\ndef test_app_runs(client):\n    res = client.get('/')\n    assert res.status_code == 200\n```\n\nSemplice, no?\n\nOk, fatto questo, la nuova versione del file `test.py` dovrebbe essere questa:\n\n```python\n# file test.py\n\nfrom app import create_app\nimport pytest\n\n@pytest.fixture\ndef app():\n    _app = create_app()\n    return _app\n\n@pytest.fixture\ndef client(app):\n    _client = app.test_client()\n    return _client\n\ndef test_app_runs(client):\n    res = client.get('/')\n    assert res.status_code == 200\n```\n\nAbbiamo appena finito di fare refactoring del nostro codice -- sì, non è il\nrefactoring \"standard\" del codice di produzione, ma del codice di test,\nma parliamo sempre di refactoring.\n\nLanciamo il test e controlliamo che questo vada bene.\n\n```\n(env)$ pytest tests.py\n============================= test session starts ==============================\nplatform darwin -- Python 3.6.1, pytest-3.2.2, py-1.4.34, pluggy-0.4.0\nrootdir: /Users/ludus/develop/github/flask-tdd-tutorial, inifile:\ncollected 1 item\n\ntest.py .\n\n=========================== 1 passed in 0.31 seconds ===========================\n```\n\nOk benissimo, niente di nuovo. Possiamo concludere il primo ciclo red-green-refactoring.\n\n## Fine prima Parte\n\nSembra inutile? Sì, sembrava inutile anche a me, ma vi assicuro che nel tempo, come vedremo piano piano), questo approccio può aiutare, se ben utilizzato, a sviluppare\ndel codice migliore, e certamente velocizza la scoperta di _regression bugs_:\nbug introdotti dai refactoring e comunque durante la normale evoluzione del codice.\n\nSembra lungo? In realtà non lo è, ad eseguire il ciclo completo di test\nho impiegato esattamente 2 min e 21 secondi (cronometro alla mano).\n\nHo esagerato su alcuni passaggi? Certamente, alcuni passaggi ovvii avrei potuto\nevitarli, ma voglio far capire bene il procedimento.\nLa prossima volta andrò più spedito! Promesso!!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-10-04-tdd-flask-pytest-1/index.md",
    frontMatter: {
      path: "/2017/10/04/tdd-flask-pytest-1/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "10 mins",
      published: "2017-10-04T00:00:00.000Z",
      publishedReadable: "4 Ott 2017",
      featured: false,
      tags: ["Python", "Test Driver Development", "Flask", "PyTest"],
      title: "TDD con Flask e PyTest per lo sviluppo di API REST. Parte 1",
      description:
        "Tutorial su come usare il Test Driver Development (TDD) con Flask e PyTest per sviluppare delle semplici API REST",
      href: "/2017/10/04/tdd-flask-pytest-1/",
      image: "/content/blog/it/2017-10-04-tdd-flask-pytest-1/tdd-python.png",
      imagePath: "/content/blog/it/2017-10-04-tdd-flask-pytest-1",
    },
  },
  {
    content:
      "\nNella carriera di ogni buon programmatore, o di chiunque si definisce tale,\narriva un momento in cui ci si rende conto dell'importanza di implementare test\nautomatici di un codice. Nel mio caso, questo è successo nel momento in cui\nla piattaforma che sto sviluppando per [HotBlack Robotics](http://www.hotblackrobotics.com)\nè diventata abbastanza complessa che ogni mia modifica al codice causava\nla rottura di un'altra parte della piattaforma, senza che io me ne rendessi conto.\n\nQuesto era dovuto al fatto che non sono mai stato un gran fan dello sviluppo di Test\nautomatici del codice, perchè credevo (come molti, da quello che ho visto) che fossero\nsolo un modo per rallentare lo sviluppo del codice.\n\nAll'interno di una startup, inoltre, in cui solitamente si tende a sperimentare\npiuttosto che sviluppare sistemi robusti, vedo la scrittura dei test come\nuna perdita di tempo molto grande.\n\nOvviamente, se sto scrivendo questo articolo, è perchè ad un certo punto mi sono\ntrovato nella situazione in cui ho preferito reimplementare la piattaforma da zero\npiuttosto che cercare di migliorarla (e rompendola).\n\nDa allora, ho iniziato a studiare e ad applicare uno dei metodi più popolari (ma anche\nmeno capiti da chi, come me, si avvicina alla programmazione): cioè il Test Driven Development.\n\nMa andiamo con ordine.\n\n## A che serve implementare test del codice?\n\nPer quanto possa sembrare strano, lo scopo primario di un test non è testare, ma è\ndocumentare.\nScrivere in modo ordinato e conciso i test del proprio codice rendono molto\nsemplice ai programmatori (e a noi stessi) capire cosa fa ogni pezzo di codice\nche abbiamo testato.\n\nIl secondo scopo dei test è, appunto, testare il codice.\nImplementare dei test in modo continuo e lanciarli il più frequentemente possibile\nci permette di scoprire subito eventuali bug che vengono introdotti nel codice durante le modifiche.\nScrivere dei test quindi permette di implementare del codice più robosto, a discapito di uno\nsviluppo leggermente rallentato.\n\nSe infatti scrivere test vuol dire, solitamente, scrivere il doppio del normale codice\nche implementeremmo senza test, è anche vero che, mano a mano che il programma cresce in dimensione,\ni test riducono enormenente il tempo di debugging e di test manuali del programma stesso.\nCiò vuol dire che, a lungo andare, lo sviluppo viene velocizzato, non rallentato.\n\n## Test Driven Development (TDD)\n\nÈ importante, quindi, implementare dei test il più frequentemente possibile.\nIstintivamente, i test dovrebbero essere scritti dopo lo sviluppo del codice stesso,\ntuttavia, esiste una metodologia di sviluppo molto pragmantica e che (nel mio caso)\nrisulta essere molto efficiente: il **TDD (Test Driven Development)**.\n\n**TDD** è una metodologia di sviluppo che necessita un po' di tempo per essere\npadroneggiata, e che, nel momento in cui i programmatori ci si imbattono per la prima volta,\nappare inutile e anti produttiva.\n\nIl mantra principale del **TDD** è il seguente: _mai sviluppare codice se non abbiamo un test che fallisce!_.\n\nL'idea del **TDD** è infatti che i test per un determinato pezzo di codice o funzionalità del nostro programma debbano essere scritti _prima_ dell'implementaizone stessa. La parte di sviluppo del test è la prima parte di un _ciclo_ del TDD (_red_).\nQuesta prima parte finisce nel momento in cui il test implementato viene eseguito: il test deve essere eseguito e questo **deve** fallire: se il test non fallisce vuol dire che qualcosa non va. Infatti, non avendo ancora implementato il codice che il test dovrebbe testare, è naturale che il test stesso fallisca.\n\nUna volta che il test fallisce, si passa alla seconda fase del ciclo (_green_) dove possiamo, finalmente, metterci a scrivere il codice che aggiusta il test.\nQuesto pezzo di codice deve essere implementato nel modo più semplice possibile, senza\nintessarci troppo al fatto che il codice venga scritto bene. Dobbiamo cioè implementare **solo quel minimo pezzo di codice che fa passare il test**.\nUna volta implemetato il codice, e possiamo lanciare l'intera suite di test implemetata fino\nad ora, e vedere se l'intera suite di test funziona. Se si, possiamo passare alla fase successiva, altrimenti dobbiamo risolvere i test che falliscono.\n\nL'ultima fase del ciclo (_refactoring_) consiste nel modificare il codice sviluppato, cercando di migliorarne la struttura. A questo punto, il ciclo di test riparte.\n\n## I Vantaggi del TDD\n\nQuando ho scoperto per la prima volta il TDD mi sembrava un'assurdità da nerd infomatici\nprecisini. Tuvvavia, ho voluto provare ad utilizzarla per un po', e adesso non riuscirei a farne a meno. Quando infatti mi capita di iniziare ad implementare del codice senza test (per fretta o perchè mi avvicino a nuove piattaforma che ancora non conosco bene), è come sentirmi nudo, in quanto so benissimo che i test mi proteggono da eventuali errori. Vediamo quindi quali sono i vantaggi di questa metogdologia:\n\n1. Il TDD ci forza a testare la quasi totalità del codice che implementiamo. Questo ha due vantaggio:\n\n- Quasi tutti i bug che una modifica del codice introduce nelle funzionalità già implementate venogno scoperte all'istante, è anche molto facile risolvere perchè vengono automaticamente riprodotti.\n- Non dobbiamo avere paura di fare il refactoring (anche molto spinto) del codice implementato.\n\n2. Come detto, tutti i test sono un'accurata documentazione del nostro codice. Ogni funzione che implementiamo viene documentata dai test, e questo ci aiuterà nel momento in cui ritorneremo a cercare di capire cosa fa del codice scritto un po' di tempo fa.\n3. Il TDD ci forza a scrivere codice in modo semplice. A volte succede di avere la sensazione che implementare un certo codice in modo \"più generico\" di quanto serva al momento possa tornarci utile in futuro. Il TDD ci obbliga a sviluppare codice nel modo più semplice possilibe. Se poi in futuro il codice dovrà complicarsi, nessun problema, il TDD ci protegge da errori causati dal refactoring.\n4. Le 3 fasi del TDD (red, green, refactor) sono molto veloci, e ci permettono di saltare da test a sviluppo in cicli di meno di un minuto. Questo permette al nostro cervello di essere più agile e di pensare in modo più focalizzato, invece che le normali fasi di sviluppo in cui si può stare anche ore dietro lo sviluppo del codice e poi altre ore dietro il debugging.\n\n## Alcune note sul TDD\n\nÈ importate sottolineare che il TDD non è una metodologia perfetta, e nemmeno una\ntecnica che si padroneggia facilmente.\n\nMolto spesso ci imbatteremo in pezzi di codice che sono difficilmente testabili.\nEvitate in questi casi di fare il mio errore di perdere troppo tempo dietro allo sviluppo\ndi test difficilissimi da implementare.\n\nInoltre, ricordatevi che l'utilizzo del TDD va acquisito con il tempo. Specialmente\nnei primi tempi, vi verrà istintivo buttarvi a scrivere codice. In questo caso, se veramente volete padroneggiare questa modo di sviluppare codice, conviene prendere una boccata d'aria e fermarsi quando ci si accorge di stare sviluppando senza avere un test che fallisce. Col tempo, verrà naturale mettersi a scrivere prima i test.\n\n## Vi interessa il TDD?\n\nVi interessa imparare a padroneggiare il TDD con Python e Flask?\nSto preparando un (lungo) tutorial per farvi vedere come utilizzo normalemnte\nquesto strumento per sviluppare codice in Flask!\nIn realtà, inizialmente questo post doveva essere un'introduzione al tutorial, ma mi sono\nreso conto che stava diventando troppo lungo e ho deciso di separarlo dal resto.\n\nA breve pubblicherò una guida su come (almeno io), lo utilizzo. Ma vorrei sapere\nda voi, che ne pensate del TDD? Lo utilizzate già? Se si, da quanto? Se no, quali sono\nle vostre impressioni leggendo questo post?\n\n## Riferimenti\n\nSe volete approfondire, consiglio i seguenti link:\n\n- [9 Benefits of Test Driven Development](https://www.madetech.com/blog/9-benefits-of-test-driven-development)\n- [5 Common Misconceptions About TDD & Unit Tests](https://medium.com/javascript-scene/5-common-misconceptions-about-tdd-unit-tests-863d5beb3ce9)\n\nOltre al libro [Test-Driven Development with Python](http://chimera.labs.oreilly.com/books/1234000000754), dal quale ho iniziato ad imparare questa metodologia.\n\n## Edit\n\nAggiungerò qui le parti del tutorial sul TDD:\n\n- [parte 1](/2017/10/04/tdd-flask-pytest-1/)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-10-03-tdd-intro/index.md",
    frontMatter: {
      path: "/2017/10/03/tdd-intro/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2017-10-03T00:00:00.000Z",
      publishedReadable: "3 Ott 2017",
      featured: false,
      tags: ["Python", "Test Driver Development", "Flask", "PyTest"],
      title: "Cosa è il Test Driven Development (TDD) e perchè lo utilizzo?",
      description: "",
      href: "/2017/10/03/tdd-intro/",
      image: "/content/blog/it/2017-10-03-tdd-intro/TDD.jpeg",
      imagePath: "/content/blog/it/2017-10-03-tdd-intro",
    },
  },
  {
    content:
      "\nPython è un linguaggio di programmazione molto pragmatico e potente.\nTra le funzionalità che preferisco (anche se ho iniziato a sfruttare seriamente da poco),\ntroviamo i _decoratos_ (decoratori), a cui Python dedica una sintassi speciale.\n\nIn questo post, voglio analizzare l'utilizzo dei decoratori in Python, facendo vedere come possono essere usati per semplificare non poco lo sviluppo di API in un'applicazione _Flask_ con un semplice esempio pratico.\n\n## Decorator Design Pattern\n\nI decorator fanno parte dei **Design Pattern** fondamentali. Per chi non lo sapesse, un design pattern è una soluzione standardizzata (e spesso elegante) ad un problema ricorrente in programmazione.\n\nIl decorator risolve la necessità (ai programmatori) di aggingere funzionalità ad uno specifico oggetto (per semplicità limitiamoci a parlare di funzioni), senza dover modificare l'oggetto stesso.\n\nFacciamo un esempio pratico:\n\nSupponiamo di definire una serie di funzioni (per semplicità due) che generano dei dizionari Python.\n\n```python\ndef dict_name(name):\n    return dict(name=name)\n\ndef dict_age(age):\n    return dict(age=age)\n```\n\nQueste due semplicissime funzioni ritornano due dizionari con un solo elemento entrambi:\n\n```\n>>> dict_name('ludovico')\n{'name': 'ludovico'}\n>>> dict_age(12)\n{'age': 12}\n```\n\nSupponiamo a questo punto di voler utilizzare queste funzioni per ritornare non un oggetto `dict` ma un oggetto `JSON`, magari da utilizzare all'interno di un server web.\n\nLe soluzioni possono essere due:\n\n1. Modificare le due funzioni come segue:\n\n```python\nimport json\n\ndef dict_name_json(name):\n    return json.dumps(dict(name=name))\n\ndef dict_age_json(age):\n    return json.dumps(dict(age=age))\n```\n\nChe può essere utilizzata esattamente nello stesso modo di prima:\n\n```\n>>> dict_age_json(12)\n'{\"age\": 12}'\n>>> dict_name_json('ludovico')\n'{\"name\": \"ludovico\"}'\n```\n\n2. Utilizzare la funzione `json.dumps()` esternamente alle due funzioni.\n\n```\n>>> json.dumps(dict_name('ludovico'))\n'{\"name\": \"ludovico\"}'\n>>> json.dumps(dict_age(12))\n'{\"age\": 12}'\n```\n\nEntrambe queste soluzioni sono funzionali ma poco _Pythoniche_. Inoltre, richiedono al programma o di modificare una funziona esistente oppure di utilizzare continuamente la funzione `json.dumps()`.\n\nA questo punto ci viene in aiuto il pattern decorator. Un decorator è (essenzialmente) una funzione che prende in ingresso un'altra funzione e ne ritorna una simile ma con il comportamento modificato.\n\nRiprendiamo il nostro esempio: se vogliamo utilizzare questo design pattern, dobbiamo scrivere una funzione che prende in ingresso un'altra funzione che ritorna un dizionario, e genera una funzione che ritorna lo stesso dizionario _jsonizzato_.\n\nEcco il codice:\n\n```python\ndef as_json(func):\n    def func_wrapper(arg):\n        d = func(arg)\n        return json.dumps(d)\n    return func_wrapper\n```\n\nVediamo cosa fa questo codice:\n\n1. Per prima cosa abbiamo definito una funzione chiamata `as_json`, che prende come parametro una funzione generica `func`.\n\n2. All'interno di questa funzione, definiamo una seconda funzione chiamata `func_wrapper`. Questa funzione prende in ingresso un parametro (`args`), chiama la funzione `func` su `args`, e ritorna il risultato come `json`, utilizzando la funzione `json.dumps()`.\n\n3. Alla fine, ritorniamo la funzione `func_wrapper`, che _decora_ la funzione `func`.\n\nDi seguito, vediamo come utilizzarla.\n\n```\n>>> dict_name = as_json(dict_name)\n>>> dict_name('ludovico')\n'{\"name\": \"ludovico\"}'\n>>> dict_age = as_json(dict_age)\n>>> dict_name(12)\n'{\"age\": 12}'\n```\n\nIn particolare, le due seguenti righe di codice\n\n```python\ndict_name = as_json(dict_name)\ndict_age = as_json(dict_age)\n```\n\nsono quelle in cui _decoriamo_ le funzioni con il decoratore `as_json`.\n\nQuesta sintassi è un po' brutta, per questo motivo, python mette a disposizione una speciale sintassi che permette di decorare una funzione nel momento in cui viene creata:\n\n```python\n@as_json\ndef dict_name(name):\n    return dict(name=name)\n\n@as_json\ndef dict_age(age):\n    return dict(age=age)\n```\n\nChe è equivalente (ma decisamente più bella) a\n\n```python\ndef dict_name(name):\n    return dict(name=name)\ndict_name=as_json(dict_name)\n\ndef dict_age(age):\n    return dict(age=age)\ndict_age=as_json(dict_age)\n```\n\n### Miglioriamo il decoratore\n\nNotare che, a questo punto, il nostro decoratore funziona con qualsiasi funzione che ritorna un oggetto `dict` (o comunque un oggetto jsonizzabile) e ha un solo parametro in ingresso.\n\nChe succede se proviamo ad usare questo decoratore con una funzione più complessa? Provando a lanciare il seguente codice\n\n```python\n@as_json\ndef dict_name_age(name, age):\n    return dict(name=name, age=age)\n\ndict_name_age(\"ludovico\", 12)\n```\n\notterremo un errore\n\n```\nTraceback (most recent call last):\n  File \"decorator_example.py\", line 13, in <module>\n    print(dict_name_age(\"ludovico\", 12))\nTypeError: func_wrapper() takes 1 positional argument but 2 were given\n```\n\nQuesto succede perchè la funzione `func_wrap` all'interno del decoratore prende solo un parametro. Come facciamo a fare in modo che questa prenda un numero indefinito di parametri in modo da essere compabile con qualsiasi funzione decorata? Ci aiuta una funzione di python chiamata **unpacking**, che magari discuterò in un altro post. Al momento, vi basti sapere che la soluzione è la seguente:\n\n```python\ndef as_json(func):\n    def func_wrapper(*args, **kargs):\n        d = func(*args, **kargs)\n        return json.dumps(d)\n    return func_wrapper\n```\n\nIn cui `*args, **kargs` intercettano genericamente qualsiasi parametro venga passato alla `func_wrapper` e li passano alla funzione `func` decorata. Ora possiamo usare il nostro decoratore in modo più generale.\n\n```python\n@as_json\ndef dict_name_age(name, age):\n    return dict(name=name, age=age)\n```\n\n```\n>>> dict_name_age(\"ludovico\", 12)\n'{\"name\": \"ludovico\", \"age\": 12}'\n```\n\n### Decoratori parametrizzabili\n\nA questo punto le cose potrebbero sembrare più complesse, ma in realtà una volta\ncapito il meccanismo il tutto risulta molto banale.\n\nChe fare se volessimo creare un decoratore _parametrizzabile_, cioè al quale\nvogliamo passare degli argomenti (come se fosse una funzione) nel momento in cui\nviene usato?\n\nL'esempio, riprendendo il discorso di prima, è il seguente. Vogliamo un decoratore\na cui specificare se ritornare il json in formato più leggibile (con le indentazioni e gli a capo per interderci) oppure normalmente senza occuparci troppo del formato visivo.\n\nPer farlo, ecco il codice che propongo:\n\n```python\ndef as_json(indent=False):\n    def as_json_dec(func):\n        def func_wrapper(*args, **kargs):\n            d = func(*args, **kargs)\n            if indent:\n                return json.dumps(d, indent=4)\n            else:\n                return json.dumps(d)\n        return func_wrapper\n    return as_json_dec\n```\n\nIn questo caso, `as_json` non è più una decorator, ma una funzione che ritorna a sua volta\nun decoratore (`as_json_dec`). Il parametro passato alla fuzione `as_json` viene utilizzato all'interno del decoratore per modificarne il suo comportamento.\n\nQuesto decoratore può essere utilizzato come segue:\n\n```python\n@as_json()\ndef dict_name_age(name, age):\n    return dict(name=name, age=age)\n```\n\no, in alternativa, in questo modo:\n\n```python\n@as_json(True)\ndef dict_name_age(name, age):\n    return dict(name=name, age=age)\n```\n\nNel secondo caso, il risultato è il seguente:\n\n```\n{\n    \"name\": \"ludovico\",\n    \"age\": 12\n}\n```\n\n## Esempio Reale: decoratore in Flask\n\nUno dei miei [framework preferiti](/2016/12/27/tutorial-flask/) è _Flask_, un microframework in python per creare siti web (lato server). Flask è molto potente per la creazione di API REST. Per chi non lo sapesse, le API REST sono una soluzione che permette ad un'applicazione generica (web, mobile, desktop) di scambiare dati con un server, indipendentemente dal linguaggio di programmazione scelto e dalla piattaforma.\n\nEntrerò nel dettaglio sulle funzionalità di REST in futuro, vediamo però ora come utilizzare il nostro decoratore in Flask per ritornare dati in JSON dalla nostra applicazione.\n\n### WebApp Flask\n\nVogliamo implementare una semplice app _Flask_ che ritorna una dato json, invece di una pagina in HTML.\nPer farlo, esiste un'estensione di Flask che già implementa questa funzionalià, ma voglio farvi vedere come, utilizzando i decoratori, la cosa è molto semplice da implementare.\n\nPrima di tutto, notiamo che Flask mette a disposizione la funzione `jsonify()` che ha un comportamento simile a `json.dumps()`, ma ritorna una risposta HTML completa, settando anche nell'header il tipo di contenuto come `application/json` (in questo modo i browser capiranno che stiamo utilizzando dei dati di tipo json).\n\nPer farlo, quindi, definitiamo il nostro decoratore come segue:\n\n```python\nfrom flask import Flask, jsonify\n\ndef as_json(func):\n    def func_wrapper(*args, **kargs):\n        d = func(*args, **kargs)\n        return jsonify(d)\n    return func_wrapper\n```\n\nE utilizziamolo all'interno della nostra `route` flask, nel seguente modo:\n\n```python\napp = Flask(__name__)\n\n@app.route('/')\n@as_json\ndef index():\n    res = {'risposta': 'Ciao a Tutti!'}\n    return res\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```\n\nSe a questo punto lanciamo la nostra applicazione **Flask** e accediamo al browser, vedremo che la riposta viene correttamente interpretata come un JSON.\n\n![Risposta JSON](./json_resp.png)\n\nOvviamente questo decoratore ha ancora molti margini di miglioramento: ad esempio, non possiamo specificare lo _status code_ di risposta nella nostra funzione decorata.\n\n## Conclusioni\n\nL'esempio qui presentato è molto banale, ma fa capire le potenzialità dei decoratori!\nFatemi sapere nei commenti come implementate voi questo tipo di operazioni.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-09-30-python_decorators/index.md",
    frontMatter: {
      path: "/2017/09/30/python_decorators/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2017-09-30T00:00:00.000Z",
      publishedReadable: "30 Set 2017",
      featured: false,
      tags: ["Python"],
      title: "Python Decorators",
      description: "Introduzione ai decoratori in Python",
      href: "/2017/09/30/python_decorators/",
      image: "/content/blog/it/2017-09-30-python_decorators/json_resp.png",
      imagePath: "/content/blog/it/2017-09-30-python_decorators",
    },
  },
  {
    content:
      "\nCiao a tutti,\nchi mi segue si è accorto che da un po' di tempo la mia attività sul blog\nè scemata! Questo è dovuto a due motivi principali:\n\n- Tantissimo lavoro da fare, ormai tra **[HotBlack Robotics](http://hotblackrobotics.com)** e **[Parloma](http://parloma.github.com)** ho sempre meno tempo per dedicarmi alla scrittura\n- La gestione del blog inizia a diventare molto complicata, perché le imperfezioni del mio blog scritto in Flask iniziano a farsi sentire.\n\nPer questi motivi, ho deciso di spostarmi completamente su un manager diverso e più testato,\novviamente seguendo la filosofia OpenSource del vecchio blog.\n\nHo quindi deciso di sviluppare questo sito in [Jekyll](https://jekyllrb.com/) su [GitHub Pages](https://pages.github.com/),\ndue progetti che permettono di sviluppare un blog in modo semplice (e quasi gratuito).\nSe siete interessati, potrei quindi approfondire l'utilizzo di tali soluzioni per lo sviluppo di un Blog Personale.\n\nLa cosa interessante? Il sito è direttamente hostato da GitHub, e la repository di questo blog è pubblica ed è disponibile sul [mio GitHub](http://github.com/ludusrusso/ludusrusso.github.io). Se trovare errori potete segnarli direttamente da GitHub, o correggerli direttamente voi e sottometterli tramite un pull request!\n\nA presto :D\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-09-17-nuovo-blog/index.md",
    frontMatter: {
      path: "/2017/09/17/nuovo-blog/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-09-17T00:00:00.000Z",
      publishedReadable: "17 Set 2017",
      featured: false,
      tags: ["news"],
      title: "Vi presento il mio nuovo Blog",
      description: "Vi presento il mio nuovo Blog!",
      href: "/2017/09/17/nuovo-blog/",
      image: "/content/blog/it/2017-09-17-nuovo-blog/screen-shot.png",
      imagePath: "/content/blog/it/2017-09-17-nuovo-blog",
    },
  },
  {
    content:
      '\nCon un po\' di dispiacere, qualche giorno fa si è concluso il corso "Laboratorio di Robotica", organizzato dal mio vecchio Liceo (il Liceo Stampacchia di Tricase) a cui io ho partecipato come docente!\n\nIl corso è stato organizzato dal Liceo Stampacchia di Tricase in collaborazione con il CINI (Consorzio Interuniversitario Nazionale di Informatica). Durante il corso, gli studenti hanno potuto imparare ad utilizzare tecnologie innovative come Stampa 3D e programmazione Arduino per costruire (partendo da zero) un robot in grado di disegnare.\n\nÈ stata una bellissima esperienza, e sono stato felicemente stupito dalla capacità dei ragazzi (tra i 13 e i 15 anni) di riuscire ad imparare tante cose in così poco tempo! Il loro lavoro, è disponibile al seguente [link](https://t.co/NOuODheJbA).\n\nUn ringraziamento particolare va al Preside Mauro Polimento, alla professoressa Greco, che mi ha supportanto durante tutto il corso (rinunciando alle vacanze :D) e a tutti gli aiutanti che mi hanno permesso di gestire un numero così alto di studenti!\n\nVi lascio con un video, realizzato da [Davide Marra](https://www.youtube.com/channel/UCX0qIlG6xtKAzsXIl1uGrhg), ed alcune foto del corso.\n\n<div class="rwd-video">\n  <iframe width="100%" src="https://www.youtube.com/embed/NG4cZG6Y9Wo" frameborder="0">\n</iframe>\n</div>\n\n![](./1.jpg)\n![](./2.jpg)\n![](./3.jpg)\n![](./4.jpg)\n![](./5.jpg)\n![](./6.jpg)\n![](./7.jpg)\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-09-11-un-super-grazie-ai-ragazzi-del-corso-laboratorio-di-robotica/index.md",
    frontMatter: {
      path: "/2017/09/11/un-super-grazie-ai-ragazzi-del-corso-laboratorio-di-robotica/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-09-11T00:00:00.000Z",
      publishedReadable: "11 Set 2017",
      featured: false,
      tags: ["Corso", "Robotica", "Stampacchia"],
      title: 'Un super grazie ai ragazzi del corso "Laboratorio di Robotica"',
      description: "",
      href: "/2017/09/11/un-super-grazie-ai-ragazzi-del-corso-laboratorio-di-robotica/",
      image:
        "/content/blog/it/2017-09-11-un-super-grazie-ai-ragazzi-del-corso-laboratorio-di-robotica/5.jpg",
      imagePath:
        "/content/blog/it/2017-09-11-un-super-grazie-ai-ragazzi-del-corso-laboratorio-di-robotica",
    },
  },
  {
    content:
      '\nSono felice di informarvi che è stato finalmente attivato un corso di robotica presso il Liceo G. Stampacchia di Tricase (Lecce) per due settimane di Agosto.\n\n![STEM Stampacchia](./tricaseAgosto.png)\n\nIl corso, introdurrà i partecipanti alle tecnologie di **making**, **fabbricazione digitale** e **robotica**.\n\nDi seguito l\'avviso ufficiale.\n\nSono aperte le iscrizioni al corso **Laboratorio di Robotica** autorizzato dalla Presidenza del Consiglio dei Ministri – Dipartimento per le Pari Opportunità.\n\nRivolto prioritariamente a ragazzi di terza media (iscritti per l’A.S. 2017/2018 al primo anno di Scuola Superiore).\nIl numero di partecipanti è 20, selezionati secondo le seguenti priorità:\n\n1.  Iscritti alla curvatura "Robotica" del Liceo "G. Stampacchia"\n2.  Iscritti al Liceo "G. Stampacchia"\n3.  Iscritti presso altri istituti\n\nIl corso, completamente **gratuito** per n. 40 ore, si terrà presso il centro ACAIT di Tricase, dal 10/08/2017 al 30/08/2017, secondo il calendario seguente:\n\n- 11/08/2917 dalle 16:30 alle 20:30\n- 12/08/2017 dalle 8:30 alle 12:30\n- 17/08/2017 dalle 16:30 alle 20:30\n- 18/08/2017 dalle 16:30 alle 20:30\n- 19/08/2017 dalle 8:30 alle 12:30\n- 21/08/2017 dalle 16:30 alle 20:30\n- 22/08/2017 dalle 16:30 alle 20:30\n- 23/08/2017 dalle 16:30 alle 20:30\n- 24/08/2017 dalle 16:30 alle 20:30\n- 25/08/2017 dalle 16:30 alle 20:30\n\nAl calendario potranno essere apportate lievi modifiche in accordo con il Docente formatore.\nSi allega modulo di iscrizione da consegnare alla segreteria alunni entro e non oltre il 30.07.2017.\nPer la relativa graduatoria si terrà conto:\n\n1. delle percentuali previste dal bando: 40% ragazzi - 60% ragazze;\n2. delle priorità su elencate\n3. dell’ordine cronologico di arrivo delle domande.\n\nIl modulo di iscrizione è scaricabile da [qui](https://www.dropbox.com/s/93r4dqtq8qsvb4w/avviso-di-ROBOTICA-e-domanda.pdf?dl=1)\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-07-22-laboratorio-di-robotica-al-liceo-stampacchia/index.md",
    frontMatter: {
      path: "/2017/07/22/laboratorio-di-robotica-al-liceo-stampacchia/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-07-22T00:00:00.000Z",
      publishedReadable: "22 Lug 2017",
      featured: false,
      tags: ["Corso", "Stampacchia"],
      title: "Laboratorio di Robotica al Liceo Stampacchia",
      description:
        'Aperte le iscrizioni al corso "Laboratorio di Robotica" presso il Liceo G. Stampacchia di Tricase',
      href: "/2017/07/22/laboratorio-di-robotica-al-liceo-stampacchia/",
      image:
        "/content/blog/it/2017-07-22-laboratorio-di-robotica-al-liceo-stampacchia/tricaseAgosto.png",
      imagePath:
        "/content/blog/it/2017-07-22-laboratorio-di-robotica-al-liceo-stampacchia",
    },
  },
  {
    content:
      "\r\n![enter image description here](./az3Qd96.png)\r\nIn questo tutorial vedremo:\r\n\r\n- come collegare un sensore DHT11 (temperatura e umidità) sul Raspberry Pi 3\r\n- come sviluppare lo sketch in ROS per pubblicare dati sulla\r\n  WebApp - Python\r\n- sviluppare la WebApp - Html/Javascript\r\n\r\n## Di cosa abbiamo bisogno\r\n\r\n1.  Un Raspberry Pi 3 oppure un Pi 2\r\n2.  Tre cavi GPIO femmina/femmina\r\n3.  Un sensore DHT11\r\n\r\n![enter image description here](./SgzBq3p.jpg)\r\n\r\n## Collegamenti\r\n\r\nCome prima cosa prendete il Raspberry Pi 3 e accendetelo collegandola alla corrente. Una volta collegato in cloud, colleghiamo il sensore.\r\n\r\n![enter image description here](./XGvFqya.jpg)\r\n\r\nIl sensore DHT11 è un sensore di temperatura e umiditàe composta da 3 Pin: G (GND) – V (VCC) – D (Data)\r\n\r\nIn questa figura potete vedere come collegare i PIN del sensore sul Raspberry\r\n\r\n![enter image description here](./Gq0HBH9.png)\r\n\r\nOra che abbiamo connesso il sensore , procediamo con l'installazione delle librerie necessarie.\r\nPer installare le librerie dobbiamo usare un programma client SSH (Per esempio: Putty oppure la shell sul browser).\r\n\r\n**Eseguiamo questi commandi:**\r\nInstalla alcune dipendenze sul Raspberry:\r\n\r\n    sudo apt-get update\r\n    sudo apt-get install build-essential python-dev python-openssl\r\n\r\nUsare Git per clonare il software direttamente sul Raspberry utilizzando il terminale:\r\n\r\n    git clone https://github.com/adafruit/Adafruit_Python_DHT.git\r\n    cd Adafruit_Python_DHT\r\n\r\nOra, per installare la libreria eseguire:\r\n\r\n      sudo python setup.py install\r\n\r\n## Sketch ROS\r\n\r\nScriviamo ora un semplice sketch in ROS che ci stampa la temperatura e l'umidità.\r\nImportiamo ora le librerie:\r\n\r\n    import dotbot_ros #libreria di default ROS\r\n    import Adafruit_DHT #libreria per il funzionamento del sensore\r\n    import sys #libreria per forzare la stampa sulla shell\r\n\r\n**Codice Completo**\r\n\r\n    import dotbot_ros\r\n    import Adafruit_DHT\r\n    import sys\r\n\r\n    class Node(dotbot_ros.DotbotNode):\r\n        node_name = 'node'\r\n\r\n        def setup(self):\r\n            sensor = 11\r\n            pin = 4\r\n            humidity, temperature = Adafruit_DHT.read_retry(sensor, pin)\r\n            print('Temp={0:0.1f}*  Humidity={1:0.1f}%'.format(temperature, humidity))\r\n            sys.stdout.flush()\r\n\r\n## Analizziamo il codice:\r\n\r\nNella funzione **setup** abbiamo la dichiarazione delle variabili sensor e pin.\r\n_Sensor_ è il tipo di sensore utilizzato , nel nostro caso è 11 (DHT11).\r\n_Pin_ è in numero del pin GPIO sul quale è collegata l'uscita _DATA_ del sensore.\r\n\r\nUna volta che le variabili sono state inizializzate , viene lanciata queste funzione che si occupa di leggere i dati ricevuti dal sensore.\r\n\r\n    humidity, temperature = Adafruit_DHT.read_retry(sensor, pin)\r\n\r\nSuccessivamente per visualizzare la temperatura e l'umidità , stampiamo questi dati.\r\n\r\n    print('Temp={0:0.1f}*  Humidity={1:0.1f}%'.format(temperature, humidity))\r\n    sys.stdout.flush()\r\n\r\n**Lanciamo il codice:**\r\nSe tutto è andato a buon fine, dobbiamo visualizzare questo output:\r\n![enter image description here](./8aKlYVM.jpg)\r\n\r\nWebapp per ricevere i dati dal sensore.\r\nCome prima cosa andiamo a sviluppare l'applicazione web , il codice completo lo trovate [qui](https://github.com/ganduras/dht11/blob/master/index.html).\r\n\r\n**Analizziamo il codice HTML:**\r\nAll'interno abbiamo la prima parte del codice , scritto in JavaScript che permette alla WebApp di comunicare con il nostro robottino (riga 136).\r\n\r\n    <script type=\"text/javascript\">\r\n    start_ros('192.168.0.108', 'cyberbot', '192.168.0.108', '192.168.0.108/bridge/');\r\n    </script>\r\n\r\nIMPORTANTE: ricordate di modificare i campi '192.168.0.108' e 'cyberbot' inserendo l'IP e il nome del robot.\r\n\r\nLa seconda parte di questo file JavaScript si occupa di sottoscriversi al topic \"temperature_status\" e ricevere la temperatura espressa in Float32 (riga 140).\r\n\r\n    <script>\r\n    var listener = new ROSLIB.Topic({\r\n          ros : ros,\r\n          name : '/' + robot.name + '/temperature_status',\r\n          messageType : 'std_msgs/Float32'\r\n        });\r\n        listener.subscribe(function temperatura (message){\r\n            document.getElementsByClassName(\"data\")[0].innerHTML = message.data + \"°C\";\r\n          });\r\n    </script>\r\n\r\nLa terza parte del codice JavaScript , si sottoscrive al topic \"humidity_status\" , riceve un messaggio di tipo Float32, e lo stampa sulla pagina HTML (riga 155).\r\n\r\n    <script>\r\n    var listener = new ROSLIB.Topic({\r\n          ros : ros,\r\n          name : '/' + robot.name + '/humidity_status',\r\n          messageType : 'std_msgs/Float32'\r\n        });\r\n        listener.subscribe(function umidita (message){\r\n            document.getElementsByClassName(\"data\")[1].innerHTML = message.data + \"%\";\r\n          });\r\n    </script>\r\n\r\n## Sketch ROS:\r\n\r\nImportiamo le librerie\r\n\r\n    import dotbot_ros #libreria ROS\r\n    import Adafruit_DHT #libreria necessaria per il funzionamento del sensore\r\n    from std_msgs.msg import Float32 #serve per pubblicare dati di tipo Float32 sul topic\r\n\r\nNella funzione principale **setup** , inizializziamo il sensore e il pin , ed creiamo 2 Publisher.\r\n\r\n    self.sensor = 11\r\n            self.pin = 4\r\n            self.loop_rate = dotbot_ros.Rate(5)\r\n            self.umedita = dotbot_ros.Publisher('humidity_status', Float32)\r\n            self.temperatura = dotbot_ros.Publisher('temperature_status', Float32)\r\n\r\nOltre a ciò la funzione setup, chiama la funzione loop passandole la frequenza di esecuzione _dotbot_ros.Rate(5)_.\r\n\r\n    def loop(self):\r\n            humidity, temperature = Adafruit_DHT.read_retry(self.sensor, self.pin)\r\n            self.umedita.publish(humidity)\r\n            self.temperatura.publish(temperature)\r\n\r\nLa funzione loop riceve i dati dai sensori e successivamente li pubblica sui Topic.\r\n\r\n## Codice Completo:\r\n\r\nEcco il codice completo del nostro programma:\r\n\r\n      import dotbot_ros\r\n        import Adafruit_DHT\r\n        from std_msgs.msg import Float32\r\n\r\n        class Node(dotbot_ros.DotbotNode):\r\n            node_name = 'node'\r\n\r\n            def setup(self):\r\n                self.sensor = 11\r\n                self.pin = 4\r\n                self.loop_rate = dotbot_ros.Rate(5)\r\n                self.umedita = dotbot_ros.Publisher('humidity_status', Float32)\r\n                self.temperatura = dotbot_ros.Publisher('temperature_status', Float32)\r\n\r\n\r\n\r\n            def loop(self):\r\n                humidity, temperature = Adafruit_DHT.read_retry(self.sensor, self.pin)\r\n                self.umedita.publish(humidity)\r\n                self.temperatura.publish(temperature)\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-06-28-come-collegare-il-sensore-dht11-temperatura-e-umidita-in-cloud/index.md",
    frontMatter: {
      path: "/hbr/come-collegare-il-sensore-dht11-temperatura-e-umidita-in-cloud/",
      author: {
        id: "ruslan",
        name: "Ruslan",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ruslan.jpg",
      },
      readTime: "4 mins",
      published: "2017-06-28T09:33:04.000Z",
      publishedReadable: "28 Giu 2017",
      featured: false,
      tags: [],
      title: "Come collegare il sensore DHT11 (Temperatura e umidità) in cloud",
      description: "",
      href: "/hbr/come-collegare-il-sensore-dht11-temperatura-e-umidita-in-cloud/",
      image:
        "/content/hbr/2017-06-28-come-collegare-il-sensore-dht11-temperatura-e-umidita-in-cloud/az3Qd96.png",
      imagePath:
        "/content/hbr/2017-06-28-come-collegare-il-sensore-dht11-temperatura-e-umidita-in-cloud",
    },
  },
  {
    content:
      '\nEcco qui la seconda parte del mio tutorial sull\'utilizzo di Electron per sviluppare un\'applicazione Desktop in grado di interfacciarsi con Arduino.\n\n![Arduinoscope](./arduinoscope.png)\n\nMentre nella [prima parte](http://www.ludusrusso.cc/posts/2017-06-26-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-1) abbiamo visto come creare la nostra applicazione ed impostare la grafica, in questo parte entremo nel dettaglio su come utilizzare **arduino-firmata** per far comunicare la nostra applicazione con Arduino.\n\nMa prima di tutto, cerchiamo di capire cosa è **Firmata**.\n\n### Il protocollo Firmata\n\n[**Firmata**](https://github.com/firmata/protocol) è un protocollo pensato per permettere la comunicazione tra un microcontrollore ed un software su un computer. Il protocollo è abbastanza generico da poter essere implementato sul firmware di qualsiasi microcontrollore e sul software di un qualsiasi computer. Firmata è già implemetato in Arduino ed è talmente popolare che nelle ultime versioni dell\'IDE lo troviamo già disponibile all\'installazione. Inoltre, firmata è disponibile su tantissimi linguaggi di programmazione, come Python o javascript in Node.\n\n#### Firmata su Arduino\nFirmata in Arduino può essere usata in due modi diversi:\n\n- il modo più semplice, è di utilizzare uno sketch preimpostato e general porpouse (**StandardFirmata**) che permette di interagire in modo semplice con la scheda Arduino dal computer principale, e permette (con delle API già impostate) di accedere alle varie funzionalità di Arduino, come accendi/spegni i led. Questo è il modo che utilizzeremo in questo tutorial.\n- il secondo modo, più interessante, è quello di sviluppare uno schetch custom sfruttando le varie funzionalità di firmata, in modo da creare uno sketch più leggero e che faccia esattamente quello che serve fare.\n\n#### Firmata e Node.js\n\nCome sapete, Node.js è una piattaforma che permette di sviluppare applicazioni in javascript che girano su un computer (invece che su un browser come normalmente avviene).\n\nPer node, troviamo implementazioni già pronte di Firmata, e tra queste, vi è anche la libreria [arduino-firmata](https://github.com/shokai/node-arduino-firmata) che è già pronta per comunicare con lo schetch **StandardFirmata**.\n\n## Installare Firmata su Arduino\n\nL\'installazione di Firmata su Arduino risulta essere molta facile. Infatti, lo Sketch **StandardFirmata** è già disponibile in Arduino accendendo da menu _File_ ad _Esempi_ > _Firmata_ > _StandardFirmata_.\n\n![](./menufirmata.png)\n![](./sketchfirmata.png)\n\nUna volta aperto lo Sketch, non ci resta che uploadarlo su un Arduino collegato via USB al computer. Dato che ci siamo, ricordiamo di segnare la porta seriale dell\'Arduino, in quanto dovrà essere utilizzata nel nostro progetto! Nel mio caso, la porta è `/dev/cu.usbmodem1461`.\n\n## Utilizzo di Arduino Firmata nel progetto Electron\n\nUploadato il Firmware StandardFirmata, siamo pronti ad installare ed utilizzare `arduino-firmata` all\'interno della nostra applicazione in electron.\n\n### Installazione di `arduino-firmata`\n\nApriamo quindi (da terminale) la cartella di lavoro, ed installiamo il pacchetto `arduino-firmata` digitando:\n\n```bash\n$ npm install --save arduino-firmata\n```\n\nUna volta installato il pacchetto, possiamo iniziare ad usarlo all\'interno della nostra applicazione.\n\nUna piccola nota: purtroppo, arduino-firmata attualmente non è disponibile come pacchetto generico TypeScript. Questo non significa che non possiamo usarlo (ricordo che TypeScript è un _superset_ di JavaScript, quindi ogni cosa implementata in JavaScript è automaticamente funzionante in TypeScript). Tuttavia, dovremo usare alcuni "trick" strani per utilizzare il pacchetto nel nostro codice.\n\n### Primo utilizzo `arduino-firmata`\n\nCome anticipato nel precedente tutorial, lavoreremo principalmente nel processo di rendering, cioè nel file `src/index.ts`. All\'interno di questo file, dobbiamo importare la libraria, aprire una comunicazione seriale con Arduino ed interagire sfruttando la API di Arduino Firmata.\n\nApriamo il file `src/index.ts`. Per prima cosa, dobbiamo importare la libreria, aggiungendo la linea di codice all\'inizio del programma (possiamo rimuovere il vecchio codice typescript che cambia il titolo al progetto):\n\n```typescript\nlet ArduinoFirmata = require("arduino-firmata")\n```\n\nSi noti che, invece di utilizzare il classico import TypeScript `import {ArduinoFirmata} from \'arduino-firmata\'`, ho dovuto utilizzare il "vecchio" metodo `require`. Questo è il "trick" di cui accennavo poco fa per far funzionare un modulo JavaScript in TypeScript.\n\nA questo punto, creiamo l\'oggetto che si occuperà di comunicare con la scheda Arduino. Una volta creato, dobbiamo utilizzare il metodo `.connect` per connettere l\'oggetto alla porta seriale.\n\n```typescript\nlet ArduinoFirmata = require("arduino-firmata")\n\nlet arduino = new ArduinoFirmata()\n\nlet arduino_port = "/dev/cu.usbmodem1461"\narduino.connect(arduino_port)\n```\n\nOvviamente, dovete inzializzare la variabile `arduino_port` con il nome della porta a cui è collegata il vostro arduino, che (al 99%) sarà diversa dalla mia.\n\nCome sapete, JavaScript (e quindi TypeScript), sono linguaggi fortemente orientati agli eventi. Come nel caso dell\'applicazione electron, che chiama l\'evento `ready`, anche in questo caso, possiamo iniziare ad utilizzare arduino una volta che si verifica l\'evento `connect`, ed utilizzeremo di nuovo il metodo `on` ed una **callback**:\n\n```typescript\nlet ArduinoFirmata = require("arduino-firmata")\n\nlet arduino = new ArduinoFirmata()\n\nlet arduino_port = "/dev/cu.usbmodem1461"\narduino.connect(arduino_port)\n\narduino.on("connect", () => {\n  // il codice da implementare va qui!\n})\n```\n\nAll\'interno della funzione, dobbiamo implementare le varie azioni da fare una volta che Arduino è connesso. Per prima cosa, stampiamo sulla console di Electron la versione di della scheda a cui siamo connessi:\n\n```typescript\n// ...\n\narduino.on("connect", () => {\n  console.log("board version" + arduino.boardVersion)\n  // ...\n})\n```\n\nCome ultima cosa, per verificare l\'effettivo funzionamento del programma, programmiamo in TypeScript il classico **blink** di Arduino, facendo lampeggiare il led 13.\n\nCome al solito, dovremmo usare gli eventi per eseguire questa operazione. In particolare, dobbiamo chiamare una callback (che cambialo lo stato del pin), associata ad un evento che si verifica periodicamente (ogni secondo), sfruttando la funzione `setInterval` di JavaScript.\n\n`setInterval` prende due parametri in ingresso:\n\n- il primo, è la funzione di callback da eseguire\n- il secondo, è l\'intervallo di tempo tra le varie chiamate della funzione (in millisecondi).\n\nCome al solito su Arduino, dobbiamo ricordarci di settare il pin 13 come pin di output, usando la stringa `arduino.pinMode(7, ArduinoFirmata.OUTPUT);`.\n\nUtilizzo una variabile `status` per far cambiare lo stato del led. Sfruttiamo `status` anche per stampare a video lo stato attuale del led, usando un semplice `if`.\n\n```typescript\n// ...\narduino.on("connect", () => {\n  console.log("board version" + arduino.boardVersion)\n\n  arduino.pinMode(13, ArduinoFirmata.OUTPUT)\n\n  let status = true\n  setInterval(() => {\n    status = !status\n    arduino.digitalWrite(13, status)\n    if (status == true) console.log("stato led: acceso")\n    else console.log("stato led: spento")\n  }, 1000)\n})\n```\n\nEcco qui il codice completo appena sviluppato\n\n```typescript\nlet ArduinoFirmata = require("arduino-firmata")\n\nlet arduino_port = "/dev/cu.usbmodem1461"\nlet arduino = new ArduinoFirmata()\narduino.connect(arduino_port)\narduino.on("connect", () => {\n  console.log("board version" + arduino.boardVersion)\n\n  arduino.pinMode(13, ArduinoFirmata.OUTPUT)\n\n  let status = true\n  setInterval(() => {\n    status = !status\n    arduino.digitalWrite(13, status)\n    if (status == true) console.log("stato led: acceso")\n    else console.log("stato led: spento")\n  }, 1000)\n})\n```\n\n### Test del codice... OPS, errore\n\nPrima di testare il codice, configuriamo l\'app in modo che apra all\'avvio la il tool degli sviluppatori, da cui potremmo vedere in modo più semplice eventuali errori e tutti i log sulla console.\n\nPer farlo, aggiugiamo la riga di codice `mainWindow.toggleDevTools();` all\'interno del file `app.ts`, che diventerà così:\n\n```typescript\nimport { app, BrowserWindow } from "electron"\n\napp.on("ready", () => {\n  let mainWindow = new BrowserWindow({ width: 800, height: 600 })\n  mainWindow.toggleDevTools() // <- Riga Aggiunta\n  mainWindow.loadURL("file://" + __dirname + "/index.html")\n})\n```\n\nAvendo cura che l\'arduino sia collegato al nostro computer, lanciamo l\'app con `npm start` e vediamo che succedere.\n\n![errore serial firmata](./serialerror.png)\n\nNel mio caso, appare un brutto errore sulla console, che probabilmente apparirà anche a voi. Se non appare, potete saltare completamente questa sezione e riprendere alla prossima, altrimenti, vediamo come risolvere il problema.\n\nL\'errore che ottengo è il seguete:\n\n```\nUncaught Error: The module \'../node_modules/serialport/build/Release/serialport.node\'\nwas compiled against a different Node.js version using\nNODE_MODULE_VERSION 48. This version of Node.js requires\nNODE_MODULE_VERSION 53. Please try re-compiling or re-installing\nthe module (for instance, using `npm rebuild` or`npm install`).\n```\n\nEssenzialmente questo ci dice che il modulo `serialport` (utilizzato internamente da `arduino-firmata`), è stato compilato su una versione diversa di `npm`. Fortunatamente, c\'è un modo molto semplice per risolvere il problema, e consiste nell\'utilizzare il progetto `electron-rebuild`, che è stato sviluppato proprio per risolvere questo tipo di incoveniente.\n\nInstalliamo il progetto con il comando:\n\n```\n$ npm install --save-dev electron-rebuild\n```\n\nAggiungiamo quindi un nuovo script all\'interno del file `package.json`:\n\n```json\n...\n"scripts": {\n  "test": "echo \\"Error: no test specified\\" && exit 1",\n  "start": "electron .",\n  "rebuild": "electron-rebuild ."\n},\n...\n```\n\nEd eseguiamo questo script:\n\n```bash\n$ npm run rebuild\n```\n\nUna volta completata la fase di compilazione, lanciamo l\'app! Vedrete che tutto funziona come previsto:\n\n![errore serial firmata](./arduinoblink.png)\n\nCome vedete, il programma scrive (correttamente), la versione di Arduino, fa blinkare il led 13 a frequenza di 1 secondo, e stampa sulla console lo stato della scheda stessa.\n\n## Interagire con la GUI - Implementiamo un oscilloscopio\n\nTestato il classico esempio di Blink, iniziamo a fare qualcosa di più interessante. La mia idea è di sviluppare un semplice oscilloscopio, che legge i dati dal PIN A0 di Arduino e li disegna su un grafico animato.\n\nPer farlo, utilizzeremo la libreria JavaSript [smoothie](http://smoothiecharts.org/), che permette di disegnare plot nel tempo in modo semplice e veloce.\n\nInstalliamo la libreria utilizzando il comando npm, e le sue definizione per TypeScript `@types/smoothie`.\n\n```bash\n$ npm install --save smoothie @types/smoothie\n```\n\nA questo punto, dobbiamo creare un\'area **html** in cui disegnare il grafico. Per farlo, modifichiamo il file `index.html`, aggiungendo una nuova `div`\n(classe `col-md-12`) con all\'interno un `canvas`, come segue:\n\n```html\n<html>\n  ...\n  <body>\n    ...\n    <div class="container">\n      <div class="row">\n        ...\n        <div class="col-md-12">\n          <canvas id="plotA0" style="width:100%; height: 300px"></canvas>\n        </div>\n      </div>\n    </div>\n  </body>\n  ...\n</html>\n```\n\nNotare che al canvas abbiamo settato un `id` a `plotA0`!\n\nIl file completo `src/index.html` sarà quindi così\n\n```html\n<html>\n  <head>\n    <title>Arduino Electron</title>\n    <link rel="stylesheet" href="./index.scss" />\n  </head>\n  <body>\n    <h1 id="title_id">Funziona</h1>\n\n    <div class="container">\n      <div class="row">\n        <div class="col-xs-4 col-xs-offset-4">\n          <img\n            class="img-responsive "\n            src="./imgs/arduino_white.png"\n            alt="Arduino Logo"\n          />\n        </div>\n\n        <div class="col-md-12">\n          <canvas id="plotA0" style="width:100%; height: 300px"></canvas>\n        </div>\n      </div>\n    </div>\n  </body>\n  <script>\n    require("./index.ts")\n  </script>\n</html>\n```\n\nApriamo quindi il file `src/index.ts`. Prima di tutto, dobbiamo importare gli oggetti `SmoothieChart` e `TimeSeries` dalla libreria `smoothie`:\n\n```typescript\nimport { SmoothieChart, TimeSeries } from "smoothie"\n```\n\nA questo punto, creiamo un nuovo `SmoothieChart` (cioè un elemento grafico in cui visualizzare il plot) a partire dall\'elemento con id `plotA0` appena creato\n\n```typescript\nlet plotter = new SmoothieChart({ responsive: true })\nlet canvasPlot = document.getElementById("plotA0")\nplotter.streamTo(canvasPlot, 30)\n```\n\nIl parametro di configurazione `{responsive: true}` che passiamo al costruttore `SmoothieChart` serve a far si che il grafico di adatti automaticamente alle dimensioni della pagina all\'interno della quale si trova.\n\nNotare che il metodo `streamTo` prende due parametri:\n\n- il primo rappresenza l\'elemento del file `html` all\'interno del quale mostrare i dati;\n- il secondo, rappresenta il tempo di refresh del grafico, in questo case impostato a $30ms$.\n\nIl file `src/index.ts` avrà quindi questa forma\n\n```typescript\nlet ArduinoFirmata = require("arduino-firmata")\nimport { SmoothieChart, TimeSeries } from "smoothie"\n\nlet plotter = new SmoothieChart({ responsive: true })\nlet canvasPlot = document.getElementById("plotA0")\nplotter.streamTo(canvasPlot, 30)\n\nlet arduino_port = "/dev/cu.usbmodem1461"\nlet arduino = new ArduinoFirmata()\narduino.connect(arduino_port)\n\narduino.on("connect", () => {\n  console.log("board version" + arduino.boardVersion)\n\n  arduino.pinMode(13, ArduinoFirmata.OUTPUT)\n\n  let status = true\n  setInterval(() => {\n    status = !status\n    arduino.digitalWrite(13, status)\n    if (status == true) console.log("stato led: acceso")\n    else console.log("stato led: spento")\n  }, 1000)\n})\n```\n\nUna volta lanciata l\'applicazione, dovremmo vedere un grafico (vuoto). Vediamo come inserire i dati da arduino al suo interno.\n\n![plot vuoto](./plotempty.png)\n\n### Leggere dati da arduino e disegnarli dentro il plotter\n\nVediamo adesso come leggere i dati da Arduino e creare un plot con questi dati.\n\nPer prima cosa, dobbiamo creare un oggetto `TimeSeries`. Questa classe rappresenta una linea da disegnare che varia nel tempo.\n\n```typescript\nvar plotline = new TimeSeries()\n```\n\nUna volta creato questo oggetto, dobbiamo informare l\'oggetto `plotter`, creato prima, di disegnare i valori contenuti all\'interno della `plotline`.\n\n```typescript\nplotter.addTimeSeries(plotline)\n```\n\nPerfetto, ora abbiamo una linea correttamente configurata, ma ancora senza dati. Usiamo l\'oggetto `arduino` per inserire i dati a partire dai valori letti dal pin `A0`. Dato che la lettura dei dati deve essere periodica, utilizziamo nuovamente la funzione `setInterval`. Come prima, lavoreremo dentro la callback chiamata dell\'eventi `connect`.\n\n```typescript\narduino.on("connect", () => {\n  // ...\n  setInterval(() => {\n    let v = (arduino.analogRead(0) * 5.0) / 1023\n    let time = new Date().getTime()\n    plotline.append(time, v)\n  }, 30)\n})\n```\n\nCome vedete, l\'oggetto `plotline` presenta un metodo `append`, che vuole due valori: il tempo a cui è stato preso il dato `time`, ed il dato stesso `v`.\n\nIl dato `v` è ottenuto leggendo il pin `A0` di arduino, e normalizzando la lettura nell\'intervallo $[0 -- 5]V$. Il dato `time`, invece, viene ottenuto pendendo il tempo del sistema nel momento in cui è eseguita la funzione, utilizzando l\'oggetto `Date()``.\n\n```typescript\nlet v = (arduino.analogRead(0) * 5.0) / 1023\nlet time = new Date().getTime()\nplotline.append(time, v)\n```\n\nQueste tre operazioni vengono eseguite ogni 30ms, il tempo di refresh del plotter.\n\nIl codice completo è riportato qui sotto\n\n```typescript\nlet ArduinoFirmata = require("arduino-firmata")\nimport { SmoothieChart, TimeSeries } from "smoothie"\n\nlet plotter = new SmoothieChart({ responsive: true })\nlet canvasPlot = document.getElementById("plotA0")\nplotter.streamTo(canvasPlot, 30)\n\nvar plotline = new TimeSeries()\n\nplotter.addTimeSeries(plotline)\n\nlet arduino_port = "/dev/cu.usbmodem1461"\nlet arduino = new ArduinoFirmata()\narduino.connect(arduino_port)\narduino.on("connect", () => {\n  console.log("board version" + arduino.boardVersion)\n\n  arduino.pinMode(13, ArduinoFirmata.OUTPUT)\n\n  let status = true\n  setInterval(() => {\n    status = !status\n    arduino.digitalWrite(13, status)\n    if (status == true) console.log("stato led: acceso")\n    else console.log("stato led: spento")\n  }, 1000)\n\n  setInterval(() => {\n    let v = (arduino.analogRead(0) * 5.0) / 1023\n    let time = new Date().getTime()\n    plotline.append(time, v)\n  }, 30)\n})\n```\n\nLanciamo l\'applicazione, e vedremo finalmente il grafico apparire all\'interno dell\'aria dedicata.\nSe non collegate niente al pin `A0`, noterete un segnale molto casuale, come quello mostrato qui sotto\n\n![Circuito Random](./appv2.png)\n\nHo anche provato a realizzare un semplicissimo circuito RC, la cui uscita è stata collegata al pin `A0`. Il tutto sembra funzionare come previsto!\nSi noti che ho sfruttato il Pin 13 (che continua a blinkare), per controllare la carica e scarica del condensatore nel circuito.\n\n![Circuito RC plot](./appv2RC.png)\n\n![Circuito RC](./circuito.png)\n\n### Miglioriamo la grafica\n\nApp funzionante, cerchiamo ora di renderla un po\' più carina.\n\nPrima di tutto, scegliamo un titolo decente: `Arduinoscope`. Settiamo questo\ntitolo sia come titolo dell\'applicazione, che come testo all\'interno del tag `h1` principale.\nEntrambi sono definiti nel file ``src/index.html`, che diventerà così dopo le modifiche:\n\n```html\n<html>\n  <head>\n    <title>Arduinoscope</title>\n    <link rel="stylesheet" href="./index.scss" />\n  </head>\n  <body>\n    <h1 id="title_id">Arduinoscope</h1>\n\n    <div class="container">\n      <div class="row">\n        <div class="col-xs-4 col-xs-offset-4">\n          <img\n            class="img-responsive "\n            src="./imgs/arduino_white.png"\n            alt="Arduino Logo"\n          />\n        </div>\n\n        <div class="col-md-12">\n          <canvas id="plotA0" style="width:100%; height: 300px"></canvas>\n        </div>\n      </div>\n    </div>\n  </body>\n  <script>\n    require("./index.ts")\n  </script>\n</html>\n```\n\nAllontaniamo un po\' il grafico dal logo di Arduino, settando il `padding-top` del grafico nel file `index.scss`,\nche diventerà così\n\n```scss\n@import url("../node_modules/bootstrap/dist/css/bootstrap.min.css");\n\n$arduino-color: #00979d;\n\nbody {\n  background-color: $arduino-color;\n  color: white;\n\n  #title_id {\n    text-align: center;\n    padding: 30px;\n    font-weight: bold;\n  }\n\n  #plotA0 {\n    padding-top: 20px;\n  }\n}\n```\n\nPer finire, settiamo alcune configurazione agli oggetti `plotter` e `plotline` nel file `index.html`.\n\nPer prima cosa, fissiamo l\'asse verticale del grafico a valori fissi: in particolare fisserò il valore inferiore a $-0.1$ e quello superiore a $5.1$. Questo si fa\npassando i valiri `minValue` e `maxValue` al costruttore `SmoothieChart`.\n\n```typescript\nlet plotter = new SmoothieChart({\n  responsive: true,\n  minValue: -0.1,\n  maxValue: 5.1,\n})\n```\n\nPer finire, diamo uno stile migliore alla linea `plotline`, settandone un colore e uno spessore.\nQuesto viene fatto passando i parametri di configurazione `strokeStyle` e `lineWidth` al metodo `addTimeSeries`\n\n```\nplotter.addTimeSeries(plotline, {\n  strokeStyle: \'rgba(0, 124, 0, 1)\',\n  lineWidth: 4\n});\n```\n\nIl file `src/index.ts` diventerà quindi così\n\n```typescript\nlet ArduinoFirmata = require("arduino-firmata")\nimport { SmoothieChart, TimeSeries } from "smoothie"\n\nlet plotter = new SmoothieChart({\n  responsive: true,\n  minValue: -0.1,\n  maxValue: 5.1,\n})\n\nlet canvasPlot = document.getElementById("plotA0")\nplotter.streamTo(canvasPlot, 30)\n\nvar plotline = new TimeSeries()\n\nplotter.addTimeSeries(plotline, {\n  strokeStyle: "rgba(0, 124, 0, 1)",\n  lineWidth: 4,\n})\n\nlet arduino_port = "/dev/cu.usbmodem1461"\nlet arduino = new ArduinoFirmata()\narduino.connect(arduino_port)\narduino.on("connect", () => {\n  console.log("board version" + arduino.boardVersion)\n\n  arduino.pinMode(13, ArduinoFirmata.OUTPUT)\n\n  let status = true\n  setInterval(() => {\n    status = !status\n    arduino.digitalWrite(13, status)\n    if (status == true) console.log("stato led: acceso")\n    else console.log("stato led: spento")\n  }, 1000)\n\n  setInterval(() => {\n    let v = (arduino.analogRead(0) * 5.0) / 1023\n    let time = new Date().getTime()\n    plotline.append(time, v)\n  }, 30)\n})\n```\n\nE questo è il risultato finale dell\'applicazione\n\n![Arduinoscope](./arduinoscope.png)\n\n## Conclusioni\n\nSiamo giunti alla fine di questo lungo tutorial. Trovate la versione qui realizzata dell\'applicazione a [questo link](https://github.com/ludusrusso/electron-arduino/tree/07c897b1a462baf6e6f22260db730cc9678f7bc3).\nChe dire, mi sto divertendo tantissimo ad usare TypeScript ed Electron, e penso che, con poco effort, si riescano a fare grandi cose.\nSicuramente approfondirò ancora queste tecnologie!\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-06-28-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-2/index.md",
    frontMatter: {
      path: "/2017/06/28/sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-2/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "12 mins",
      published: "2017-06-28T00:00:00.000Z",
      publishedReadable: "28 Giu 2017",
      featured: false,
      tags: ["Arduino", "Electron", "Typescript", "Oscilloscopio"],
      title:
        "Sviluppiamo un'app in Electron per controllare la scheda Arduino - parte 2",
      description:
        "In questo tutorial, vediamo come sviluppare un oscilloscopio con Node.js, Electron e Typescript",
      href: "/2017/06/28/sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-2/",
      image:
        "/content/blog/it/2017-06-28-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-2/arduinoscope.png",
      imagePath:
        "/content/blog/it/2017-06-28-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-2",
    },
  },
  {
    content:
      '\nIn un mio [precedente post](http://www.ludusrusso.cc/posts/2017-06-04-primi-test-con-typescript-ed-electron) vi ho parlato di come creare una semplicissima applicazione sfruttando Electron e il nuovo linguaggio di programmazione TypeScript. In questo periodo, ho approfondito un po\' queste tecnologie, ed oggi vi propongo qui un tutorial completo su come sviluppare un\'applicazione in Electron per il controllo di una scheda Arduino connessa via USB al computer su cui gira l\'applicazione.\n\n![app grafica def](./gui_def.png)\n\nIl tutorial sarà diviso in due parti:\n\n- Nella prima parte (questa), imposteremo ed entreremo nel dettaglio dell\'utilizzo di Electron. Questa parte può quindi essere considerata una versione riveduta e corretta del mio [precedente post](http://www.ludusrusso.cc/posts/2017-06-04-primi-test-con-typescript-ed-electron).\n- [Nella seconda parte](http://www.ludusrusso.cc/posts/2017-06-28-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-2), ci interfacceremo ad Arduino da TypeScript, e svilupperemo una semplice (ma efficace ed estendibile) interfaccia di controllo per Arduino.\n\nQuesto tutorial si basa sul protocollo **Firmata** e sulla libreria **arduino-firmata** in Node.js. Vedremo nel dettaglio in seguito di cosa parliamo.\n\nIn questo tutorial, useremo anche l\'interessantissimo progetto [electron-compile](https://github.com/electron/electron-compile), che essenzialmente permette direttamente di utilizzare codice **TypeScritp** (ed altri linguaggi ad alto livello per web) senza doverlo prima compilare.\n\n## Creazione del progetto e installazione delle librerie\n\nVediamo come inizializzare il progetto ed installare le librerie necessarie.\n\n### Inizializzazione del progetto Node\n\nDopo aver scaricato **node.js**, come illustrato nel mio [precedente post](http://www.ludusrusso.cc/posts/2017-06-04-primi-test-con-typescript-ed-electron), creiamo un nuovo progetto chiamato `electron-arduino`:\n\n```bash\n$ mkdir electron-arduino\n$ cd electron-arduino\n$ npm init\n```\n\nDopo aver eseguito il comando `npm init`, rispondiamo alle domande per creare il progetto node.\n\n### Installazione delle dipendenze\n\nPossiamo quindi iniziare ad installare le dipendenze di cui abbiamo bisogno. Installiamo `electron-prebuilt-compile` con il comando\n\n```bash\n$ npm install --save-dev electron-prebuilt-compile\n```\n\n`electron-prebuilt-compile` è una versione precompilata di electron-compile, che ci permette di utilizzarlo esattamente come se fosse electron.\n\nAndiamo anche ad installare `typescript` in quanto useremo questo linguaggio, invece che javascript, per lo sviluppo dell\'applicazione\n\n```bash\n$ npm install --save-dev  typescript\n```\n\n## Iniziamo ad implementare l\'applicazione\n\nSiamo quindi pronti per iniziare a scrivere codice. Al momento svilupperemo lo scheletro dell\'app, che si compone di due file principali:\n\n- Il file `app.ts` conterrà il codice per creare e lanciare l\'applicazione electron.\n- Il file `index.html` conterrà un template html per gestire l\'aspetto dell\'applicazione.\n- Il file `index.ts`, che conterrà il codice TypeScript che verrà eseguito una volta renderizzata la finestra.\n\nCreiamo quindi una cartella `src` in cui inserire tutti i sorgenti dell\'app, e creiamo questi due file al suo interno:\n\n```bash\n$ mkdir src && cd src\n$ touch app.ts  index.html index.ts\n```\n\n### Il file `app.ts`\n\nAd essere onesti, il file `app.ts` deve fare veramente poche operazioni: in particolare, deve creare una finestra grafica (di dimensioni specificate da noi) e renderizzare al suo interno il file `index.html`.\n\nVediamo quindi come implementare questo semplice codice. Apriamo questo file con un qualsiasi editor di test e iniziamo a scrivere.\n\nPer prima cosa, importiamo gli oggetti `app` e `BrowserWindow` da `electron`:\n\n```typescript\nimport { app, BrowserWindow } from "electron"\n```\n\n`app` reppresenta l\'istanza dell\'applicazione che stiamo creando, mentre `BrowserWindow` è una classe necessaria per la creazione di finestre grafiche.\n\nA questo punto, è necessario aspettare che l\'applicazione venga correttamente caricata prima di fare qualsiasi operazione. Per farlo, possiamo usare la funzione `app.on`, che crea una callback in base ad alcuni eventi del ciclo vita dell\'applicazione. A noi, in particolare, interessa l\'evento `ready`, che viene eseguito quando l\'app è stata correttamente caricata:\n\n```typescript\napp.on("ready", () => {\n  // codice da implementare\n})\n```\n\nCome vedete, il secondo argomento della funzione è un\'altra funzione (callback), che verrà eseguita solo quando l\'app sarà pronta.\n\nAll\'interno della callback, creiamo la nostra finestra, usando l\'oggetto `BrowserWindow`, dandogli una dimensione di 600x800:\n\n```typescript\napp.on("ready", () => {\n  let mainWindow = new BrowserWindow({ width: 800, height: 600 })\n  // codice da implementare\n})\n```\n\nPer finire, carichiamo all\'interno della finestra il file `index.html`:\n\n```typescript\napp.on("ready", () => {\n  let mainWindow = new BrowserWindow({ width: 800, height: 600 })\n  mainWindow.loadURL("file://" + __dirname + "/index.html")\n})\n```\n\nSi noti l\'utilizzo della variabile `__dirname`, che contiene al suo interno il path globale della cartella all\'interno della quale ci troviamo.\n\nEcco il codice completo sviluppato:\n\n```typescript\nimport { app, BrowserWindow } from "electron"\n\napp.on("ready", () => {\n  let mainWindow = new BrowserWindow({ width: 800, height: 600 })\n  mainWindow.loadURL("file://" + __dirname + "/index.html")\n})\n```\n\n### Il file `index.html`\n\nMentre il file `app.ts` rimarrà invariato da qui alla fine del tutorial, il file `index.html` sarà un po\' più complicato e ci lavoreremo molto.\nPer il momento, per arrivare il prima possibile a far girare l\'applicazione, sviluppiamo un file più semplice possibile :D\n\nApriamo il file `index.html` e scriviamo questo codice:\n\n```html\n<html>\n  <head>\n    <title>Arduino Electron</title>\n  </head>\n  <body>\n    <h1>Funziona</h1>\n  </body>\n</html>\n```\n\nIn questo file, abbiamo implementato il titolo (_Arduino Electron_) e stampiamo nella finestra, con tag `h1` la stringa _Funziona_.\n\n### Testiamo l\'applicazione\n\nSiamo quasi pronti per far partire l\'applicazione, un ultimo sforzo è necessario per configurare il file `package.json` per dire ad `npm` cosa fare per avviare l\'app.\n\nApriamo il file `package.json`, e modifichiamo il campo `main`, in modo da settarlo a `src/app.ts`. In questo modo diremo all\'applicazione che lo script principale è questo file.\n\nInoltre, all\'interno del campo `scripts`, settiamo `start` ad `electron .`. In questo modo, informiamo npm, eseguendo il comando `npm start`, dovremmo lanciare electron!\n\nPossiamo anche rimuovere lo script `test`. Il file dovrebbe apparire come segue:\n\n```json\n{\n  ...\n  "main": "src/app.ts",\n  "scripts": {\n    "start": "electron ."\n  },\n  ...\n}\n```\n\nUna volta salvato il file, lanciamo il comando `npm start` per avviare l\'applicazione. Se tutto va come deve, si aprirà la finestra che vedete in figura. Si noti il titolo e il suo contenuto!\n\n![Electron app base](./first.png)\n\n### Il file `index.ts`\n\nA differenza del file `app.ts`, che serve semplicemente per far partire l\'applicazione, il file `index.ts` conterrà l\'_intelligenza_ dell\'applicazione stessa, cioè il codice che ne decide il comportamento. Questo file è separato dal primo in quanto è associato alla finestra della nostra app, e quindi al file `index.html` (non è un caso che entrambi i file abbiano lo stesso nome).\n\nIn gergo, il file `main.ts` viene chiamato **main process**, mentre il file `index.ts` è detto **render process**.\n\nIl fatto di avere due file può sembrare confusionario, ma questa scelta si comprende meglio se immaginiamo un\'applicazione con più finestre. In questo caso, avremmo sempre un unico **main process**, ma tanti **render process** quante sono le finistre!\n\nCapito (spero) questo concetto di Electron, iniziamo ad implementare un semplice file `index.ts` che cambia il contenuto del tag `h1`, per vedere se tutto fuonziona correttamente. Apriamo il file `index.ts` e sviluppiamo il seguente codice:\n\n```typescript\nlet title_h1 = document.getElementById("title_id")\ntitle_h1.innerHTML = "Sono il processo di render"\n```\n\nLa prima riga, serve per selezionare dal documento html (il file `index.html`) l\'elemento avente **id** pari a _title_id_.\nLa seconda riga, cambia il contenuto di tale elemento con la stringa _Sono il processo di render_.\n\nCome è possibile immaginare, prima di testare l\'applicazione, dobbiamo modificare il file `index.html`. Le modifiche sono due:\n\n- Aggiungere l\'id _title_id_ all\'elemento `h1`, modificando la riga corrispondente come segue: `<h1 id="title_id">Funziona</h1>`;\n- Importare lo script `index.ts` alla fine del file, aggiungendo le seguenti linee prima della chiusura del tag `html`:\n\n```html\n<script>\n  require("./index.ts")\n</script>\n```\n\nIl file `index.html` dovrà quindi avere la seguente forma:\n\n```html\n<html>\n  <head>\n    <title>Arduino Electron</title>\n  </head>\n  <body>\n    <h1 id="title_id">Funziona</h1>\n  </body>\n  <script>\n    require("./index.ts")\n  </script>\n</html>\n```\n\nSalviamo i file, rilanciamo il programma digitando `npm start`, e dovrebbe apparire la finestra nell\'immagine seguente:\n\n![Render process funzionante](./render.png)\n\nSi noti come il processo di render modifica l\'html della nostra applicazione.\n\nL\'applicazione sviluppata fino a questo punto è disponibile a [questo link](https://github.com/ludusrusso/electron-arduino/tree/55c979ed57b39dcbaf9efd3d8a2ebbfbdbdccf5d).\n\n## L\'aspetto conta\n\nLa nostra applicazione è funzionante ma poco interessante da un punto di vista grafico. Vediamo come migliorarla.\n\nPer prima cosa, installiamo `boostrap` nella nostra applicazione, in modo da poter utilizzare i pacchetti css definiti da questo progetto.\n\n```sh\n$ npm install --save bootstrap\n```\n\n[Bootstrap](http://getbootstrap.com/) è un popolarissimo framework per la cura grafica di applicazioni web.\n\nPer definire l\'aspetto dell\'applicazione, inoltre, useremo `scss` (e non direttamente `css`) per definire lo stile. Come per `TypeScript`, electron-compile è in grado di usare direttamente file `.scss`, senza una fase di compilazione per generare `css`.\n\n### file `index.scss`\n\nCreiamo quindi un file `src/index.scss` e apriamolo per editarlo.\n\nPer prima cosa, importiamo i sorgenti css di bootstrap:\n\n```scss\n@import url("../node_modules/bootstrap/dist/css/bootstrap.min.css");\n```\n\nSettiamo quindi il colore di backgroud dello sfondo al colore di Arduino (codice `#00979d`) e il colore del testo bianco. Per farlo, definiamo una variabile contenente il codice colori richiesto\n\n```scss\n$arduino-color: #00979d;\n```\n\ne quindi settiamo le proprietà del tag `body`\n\n```scss\nbody {\n  background-color: $arduino-color;\n  color: white;\n}\n```\n\nandiamo anche a settare la proprietà del titolo `h1` in modo che il testo sia centrato. Aumentiamo anche il padding e settiamo il font in modo che sia in grassetto (bold). Per farlo, selezioniamo l\'elemento tramite il suo tag `#title_id`\n\n```scss\nbody {\n  // ...\n  #title_id {\n    text-align: center;\n    padding: 30px;\n    font-weight: bold;\n  }\n}\n```\n\nIl file completo avrà quindi questa forma:\n\n```scss\n@import url("../node_modules/bootstrap/dist/css/bootstrap.min.css");\n\n$arduino-color: #00979d;\n\nbody {\n  background-color: $arduino-color;\n  color: white;\n\n  #title_id {\n    text-align: center;\n    padding: 30px;\n    font-weight: bold;\n  }\n}\n```\n\n### modifichiamo il file `index.html`\n\nPer finire, modifichiamo il file `index.html` in modo che usi il file appena implementato.\n\nAggiungiamo, per prima cosa, il link file `index.scss` appena creato, all\'interno del tag `head`:\n\n```html\n<head>\n  <title>Arduino Electron</title>\n  <link rel="stylesheet" href="./index.scss" />\n</head>\n```\n\nLanciamo l\'applicazione, il risultato sarà questo:\n\n![Prima app con grafica](./app_color.png)\n\nA questo punto, aggiungiamo un\'immagine (figa) per completare l\'aspetto della nostra applicazione. Per l\'occasione, userò il logo di Arduino (che trovate [qui](https://raw.githubusercontent.com/ludusrusso/electron-arduino/master/img/arduino_white.png)).\n\nCreiamo una cartella `src/imgs/` e copiamo al suo interno il logo.\n\nA questo punto, aggiorniamo il file `index.html` aggiungendo il codice che seguente sotto subito dopo il tag `h1`\n\n```html\n<body>\n  <h1 id="title_id">Funziona</h1>\n\n  <div class="container">\n    <div class="row">\n      <div class="col-xs-4 col-xs-offset-4">\n        <img\n          class="img-responsive "\n          src="./imgs/arduino_white.png"\n          alt="Arduino Logo"\n        />\n      </div>\n    </div>\n  </div>\n</body>\n```\n\nIn questo modo, abbiamo creato un container bootstrap. All\'interno del container troviamo una `row`, con all\'interno una colonna con offset: in questo modo, l\'immagine non sarà a tutto schermo. Per finire, all\'interno della colonna, abbiamo renderizzato l\'immagine come classe `img-responsive`, in modo che si adatti automaticamente alle dimensioni della colonna.\n\nLanciamo il programma ed otterremo questo risultato:\n\n![app grafica def](./gui_def.png)\n\nL\'app, sviluppata fino a questo punto, è disponibile [qui](https://github.com/ludusrusso/electron-arduino/tree/5fc13acf71c0c7b9744ca9e7660f5d91cdcb59ab).\n## Fine prima parte\n\nCome vedete, in questa prima parte abbiamo tirato su, usando Electron e Typescript, una prima applicazione! Nella prossima parte della guida, vedremo come interfacciare Arduino all\'app per leggere i dati.\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-06-26-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-1/index.md",
    frontMatter: {
      path: "/2017/06/26/sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-1/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "8 mins",
      published: "2017-06-26T00:00:00.000Z",
      publishedReadable: "26 Giu 2017",
      featured: false,
      tags: ["Typescript", "Electron", "Arduino"],
      title:
        "Sviluppiamo un'app in Electron per controllare la scheda Arduino - parte 1",
      description: "",
      href: "/2017/06/26/sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-1/",
      image:
        "/content/blog/it/2017-06-26-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-1/gui_def.png",
      imagePath:
        "/content/blog/it/2017-06-26-sviluppiamo-un-app-in-electron-per-controllare-la-scheda-arduino-parte-1",
    },
  },
  {
    content:
      "\r\n![enter image description here](./7GYgCAW.png)\r\nIn questo tutorial vedremo come creare una WebApp in grado di gestire il robot attraverso dei bottoni che fungono da frecce sulla pagina web. In particolare vedremo:\r\n\r\n- come sviluppare una WebApp in grado di controllare il robot\r\n  attraverso le frecce (UP,DOWN,LEFT,RIGHT)\r\n- come gestire la velocità del robot attraverso uno slider\r\n- come sviluppare lo sketch in ROS per sottoscriversi al topic della  \r\n  WebApp\r\n\r\n## La webapp\r\n\r\nCome prima cosa andiamo a sviluppare l'applicazione web che ci permetterà di controllare il robot tramite le frecce. Il codice Html lo potete trovare [qui](https://github.com/ganduras/webapp1/blob/master/index.html).\r\n\r\n**Analizziamo il codice:**\r\nAll'interno del file abbiamo la prima parte scritta in JavaScript che permette alla Webapp di comunicare con la piattaforma (riga 42).\r\n\r\n```html\r\n<script type=\"text/javascript\">\r\n  start_ros(\r\n    \"192.168.0.108\",\r\n    \"cyberbot\",\r\n    \"192.168.0.108\",\r\n    \"192.168.0.108/bridge/\"\r\n  )\r\n</script>\r\n```\r\n\r\nIMPORTANTE: ricordate di modificare i campi '_192.168.0.108_' e '_cyberbot_' inserendo l'IP e il nome del bot.\r\n\r\nLa seconda parte di questo file JavaScript si occupa di gestire la velocità (riga 47).\r\n\r\n```html\r\n<script>\r\n  $(document).ready(function () {\r\n    function update() {\r\n      var cmdJoy = new ROSLIB.Topic({\r\n        ros: ros,\r\n        name: \"/\" + robot.name + \"/velocita\",\r\n        messageType: \"std_msgs/Float32\",\r\n      })\r\n\r\n      var tasks_time = $(\"#tasks_time\").slider(\"value\")\r\n\r\n      var joy = new ROSLIB.Message({\r\n        data: tasks_time,\r\n      })\r\n      cmdJoy.publish(joy)\r\n    }\r\n\r\n    $(\"#tasks_time\").slider({\r\n      range: \"max\",\r\n      step: 0.1,\r\n      min: 0,\r\n      max: 1,\r\n      stop: function () {\r\n        update()\r\n      },\r\n    })\r\n  })\r\n</script>\r\n```\r\n\r\nLa funzione _update()_ è un nodo publisher che si sottoscrive al topic _/velocita_ ed invia i dati ogni volta che lo slider viene trascinato.\r\nLa velocità deve essere espressa nel range tra 0 e 1 quindi utilizziamo il formato _std_msgs/Float32_\r\n\r\nLa terza funzione è _myFunction_ (riga 209) , questa funzione viene chiamata ogni volta che l'utente fa click su uno dei pulsanti. Come parametro la funzione riceve la posizione di tipo String.\r\nOgni volta che la funzione viene chiamata , il nodo si sottoscrive al topic _/comando_ ed invia la direzione.\r\nA questo punto la parte relativa alla WebApp è completa e possiamo iniziare a scrivere lo sketch in Python su ROS.\r\n\r\n## Sketch ROS\r\n\r\nIl primo passo è quello di importare le librerie:\r\n\r\n```python\r\n    import dotbot_ros\r\n    from sys import stdout\r\n    from std_msgs.msg import String\r\n    from std_msgs.msg import Float32\r\n    from gpiozero import Robot\r\n```\r\n\r\nLa prima libreria è ovviamente quella di ROS, la seconda è _stdout_ che ha il compito di forzare la stampa effettiva sulla shell. Le librerie successive sono quelle che ci servono per estrarre i valori, cioè String per la direzione e Float32 per la velocità. Importiamo l'oggetto Robot dalla libreria gpiozero per gestirne il movimento del robot.\r\n\r\nCome al solito, il nostro programma è composto da un nodo ROS, la funzione principale è la funzione setup, che si occupa di inizializzare il robot e creare una callback di gestione.\r\n\r\n```python\r\n    self.speed = 0\r\n    self.posizione = 'none'\r\n    self.robot = Robot(left=(9, 10), right=(7, 8))\r\n    dotbot_ros.Subscriber('comando', String, self.direzione)\r\n    dotbot_ros.Subscriber('velocita', Float32, self.speedy)\r\n```\r\n\r\nInizializziamo le variabili speed e posizione. Dopodichè cambiamo le coppie di Pin GPIO a cui sono collegate i due motori.\r\n\r\n## Sottoscriviamoci ai Topic ROS e usiamo le Callback.\r\n\r\n     dotbot_ros.Subscriber('comando', String, self.direzione)\r\n\r\nServe per sottoscriversi al nodo _comando_, ricevere una Stringa e passare i dati alla funzione di callback self.direzione.\r\nLa stessa cosa vale per la velocità:\r\n\r\n    dotbot_ros.Subscriber('velocita', Float32, self.speedy)\r\n\r\nCi sottoscriviamo al nodo _velocita_ , riceviamo un messaggio di tipo Float32 e passiamo i dati alla funzione di callback _speedy_.\r\n\r\nLa funzione che mette insieme la direzione e la velocità è:\r\n\r\n```python\r\n    def controller(self,speed,posizione):\r\n            if self.posizione == 'avanti':\r\n                self.robot.forward(self.speed)\r\n\r\n            elif self.posizione == 'indietro':\r\n                self.robot.backward(self.speed)\r\n\r\n            elif self.posizione == 'destra':\r\n                self.robot.right(self.speed)\r\n\r\n            elif self.posizione == 'sinistra':\r\n                self.robot.left(self.speed)\r\n\r\n            elif self.posizione == 'stop':\r\n                self.robot.stop()\r\n```\r\n\r\nQuesta funzione riceve come parametro _self_ (rappresenta il nodo), _speed_ (la velocità) e _posizione_.\r\nLa funzione _controller_ viene chiamata in 2 casi:\r\n\r\n1. Quando viene eseguita la funzione di callback \"speedy\":\r\n\r\n```python\r\n    def speedy(self, msg):\r\n                self.speed = msg.data\r\n                self.controller(self.speed,self.posizione)\r\n```\r\n\r\n2. Quando viene eseguita la funzione di callback \"direzione\":\r\n\r\n```python\r\n    def direzione(self, msg):\r\n            self.posizione = msg.data\r\n            self.controller(self.speed,self.posizione)\r\n```\r\n\r\nN.B: Queste due funzioni non possono funzionare indipendentemente. Perchè il robot non può muoversi senza la velocità e senza direzione.\r\n\r\n## Codice completo\r\n\r\nEcco il codice completo del nostro programma\r\n\r\n```python\r\n    import dotbot_ros\r\n    from sys import stdout\r\n    from std_msgs.msg import String\r\n    from std_msgs.msg import Float32\r\n    from gpiozero import Robot\r\n\r\n\r\n    class Node(dotbot_ros.DotbotNode):\r\n        node_name = 'webapp'\r\n\r\n\r\n        def setup(self):\r\n            self.speed = 0\r\n            self.posizione = 'none'\r\n            self.robot = Robot(left=(9, 10), right=(7, 8))\r\n            dotbot_ros.Subscriber('comando', String, self.direzione)\r\n            dotbot_ros.Subscriber('velocita', Float32, self.speedy)\r\n\r\n        def controller(self,speed,posizione):\r\n            if self.posizione == 'avanti':\r\n                self.robot.forward(self.speed)\r\n\r\n            elif self.posizione == 'indietro':\r\n                self.robot.backward(self.speed)\r\n\r\n            elif self.posizione == 'destra':\r\n                self.robot.right(self.speed)\r\n\r\n            elif self.posizione == 'sinistra':\r\n                self.robot.left(self.speed)\r\n\r\n            elif self.posizione == 'stop':\r\n                self.robot.stop()\r\n\r\n        def speedy(self, msg):\r\n            self.speed = msg.data\r\n            self.controller(self.speed,self.posizione)\r\n\r\n        def direzione(self, msg):\r\n            self.posizione = msg.data\r\n            self.controller(self.speed,self.posizione)\r\n```\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-06-23-webapp-per-il-controllo-del-robot-via-frecce-su-webapp/index.md",
    frontMatter: {
      path: "/hbr/webapp-per-il-controllo-del-robot-via-frecce-su-webapp/",
      author: {
        id: "ruslan",
        name: "Ruslan",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ruslan.jpg",
      },
      readTime: "4 mins",
      published: "2017-06-23T14:31:31.000Z",
      publishedReadable: "23 Giu 2017",
      featured: false,
      tags: [],
      title: "Webapp per il controllo del robot via frecce su WebApp",
      description: "",
      href: "/hbr/webapp-per-il-controllo-del-robot-via-frecce-su-webapp/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-06-23-webapp-per-il-controllo-del-robot-via-frecce-su-webapp",
    },
  },
  {
    content:
      "\r\nIn questo tutorial vedremo come collegare un braccio a 3 gradi di libertà costruito con la piattaforma Lego NXT al cloud utilizzando il Raspberry pi3 e l'interfaccia Hbrain. Successivamente vedremo come scrivere una webapp che ci permetta di sfruttare le potenzialità del cloud per controllarlo.\r\n\r\n![](./27220202-9fdf2db6-5284-11e7-9fd3-85c078f423ce.jpg)\r\n\r\n## Collegamenti\r\n\r\nCome prima cosa prendete la scheda Raspberry e accendetela collegandola alla corrente. Collegatela al sito di Hotback (come imparato dal manuale). Prendete il lego NXT, accendetelo e collegate il suo cavo usb ad un ingresso qualunque della scheda Raspberry. Avete così collegato il lego NXT al cloud!\r\n\r\n## La webapp\r\n\r\nOra che abbiamo connesso l'NXT al cloud procediamo a creare una webapp che ci permetterà di controllarlo attraverso la tastiera del nostro computer. Come prima cosa scaricate, premendo sul pulsante **clone or download** i file che potete trovare [qui](https://github.com/cynicalzero4/raspnxt).\r\n\r\n![](./27223586-5bc4c21e-5291-11e7-8767-43ec9775e773.png)\r\n\r\nOra è necessario far sì che la nostra webapp sia in grado di dialogare con il nostro robot. Aprite il file html **keyboard_robotarm** con il blocco note e cercate la stringa `start_ros('192.168.0.112', 'silverbot', '192.168.0.112', '192.168.0.112/bridge/');`\r\n\r\n![](./26968358-0a5e8afc-4d02-11e7-983e-038aeaf409b3.png)\r\n\r\nDovete ora sostituire questa stringa con quella che identifica il vostro robot. Per trovarla dirigetevi sul sito di Hotblack al quale avete prima connesso la vostra scheda Raspberry, aprite una qualunque webapp e aprite la sorgente della pagina premendo il tasto destro del mouse\r\n\r\n![](./26968706-438104f8-4d03-11e7-97f7-96e6deb0a765.png)\r\n\r\nAll'interno del codice sorgente cercate la stringa `start_ros('#...');`, copiatela al posto di quella presente nel file html (aperto con il blocco note) **keyboard_robotarm** e salvate il tutto.\r\n\r\nPossiamo ora testare la nostra app: aprite il file **keyboard_robotarm** nel browser e aprite la console cliccando col tasto destro del mouse e selezionando ispeziona. Refreshate la pagina (F5) e ogni volta che premete uno dei pulsanti **wa, sd, ik** la console dovrebbe restituirvi, stampandola a video, l'azione connessa al pulsante premuto.\r\n\r\n![](./27224569-1c161e74-5296-11e7-824c-125534439931.png)\r\n\r\n## Sketch ROS\r\n\r\nScriviamo ora lo sketch in ROS che farà comunicare il nostro robot con la webapp. Importiamo subito le librerie che utilizzeremo nel programma:\r\n\r\n```python\r\nimport dotbot_ros\r\nimport sys\r\nimport nxt\r\nfrom nxt.motor import *\r\nfrom geometry_msgs.msg import Twist\r\nfrom time import sleep\r\n```\r\n\r\nOra nel `setup` andiamo a includere la stringa `self.NXT = nxt.locator.find_one_brick()` per far sì che il programma cerchi il lego NXT attraverso la connessione usb e inizializziamolo:\r\n\r\n```python\r\nprint 'starting'   #stampa starting al lancio del programma\r\nsys.stdout.flush() #forza la stampa sulla shell ROS\r\n\r\nself.NXT = nxt.locator.find_one_brick()\r\nself.m1 = Motor(self.NXT, PORT_A) #motore della porta A\r\nself.m2 = Motor(self.NXT, PORT_B) #motore dell porta B\r\nself.m3 = Motor(self.NXT, PORT_C) #motore della porta C\r\nself.cnt = -1\r\n```\r\n\r\nSempre nel **setup** creiamo un **subscriber** che sottoscriva il programma al messaggio della webapp da noi creata. Il nostro subscriber si sottoscriverà ad un topic chiamato`/keyboard` che scambia messaggi di tipo `std_msgs/Twist` inserendoli in una funzione callback chiamata `xyz` definita dai parmetri `self` e `msg` :\r\n\r\n```python\r\ndef setup(self):\r\n\r\n     #...\r\n     dotbot_ros.Subscriber(\"/keyboard\", Twist, self.xyz)\r\n\r\ndef xyz(self, msg):\r\n\r\n```\r\n\r\nProcediamo ora a sfruttare i messaggi che giungono dalla nostra webapp nella nostra funzione `xyz` per definire i movimenti che eseguirà il nostro braccio. Il messaggio di tipo `Twist` spedisce, nel nostro caso, 3 messaggi diversi:\r\n\r\n- **msg.linear.x** che useremo per muovere il primo giunto\r\n\r\n- **msg.linear.y** che useremo per muovere il secondo giunto\r\n\r\n- **msg.linear.z** che useremo per muovere il terzo giunto\r\n\r\nPer far sì che il nostro braccio si muova sfrutteremo l'attributo **turn** della classe **Motor** definito da 5 parametri:\r\n\r\n- **power**: la forza, nel range **-127 /+128**, con cui si attivano i motori. Valori inferiori a 64 sono altamente sconsigliati\r\n\r\n- **tacho_units**: il numero di gradi di cui si muoverà il motore. Il valore minimo che i motori sono in grado di leggere, già con difficoltà, è **5**\r\n\r\n- **brake**: definisce se il motore si stoppa (**True**) dopo aver compiuto il movimento o meno (**False**)\r\n\r\n- **timeout**: numero di secondi dopo il quale viene mostrato un messaggio di errore nel caso il motore non si muova\r\n\r\n- **emulate**: da definire sempre come False\r\n\r\nPer far sì che il giunto del nostro braccio si muova solamente nel caso in cui il messaggio proveniente dal topic sia diverso da 0 utilizziamo il costrutto `if-else`. in particolare il simbolo **!=** significa **diverso** e la stringa `self .m1.idle()` dice semplicemente al motore definito dalla funzione **m1** di non fare alcunchè:\r\n\r\n```python\r\ndef xyz(self, msg):\r\n\r\n    if msg.linear.x != 0:\r\n        self.m.turn(msg.linear.x*100, 5, True, 1, False)\r\n\r\n    else:\r\n        self.m1.idle()\r\n```\r\n\r\nA questo punto abbiamo creato la struttura per far muovere il primo giunto quando riceve un messaggio dal topic. Non ci resta che aggiungere il codice per fa muovere gli altri due, copiando il codice già scritto modificando semplicemente il tipo di messaggio del quale verificare la differenza da 0 e il motore da muovere:\r\n\r\n```python\r\ndef xyz(self, msg):\r\n\r\n    if msg.linear.x != 0:\r\n        self.m1.turn(msg.linear.x*100, 5, True, 1, False)\r\n\r\n    else:\r\n        self.m1.idle()\r\n\r\n\r\n    if msg.linear.y != 0:\r\n        self.m2.turn(msg.linear.x*100, 5, True, 1, False)\r\n\r\n    else:\r\n        self.m2.idle()\r\n\r\n\r\n    if msg.linear.z != 0:\r\n        self.m3.turn(msg.linear.x*100, 5, True, 1, False)\r\n\r\n    else:\r\n        self.m3.idle()\r\n```\r\n\r\n## Codice completo\r\n\r\n```python\r\nimport dotbot_ros\r\nimport sys\r\nimport nxt\r\nimport nxt.locator\r\nfrom nxt.motor import *\r\nfrom geometry_msgs.msg import Twist\r\nfrom time import sleep\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'nxt_node_keyboard'\r\n\r\n    def setup(self):\r\n        print 'starting'\r\n        sys.stdout.flush()\r\n\r\n        self.NXT = nxt.locator.find_one_brick()\r\n        self.m1 = Motor(self.NXT, PORT_A) #motore della porta A\r\n        self.m2 = Motor(self.NXT, PORT_B) #motore della porta B\r\n        self.m3 = Motor(self.NXT, PORT_C) #motore della porta C\r\n        self.cnt = -1\r\n\r\n        dotbot_ros.Subscriber(\"/keyboard\", Twist, self.xyz)\r\n\r\n    def xyz(self, msg):\r\n\r\n        if msg.linear.x != 0:\r\n            self.m1.turn(msg.linear.x*100, 5, True, 1, False)\r\n\r\n        else:\r\n            self.m1.idle()\r\n\r\n\r\n        if msg.linear.y != 0:\r\n            self.m2.turn(msg.linear.y*100, 5, True, 1, False)\r\n\r\n        else:\r\n            self.m2.idle()\r\n\r\n\r\n        if msg.linear.z != 0:\r\n            self.m3.turn(msg.linear.z*100, 5, True, 1, False)\r\n\r\n        else:\r\n            self.m3.idle()\r\n\r\n```\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-06-16-collegare-in-cloud-i-lego-nxt-ed-estenderne-le-funzionalita/index.md",
    frontMatter: {
      path: "/hbr/collegare-in-cloud-i-lego-nxt-ed-estenderne-le-funzionalita/",
      author: {
        id: "pietrochirio",
        name: "Pietro Chiro",
        bio: "Dev Passionate",
        profile: "/imgs/authors/pietrochirio.jpg",
      },
      readTime: "5 mins",
      published: "2017-06-16T13:32:57.000Z",
      publishedReadable: "16 Giu 2017",
      featured: false,
      tags: [],
      title: "Collegare in cloud i LEGO NXT ed estenderne le funzionalità",
      description: "",
      href: "/hbr/collegare-in-cloud-i-lego-nxt-ed-estenderne-le-funzionalita/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-06-16-collegare-in-cloud-i-lego-nxt-ed-estenderne-le-funzionalita",
    },
  },
  {
    content:
      '\r\nIn questo tutorial vedremo come collegare un Arduino UNO al nostro Raspberry con ROS. In questo modo potremmo sfruttare l\'alto livello del codice di programmazione di ROS in parallelo alla versatilità nel controllo di sensori/motori/periferiche di Arduino.\r\n\r\n# Nota Bene\r\n\r\nPer far funzionare questo tutorial, prima di tutto è necessario accedere al terminale, utilizzando [questa guida](http://hotblackrobotics.github.io/blog/posts/2017-05-23-accedere-al-terminale-linux-di-hbrain-da-browser), ed eseguire il seguente comando (basta fare copia incolla). Una volta fatto questo, riavviare il robot!\r\n\r\n```bash\r\ncurl https://gist.githubusercontent.com/ludusrusso/a3533daae7a03c07ce55b90019f2a0ba/raw/c20b544de544f0c13577c31a3bc0322718c884d8/arduino_patch_hbrain | bash\r\n```\r\n\r\n## Includiamo le librerie di ROS su Arduino\r\n\r\nUtilizzando il pacchetto **rosserial_arduino** si "trasforma" Arduino in un nodo ROS a tutti gli effetti, che può pubblicare o sottoscriversi a topic ROS. La comunicazione con ROS è resa possibile dalla libreria `ros_lib`, quindi basta implementarla nella cartella delle librerie di Arduino in questo modo:\r\n\r\n- scaricate [da qui](https://github.com/HotBlackRobotics/ros_lib_arduino) (premendo su **clone or download**) le librerie presenti\r\n  ![](./27024733-1708cddc-4f58-11e7-9427-c3b4e0770ae6.png)\r\n\r\n- aprite l\'Arduino IDE e andate su **sketch/include library/manage libraries**, cercate **Rosserial Arduino Library** e cliccate su **install**\r\n  ![](./27024877-b5702b28-4f58-11e7-87cb-16065a54e8d9.png)\r\n\r\nA questo punto Arduino è in grado di comunicare con ROS pubblicando o sottoscrivendosi ai topic. E\' però necessario predisporre anche il Raspberry per poter comunicare con l\'Arduino: collegate la vostra scheda al portale hotblack e digitate nella bara di ricerca di Google l\'indirizzo IP assegnatovi dal sito (nel mio caso **192.168.0.112**)\r\n\r\n![](./27025222-02c428f6-4f5a-11e7-8c25-2c40a3aa018f.png)\r\n\r\nSi aprirà in questo modo una pagina chiamata **supervisor status**. Cercate la voce **ros_serial** e cliccate su **Start**\r\n\r\n![](./27025423-b9efd336-4f5a-11e7-9b1e-0a82eb2bf6d8.png)\r\n\r\nIn questo modo sarà sufficiente collegare l\'Arduino al Raspberry attraverso una qualunque delle sue porte USB e le due schede saranno pronte a lavorare in parallelo!\r\n\r\n## Scrittura di un semplice publisher per Arduino\r\n\r\nProcediamo ora a scrivere il codice di un semplice pulisher per pubblicare una stringa testuale sulla console ROS. Apriamo quindi l\'Arduino IDE e iniziamo un nuovo progetto. Andiamo ad includere immediatamente le librerie che utilizzeremo e la stringa `ros::NodeHandle nh;` che permetterà al nostro programma di creare publisher e subscriber:\r\n\r\n```c++\r\n#include <ros.h>\r\n#include <std_msgs/String.h>\r\n\r\nros::NodeHandle nh;\r\n```\r\n\r\nOra dobbiamo definire il nostro publisher/subscriber. In questo caso lavoriamo su un publisher chiamato **chatter** che pubblicherà un messaggio di tipo **&str_msg**\r\n\r\n```c++\r\nstd_msgs::String str_msg;\r\nros::Publisher chatter("chatter", &str_msg);\r\n```\r\n\r\nNel **setup** inizializziamo il nostro nodo ROS e definiamo i topic a cui vogliamo sottoscriverci utilizzando la stringa `nh.subscribe(nomedeltopic)` e quelli che vogliamo pubblicare, come nel nostro caso, con la stringa `nh.advertise(nomedeltopic)`\r\n\r\n```c++\r\nvoid setup()\r\n{\r\n  nh.initNode();\r\n  nh.advertise(chatter);\r\n}\r\n```\r\n\r\nCome ultimo passo nella funzione **loop** il nodo pubblica la stringa "Hello World" e si chiama la funzione `ros::spinOnce()` con la quale si gestiscono tutte le **callback**\r\n\r\n```c++\r\nvoid loop()\r\n  {\r\n    str_msg.data = hello;\r\n    chatter.publish( &str_msg );\r\n    nh.spinOnce();\r\n    delay(1000);\r\n  }\r\n```\r\n\r\n## Codice completo\r\n\r\n```c++\r\n#include <ros.h>\r\n#include <std_msgs/String.h>\r\n\r\nros::NodeHandle  nh;\r\n\r\nstd_msgs::String str_msg;\r\nros::Publisher chatter("chatter", &str_msg);\r\n\r\nchar hello[13] = "hello world!";\r\n\r\nvoid setup()\r\n{\r\n  nh.initNode();\r\n  nh.advertise(chatter);\r\n}\r\n\r\nvoid loop()\r\n{\r\n  str_msg.data = hello;\r\n  chatter.publish( &str_msg );\r\n  nh.spinOnce();\r\n  delay(1000);\r\n}\r\n```\r\n\r\nPer avere altre informazioni e tutorial più approfonditi potete visitare la pagina dedicata a [rosserial_arduino](http://wiki.ros.org/rosserial_arduino/Tutorials) del sito Ros.org\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-06-16-collegare-un-arduino-in-parallelo-al-raspberry/index.md",
    frontMatter: {
      path: "/hbr/collegare-un-arduino-in-parallelo-al-raspberry/",
      author: {
        id: "pietrochirio",
        name: "Pietro Chiro",
        bio: "Dev Passionate",
        profile: "/imgs/authors/pietrochirio.jpg",
      },
      readTime: "3 mins",
      published: "2017-06-16T09:54:19.000Z",
      publishedReadable: "16 Giu 2017",
      featured: false,
      tags: [],
      title: "Collegare un Arduino in parallelo al raspberry",
      description: "",
      href: "/hbr/collegare-un-arduino-in-parallelo-al-raspberry/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-06-16-collegare-un-arduino-in-parallelo-al-raspberry",
    },
  },
  {
    content:
      '\r\n**In questo tutorial vedremo come implementare l\'intelligenza artificiale sul proprio dotbot.**\r\nNavigando su internet ho trovato un servizio che mette insieme diverse API tra cui wikipedia, wolframalpha e google assistant. Si tratta del sito [https://willbeddow.com](https://willbeddow.com/) il quale unisce tutti questi servizi, e ne crea uno completamente gratuito ed ovviamente senza limiti di richieste.\r\nCome primo passo dobbiamo registrarci [qui](https://willbeddow.com/signup)\r\n![enter image description here](./SLdu1tn.jpg)\r\n\r\nUna volta registrati possiamo iniziare a scrivere il codice:\r\n\r\n    import dotbot_ros\r\n    import requests\r\n    import json\r\n    import sys\r\n\r\n    class Node(dotbot_ros.DotbotNode):\r\n        node_name = \'node\'\r\n\r\n        def setup(self):\r\n            server_url = "https://willbeddow.com"\r\n            payload = dict(username="USER", password="PASS")\r\n            response = requests.post(url="{0}/api/start_session".format(server_url), data=payload).json()\r\n            session_id = response["data"]["session_id"]\r\n            command_data = dict(session_id=session_id, command="What is the meaning of life?")\r\n            answer = requests.post(url="{0}/api/command".format(server_url), data=command_data).json()\r\n            print answer["text"]\r\n            sys.stdout.flush()\r\n            requests.post(url="{0}/api/end_session".format(server_url), data={"session_id": session_id})\r\n\r\n_IMPORTANTE: ricordate di modificare il campo username e password inserendoli tra i doppi apici._\r\n\r\n**Analizziamo il codice**\r\nCome al solito, il nostro programma è composto da un nodo ROS, la funzione principale è la funzione setup, che si occupa di inizializzare il bot .\r\n\r\n    server_url = "https://willbeddow.com"\r\n    payload = dict(username="USER", password="PASS")\r\n\r\nServer url è il link dove vengono inviate le richieste di tipo POST.\r\nUsername e Password sono i dati necessari per l\'autorizzazione.\r\n\r\n    response = requests.post(url="{0}/api/start_session".format(server_url), data=payload).json()\r\n    session_id = response["data"]["session_id"]\r\n\r\nInizio di una nuova sessione e creazione del session token.\r\n\r\n       command_data = dict(session_id=session_id, command="What is the meaning of life?")\r\n       answer = requests.post(url="{0}/api/command".format(server_url), data=command_data).json()\r\n\r\nChiamata del metodo POST , il quale invia la domanda e riceve la risposta in formato json.\r\n\r\n    requests.post(url="{0}/api/end_session".format(server_url), data={"session_id": session_id})\r\n\r\nFine della sessione e disabilitazione del token session.\r\n\r\nUna volta implementato il programma, lanciamo il codice!\r\n![enter image description here](./e4eQ1OT.jpg)\r\n\r\nCome vedete il bot ha risposto alla domanda "What is the meaning of life?".\r\n\r\nA questo punto, se il bot ha risposto correttamente, implementiamo la lingua italiana attraverso [Yandex.Translate.](https://tech.yandex.com/translate/)\r\n![enter image description here](./Hs5P4Ep.jpg)\r\nPer sviluppare questo progetto ho scelto di usare il traduttore di Yandex e non quello di Google.\r\n_Non c\'è nessuna differenza tra i due, per quanto riguarda la traduzione, entrambi i traduttori utilizzato lo stesso sistema di traduzione automatica._\r\n\r\nUna volta registrati , otteniamo la nostra API.\r\n![enter image description here](./IrGdSI6.jpg)\r\n\r\nDopo aver ottenuto la nostra API , installiamo la libreria **yandex_translate** sul nostro RaspBerry.\r\nPer installarla, basta andare sull\'IP del bot e successivamente fare click su Terminal.\r\n![enter image description here](./nYAIDVq.jpg)\r\n\r\nUna volta entrati , la piattaforma chiede i permessi per accedere su quella pagina.\r\n![enter image description here](./2mkNtJ8.jpg)\r\nIl nome utente è "hbrain" , e la password è "dotbot".\r\n\r\nAdesso apriamo il terminale, facendo click su **Open Terminal**\r\n![enter image description here](./YOu1Nqi.jpg)\r\n\r\nA questo punto possiamo installare la libreria necessaria.\r\n![enter image description here](./UsHMEGi.jpg)\r\nPer installarla dobbiamo usare il comando **apt-get install _"nome libreria"_** , nel nostro caso è apt-get install yandex_translate.\r\n\r\nPossiamo iniziare finalmente a programmare :)\r\n\r\nImplementiamo il traduttore nel nostro programma:\r\n\r\n    import dotbot_ros\r\n    import requests\r\n    import json\r\n    import sys\r\n    from yandex_translate import YandexTranslate\r\n\r\n    class Node(dotbot_ros.DotbotNode):\r\n        node_name = \'node\'\r\n        YATOKEN = "trnsl.1.1.20170523T140049Z.89213c48771026d1.7b307aff21507ba6c5251b57d13d7181f5658c34"\r\n\r\n        def setup(self):\r\n            translate = YandexTranslate(self.YATOKEN)\r\n            server_url = "https://willbeddow.com"\r\n            answer = "Qual e il senso della vita?"\r\n            domand = translate.translate(answer.encode(\'utf-8\'), \'it-en\')\r\n            question = domand[\'text\']\r\n            payload = dict(username="USER", password="PASS")\r\n            response = requests.post(url="{0}/api/start_session".format(server_url), data=payload).json()\r\n            session_id = response["data"]["session_id"]\r\n            command_data = dict(session_id=session_id, command=question)\r\n            answer = requests.post(url="{0}/api/command".format(server_url), data=command_data).json()\r\n            answ = answer["text"]\r\n            risp = translate.translate(answ, \'en-it\')\r\n            risposta = risp[\'text\']\r\n            text = risposta[0].encode(\'utf-8\')\r\n            print text\r\n            sys.stdout.flush()\r\n            requests.post(url="{0}/api/end_session".format(server_url), data={"session_id": session_id})\r\n\r\nCome avete visto ci sono servite solo qualche righe di codice per tradurre la domanda dall\'italiano in inglese.\r\n\r\n    YATOKEN = "IL TUO YANDEX TOKEN"\r\n\r\nNella funzione setup il token viene chiamato da:\r\n\r\n       translate = YandexTranslate(self.YATOKEN)\r\n\r\nLa variabile "domand" riceve un messaggio (tradotto dall\'italiano in inglese) in formato Json e viene transformato in una stringa.\r\n\r\n    domand = translate.translate(answer.encode(\'utf-8\'), \'it-en\')\r\n    question = domand[\'text\']\r\n\r\nLa stessa cosa è uguale per la risposta:\r\n\r\n    risp = translate.translate(answ, \'en-it\')\r\n    risposta = risp[\'text\']\r\n\r\nLa risposta viene tradotta dal inglese in italiano e viene trasformata in una stringa.\r\n\r\nUna volta eseguito il codice abbiamo in output questa finestra:\r\n![enter image description here](./P3afWcn.jpg)\r\n\r\n**Ora trasformiamo questo programma in una ChatBot (Telegram).**\r\nPer farlo basta creare un bot seguendo questa [guida](http://hotblackrobotics.github.io/blog/posts/2017-02-16-tutorial-sviluppiamo-un-bot-telegram-in-ros).\r\nA questo punto, ottenuto il Token , implementiamolo nel nostro codice.\r\n\r\n    import dotbot_ros\r\n    import telepot\r\n    import sys\r\n    from yandex_translate import YandexTranslate\r\n    import requests\r\n    import json\r\n\r\n    class Node(dotbot_ros.DotbotNode):\r\n        node_name = \'bot\'\r\n        TOKEN = "INSERISCI QUI IL TUO TOKEN TELEGRAM"\r\n        YATOKEN = "trnsl.1.1.20170523T140049Z.89213c48771026d1.7b307aff21507ba6c5251b57d13d7181f5658c34"\r\n\r\n\r\n        def setup(self):\r\n            self.bot = telepot.Bot(self.TOKEN)\r\n            self.bot.message_loop(self.handle)\r\n            self.server_url = "https://willbeddow.com"\r\n            self.payload = dict(username="USER", password="PASS")\r\n            self.translate = YandexTranslate(self.YATOKEN)\r\n\r\n\r\n        def handle(self, msg):\r\n            content_type, chat_type, chat_id = telepot.glance(msg)\r\n            nome = msg[\'from\'][\'first_name\']\r\n            domanda = msg[\'text\']\r\n            domand = self.translate.translate(domanda.encode(\'utf-8\'), \'it-en\') #traduzione da italiano in inglese\r\n            question = domand[\'text\']  #decodifico le api\r\n            response = requests.post(url="{0}/api/start_session".format(self.server_url), data=self.payload).json()  #viene creata una nuova sessione\r\n            session_id = response["data"]["session_id"] #viene creata la session id\r\n            command_data = dict(session_id=session_id, command=question)\r\n            answer = requests.post(url="{0}/api/command".format(self.server_url), data=command_data).json()\r\n            answ = answer["text"]\r\n            risp = self.translate.translate(answ, \'en-it\')\r\n            risposta = risp[\'text\']\r\n            text = risposta[0].encode(\'utf-8\') #decode da unicode in utf8\r\n            requests.post(url="{0}/api/end_session".format(self.server_url), data={"session_id": session_id}) #la sessione viene chiusa\r\n            self.bot.sendMessage(chat_id, text) #viene inviata la risposta\r\n            print msg\r\n            sys.stdout.flush()\r\n\r\n**Analizziamo il codice:**\r\n\r\n    self.bot = telepot.Bot(self.TOKEN)\r\n\r\nCrea il bot utilizzando il token inizializzato\r\n\r\n    self.bot.message_loop(self.handle)\r\n\r\nOgni volta che il bot riceve un messaggio , viene chiamata la funzione handle\r\n\r\nAlla funzione _handle_ viene passato il parametro msg.\r\n\r\n    def handle(self, msg):\r\n            content_type, chat_type, chat_id = telepot.glance(msg)\r\n            nome = msg[\'from\'][\'first_name\']\r\n            domanda = msg[\'text\']\r\n            domand = self.translate.translate(domanda.encode(\'utf-8\'), \'it-en\') #traduzione da italiano in inglese\r\n            question = domand[\'text\']  #decodifico le api\r\n            response = requests.post(url="{0}/api/start_session".format(self.server_url), data=self.payload).json()  #viene creata una nuova sessione\r\n            session_id = response["data"]["session_id"] #viene creata la session id\r\n            command_data = dict(session_id=session_id, command=question)\r\n            answer = requests.post(url="{0}/api/command".format(self.server_url), data=command_data).json()\r\n            answ = answer["text"]\r\n            risp = self.translate.translate(answ, \'en-it\')\r\n            risposta = risp[\'text\']\r\n            text = risposta[0].encode(\'utf-8\') #decode da unicode in utf8\r\n            requests.post(url="{0}/api/end_session".format(self.server_url), data={"session_id": session_id}) #la sessione viene chiusa\r\n            self.bot.sendMessage(chat_id, text) #viene inviata la risposta\r\n            print msg\r\n            sys.stdout.flush()\r\n\r\n\r\n     content_type, chat_type, chat_id = telepot.glance(msg)\r\n\r\nQuesta riga si occupa di estrarre il chat_id che si occupa di gestire più chat contemporaneamente e content_type: il tipo di dati contenuti nell\'messaggio.\r\n\r\n    nome = msg[\'from\'][\'first_name\']\r\n    domanda = msg[\'text\']\r\n\r\nEstraiamo il nome dell\'utente che sta scrivendo al bot e la sua domanda.\r\n\r\nUna volta generata la risposta , viene inviata all\'utente:\r\n\r\n    self.bot.sendMessage(chat_id, text)\r\n\r\nLanciamo il codice completo e vediamo il suo funzionamento:\r\n![enter image description here](./UiixahX.jpg)\r\n\r\nMa se volessimo farlo pure muovere da telegram?\r\nIl nuovo codice implementato è il seguete:\r\n\r\n    import dotbot_ros\r\n    import telepot\r\n    from gpiozero import Robot\r\n    import sys\r\n    from yandex_translate import YandexTranslate\r\n    import requests\r\n    import json\r\n    import time\r\n    from telepot.namedtuple import ReplyKeyboardMarkup, KeyboardButton\r\n\r\n    class Node(dotbot_ros.DotbotNode):\r\n        node_name = \'bot\'\r\n        TOKEN = "INSERISCI QUI IL TUO TOKEN TELEGRAM"\r\n        YATOKEN = "trnsl.1.1.20170523T140049Z.89213c48771026d1.7b307aff21507ba6c5251b57d13d7181f5658c34"\r\n\r\n\r\n        def setup(self):\r\n            self.bot = telepot.Bot(self.TOKEN)\r\n            self.bot.message_loop(self.handle)\r\n            self.server_url = "https://willbeddow.com"\r\n            self.payload = dict(username="USER", password="PASS")\r\n            self.translate = YandexTranslate(self.YATOKEN)\r\n            self.robot = Robot(left=(9,10), right=(7,8))\r\n\r\n        def handle(self, msg):\r\n            content_type, chat_type, chat_id = telepot.glance(msg)\r\n            nome = msg[\'from\'][\'first_name\']\r\n            domanda = msg[\'text\']\r\n            if domanda[0] == \'/\':\r\n                self.bot.sendMessage(chat_id, \'scegli una delle voci\', reply_markup=ReplyKeyboardMarkup(\r\n                            keyboard=[\r\n                                [KeyboardButton(text="/avanti"), KeyboardButton(text="/dietro")],\r\n                                [KeyboardButton(text="/destra"), KeyboardButton(text="/sinistra")],\r\n                                [KeyboardButton(text="/stop")]\r\n                            ]\r\n                        ))\r\n                if domanda == \'/start\':\r\n                    self.bot.sendMessage(chat_id, "ciao, " + nome + " benvenuto nella mia chat!")\r\n                elif domanda == \'/avanti\':\r\n                    self.bot.sendMessage(chat_id, "ok, vado avanti")\r\n                    self.robot.forward()\r\n                    time.sleep(0.25)\r\n                    self.robot.stop()\r\n                elif domanda == \'/dietro\':\r\n                    self.bot.sendMessage(chat_id, "ok, vado dietro")\r\n                    self.robot.backward()\r\n                    time.sleep(0.25)\r\n                    self.robot.stop()\r\n                elif domanda == \'/destra\':\r\n                    self.bot.sendMessage(chat_id, "ok, giro a destra")\r\n                    self.robot.right()\r\n                    time.sleep(0.2)\r\n                    self.robot.stop()\r\n                elif domanda == \'/sinistra\':\r\n                    self.bot.sendMessage(chat_id, "ok, giro a sinistra")\r\n                    self.robot.left()\r\n                    time.sleep(0.2)\r\n                    self.robot.stop()\r\n                elif domanda == \'/stop\':\r\n                    self.robot.stop()\r\n                else:\r\n                    self.bot.sendMessage(chat_id, "scusa, non capisco questo comando")\r\n\r\n            else:\r\n                domand = self.translate.translate(domanda.encode(\'utf-8\'), \'it-en\') #traduzione da italiano in inglese\r\n                question = domand[\'text\']  #decodifico le api\r\n                response = requests.post(url="{0}/api/start_session".format(self.server_url), data=self.payload).json()  #viene creata una nuova sessione\r\n                session_id = response["data"]["session_id"] #viene creata la session id\r\n                command_data = dict(session_id=session_id, command=question)\r\n                answer = requests.post(url="{0}/api/command".format(self.server_url), data=command_data).json()\r\n                answ = answer["text"]\r\n                risp = self.translate.translate(answ, \'en-it\')\r\n                risposta = risp[\'text\']\r\n                text = risposta[0].encode(\'utf-8\') #decode da unicode in utf8\r\n                requests.post(url="{0}/api/end_session".format(self.server_url), data={"session_id": session_id}) #la sessione viene chiusa\r\n                self.bot.sendMessage(chat_id, text) #viene inviata la risposta\r\n\r\n            print msg\r\n            sys.stdout.flush()\r\n\r\n**Analizziamo il codice**\r\n\r\nNella funzione setup abbiamo:\r\n\r\n    self.robot = Robot(left=(9,10), right=(7,8))\r\n\r\nQui si crea un oggetto Robot, il quale permette di gestire i motori e quindi farli muovere.\r\nIMPORTANTE: ricordate di modificare i campi "(left=(9,10), right=(7,8))" con i vostri PIN dei motori.\r\n\r\n    self.bot.sendMessage(chat_id, \'scegli una delle voci\', reply_markup=ReplyKeyboardMarkup(\r\n                            keyboard=[\r\n                                [KeyboardButton(text="/avanti"), KeyboardButton(text="/dietro")],\r\n                                [KeyboardButton(text="/destra"), KeyboardButton(text="/sinistra")],\r\n                                [KeyboardButton(text="/stop")]\r\n                            ]\r\n                        ))\r\n\r\nSi occupa di dare i suggerimenti all\'utente dei comandi disponibili.\r\n![enter image description here](./dvq4HZy.jpg)\r\n\r\n    elif domanda == \'/avanti\':\r\n                    self.bot.sendMessage(chat_id, "ok, vado avanti")\r\n                    self.robot.forward()\r\n                    time.sleep(0.25)\r\n                    self.robot.stop()\r\n                elif domanda == \'/dietro\':\r\n                    self.bot.sendMessage(chat_id, "ok, vado dietro")\r\n                    self.robot.backward()\r\n                    time.sleep(0.25)\r\n                    self.robot.stop()\r\n                elif domanda == \'/destra\':\r\n                    self.bot.sendMessage(chat_id, "ok, giro a destra")\r\n                    self.robot.right()\r\n                    time.sleep(0.2)\r\n                    self.robot.stop()\r\n                elif domanda == \'/sinistra\':\r\n                    self.bot.sendMessage(chat_id, "ok, giro a sinistra")\r\n                    self.robot.left()\r\n                    time.sleep(0.2)\r\n                    self.robot.stop()\r\n                elif domanda == \'/stop\':\r\n                    self.robot.stop()\r\n                else:\r\n                    self.bot.sendMessage(chat_id, "scusa, non capisco questo comando")\r\n\r\nQuesta parte permette di muovere il bot nelle 4 direzioni.\r\n\r\n    time.sleep(0.25)\r\n    Gestisce il tempo dell\'esecuzione del comando.\r\n\r\nSe avete la **picam** e volete fare pure le foto attraverso il Raspberry , allora implementate questo piccolo codice:\r\n\r\n    elif domanda == \'/image\':\r\n    img_str = cv2.imencode(\'.jpg\', self.img)[1].tostring()\r\n    self.bot.sendPhoto(chat_id(\'image.jpg\',StringIO.StringIO(img_str)))\r\n\r\nVediamo a questo punto il codice finale:\r\n\r\n    import dotbot_ros\r\n    import telepot\r\n    from gpiozero import Robot\r\n    import sys\r\n    import cv2\r\n    import time\r\n    from std_msgs.msg import String\r\n    from sensor_msgs.msg import Image\r\n    from cv_bridge import CvBridge, CvBridgeError\r\n    import StringIO\r\n    from mtranslate import translate\r\n    from yandex_translate import YandexTranslate\r\n    import requests\r\n    import json\r\n    from telepot.namedtuple import ReplyKeyboardMarkup, KeyboardButton\r\n\r\n\r\n    class Node(dotbot_ros.DotbotNode):\r\n        node_name = \'bot\'\r\n        TOKEN = "INSERISCI QUI IL TUO TOKEN TELEGRAM"\r\n        YATOKEN = "trnsl.1.1.20170523T140049Z.89213c48771026d1.7b307aff21507ba6c5251b57d13d7181f5658c34"\r\n\r\n\r\n        def setup(self):\r\n            self.bot = telepot.Bot(self.TOKEN)\r\n            self.bot.message_loop(self.handle)\r\n            self.image_sub = dotbot_ros.Subscriber("/camera/image",Image,self.callback)\r\n            self.img = None\r\n            self.bridge = CvBridge()\r\n            self.shape = None\r\n            self.image = None\r\n            self.server_url = "https://willbeddow.com"\r\n            self.payload = dict(username="USER", password="PASS")\r\n            self.translate = YandexTranslate(self.YATOKEN)\r\n            self.robot = Robot(left=(9,10), right=(7,8))\r\n\r\n        def callback(self,data):\r\n            self.img = self.bridge.imgmsg_to_cv2(data, "bgr8")\r\n\r\n        def handle(self, msg):\r\n            content_type, chat_type, chat_id = telepot.glance(msg)\r\n            nome = msg[\'from\'][\'first_name\']\r\n            domanda = msg[\'text\']\r\n            if domanda[0] == \'/\':\r\n                self.bot.sendMessage(chat_id, \'scegli una delle voci\', reply_markup=ReplyKeyboardMarkup(\r\n                            keyboard=[\r\n                                [KeyboardButton(text="/avanti"), KeyboardButton(text="/dietro")],\r\n                                [KeyboardButton(text="/destra"), KeyboardButton(text="/sinistra")],\r\n                                [KeyboardButton(text="/image")],[KeyboardButton(text="/stop")]\r\n                            ]\r\n                        ))\r\n                if domanda == \'/start\':\r\n                    self.bot.sendMessage(chat_id, "ciao, " + nome + " benvenuto nella mia chat!")\r\n                elif domanda == \'/image\':\r\n                    img_str = cv2.imencode(\'.jpg\', self.img)[1].tostring()\r\n                    self.bot.sendPhoto(chat_id,(\'image.jpg\', StringIO.StringIO(img_str)))\r\n                elif domanda == \'/avanti\':\r\n                    self.bot.sendMessage(chat_id, "ok, vado avanti")\r\n                    self.robot.forward()\r\n                    time.sleep(0.25)\r\n                    self.robot.stop()\r\n                elif domanda == \'/dietro\':\r\n                    self.bot.sendMessage(chat_id, "ok, vado dietro")\r\n                    self.robot.backward()\r\n                    time.sleep(0.25)\r\n                    self.robot.stop()\r\n                elif domanda == \'/destra\':\r\n                    self.bot.sendMessage(chat_id, "ok, giro a destra")\r\n                    self.robot.right()\r\n                    time.sleep(0.2)\r\n                    self.robot.stop()\r\n                elif domanda == \'/sinistra\':\r\n                    self.bot.sendMessage(chat_id, "ok, giro a sinistra")\r\n                    self.robot.left()\r\n                    time.sleep(0.2)\r\n                    self.robot.stop()\r\n                elif domanda == \'/stop\':\r\n                    self.robot.stop()\r\n                else:\r\n                    self.bot.sendMessage(chat_id, "scusa, non capisco questo comando")\r\n\r\n            else:\r\n                domand = self.translate.translate(domanda.encode(\'utf-8\'), \'it-en\') #traduzione da italiano in inglese\r\n                question = domand[\'text\']  #decodifico le api\r\n                response = requests.post(url="{0}/api/start_session".format(self.server_url), data=self.payload).json()  #viene creata una nuova sessione\r\n                session_id = response["data"]["session_id"] #viene creata la session id\r\n                command_data = dict(session_id=session_id, command=question)\r\n                answer = requests.post(url="{0}/api/command".format(self.server_url), data=command_data).json()\r\n                answ = answer["text"]\r\n                risp = self.translate.translate(answ, \'en-it\')\r\n                risposta = risp[\'text\']\r\n                text = risposta[0].encode(\'utf-8\') #decode da unicode in utf8\r\n                requests.post(url="{0}/api/end_session".format(self.server_url), data={"session_id": session_id}) #la sessione viene chiusa\r\n                self.bot.sendMessage(chat_id, text) #viene inviata la risposta\r\n\r\n            print msg\r\n            sys.stdout.flush()\r\n\r\n_Adesso il nostro bot riesce a rispondere a qualsiasi domanda, muoversi e infine fare foto._\r\n![enter image description here](./YhOabRU.jpg)\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-06-16-implementare-un-motore-dintelligenza-artificale-sul-vostro-bot/index.md",
    frontMatter: {
      path: "/hbr/implementare-un-motore-dintelligenza-artificale-sul-vostro-bot/",
      author: {
        id: "ruslan",
        name: "Ruslan",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ruslan.jpg",
      },
      readTime: "8 mins",
      published: "2017-06-16T07:59:40.000Z",
      publishedReadable: "16 Giu 2017",
      featured: false,
      tags: [],
      title: "Implementare un motore d'intelligenza artificale sul vostro bot",
      description: "",
      href: "/hbr/implementare-un-motore-dintelligenza-artificale-sul-vostro-bot/",
      image:
        "/content/hbr/2017-06-16-implementare-un-motore-dintelligenza-artificale-sul-vostro-bot/1iDEl1P.jpg",
      imagePath:
        "/content/hbr/2017-06-16-implementare-un-motore-dintelligenza-artificale-sul-vostro-bot",
    },
  },
  {
    content:
      "\nRecentemente mi sto spostando sempre di più verso lo sviluppo di applicazioni Web single-page. A differenza del metodo classico che ho molto esplorato [in questo blog](http://www.ludusrusso.cc/tutorial/python/ludoblog/index.html), in questo tipo di architettura l'intera applicazione web viene scaricata la prima volta, quando si accede all'url principale del sito internet.\nIn questo modo, il nostro server principale può scambiare solo i dati da visualizzare all'interno dell'applicazione, invece che dover mandare l'intera pagina da renderizzare ogni volta.\n\nQuesto, come è possibile immaginare, semplifica e alleggerisce notevolmente il lavoro del server, rendendo di fatto le applicazioni più scalabili e più semplici da gestire. Inoltre, gestendo lo scambio dati con API basate su standard come JSON, è anche possibile poi sviluppare applicazioni Desktop/Mobile native che comunicano con le stesse API della webapp.\n\nUno dei problemi principali da gestire, con questa nuova architettura, è la protezione dei dati (e quindi l'autenticazione dell'utente). Vediamo in seguito come fare sfruttando una tecnologia chiamata _JSON Web Token_ (_JWT_).\n\n## JWT: JSON Web Token\n\nJWT è uno standard Open per creare chiavi (token) di accesso tra un server e un client.\n\nIl token JWT viene creato (su richiesta) dal server (solitamente dopo l'autenticazione), e consegnato al client. Ad ogni richiesta che necessita di autenticazione, il client deve inviare anche il token, tramite il quale il server stesso verificherà che il client sia correttamente autenticato.\n\nIl token JWT è diviso in tre parti: l'_header_, il _payload_ e la _firma_.\n\n- L'_header_ contiene informazioni tecniche sul tipo di tecnologia utilizzata per codificare il token;\n- Il _payload_ contiene le informazioni che vogliamo siano contenute nel token stesso, ad esempio l'id dell'utente loggato nel server;\n- La _firma_ serve per controllare che il token non sia stato modificato, e contiene le informazioni precedenti ma codificate usando una chiave segreta nota solo al server.\n\nQueste tre informazioni vengono codificate in _base64_ e quindi il token viene generato concatenandole in ordine separate da punti:\n\n```\ntoken = encode(header) + \".\" + encode(payload) + \".\" + encode(firma)\n```\n\n## Uso di `flask-jwt-extended`\n\n`flask-jwt-extended` è un'estensione di flask che fornire tutto il necessario per gestire l'autenticazione usando JWT. Vediamo con un piccolo esempio come usarla e come funziona.\n\n### Setup Ambiente di sviluppo\n\nPer prima cosa, creiamo un ambiente virtuale python e installiamo `flask` e `flask-jwt-extended`:\n\n```bash\n$ virtualenv jwt-server && cd jwt-server\n$ source bin/activate\n(jwt-server)$ pip install flask flask-jwt-extended\n```\n\n### Sviluppo di una semplice applicazione\n\nSviluppiamo adesso una semplicissima applicazione, che permette di richiedere il token di accesso attraverso delle API di Login (in JSON) e quindi di accedere a delle API protette grazie al Token ottenuto. Sempre la stessa App, permette accesso ad API pubbliche senza necessariamente avere a disposizione un token di accesso.\n\n#### Import e inizializzazione dell'app\n\nPer prima cosa, importiamo i moduli (`flask` e `flask_jwt_extended`), inizializziamo l'app, settando anche la `secret_key` (che sarà la chiave grazie alla quale cripteremo i token), ed inizializziamo il modulo `jwt`.\n\n```python\nfrom flask import Flask, jsonify, request\nfrom flask_jwt_extended import JWTManager, jwt_required, create_access_token, get_jwt_identity\n\napp = Flask(__name__)\napp.secret_key = 'super-secret'\n\njwt = JWTManager(app)\n```\n\n#### Creazione del database utenti\n\nÈ necessario creare un database di utenti. Essendo questa un'app di test, per il momento creerò un semplice dizionario, in cui all'interno vengono salvati username e password degli utenti nella forma\n\n```\n{\n\t'username1': 'password1',\n\t'username2': 'password2',\n\t...\n\t'usernameN': 'passwordN',\n}\n```\n\nNel mio dizionario, creerò due utenti principali (ovviamente può essere esteso a piacimento).\n\n```python\nusers = {\n        'ludovico': 'ludo',\n        'user': 'password'\n    }\n```\n\n#### Creazione di API non protette\n\nPer creare un'API non protetta, possiamo banalmente evitare di usare `flask_jwt_extended ` e procedere normalmente:\n\n```python\n@app.route('/unprotected', methods=['GET'])\ndef unprotected():\n    return jsonify({'hello': 'unprotected'}), 200\n```\n\nQuesto codice, genera un nuovo endpoint nella nostra applicazione sull'url `/unprotected`, accessibile da metodo `GET`. L'API ritorna semplicemente il JSON `{'hello': 'unprotected'}`.\n\n#### Creazione di API protette\n\nPer creare un'API protetta, `flask_jwt_extended` ci fornisce il decorator `@jwt_required`, che permette di accedere all'endpoint solo dopo la verifica del Token. Inoltre, grazie al metodo `get_jwt_identity` possiamo accedere ai dati salvati nel token, che in questo caso è lo username dell'utente (vedremo dopo come inserire questo dato nel token):\n\n```python\n@app.route('/protected', methods=['GET'])\n@jwt_required\ndef protected():\n    current_username = get_jwt_identity()\n    return jsonify({'hello_from': current_username}), 200\n```\n\nCome vedete, in questo caso creiamo un nuovo endpoint sull'url `/protected` accessibile da method `GET`, lo proteggiamo tramite `@jwt_required`. All'interno dell'applicazione, accediamo allo username dell'utente chiamando la funzione `get_jwt_identity()` e ritorniamo un json nella forma `{'hello_from': username}`, dove `username` dipende dall'utente chiamante.\n\n#### Generazione del Token e Login\n\nManca quindi solo l'implementazione di un endpoint per fare il login.\nL'endpoint `/login` riceverà nella richiesta lo username e la password dell'utente che si vuole loggare, una volta verificato che queste siano corrette, ritornerà il token JWT contenente nel payload lo username dell'utente stesso.\n\n```python\n@app.route('/login', methods=['POST'])\ndef login():\n    username = request.json.get('username', None)\n    password = request.json.get('password', None)\n    if username in users and users[username] == password:\n        ret = {'access_token': create_access_token(identity=username)}\n        return jsonify(ret), 200\n    return jsonify({\"msg\": \"Bad username or password\"}), 401\n```\n\nIn questo caso, abbiamo creato un endpoint (pubblico) sull'url `/login` che risponde al metodo `GET`. Per prima cosa, accediamo a username e password contenute nella richiesta, con le righe\n\n```python\n    username = request.json.get('username', None)\n    password = request.json.get('password', None)\n```\n\nControlliamo quindi che lo username esiste e che questo metcha correttamente con la password:\n\n```python\n    if username in users and users[username] == password:\n```\n\nIn caso positivo, generiamo un nuovo token con la funzione `create_access_token(identity=username)`, a cui passiamo come parametro `identity` lo username dell'utente, e ritorniamo un json contenente tale token.\n\nAltrimenti, ritorniamo (con errore `401`) un json che informa l'app che lo username e la password non sono corretti.\n\n#### Codice completo\n\nIl codice completo è il seguente\n\n```python\nfrom flask import Flask, jsonify, request\nfrom flask_jwt_extended import JWTManager, jwt_required, create_access_token, get_jwt_identity\n\napp = Flask(__name__)\napp.secret_key = 'super-secret'\n\njwt = JWTManager(app)\n\nusers = {\n        'ludovico': 'ludo',\n        'user': 'password'\n    }\n\n@app.route('/unprotected', methods=['GET'])\ndef unprotected():\n    return jsonify({'hello': 'unprotected'}), 200\n\n@app.route('/login', methods=['POST'])\ndef login():\n    username = request.json.get('username', None)\n    password = request.json.get('password', None)\n    if username in users and users[username] == password:\n        ret = {'access_token': create_access_token(identity=username)}\n        return jsonify(ret), 200\n    return jsonify({\"msg\": \"Bad username or password\"}), 401\n\n@app.route('/protected', methods=['GET'])\n@jwt_required\ndef protected():\n    current_username = get_jwt_identity()\n    return jsonify({'hello_from': current_username}), 200\n\nif __name__ == '__main__':\n    app.run()\n```\n\n## Test dell'applicazione\n\nPer testare l'applicazione, conviene usare un tool per la generazione di richieste verso un server. Personalmente mi trovo molto comodo con il tool [Insomnia](https://insomnia.rest), che permette di testare API restful in modo molto intuitivo.\n\nPer prima cosa, vediamo se l'applicazione risponde correttamente all'url `/unprotected`. Se facciamo una richiesta `GET` su questo URL, infatti, dovremmo ottenere come risposta\n\n```json\n{\n  \"hello\": \"unprotected\"\n}\n```\n\n![](./unprotected.png)\n\nSe proviamo, similmente, a mandare una richiesta sul metodo `/protected`, invece, dovremmo ottenere la risposta di errore di autenticazione:\n\n```json\n{\n  \"msg\": \"Missing Authorization Header\"\n}\n```\n\n![](./protected_error.png)\n\nPer accedere all'url `/protected`, dobbiamo prima di tutto ottenere un token, per farlo, mandiamo una richiesta `POST` all'url `/login` con un json contenente username e password:\n\n```json\n{\n  \"username\": \"ludovico\",\n  \"password\": \"ludo\"\n}\n```\n\nSe il login non è corretto, otterremo come risultato\n\n```json\n{\n  \"msg\": \"Bad username or password\"\n}\n```\n\n![](./login2.png)\n\naltrimenti avremmo finalmente il nostro token:\n\n```json\n{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2NsYWltcyI6e30sImp0aSI6ImMxOGE3MWMxLTM4Y2EtNGYwNi1hNzYwLWY0YTVlOGUxMGZhMiIsImV4cCI6MTQ5NzI2MjQ3NiwiZnJlc2giOmZhbHNlLCJpYXQiOjE0OTcyNjE1NzYsInR5cGUiOiJhY2Nlc3MiLCJuYmYiOjE0OTcyNjE1NzYsImlkZW50aXR5IjoibHVkb3ZpY28ifQ.Eru4JFykJzqkNx7epmUkxRW82JfYUN5b2OdrG_osGe4\"\n}\n```\n\n![](./login1.png)\n\nA questo punto, possiamo finalmente fare una richiesta sull'url `/protected`. Ricordatevi di risettare il metodo a `GET`, prima di fare la richiesta, accediamo al tab `Auth` e settiamo come metodo di autenticazione `Bearer Token`, settiamo il token ottenuto e quindi facciamo la richiesta. Dovremmo ottenere come risultato:\n\n```json\n{\n  \"hello_from\": \"ludovico\"\n}\n```\n\n![](./protected.png)\n\n## Conclusioni\n\nAl momento sto investigando l'utilizzo di JWT con alcune librerie client web come ad esempio Angular. Seguiranno a breve altri tutorial sull'argomento.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-06-12-gestire-l-autenticazione-in-flask-con-flask-jwt-extended/index.md",
    frontMatter: {
      path: "/2017/06/12/gestire-l-autenticazione-in-flask-con-flask-jwt-extended/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2017-06-12T00:00:00.000Z",
      publishedReadable: "12 Giu 2017",
      featured: false,
      tags: ["Jwt", "Flask", "Restful"],
      title: "Gestire l'autenticazione in Flask con flask-jwt-extended",
      description:
        "Un breve tutorial che mostra come gestire l'autenticazione JWT in Flask",
      href: "/2017/06/12/gestire-l-autenticazione-in-flask-con-flask-jwt-extended/",
      image:
        "/content/blog/it/2017-06-12-gestire-l-autenticazione-in-flask-con-flask-jwt-extended/login1.png",
      imagePath:
        "/content/blog/it/2017-06-12-gestire-l-autenticazione-in-flask-con-flask-jwt-extended",
    },
  },
  {
    content:
      "\r\nIn questo tutorial vedremo come controllare un robot attraverso i tasti **wasd** per farlo muovere nelle 4 direzioni. In particolare vedremo:\r\n\r\n- come sviluppare una webapp in grado di controllare il robot attraverso la tastiera\r\n\r\n- come sviluppare lo **sketch** in ROS per sottoscriversi al topic della webapp\r\n\r\n## La webapp\r\n\r\nCome prima cosa andiamo a sviluppare l'applicazione web che ci permetterà di controllare il robot tramite la tastiera. [Da qui](https://github.com/sgabello1/WebApp) scaricate (premendo sul pulsante **clone or download**) la cartella ed estraetela in un luogo facilmente raggiungibile.\r\n\r\n![](./26967384-5320d1c2-4cfe-11e7-8e7f-1ca7de8dcf1b.png)\r\n\r\nAprite la cartella **keyboardteleop_files** e aprite il file all'interno della cartella (la \"struttura\" in javascript della nostra webapp) con l'applicazione blocco note. A questo punto cercate le righe dove sono indicate le direzioni (nella forma `//command`) e aggiungete sotto ognuno di essi la stringa `console.log(\"direzione\")`, sostituendo la parola \"direzione\" in base a dove si dirigerà il robot.\r\n\r\n![](./26967302-ff0a2fde-4cfd-11e7-8a97-693cca91596a.png)\r\n\r\nQueste aggiunte serviranno a verificare l'effettiva funzionalità della nostra webapp. Il lavoro non è però ancora completo: è necessario far sì che la nostra app sia in grado di dialogare con il nostro robot. Aprite il file html **keyboardteleop** con il blocco note e cercate la stringa `start_ros('192.168.0.112', 'silverbot', '192.168.0.112', '192.168.0.112/bridge/');`\r\n\r\n![](./26968358-0a5e8afc-4d02-11e7-983e-038aeaf409b3.png)\r\n\r\nDovete ora sostituire questa stringa con quella che identifica il vostro robot. Per trovarla collegate il vostro robot al sito di Hotblack, aprite una qualunque webapp e aprite la sorgente della pagina (tasto destro):\r\n\r\n![](./26968706-438104f8-4d03-11e7-97f7-96e6deb0a765.png)\r\n\r\nAll'interno del codice sorgente cercate la stringa `start_ros('#...');`, copiatela al posto di quella presente nel file html (aperto con il blocco note) **keyboardteleop** e salvate il tutto.\r\n\r\nPossiamo ora testare la nostra app: aprite il file **keyboardteleop** nel browser e aprite la console cliccando col tasto destro del mouse e selezionando seleziona. Refreshate la pagina (F5) e ogni volta che premete uno dei pulsanti **wasd** la console dovrebbe restituirvi, stampandola a video, l'azione connessa al pulsante premuto.\r\n\r\n![](./26967298-fc17bf12-4cfd-11e7-824d-a1f437043c57.png)\r\n\r\n## Sketch ROS\r\n\r\nScriviamo ora lo sketch in Ros che farà comunicare il nostro robot con la webapp. Importiamo l'oggetto `Robot` dalla libreria `gpiozero` per gestirne il movimento e costruiamo le coppie di PIN GPIO a cui sono collegate i due motori, sfruttando i parametri left e right:\r\n\r\n```python\r\nself.robot = Robot(left=(16, 19), right=(20, 26))\r\n```\r\n\r\n## Sottoscriviamoci ad un Topic ROS e usiamo le Callback\r\n\r\nAndiamo ad implementare una funzione di callback, chiamata `keyb_wasd`. Questa funzione (come tutte le funzioni di callback) avrà la seguente forma:\r\n\r\n```python\r\ndef keyb_wasd(self, msg):\r\n    pass\r\n```\r\n\r\nI due parametri che la funzione sfrutta sono `self` (che rappresenta il nodo) e `msg`, che conterrà il messaggio scambiato dal topic.\r\n\r\nIl messaggio `geometry_msgs/Twist` contiene 2 valori a noi utili:\r\n\r\n- `linear.x` che varia nell'intervallo `+20` e `-20`\r\n- `linear.z` che varia nell'intervallo `+1` e `-1`\r\n\r\nLa classe `Robot` funziona in modo simile, ma i valori di velocità delle ruote possono variare tra `-1.0` (massima velocit‡ all'indietro) e `1.0` (massima velocità in avanti). La prima cosa che dovrà fare la funzione, quindi, è convertire questi valori e controllare che i valori finali siano nell'intervallo `[-1, 1]`.\r\n\r\n```python\r\ndef on_speed(self, msg):\r\n    v_dx = (msg.linear.x/20) - msg.linear.z\r\n    v_sx = (msg.linear.x/20) + msg.linear.z\r\n\r\n```\r\n\r\nUna volta generati i due comandi di velocità (`v_dx` e `v_sx`), aggiungiamo una stringa per stamparne a video i valori finali utilizzando la funzione `print`:\r\n\r\n```python\r\ndef on_speed(self, msg):\r\n       #...\r\n       print 'v_dx', v_dx\r\n       print 'v_sx', v_sx\r\n       stdout.flush()\r\n       #...\r\n```\r\n\r\nRicordate di aggiungere sempre la linea di codice `stdout.flush()` (ed importare il modulo `flush` con la stringa `from sys import flush` per forzare la stampa effettiva sulla shell.\r\nOra non ci resta che settare questi valori per far muovere le ruote. Per farlo, utilizziamo il prametro `Robot.value`dell'oggetto `Robot`\r\n\r\n```python\r\nself.robot.value = (v_sx, v_dx)\r\n```\r\n\r\nLa funzione `keyb_wasd`, quindi, verrà completata in questo modo:\r\n\r\n```python\r\ndef keyb_wasd(self, msg):\r\n   v_dx = (msg.linear.x/20) - msg.linear.z\r\n   v_sx = (msg.linear.x/20) + msg.linear.z\r\n\r\n    #stampo a video i valori di v_dx e v_sx\r\n    print 'v_dx', v_dx\r\n    print 'v_sx', v_sx\r\n    stdout.flush()\r\n\r\n\r\n    #controllo del robot\r\n    self.robot.value = (v_dx, v_sx)\r\n```\r\n\r\n### Sottoscrizione al topic\r\n\r\nUna volta implementata la funzione di callback, non ci resta che sottoscriverci al topic `keyboard` per poterla correttamente utilizzare. Per farlo, nella funzione `setup`, aggiungiamo la seguente linea di codice:\r\n\r\n```python\r\n dotbot_ros.Subscriber('keyboard', Twist, self.keyb_wasd)\r\n```\r\n\r\nricordandoci di importare l'oggetto `Twist` da `geometry_msgs.msg`\r\n\r\n```python\r\nfrom geometry_msgs.msg import Twist\r\n```\r\n\r\n### Codice completo\r\n\r\nEcco il codice completo del nostro programma\r\n\r\n```python\r\nimport dotbot_ros\r\nfrom sys import stdout\r\nfrom geometry_msgs.msg import Twist\r\nfrom gpiozero import Robot\r\n\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'keyboard'\r\n\r\n    def setup(self):\r\n        self.robot = Robot(left=(16, 19), right=(20, 26))\r\n        dotbot_ros.Subscriber('keyboard', Twist, self.keyb_wasd)\r\n\r\n    def keyb_wasd(self, msg):\r\n        print msg.linear.x\r\n        stdout.flush()\r\n\r\n        v_dx = (msg.linear.x/20) - msg.linear.z\r\n        v_sx = (msg.linear.x/20) + msg.linear.z\r\n\r\n        print v_dx\r\n        print v_sx\r\n        stdout.flush()\r\n\r\n\r\n        self.robot.value = (v_dx, v_sx)\r\n        stdout.flush()\r\n```\r\n\r\nPer inviare i comandi dobbiamo aprire la nostra webapp, la console ROS e lanciare il nostro nodo. A questo punto refreshando la webapp dovrebbe comparire sulla console il topic `nomerobot/keyboard`. Premendo sul pulsante `echo` ci comparirà una schermata che mostrerà il variare dei valori del messaggio pubblicato come topic dalla webapp.\r\n\r\n![](./26968915-1d9efcee-4d04-11e7-9b28-75660dccf4f5.png)\r\n\r\nRefreshiamo un'ultima volta la pagina della webapp e siamo pronti a comandare il nostro robot dalla tastiera!\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-06-09-webapp-per-il-controllo-da-tastiera-wasd/index.md",
    frontMatter: {
      path: "/hbr/webapp-per-il-controllo-da-tastiera-wasd/",
      author: {
        id: "pietrochirio",
        name: "Pietro Chiro",
        bio: "Dev Passionate",
        profile: "/imgs/authors/pietrochirio.jpg",
      },
      readTime: "4 mins",
      published: "2017-06-09T09:57:40.000Z",
      publishedReadable: "9 Giu 2017",
      featured: false,
      tags: [],
      title: "Webapp per il controllo da tastiera wasd",
      description:
        "In questo tutorial vedremo come controllare un robot attraverso i tasti **wasd** per farlo muovere nelle 4 direzioni.",
      href: "/hbr/webapp-per-il-controllo-da-tastiera-wasd/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-06-09-webapp-per-il-controllo-da-tastiera-wasd",
    },
  },
  {
    content:
      '\nMi sono avvicinato alle tecnologie Web per caso qualche anno fa, e mi si è aperto un mondo che molto spesso non sono riuscito ad approfondire, un po\' per questioni di tempo, un po\' perchè il linguaggio Javascript (il principale linguaggio per la programmazione di WebApp) non mi ha mai appassionato tanto.\n\n![Typescript + Electron](./ts_elec.png)\n\nRecentemente ho iniziato ad approfondire invece un linguaggio di programma ideato da Mycrosoft chiamato [**TypeScript**](https://www.typescriptlang.org/). Da definizione, TypeScript è un "superset" di JavaScript, cioè un\'estensione di JavaScript, ed include una serie di caratteristiche dei linguaggi di programmazione moderni, quali classi, interfacce, ecc., rendendolo un linguaggio di programmazione degno di questo nome.\n\nCon TypeScript, mi sto riavvicinando ad un progetto che conosco già da tempo ma che non ho mai approfondito: [**Electron**](https://electron.atom.io/). Electron è un sistema che sfrutta tecnologie web (quindi HTML, CSS e JS) per creare applicazioni native desktop. L\'idea di base è molto semplice: le tecnologie web sono arrivate ad una maturità tale da permettere di scrivere applicazioni complesse che girano su qualsiasi browser e su qualsiasi piattaforma, quindi perchè non sfruttarle per sviluppare anche per applicazioni native? In pratica, con electron possiamo prendere una WebApp, impacchetarla e distribuirla come applicazione nativa su Windows, macOS e Linux.\n\nVediamo in seguito come fare!\n\n## Installare Node.js\n\nPer utilizzare electron, è necessario installare node.js sul nostro computer. Per farlo, accedete al [sito nodejs.org](https://nodejs.org/it/) e scaricate l\'ultima versione disponibile (consiglio la versione LTS), scaricate e seguite le istruzioni di installazione.\n\n![Typescript + Electron](./node.png)\n\nUna volta installato node, avremmo a disposizione il comando npm per la gestione dei pacchetti javascript. Dobbiamo installare sul nostro computer il compilatore **typescript**. Per farlo, basterà aprire il terminale e digitare\n\n```\n$ npm install -g typescript\n```\n\nper installare globalmente (opzione `-g`) typescrit.\n\n## Creazione progetto e installazione dipendenze\n\nA questo punto, sempre da terminale, accediamo nel nostro workspace e creiamo una certella chiamata `electro_ts`: questa sarà la base del nostro progetto.\n\n```bash\n$ mkdir electro_ts\n$ cd electro_ts\n```\n\nAll\'interno della cartella, inizializziamo il progetto digitando il comando\n\n```\n$ npm init\n```\n\nIl prompt di comandi ci chiederà una serie di informazioni per inizializzare il progetto, come nome dell\'autore, licenza, ecc. Una volta risposto a tutte quante, noteremo che è stato creato un nuovo file chiamato `package.json`, con il seguente cotenuto:\n\n```json\n{\n  "name": "electron_ts",\n  "version": "1.0.0",\n  "description": "",\n  "main": "index.js",\n  "scripts": {\n    "test": "echo \\"Error: no test specified\\" && exit 1"\n  },\n  "author": "",\n  "license": "ISC"\n}\n```\n\nPotete modificare dopo queste informazioni per inserire correttamente alcuni dati.\n\n### Installazione di Electron\n\nPer usare Electron, ovvialmente, dobbiamo installare la libreria. Per farlo, eseguiamo il comando\n\n```bash\n$ npm install --save-dev electron\n```\n\ndove l\'opzione `--save-dev` dice di installare electron come componente di sviluppo.\n\nUna volta eseguito il comando, noterete che è apparsa una nuova cartella chiamata `node_modules`. Qui dentro verranno salvate tutte le dipendenze locali del progetto.\n\nInoltre, aprendo il file `package.json`, vi accorgerete che sono state aggiunge alcune righe, che essenzialmente memorizzano le dipendenze del progetto.\n\n```json\n{\n  ...\n  "devDependencies": {\n    "electron": "^1.6.10"\n  }\n}\n```\n\nSiamo pronti per implementare l\'applicazione.\n\n## Prima App in Electron: Hello, World!\n\nSviluppiamo adesso una semplice applicazione che mostra, all\'interno di una finestra, la scritta `Hello World!`.\n\nCreiamo un file chiamato `main.ts`. Questo è un file in cui andremo a sviluppare il core dell\'app usando typescript.\n\nCreiamo anche un file `index.html`, in cui implementeremo la schermata dall\'applicazione.\n\nAll\'interno del file `index.html`, implementiamo semplicemente un tag `h1` con il testo _Hello, World!_\n\n```html\n<html>\n  <head>\n    <title>App in Electron</title>\n  </head>\n  <body>\n    <h1>Hello, World!</h1>\n  </body>\n</html>\n```\n\nAll\'interno del file `main.ts`, implementiamo il seguente codice:\n\n```typescript\nimport { app, BrowserWindow } from "electron"\n\nlet mainWindows = null\n\napp.on("ready", () => {\n  mainWindows = new BrowserWindow({ width: 800, height: 600 })\n  mainWindows.loadURL("file://" + __dirname + "/index.html")\n})\n```\n\n### Analizziamo il codice TypeScript\n\nVediamo riga per riga il significato del codice.\n\nPer prima cosa, importiamo i componenti `app` e `BrowserWindow` dal modulo `electron`:\n\n```typescript\nimport { app, BrowserWindow } from "electron"\n```\n\nCreiamo quindi una variabile, che gestirà la finestra principale della nostra applicazione:\n\n```typescript\nlet mainWindows = null\n```\n\nA questo punto, dobbiamo aspettare che l\'applicazione sia correttamente lanciata prima di iniziare a fare qualcosa. Per far questo, associamo all\'evento `ready` una funzione:\n\n```typescript\napp.on("ready", () => {\n  // codice da eseguire quando l\'app è pronta.\n})\n```\n\nAll\'interno della funzione, creiamo una finestra di dimensioni $800x600$ e, all\'interno di questa finestra, carichiamo il file `index.html`:\n\n```typescript\nmainWindows = new BrowserWindow({ width: 800, height: 600 })\nmainWindows.loadURL("file://" + __dirname + "/index.html")\n```\n\n### Compiliamo il codice\n\nCome detto prima, ogni file `ts` deve essere compilato in modo da generare codice `javascript`. Per farlo, eseguiamo il comando\n\n```bash\ntsc main.ts\n```\n\nChe esegue il compilatore typescript sul file `main.ts`. Terminato il processo di compilazione, noterete che è stato creato un nuovo file, chiamato `main.js`. Questo sarà il file che andremo ad eseguire per lanciare il programma.\n\n### Eseguiamo il codice\n\nPer eseguire il codice, ci manca un ultimo passaggio: dobbiamo creare un nuovo comando di npm che lancia electron passandogli il file `main.js`, che viene gerato compilando `main.ts`.\n\nPer farlo, modifichiamo il file `package.json` aggiungendo un nuovo script:\n\n```json\n{\n  ...\n  "scripts": {\n    "electron": "electron main.js",\n    ...\n  },\n  ...\n}\n```\n\nSalviamo il file, ed eseguiamo il comando da terminale\n\n```bash\nnpm run electron\n```\n\nSe tutto va bene, la nuova applicazione si aprirà e vedremo una schermata come questa.\n\n![Typescript + Electron](./app.png)\n\n## Conclusioni\n\nCome potete notare, lo sviluppo di applicazioni usando questa tecnologia, risulta molto semplice.\nNei prossimi giorni approfondirò l’uso di TypeScript per incominciare a sviluppare applicazioni complete.\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-06-04-primi-test-con-typescript-ed-electron/index.md",
    frontMatter: {
      path: "/2017/06/04/primi-test-con-typescript-ed-electron/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2017-06-04T00:00:00.000Z",
      publishedReadable: "4 Giu 2017",
      featured: false,
      tags: ["Electron", "Typescript", "Webapp"],
      title: "Primi test con TypeScript ed Electron",
      description:
        "Un tutorial per iniziare a sviluppare applicazioni native desktop usando tecnologi Web ed il nuovo linguaggio di programmazione Typescript",
      href: "/2017/06/04/primi-test-con-typescript-ed-electron/",
      image:
        "/content/blog/it/2017-06-04-primi-test-con-typescript-ed-electron/ts_elec.png",
      imagePath:
        "/content/blog/it/2017-06-04-primi-test-con-typescript-ed-electron",
    },
  },
  {
    content:
      "\r\nDalla versione 0.5.2, come annunciato, è disponibile una nuova funzione che permette agli utenti di accedere al terminale linux di HBrain direttamente da browser, vediamo come fare.\r\n\r\nPer prima cosa, è necessario scaricare l'ultima versione di HBrain (o una versione superiore o uguale alla 0.5.2) ed installarla sul raspberry seguendo [questo tutorial](http://hotblackrobotics.github.io/blog/posts/2017-03-24-immagine-sd-per-la-cloud-e-configurazione).\r\n\r\nUna volta fatto, accediamo alla pagina di [HBR Cloud](http://hotblackrobotics.github.io/cloud/index) e connettiamoci al Robot.\r\n\r\nA questo punto, accediamo al tab _Robot_ in alto a sinistra e quindi accediamo al server interno del robot premendo il tasto **Connetti al Robot**.\r\n\r\n![Robot page](./robotpage.png)\r\n\r\nPremiamo quindi sul pulsante al centro **Terminal**.\r\n\r\n![Robot Server](./robotserver.png)\r\n\r\nInseriamo Nome utente (_hbrain_) e password (_dotbot_).\r\n\r\n![Robot Server](./userpass.png)\r\n\r\nPremiamo il pulsante _Open Terminal_\r\n\r\n![Robot User Password](./tty.png)\r\n\r\nE quindi potremmo accedere al terminale shell linux di HBrain.\r\n\r\n![Shell](./shell.png)\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-05-23-accedere-al-terminale-linux-di-hbrain-da-browser/index.md",
    frontMatter: {
      path: "/hbr/accedere-al-terminale-linux-di-hbrain-da-browser/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-05-23T13:37:19.000Z",
      publishedReadable: "23 Mag 2017",
      featured: false,
      tags: [],
      title: "Accedere al Terminale Linux di HBrain da Browser",
      description: "",
      href: "/hbr/accedere-al-terminale-linux-di-hbrain-da-browser/",
      image:
        "/content/hbr/2017-05-23-accedere-al-terminale-linux-di-hbrain-da-browser/shell.png",
      imagePath:
        "/content/hbr/2017-05-23-accedere-al-terminale-linux-di-hbrain-da-browser",
    },
  },
  {
    content:
      "\nCon piacere annunciamo il rilascio di una nuova versione del sistema HBRain: la v0.5.2.\n\nEcco le modifiche apportate:\n\n- Supporto nativo a Lego NXT tramite la libreria nxt-python\n- Aggiunta la possibilità di accedere al terminale linux di HBrain tramite web browser\n- Bux Fix e migliorie minori.\n\nLa versione è scaricabile dal seguente [link](https://sourceforge.net/projects/hbrain/).\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-05-23-rilascio-hbrain-v052/index.md",
    frontMatter: {
      path: "/hbr/rilascio-hbrain-v052/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-05-23T11:32:38.000Z",
      publishedReadable: "23 Mag 2017",
      featured: false,
      tags: [],
      title: "Rilascio HBrain v0.5.2",
      description: "",
      href: "/hbr/rilascio-hbrain-v052/",
      image: "/content/hbr/hotblack.jpg",
      imagePath: "/content/hbr/2017-05-23-rilascio-hbrain-v052",
    },
  },
  {
    content:
      '\nQuesto brevissimo post è un tutorial che spiega come cambiare nome al robot usando la piattaforma.\nQuesto tutorial prevede una versione del sistema operativo HBrain > 0.5\n\n- Collegare il robot alla rete wifi (o ethernet)\n- Accedere alla [piattaforma cloud](http://cloud.hotblackrobotics.com/cloud)\n- Premere il pulsante "cerca robot", il nome del robot (di default è **hotbot**) apparirà nella tabella\n  ![](./search.png)\n- Connettersi al Robot, una volta connessi, è necessario refreshare la pagina\n  ![](./connect.png)\n- Accedere al tab **Robot** in alto a sinistra\n- Inserire il nome che vogliamo al robot nell\'apposito form e premere **Set Hostname**. **Attenzione: il nome del robot deve essere tutto minuscolo e non contenere spazi o caratteri speciali)**\n- Riavviare il robot dal pulsante **Reboot**.\n  ![](./change.png)\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-05-11-cambiare-nome-al-robot-dotbot-da-piattaforma/index.md",
    frontMatter: {
      path: "/hbr/cambiare-nome-al-robot-dotbot-da-piattaforma/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-05-11T15:09:55.000Z",
      publishedReadable: "11 Mag 2017",
      featured: false,
      tags: [],
      title: "Cambiare nome al Robot DotBot da piattaforma",
      description: "",
      href: "/hbr/cambiare-nome-al-robot-dotbot-da-piattaforma/",
      image:
        "/content/hbr/2017-05-11-cambiare-nome-al-robot-dotbot-da-piattaforma/change.png",
      imagePath:
        "/content/hbr/2017-05-11-cambiare-nome-al-robot-dotbot-da-piattaforma",
    },
  },
  {
    content:
      "\nIeri, durante la prima Cloud Roker Faire, abbiamo annunciato la volontà, nostra e di Michele Maffucci, di far nascere una community dedicata al mondo del making e della robotica. Oggi siamo felici di annunciare [Rokers](http://www.rokers.io), che ha lo scopo di riunire appassionati, insegnanti, ingegneri e maker legati al mondo della robotica.\n\n![I primi Rokers](./WhatsApp%20Image%202017-05-08%20at%2007.49.12.jpeg)\n\n### Ma cosa farà Rokers\n\nAl momento stiamo raccogliendo interessi. Nel breve periodo, lo scopo principale della community sarà quello di fare networking organizzando incontri informali a cadenza periodica. Se sei interessato alla nascita di Rokers, compila il [form cliccando qui](https://docs.google.com/forms/d/e/1FAIpQLSdacsFXWljnXINhFau6-zZgNw94zj0sfapZpmC0Xd5YJ02gbw/viewform?usp=sf_link).\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-05-08-nasce-rokers-la-community-di-robot-makers/index.md",
    frontMatter: {
      path: "/hbr/nasce-rokers-la-community-di-robot-makers/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-05-08T06:46:05.000Z",
      publishedReadable: "8 Mag 2017",
      featured: false,
      tags: [],
      title: "Nasce Rokers, la community di Robot Makers",
      description: "",
      href: "/hbr/nasce-rokers-la-community-di-robot-makers/",
      image:
        "/content/hbr/2017-05-08-nasce-rokers-la-community-di-robot-makers/WhatsApp%20Image%202017-05-08%20at%2007.49.12.jpeg",
      imagePath:
        "/content/hbr/2017-05-08-nasce-rokers-la-community-di-robot-makers",
    },
  },
  {
    content:
      "\r\nIn HotBlack Robotics, lavoriamo ogni giorno per creare una community di sviluppatori robotici. Ormai siete in tanti ad usare la nostra piattaforma, e per questo motivo abbiamo sviluppato una nuova piattaforma per la condivisione dei vostry progetti!\r\n\r\n![Profilo Pubblico](./Schermata_2017-05-03_alle_19.14.29_ibixnv.png)\r\n\r\nQuesta piattaforma è accessibile dal nuovo tab community che è apparso nel nostro sito, e permetterà agli utenti di condividere i propri progetti e avere nuove idee per svilupparne di nuovi. Sarà anche un'ottima piattaforma per permettere ai nuovi utenti di creare progetti in modo semplice e veloce, prendendo spunto dai progetti esisteni.\r\n\r\n## Come abilitare la condivisione dei progetti\r\n\r\nPer abilitare la condivisione dei progetti, un utente deve rendere pubblico il proprio profilo. Per farlo, seguite la guida qui di seguito:\r\n\r\n1. Una volta loggati nella piattaforma, accedere al tab _profilo_.\r\n   ![Homepage Profilo](./Schermata_2017-05-02_alle_20.05.02_kv92jf.png)\r\n2. Sulla pagina che viene visualizzata, premete il pulsante _Modifica_.\r\n   ![Profilo](./Schermata_2017-05-02_alle_20.05.38_gtnr6z.png)\r\n3. Compilate i campi richiesti e ricordatevi di spuntare il flag _Profilo Pubblico?_. Quindi salvate.\r\n   ![Abilitare Profilo Pubblico](./Schermata_2017-05-02_alle_20.10.44_gnclvv.png)\r\n4. A questo punto sarete abilitati alla pubblicazione dei progetti. Il vostro profilo sarà visibili all'interno della HBR Community. Potrete accederci dal tasto _Accedi al Profilo Pubbico_.\r\n   ![Profilo](./Schermata_2017-05-02_alle_20.11.49_wy9e3q.png)\r\n\r\n## Come pubblicare un progetto sulla piattaforma\r\n\r\nOgni sketch che stiamo sviluppando può diventare pubblico in modo semplice e veloce. Tuttavia, è importante scrivere della documentazione per permettere agli utenti di comprenderne lo scopo e il funzionamento e di realizzarlo.\r\n\r\nPer far questo, scegliamo uno sketch che vogliamo rendere pubblico, apriamolo e premiamo il pulsante _Edit Info_. Compiliamo i campi richiesti.\r\n\r\n![](./Schermata_2017-05-02_alle_20.32.57_lbnbtc.png)\r\n\r\n![](./Schermata_2017-05-03_alle_19.14.05_sr0nee.png)\r\n\r\nSi noti che:\r\n\r\n1. Attualemnte non disponiamo di un sistema di caricamento di immagini: l'utente dovrà caricare immagini autonomamente (consigliamo di usare [Cloudinary](http://cloudinary.com/) ed inserire il link\r\n2. I campi `long description` e `istruction` sono abilitati a ricevere testo in **Markdown**. Per un tutorial su Markdown, si veda [questo link](http://www.maffucci.it/2013/08/29/formattazione-del-testo-con-markdown/).\r\n\r\nUna volta compilati i cambi, spuntiamo il flag **is public** e salviamo.\r\n\r\nNoterete subito che lo sketch non è più modificabile. Se ora profate ad eccedere al vostro profilo pubblico, vedrete che il vostro sketch è presenta all'interno del vostro profilo.\r\n\r\n![Profilo Pubblico](./Schermata_2017-05-03_alle_19.14.29_ibixnv.png)\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-05-03-apre-hbr-community-il-nuovo-sistema-per-la-condivisione-di-progetti-robotici/index.md",
    frontMatter: {
      path: "/hbr/apre-hbr-community-il-nuovo-sistema-per-la-condivisione-di-progetti-robotici/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-05-03T07:09:39.000Z",
      publishedReadable: "3 Mag 2017",
      featured: false,
      tags: [],
      title:
        "Apre HBR Community, il nuovo sistema per la condivisione di progetti Robotici",
      description: "",
      href: "/hbr/apre-hbr-community-il-nuovo-sistema-per-la-condivisione-di-progetti-robotici/",
      image:
        "/content/hbr/2017-05-03-apre-hbr-community-il-nuovo-sistema-per-la-condivisione-di-progetti-robotici/Schermata_2017-05-03_alle_19.14.29_ibixnv.png",
      imagePath:
        "/content/hbr/2017-05-03-apre-hbr-community-il-nuovo-sistema-per-la-condivisione-di-progetti-robotici",
    },
  },
  {
    content:
      "\nDa un po' di tempo ho scoperto la bellezza ed il divertimento di implementare bot telegram, cioè chatbot automatici che possono essere programmati per rispondere in modo semplice (o complesso) a messaggi da utenti reali.\n\nChi mi segue su questo blog o su [HotBlack Robotics](http://www.hotblackrobotics.com/) sa bene che mi diletto non poco con questa tecnologia. Vi propongo oggi quindi una brevissima introduzione allo sviluppo di chatbot utilizzando _Python_ e la libreria _Telepot_.\n\n![ChatBot telegram in azione](./chatbotIntro.png)\n\n## La libreria telepot\n\nEsistono diverse api Telegram per lo sviluppo di bot telegram in Python.\nTra le più semplici, almeno dal mio punto di vista, troviamo [telepot](https://github.com/nickoala/telepot).\nQuesta libreria permette in modo semplice e veloce di implementare bot telegram semplici, anche se risulta essere complessa e poco scalabile nel caso in cui si vogliano creare bot telegram più professionali.\n\nPer installare questa libreria, basta semplicemente eseguire il comando `pip install telepot`.\n\n## Setup Ambiente di sviluppo\n\nCome sempre (e non smetterò mai di dirlo), consiglio di creare prima di tutto un ambiente virtuale python su cui lavorare.\n\nPer farlo, accediamo nel nostro workspace di lavoro e creiamo un nuovo ambiente virtuale con il seguete comando:\n\n```bash\n$ virtualenv telepot-example\n$ cd telepot-example\n$ source bin/activate\n(telepot-example)$ pip install telepot\n(telepot-example)$ mkdir project\n(telepot-example)$ cd project\n```\n\n## Creazione di un bot Telegram\n\nPer creare un bot in telegram, possiamo sfruttare il bot Telegram (scusate il gioco di parole) @BotFather, a cui si può accedere cercando semplicemente @BotFather tra le chat telegram.\n\nUna volta connessi al bot, ci basterà scrivere il comando `/newbot` e seguire le sue istruzioni per avere a di sposizione il nostro bot. In particolare, dovremmo fornire al bot le seguenti informazioni:\n\n- Nome del bot\n- username (che deve essere unico e finire con la parola \"bot\")\n\nUna volta completata la procedura, il avremmo a disposizione un nostro TOKEN univoco (attenzione, non pubblicatelo altrimenti chiunque potrà usarlo) da utilizzare per sviluppare il nostro programma.\n\n![ChatBot telegram in azione](./newbot.png)\n\n## Implementiamo il primo programma!\n\nUna volta ottenuto il token, siamo pronti a sviluppare il nostro primo bot! Questo bot semplicementemente risponderà a qualsiasi messaggio con una frase preimpostata, del tipo: \"ciao, sono un bot molto stupido!\".\n\nCreiamo un file chiamato `simple_bot.py`, apriamolo e inseriamoci il seguiente codice. Questo basta per creare il nostro semplicissimo bot!\n\n```python\nimport telepot\n\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n\nTOKEN = '*** inserisci il tuo token qui  ***'\n\nbot = telepot.Bot(TOKEN)\nbot.message_loop(on_chat_message)\n\nprint 'Listening ...'\n\nimport time\nwhile 1:\n    time.sleep(10)\n```\n\n### Analizziamo il codice passo passo\n\nVediamo adesso passo passo come funziona il codice implementato sopra:\n\nPer prima cosa, dobbiamo importare la libreria telepot all'interno del nostro programma, in modo da porterla usare in seguito.\n\n```python\nimport telepot\n```\n\nUna volta importata la libreria, possiamo andare a creare il nostro bot con questi semplici passaggi:\n\n```python\nTOKEN = '*** inserisci il tuo token qui  ***'\nbot = telepot.Bot(TOKEN)\nbot.message_loop(on_chat_message)\n```\n\nIn particolare, all'interno della variabile `TOKEN` dovremmo andare a inserire il token ritornato dal botFather (attezione, si tratta di una stringa).\n\nUna volta ottenuto il token, creiamo realmente il bot con il comando `bot = telepot.Bot(TOKEN)`.\n\nPer finire, linkiamo il bot con la funzione `on_chat_message`. Questa funzione verrà richiamata ogni qual volta il nostro bot riceve un messaggio, ed è (a tutti gli effetti), il vero cuore del nostro programma.\n\nQuesta funzione riceverà sempre un argomento, che corrisponde al messaggio che è stato inviato al bot, contenuto nel parametro `msg`:\n\n```python\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')\n```\n\nEssendo il bot semplice, anche la funzione è semplice. In particolare, all'interno di `on_chat_message`, facciamo solo 3 operazioni.\n\nPer prima cosa, estraiamo dei dati importanti dal messaggio usando il comando `content_type, chat_type, chat_id = telepot.glance(msg)`. In questo modo, creiamo 3 variabili con i seguenti significati:\n\n- `content_type` dice che tipo di dati sono contenuti nel messaggio (se un messaggio di testo, un'immagine, un messaggio vocale, o altro);\n- `chat_type` contiene informazioni sul tipo di chat: se privata, gruppo, ecc.\n- `chat_id` contiene un identificativo univoco alla chat, e può essere usato per rispondere nella stessa chat in cui è stato mandato il messaggio.\n\nCome seconda operazione, controlliamo che il messaggio che è stato mandato al robot sia di tipo testuale, andando a fare un check sul contenuto di `content_type`, con la rica `if content_type == 'text':`.\nRicordiamo infatti che il bot è stupido, e sa rispondere solo a messaggi testuale.\n\nPer finire, il bot invia sulla chat da cui è arrivato il messaggio un messaggio fisso: `bot.sendMessage(chat_id, 'ciao, sono un bot molto stupido!')`.\n\nL'utima parte del codice, serve semplicemente per evitare che il programma termini. Senza un ciclo infino, infatti, il programma terminerebbe e il bot non potrebbe rispondere alla chat.\n\n```python\nprint 'Listening ...'\n\nimport time\nwhile 1:\n    time.sleep(10)\n```\n\n### Test del programma\n\nPer testare il programma, semplicemente lanciamolo utilizzando il seguente comando:\n\n```bash\n(telepot-example)$ python simple_bot.py\n```\n\nUna volta in funzione, apriamo la chat telegram ed iniziamo a messaggiare con il nostro bot. Per chiudere il programma, semplicemente basta premere i pulsanti `ctrl-C` dal terminale.\n\n## Leggere il messaggio e le informazioni dell'utente!\n\nComplichiamo adesso leggermente il nostro piccolo bot in modo che sia in grado di ricevere informazioni sull'utente con sta chattando e i messaggi che gli arrivano.\n\nPer farlo, modifichiamo la funzione `on_chat_message` come segue (lasciando il resto inalterato):\n\n```python\ndef on_chat_message(msg):\n    content_type, chat_type, chat_id = telepot.glance(msg)\n    if content_type == 'text':\n        name = msg[\"from\"][\"first_name\"]\n        txt = msg['text']\n        bot.sendMessage(chat_id, 'ciao %s, sono un bot molto stupido!'%name)\n        bot.sendMessage(chat_id, 'ho ricevuto questo: %s'%txt)\n```\n\ncome vedete, abbiamo aggiunto le due variabili\n\n```python\nname = msg[\"from\"][\"first_name\"]\ntxt = msg['text']\n```\n\nIn cui estrapoliamo e salviamo, rispettivamente, il nome dell'utente che ha mandato il messaggio al bot e il testo del messaggio.\n\nA questo punto, usiamo queste informazioni per scrivere delle risposte dinamiche, sfruttando l'operatore speciale `%s` delle stringhe python:\n\n```python\nbot.sendMessage(chat_id, 'ciao %s, sono un bot molto stupido!'%name)\nbot.sendMessage(chat_id, 'ho ricevuto questo: %s'%txt)\n```\n\nIn particolare, utilizzando una stringa contenente la sequenza `%s` e seguita da `%variabile`, python automaticante inserirà il contenuto della variabile nella posizione in cui si trova il `%s`.\n\nL'effetto, come potete immaginare, è quello di far sembrare il bot un po' meno stupido.\n\n![ChatBot telegram in azione](./chatbot.png)\n\n## Conclusioni\n\nChe ve ne pare di questa breve guida? Siete interessati ad approfondire l'utilizzo di questa libreria? Scrivetemelo su [facebook](https://www.facebook.com/ludusrusso.cc/).\n\n## Update\n\nQuesto post ha ricevuto un notevole successo, per questo motivo, ho deciso di scrivere altri\ntutorial sull'argomento telegram.\n\nMa voglio fare qualcosa di più divertente.. Invece che pubblicare i nuovi tutorial direttamente\nsul sito, ho sviluppato un bot Telegram che vi dirà dove trovare i nuovi tutorial!\n\nProvatelo [cliccando qui](https://t.me/ludusrusso_bot)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-04-27-implementiamo-un-bot-telegram-con-python/index.md",
    frontMatter: {
      path: "/2017/04/27/implementiamo-un-bot-telegram-con-python/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2017-04-27T00:00:00.000Z",
      publishedReadable: "27 Apr 2017",
      featured: false,
      tags: ["Python", "Tutorial", "Telegram"],
      title: "Implementiamo un bot Telegram con Python",
      description:
        "Una semplice guida per iniziare a muovere i primi passi nello sviluppo di chatbot Telegram con Python",
      href: "/2017/04/27/implementiamo-un-bot-telegram-con-python/",
      image:
        "/content/blog/it/2017-04-27-implementiamo-un-bot-telegram-con-python/chatbotIntro.png",
      imagePath:
        "/content/blog/it/2017-04-27-implementiamo-un-bot-telegram-con-python",
    },
  },
  {
    content:
      "\nDopo un mio recente post, mi è stato chiesto se fosse possibile creare uno script python in grado di catturare uno screenshot dello schermo del computer. Dopo una breve ricerca ho trovato il modulo [pyscreenshot](http://pyscreenshot.readthedocs.io/en/latest/) che promette di risolvere questo problema.\n\n![main screenshot](./main.png)\n\nScrivo questo brevissimo tutorial per far vedere come è possibile, in pochissime linee di codice, scrivere un semplice programma che cattura lo schermo del computer e salva l'immagine su un file .png.\n\n## Installazione\n\nCreiamo un ambiente virtuale chiamato (ad esempio) `screen` e installiamo i due moduli python che usaremo per lo sviluppo del programma, cioè `pyscreenshot` e `image` (un modulo per la gestione delle immagini in python).\n\n```bash\n$ virtualenv screen\n$ cd screen\n$ source bin/activate\n(screen)$ pip install pyscreenshot image\n```\n\n## Utilizzo della libreria\n\nUna volta installato il tutto, creiamo un file `screensaver.py` ed inseriamoci il seguente codice:\n\n```python\nimport pyscreenshot as ImageGrab\n\nim = ImageGrab.grab()\nim.save('screenshot.png')\n```\n\nSalviamo ed eseguiamo il programma con il comando\n\n```bash\n(screen)$ screensaver.py\n```\n\ne vedremo apparire un nuovo file, nella cartella di lavoro, contenente lo screenshot del vostro computer (trovate il mio sotto).\n\n![screenshot](./screenshot.png)\n\n### Analizziamo il codice\n\nIl codice è molto semplice, ma andiamo ad analizzarlo riga per riga:\n\n- La prima riga importa il modulo `pyscreenshot` sotto il nome si `ImageGrab`. Questo viene fatto tramite il costrutto `import .. as ..`, che permette di rinominare come preferiamo in nomi dei moduli.\n\n  ```python\n  import pyscreenshot as ImageGrab\n  ```\n\n- La seconda riga cattura l'immagine dello schermo e la salva all'interno della variabile `im`\n\n  ```python\n  im = ImageGrab.grab()\n  ```\n\n- Infine, la terza riga salva l'immagine contenuta nella variabile `im` all'interno del file `screenshot.png`.\n\n      ```python\n\n  im.save('screenshot.png')\n\n  ```\n\n  ```\n\n## Conclusioni\n\nCome potete vedere, questa libreria è veramente semplice da usare, però abilita tantissime possibilità se usata in modo adeguato.. Avete qualche idea su cosa farci? Scrivetemi su [Facebook](https://www.facebook.com/ludusrusso.cc/).\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-04-27-pillole-di-python-pyscreenshot/index.md",
    frontMatter: {
      path: "/2017/04/27/pillole-di-python-pyscreenshot/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-04-27T00:00:00.000Z",
      publishedReadable: "27 Apr 2017",
      featured: false,
      tags: ["Python", "Pillole", "Pyscreenshot"],
      title: "Pillole di Python: pyscreenshot",
      description:
        "Una semplice tutorial che mostra il funzionamento della libreria pyscreenshot",
      href: "/2017/04/27/pillole-di-python-pyscreenshot/",
      image:
        "/content/blog/it/2017-04-27-pillole-di-python-pyscreenshot/main.png",
      imagePath: "/content/blog/it/2017-04-27-pillole-di-python-pyscreenshot",
    },
  },
  {
    content:
      "\n![vagrant](./687474703a2f2f6572696b6168656964692e636f6d2f7468656d652f6661746361747a2f696d616765732f76616772616e742f6c6f676f5f76616772616e742e706e67.png)\n\nScrivo questo post come introduzione all'utilizzo di Vagrant per la gestione di Macchine virtuali. Ho scoperto Vagrant qualche mese fa e mi è subito sembrato un ottimissimo tool per gestione progetti e per muovere i primi passi con Linux senza necessariamente avere un computer Linux e senza dover usare Macchine Virtuali con interfaccia grafica.\n\n## Perchè Vagrant?\n\nLa risposta è molto semplice.. Da anni lavoro spesso con macchine virtuali (solitamente Linux) su host diversi, per vari motivi ma principalmente per fare prove senza dover necessariamente tirare su una partizione o un nuovo computer.\n\nUtilizzare VirtualBox è la soluzione migliore. Ciò che però odio di VirtualBox è la necessità di tirare su anche l'interfaccia grafica per lavorare con la macchina virtuale, cosa molto scomoda per chi lavora principalmente da terminale come il sottoscritto. Il problema quindi è dovuto al fatto che devo editare file con un editor di testo sulla macchina virtuale...\n\nIn questo contesto ci aiuta Vagrant. Questo progetto ha tantissime features che ancora non uso, ma ce ne sono alcune che lo rendono per me super interessante:\n\n- creare e gestire macchine virtuali da linea di comando in modo semplice e veloce\n- condivere immagini di macchine virtuali\n- lavorare sulla macchina virtuale via terminale per mezzo di SSH\n- gestione semplificata di una cartella condivisa per editare file da host (e non da macchina virtuale).\n\n### Scopo di questo tutorial\n\nLo scopo del tutorial è il seguente:\n\n- mostrare come installare Vagrant\n- proporre un esempio del normale utilizzo di Vagrant\n\n## Installazione\n\nL'installazione di Vagrant è estramemente semplice, per farlo, basta scaricare il pacchetto per il vostro sistema operativo da [qui](https://www.vagrantup.com/downloads.html), e seguire la procedura di installazione.\n\n![installazione vagrant 1](./install1.png)\n![installazione vagrant 2](./install2.png)\n\nIn alcuni casi, sarà necessario installare manualmente anche virtualbox, che può essere scaricato da [qui](https://www.virtualbox.org/).\n\n## Utilizzo\n\nVeniamo al cuore di questo tutorial. La mia idea è di installare una macchina virtuale contenente Ubuntu 16.06 (Xenial) e poi giorcarci un po' per farci girare una semplice applicazione in Flask.\n\nPer un elenco di macchine virtuali disponibili, potete accedere a [questo link](https://atlas.hashicorp.com/boxes/search), messo a disposizione dagli sviluppatori di Vagrant. Ad ogni modo, online si trovano tantissime altre immagini disponibili.\n\n### Installazione macchina virtuale\n\nPer vagrant, ogni macchina virtuale corrisponde ad una cartella nel nostro computer. Iniziamo quindi a creare uno spazio di lavoro in cui mettere le nostre macchine virtuali, io solitamente lavoro all'interno di una cartella chiamata `~/develop` e, per l'occasione, ho creato una cartella chiamata `~/develop/vagrant_machines` in cui mettere le nostre macchine virtuali.\n\nAccediamo quindi alla cartella e creiamo una nuova cartella chiamata `ubuntu-xenial64` in cui metteremo la nostra macchina.\n\n```shell\n$ cd ~/develop/vagrant_machines\n$ mkdir ubuntu-xenial64\n$ cd ubuntu-xenial64\n```\n\nUna volta all'interno della cartella, lanciamo il comando per la creazione della nostra macchia virtuale:\n\n```shell\n$ vagrant init ubuntu/xenial64\n```\n\nil cui output sarà il seguente:\n\n```shell\nA `Vagrantfile` has been placed in this directory. You are now\nready to `vagrant up` your first virtual environment! Please read\nthe comments in the Vagrantfile as well as documentation on\n`vagrantup.com` for more information on using Vagrant.\n```\n\nIn questo modo, abbiamo creato un file chiamato `Vagrantfile` all'interno della nostra cartella. Questo file indica le varie impostazioni della macchina. Per ora non ci interessa troppo il suo contenuto e quindi possiamo semplicemente tenerlo così come è.\n\nPer info, il suo contenuto (a parte i commenti) è il seguente:\n\n```\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"ubuntu/xenial64\"\nend\n```\n\n### Lanciamo la macchina virtuale\n\nA questo punto, siamo pronti per far partire la nostra macchina virtuale. Per farlo, basta eseguire il comando\n\n```shell\n$ vagrant up\n```\n\nQuesto comando controlla che all'interno della cartella in cui viene lanciato esista un file `Vagrantfile`, ed esegue tutte le istruzioni per far partire la macchiana virtuale secondo le istruzioni che esso contiene.\n\nLa prima volta che viene eseguito il comando, impiegherà qualche minuto, in quanto deve scaricare la macchina virtuale ed installarla. Le altre volte, sarà molto veloce in quanto dovrà solamente far partire la macchiana virtuale.\n\nUna volta terminata la procedura, la macchina virtuale sarà funzionante e pronta per essere utilizzata. Notate inoltre che è stata creata una cartella nascosta nella nostra cartella di lavoro chiamata `.vagrant`. Al suo interno è contenuta l'immagine della macchina virtuale e tutti i file ad essa associata.\n\n### Giochiamo con Vagrant\n\nAdesso vediamo alcuni comandi base di Vagrant per gestire la macchina virtuale.\n\n- `vagrant status` vi da informaizoni sulla macchina virtuale attuale (nella cartella in cui vi trovate).\n\n  ```bash\n  $ vagrant status\n  Current machine states:\n\n  default                   running (virtualbox)\n\n  The VM is running. To stop this VM, you can run `vagrant halt` to\n  shut it down forcefully, or you can run `vagrant suspend` to simply\n  suspend the virtual machine. In either case, to restart it again,\n  simply run `vagrant up`.\n  ```\n\n- `vagrant global-status` è molto utile se avete più di una macchiana virtuale Vagrant da gestire, in quanto vi da informazioni su tutte le macchine installate sul vostro computer\n\n  ```bash\n  $ vagrant global-status\n  id       name    provider   state    directory\n  -----------------------------------------------------------------------------------------\n  f8b13dd  default virtualbox saved    /Users/ludus/code/projects/dotbot/vagrant\n  96c2ff0  default virtualbox aborted  /Users/ludus/code/dotbot_ws/emulations/dotbot_emu1\n  9b1f914  default virtualbox poweroff /Users/ludus/code/virtualmachines/ubuntu_ros\n  85e93d5  default virtualbox poweroff /Users/ludus/code/virtualmachines/cloud_platform\n  6ff7199  default virtualbox running  /Users/ludus/develop/vagrant_machines/ubuntu-xenial64\n\n  The above shows information about all known Vagrant environments\n  on this machine. This data is cached and may not be completely\n  up-to-date. To interact with any of the machines, you can go to\n  that directory and run Vagrant, or you can use the ID directly\n  with Vagrant commands from any directory. For example:\n  \"vagrant destroy 1a2b3c4d\"\n  ```\n\n- `vagrant suspend` e `vagrant halt` servono rispettivamente per sospendere e spegnere la nostra macchina virtuale.\n- `vagrant reload` riavvia la macchiana virtuale.\n- `vagrant destroy` serve per cancellare definitivamente la macchina (non eseguite questo comando a meno che non siate certi di quello che fate).\n\n### Accediamo alla macchina virtuale tramite SSH\n\nOk perfetto, a questo punto siamo pronti ad accedere alla macchina virtuale. Per prima cosa, controlliamo che la macchina sia accesa, eseguendo il `vagrant status`. Se la macchina non risulta in _running_, allora accendiamola col comando `vagrant up`.\n\n![Vagrant ssh](./sshpng.png)\n\nPer accedere quindi alla macchina virtuale, basta eseguire il comando `vagrant ssh`, che automaticamente porterà la shell all'interno della macchina tramite protocollo SSH.\n\nUna volta eseguito questo comando, infatti, accederemo alla nuova shell di Ubuntu, saremo quindi nella nostra macchina virtuale.\n\nPer uscire dalla macchina, basta eseguire il comando `exit` o premere ctrl+D.\n\n## Creiamo un server Web in Flask sulla macchina virtuale\n\nA questo punto, siamo pronti per sfruttare la macchina virtuale per implementare un semplicissimo server flask.\n\nPer prima cosa, dobbiamo installare le dipendenze e creare il nostro ambiente virtuale su cui lavorare.\n\nInstalliamo `pip` usando il comando linux `apt-get` e poi installiamo `virtualenv` usando pip.\n\n```bash\n$ sudo apt-get install python-pip\n$ sudo pip install virtualenv\n```\n\n### Cartella condivisa con l'Host\n\nA questo punto, possiamo creare il nostro ambiente virtuale e iniziare ad implementare il server in flask. Per prima cosa, però, vorrei far notare una delle più importanti features in Vagrant che migliorerà notevolmente la vostra produzione.\n\nIn particolare, all'interno della macchina virtuale che abbiamo creato, esiste una cartella (chiamata `/vagrant`) che è esattamente la stessa cartella su cui si trova il nostro `VagrantFile` nell'host.\n\nPer fare una prova, creiamo dei file all'interno di questa cartella, e vedrete che questi magicamente appariranno anche nella cartella principale.\n\nQuel è il vantaggio? Semplice, possiamo lavorare all'interno di questa cartella con un editor di testo sul computer principale e con il terminale sulla macchina virtuale (in questo modo, l'editor che usiamo per lavorare non deve essere un editor virtualizzato).\n\nScegliete l'editor di testo che preferite, io mi trovo molto bene con [Atom](https://atom.io/).\n\nPer iniziare a lavorare, quindi, apriamo atom nella cartella `~/develop/vagrant_machines/ubuntu-xenial64` e posizioniamoci all'interno della cartella `/vagrant` dalla macchina virtuale\n\n```bash\n$ cd /vagrant\n```\n\n### Creazione di un ambiente virtuale e installazione dipendenze\n\nAll'interno della cartella condivisa, creiamo un nuovo ambiente virtuale, digitando\n\n```\n$ virtualenv server-flask\n```\n\nQuesto comando, creerà una nuova cartella chiamata `server-flask`. Accediamoci e attiviamo il virtual env\n\n```bash\n$ cd server-flask/\n$ source bin/activate\n```\n\nUna volta eseguito questo comando, apparirà all'inizio della nuova riga della shell, la scritta `(server-flask)`, ad indicare che ci troviamo all'interno dell'ambiente virtuale.\n\nA questo punto, installiamo Flask usando pip (senza sudo).\n\n```bash\n(server-flask)$ pip install flask\n```\n\nPer finire, creiamo una cartella chiama `project` in cui sviluppare il nostro server, e accediamo a questa cartella:\n\n```bash\n(server-flask)$ mkdir project\n(server-flask)$ cd project/\n```\n\n### Sviluppo di un semplicissimo webserver in Flask\n\nUna volta creata la cartella, possiamo accedere ad essa dalla macchina principale e lavorare direttamente da li con il nostro editor di testo (e ambiente di sviluppo) preferito.\n\nUtilizzando Atom (nel mio caso) creiamo un file chiamato `server.py` all'interno della cartella `project` e inseriamo il seguente codice:\n\n```python\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route('/')\ndef hello_world():\n    return '<h1>Ciao, sono un server virtuale!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True, host='0.0.0.0')\n```\n\nQuesto semplicissimo server flask risponde all'indirizzo principale con la stringa html `<h1>Ciao, sono un server virtuale!</h1>`.\n\nPer eseguirlo, da macchina virtuale, basta lanciare il comando\n\n```bash\n(server-flask)$ python server.py\n```\n\n![Vagrant ssh](./run.png)\n\n### Configurare una rete virtuale per l'accesso alla macchina da host\n\nPrima di testare l'applicazione, dobbiamo fare in modo che la macchina virtuale sia raggiungibile dall'host. Per fare questo, dobbiamo configurare vagrant in modo da creare una rete privata.\n\nCon vagrant questo è semplicissimo, basta modificare il `Vagrantfile` aggiungendo la stringa\n\n```ruby\nconfig.vm.network \"private_network\", ip: \"192.168.33.10\"\n```\n\nIn modo che il file (tolti i commenti) sia come segue\n\n```ruby\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"ubuntu/xenial64\"\n  config.vm.network \"private_network\", ip: \"192.168.33.10\"\nend\n```\n\nIn particolare, in questo modo, diciamo a vagrant di creare una rete condivisa con l'host e di assegnare come indirizzo ip alla macchina virtuale l'ip `192.168.33.10` (ovviamente potete scegliere un ip diverso).\n\nA questo punto, è necessario riavviare la macchina per permettere a vagrant di aggiornare le impostazioni:\n\n- Eseguiamo il logout dalla macchina virtuale con il comando `exit`\n- riavviamo la macchina con `vagrant reload`\n- riaccendiamo alla macchina con `vagrant ssh`\n- lanciamo il server, eseguendo i seguenti comandi\n\n  ```bash\n  $ cd /vagrant/server-flask/\n  $ source bin/activate\n  (server-flask)$ cd project\n  (server-flask)$ python server.py\n  ```\n\nUna volta partito, apriamo un browser qualsiasi e accediamo all'url `http://192.168.33.10:5000`.\n\nSe tutto va bene, dovreste vedere il server ed otterrete la seguente pagina web.\n\n![Vagrant ssh](./site.png)\n\n## Conclusioni\n\nQuesto è un banalissimo esempio di cosa si può fare con Vagrant.. Ovviamente quello fatto qui si può benissimo fare con una qualsiasi macchina, senza dover necessariamente virtualizzare. Ma ci sono ben due vantaggi non da poco:\n\n1. Si può lavorare su un ambiente che è sempre uguale indipendentemente dalla macchina che si possiede (quindi possiamo sviluppare sempre Linux su una qualsiasi macchina, anche Mac o Windows).\n2. Quello che facciamo non intaccherà il nostro SO, quindi possiamo fare tutte le cose che vogliamo (compreso cancellare interamente il filesystem per sbaglio) senza però avere l'ansia di aver rovinato qualcosa sul nostro computer principale.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-04-25-introduzione-a-vagrant/index.md",
    frontMatter: {
      path: "/2017/04/25/introduzione-a-vagrant/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "9 mins",
      published: "2017-04-25T00:00:00.000Z",
      publishedReadable: "25 Apr 2017",
      featured: false,
      tags: ["Vagrant", "Tutorial", "Linux"],
      title: "Gestire le macchine virtuali senza sforzo con Vagrant",
      description:
        "Introduzione ed esempio di utilizzo su Vagrant, il tool che semplifica la gestione delle macchine virtuali per lo sviluppo.",
      href: "/2017/04/25/introduzione-a-vagrant/",
      image:
        "/content/blog/it/2017-04-25-introduzione-a-vagrant/vagrant-logo-800px.jpg",
      imagePath: "/content/blog/it/2017-04-25-introduzione-a-vagrant",
    },
  },
  {
    content:
      "\nA poche ore dal corso che ho tenuto ieri al mio vecchio Liceo, già iniziano ad nascere progetti interessanti dei partecipanti. Alcuni ragazzi, in particolare, mi hanno stupito, in quanto in pochissimo tempo e con poco supporto sono riusciti a realizzare un bot telegram in grado di mandare comandi ad Arduino.\n\n<iframe width=\"100%\" height=\"400px\" src=\"https://www.youtube-nocookie.com/embed/PHGNhq8j1JU\" frameborder=\"0\" allowfullscreen></iframe>\n\nHo chiesto loro di scrivere questo breve tutorial per realizzare il progetto.\n\n## Tutorial: realizzare un bot telegram per controllare Arduino\n\nOrmai sono veramente tanti i progetti realizzati con Arduino, e una delle cose a mio giudizio più interessanti è la possibilità di attivare Arduino a distanza tramite dispositivi mobili. Così, in occasione di un corso tenuto al liceo G. Stampacchia di Tricase da Ludovico Russo, ho iniziato a programmare un bot su Telegram che facesse accendere o spegnere vari led ad Arduino, perfezionandolo poi a casa.\n\nIl risultato che ho ottenuto mi ha molto soddisfatto, anche perchè sono riuscito a rimediare a delle piccole imperfezioni che avevo riscontrato all'inizio e che non mi piacevano. Scriverò quindi questo tutorial per spiegarvi di preciso cosa e come ho fatto.\n\n### 1. Cosa serve\n\n- Arduino UNO\n- cavo USB per Arduino\n- breadboard\n- 4 LED di colori diversi (blu, rosso, giallo, verde)\n- 4 resistenze da 330Ω\n- 5 jumper\n- l'IDE Arduino, scaricabile da [qui](https://www.arduino.cc/en/main/software)\n- la piattaforma Anaconda, scaricabile da [qui](https://www.continuum.io/downloads)\n- il firmware nanpy di Ludovico, scaricabile da [qui](https://github.com/ludusrusso/nanpy-firmware)\n- l'app Telegram\n\n### 2. Come collegare le varie componenti\n\nLo schema per collegare tutte le componenti ad Arduino è il seguente:\n![alt text](./telegram_ele.jpeg)\n\n### 3. Come preparare Arduino\n\nBasta aprire il file nanpy-firmware-master/Nanpy/Nanpy.ino dalla cartella del firmware nanpy con l'IDE Arduino e caricarlo su Arduino UNO.\n\n### 4. Come creare il bot di Telegram\n\nQuesta fase si divide in due parti: la prima va fatta dal dispositivo su cui c'è installata l'app di Telegram, la seconda dal computer su cui si è installato Anaconda.\n\n#### 4.1 Da dispositivo\n\nBisogna cercare su Telegram il bot BotFather e avviarlo.\n\nTramite il comando `/newbot` si avvierà la procedura di creazione che consiste nel dare un nome ed uno username (quest'ultimo deve essere univoco) al bot. BotFather invierà quindi un codice, detto token, che noi potremmo in seguito usare per modificare il bot stesso.\n\n#### 4.2 Da computer\n\nAprire Anaconda Navigator (che non useremo direttamente) e Spyder, su cui scriveremo il codice vero e proprio.\nSe è la prima volta che si usa Spyder, bisogna installare la libreria nanpy. Per fare ciò è sufficiente inserire nella IPython console (in basso a destra) il codice\n\n```sh\n! pip install telepot nanpy\n```\n\nUna volta installata, viene la parte di vera e propria programmazione (in Python). Bisogna infatti scrivere nell'editor principale di Spyder il codice che detta il comportamento del bot. nel nostro caso il codice è questo:\n\n```sh\nimport telepot\nimport time\nfrom nanpy import ArduinoApi, SerialManager\nfrom telepot.namedtuple import InlineKeyboardMarkup, InlineKeyboardButton\n\n\nconnection = SerialManager(device='COM3') #eventualmente cambiare la porta COM3\na = ArduinoApi(connection=connection)     #con quella effettivamente usata\na.pinMode(12, a.OUTPUT)\na.pinMode(11, a.OUTPUT)\na.pinMode(10, a.OUTPUT)\na.pinMode(9, a.OUTPUT)\n\ndef on_chat_message(msg): #crea la tastiera personalizzata\n    content_type, chat_type, chat_id = telepot.glance(msg)\n\n    keyboard = InlineKeyboardMarkup(inline_keyboard=[[InlineKeyboardButton(text=\"Blu\", callback_data='/blu'), InlineKeyboardButton(text=\"Rosso\", callback_data='/rosso')],\n                                     [InlineKeyboardButton(text=\"Verde\", callback_data='/verde'), InlineKeyboardButton(text=\"Giallo\", callback_data='/giallo')]])\n\n    bot.sendMessage(chat_id, 'Premi un pulsante per cambiare lo stato del led corrispondente', reply_markup=keyboard)\n\n\ndef on_callback_query(msg): #aziona i vari LED in base al pulsante toccato\n    query_id, from_id, query_data = telepot.glance(msg, flavor='callback_query')\n    print('Callback Query:', query_id, from_id, query_data)\n\n    if query_data == '/blu':\n         if a.digitalRead(12)==0:\n                a.digitalWrite(12, 1)\n                bot.answerCallbackQuery(query_id, text='Blu acceso')\n         else:\n                    a.digitalWrite(12, 0)\n                    bot.answerCallbackQuery(query_id, text='Blu spento')\n    elif query_data == '/rosso':\n                        if a.digitalRead(11)==0:\n                            a.digitalWrite(11, 1)\n                            bot.answerCallbackQuery(query_id, text='Rosso acceso')\n                        else:\n                            a.digitalWrite(11, 0)\n                            bot.answerCallbackQuery(query_id, text='Rosso spento')\n\n    elif query_data == '/verde':\n            if a.digitalRead(10)==0:\n                a.digitalWrite(10, 1)\n                bot.answerCallbackQuery(query_id, text='Verde acceso')\n            else:\n                a.digitalWrite(10, 0)\n                bot.answerCallbackQuery(query_id, text='Verde spento')\n\n    elif query_data == '/giallo':\n            if a.digitalRead(9)==0:\n                a.digitalWrite(9, 1)\n                bot.answerCallbackQuery(query_id, text='Giallo acceso')\n            else:\n                a.digitalWrite(9, 0)\n                bot.answerCallbackQuery(query_id, text='Giallo spento')\n\n\nbot=telepot.Bot('*inserire il token del proprio bot*')\nbot.message_loop({'chat': on_chat_message,\n                  'callback_query': on_callback_query})\nprint ('Listening ...')\n\nwhile 1:\n    time.sleep(10)\n\n```\n\nA questo punto bisogna eseguire il file e, se tutto è andato bene, il bot di Telegram farà accendere e spegnere i LED che vogliamo notificandoci di volta in volta cosa è successo con l'ultima azione.\n\nEcco un esempio di chat il con bot\n\n![chat con il bot](./telegram_ui.jpeg)\n\n## Autori\n\n- Matteo Protopapa\n- Giuseppe Galilei\n- Gianvito Marzo\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-04-15-accendere-led-con-arduino-e-telegram/index.md",
    frontMatter: {
      path: "/2017/04/15/accendere-led-con-arduino-e-telegram/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-04-15T00:00:00.000Z",
      publishedReadable: "15 Apr 2017",
      featured: false,
      tags: ["Stampacchia", "Arduino", "Telegram", "Python"],
      title: "Accendere led con Arduino e Telegram",
      description:
        "Un bot telegram in grado di controllare Arduino realizzato da 3 ragazzi del Liceo Stampacchia",
      href: "/2017/04/15/accendere-led-con-arduino-e-telegram/",
      image:
        "/content/blog/it/2017-04-15-accendere-led-con-arduino-e-telegram/telegram_esempio.png",
      imagePath:
        "/content/blog/it/2017-04-15-accendere-led-con-arduino-e-telegram",
    },
  },
  {
    content:
      "\nÈ stato veramente divertente aver organizzato e tenuto il mio primo corso di Arduino nella mia vecchia scuola, il Liceo G. Stampacchia di Tricase.\n\n![](./429839548_15180008906508156947.jpg)\n\nTantissimo l'interesse e l'entusiamo dei partecipanti, non solo studenti ma anche professori sia del liceo che di scuola primaria.\n\nTantissimi anche i progetti e le idee dei partecipanti che, dopo poche ore di introduzione ad Arduino, sono riusciti in pochissimo tempo e realizzare!\n\nUn grandissimo ringraziamento va al dirigente scolastico Mauro Polimeno, che ci ha dato l'opportunità e gli spazi per organizzare il corso, e ad Andrea Rizzo per avermi aiutato durante tutta la giornata di ieri.\nE un grazie a tutti i partecipanti per l'entusiasmo dimostrato!!\n\n![](./430509668_5099670742256406301.jpg)\n\n![](./430517112_13201974008426520802.jpg)\n\n![](./430528938_9303448935594151752.jpg)\n\n![](./IMG_2349.JPG)\n![](./IMG_2350.JPG)\n![](./IMG_2351.JPG)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-04-15-corso-arduino-al-liceo-stampacchia-grazie-a-tutti/index.md",
    frontMatter: {
      path: "/2017/04/15/corso-arduino-al-liceo-stampacchia-grazie-a-tutti/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-04-15T00:00:00.000Z",
      publishedReadable: "15 Apr 2017",
      featured: false,
      tags: ["Stampacchia", "Corso", "Arduino"],
      title: "Corso Arduino al Liceo Stampacchia - Grazie a tutti",
      description: "",
      href: "/2017/04/15/corso-arduino-al-liceo-stampacchia-grazie-a-tutti/",
      image:
        "/content/blog/it/2017-04-15-corso-arduino-al-liceo-stampacchia-grazie-a-tutti/429839548_15180008906508156947.jpg",
      imagePath:
        "/content/blog/it/2017-04-15-corso-arduino-al-liceo-stampacchia-grazie-a-tutti",
    },
  },
  {
    content:
      '\r\nIn occasione della Cloud Roker Faire, vogliamo proporre un evento in cui makers un po\' più skillati si riuniscono per costruire un robot funzionante a partire da oggetti di recupero.\r\n\r\n## Come funziona\r\n\r\nDomenica 7 maggio, chiunque si senta un maker esperto, è il benvenuto all\'evento **Hackeriamo oggetti per costruire un robot**. Ogni partecipante deve portare almeno uno tra i seguenti componenti:\r\n\r\n- Scheda Arduino\r\n- Scheda Raspberry\r\n- Sersori Random\r\n- Attuatori Random\r\n- Oggetti quali Scatole, bottiglie ecc...\r\n- Nastro adesivo\r\n- Strumenti e Attrezzi vari\r\n\r\nAvremo a disposizione un tavolo abbastanza largo su cui poter lavorare, con lo scopo di _montare cose a caso_ per realizzare un robot autonomo connesso alla cloud.\r\n\r\nAlla fine dell\'evento, il progetto verrà presentato al pubblico!\r\n\r\nPer partecipare, basta compilare questo google form:\r\n\r\n<a type="button" href="https://goo.gl/forms/Km0XwYWtqt30OdQC2" class="btn btn-bg btn-default"> Partecipa all\'evento</a>\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-04-13-hackeriamo-oggetti-per-costruire-un-robot-completo/index.md",
    frontMatter: {
      path: "/hbr/hackeriamo-oggetti-per-costruire-un-robot-completo/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-04-13T06:59:40.000Z",
      publishedReadable: "13 Apr 2017",
      featured: false,
      tags: [],
      title: "Hackeriamo oggetti per costruire un robot completo",
      description: "",
      href: "/hbr/hackeriamo-oggetti-per-costruire-un-robot-completo/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-04-13-hackeriamo-oggetti-per-costruire-un-robot-completo",
    },
  },
  {
    content:
      "\r\nIn questo tutorial, vedremo molto brevemente come utilizzare la raspicam tramite il robot dotbot e fare streaming dell'immagine tramite ROS e la piattaforma cloud.\r\n\r\nQuesta funzione è ancora in stato di test, quindi qualcosa potrebbe non funzionare. Nel caso, contattateci a **info@hotblackrobotics.com**.\r\n\r\n## Connettere la RaspiCam\r\n\r\nPer prima cosa, è impostante connettere la raspicam al DotBot. Essa deve essere connessa sull'adatattore del raspberry recante la scritta _camera_, **con il Raspberry Pi spento**, come mostrato in foto\r\n\r\n![Connessione Camera](./maxresdefault.jpg)\r\n\r\nState attenti a posizionare la linguetta colorata orientata verso le USB!\r\n\r\n## Gestore RapiCam\r\n\r\nIl driver ROS che gestisce la camera è normalmente disabilitato. Per abilitarlo, per prima cosa bisogna connettersi al robot ramite piattaforma.\r\n\r\n![Connessione al Robot](./connessione.png)\r\n\r\nQuindi accedere al tab _APPS > Raspicam_\r\n\r\n![Accedere al tab raspicam](./webapp.png)\r\n\r\nE finalmente saremo entrati nella nostra pagina di gestione, che avrà questa forma:\r\n\r\n![Raspicam Manager](./gestore.png)\r\n\r\n### Abilitare il Nodo ROS-CAMERA\r\n\r\nA questo punto, dobbiamo premere sul bottone _Apri Manager Robot_, che aprirà una nuova schermata chiedendovi di inserire Nome e Password. Inserite i seguenti campi:\r\n\r\n- nome: test\r\n- password: test\r\n\r\n![Login DotBot Manager](./login.png)\r\n\r\nNella schermata aperta, dobbiamo quindi abilitare il nodo **ros-camera**, cliccando sul pulsante _start_ ad esso rifertio.\r\n\r\n![Start Camera DotBot Manager](./start.png)\r\n\r\nUna volta premuto il pulsante, vedrete che lo stato del nodo diventerà **running**.\r\n\r\n![Started Camera DotBot Manager](./started.png)\r\n\r\n### Far partire lo streaming\r\n\r\nAnche se il nodo è in running, non è ancora possibile vedere la camera, perchè questa aspetta di essere attivata prima di funzionare. Per farlo, dal manager della camera, premiamo il pulsante **start camera**.\r\n\r\n![Pulsante Start Camera](./gestore-start.png)\r\n\r\nE se tutto va bene, vedrete apparire streaming video della camera in funzione.\r\n\r\n![Streaming Camera](./streaming.png)\r\n\r\nPer stoppare la telecamera, a questo punto, basta premere il pulsante **stop camera**.\r\n\r\n## RapiCam da ROS Console\r\n\r\nUna volta lanciato il nodo ros-camera e lanciato lo streaming, sarà possibile accedere al topic della telecamera da ROS, e quindi sviluppare applicazioni di Computer Vision.\r\n\r\nLo streaming video della camera sarà anche visibile dalla ROS console, abilitando il topic `/camera/image`.\r\n\r\n![Topic Camera Image](./console.png)\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-04-10-utilizzare-la-raspicam-in-streaming-con-la-piattaforma-cloud/index.md",
    frontMatter: {
      path: "/hbr/utilizzare-la-raspicam-in-streaming-con-la-piattaforma-cloud/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-04-10T17:01:19.000Z",
      publishedReadable: "10 Apr 2017",
      featured: false,
      tags: [],
      title: "Utilizzare la RaspiCam in streaming con la piattaforma Cloud",
      description:
        "Breve tutorial che spiega come abilitare la RaspiCam su ROS e la piattaforma di Cloud Robotics",
      href: "/hbr/utilizzare-la-raspicam-in-streaming-con-la-piattaforma-cloud/",
      image:
        "/content/hbr/2017-04-10-utilizzare-la-raspicam-in-streaming-con-la-piattaforma-cloud/streaming.png",
      imagePath:
        "/content/hbr/2017-04-10-utilizzare-la-raspicam-in-streaming-con-la-piattaforma-cloud",
    },
  },
  {
    content:
      "\nQuesta breve introduzione a Spyder è scritta come supporto per il corso _Costruiamo un Laboratorio di Fisica con Arduino e Python_ tenuto durante Pycon8 a Firenze il 6 Aprile 2017. È mia intenzione ampliare e completare questa guida appena avrò un po' di tempo.\n\n## Spyder\n\nSpyder è un IDE per la programmazione scientifica che fa parte per tool Anaconda. È completamente basato in Python è può essere installato in modo semplice installando Anaconda [questo link](https://www.continuum.io/downloads).\n\n## PyLab\n\nSpyder viene installato insieme a Pylab, un modulo python molto utile per la programmazione scientifica e il plot di dati su un grafico.\n\nPer abilitare PyLab all'avvio di Spyder (in modo da non doverlo importare manualmente ogni volta) basta abilitarlo da importazioni, accedendo (da barra dei menu) a **Tool > Preference** e selezionando il pannello **IPython Console > Graphics**, e abilitando _Automatically load PyLab and Numpy Modules_.\n\nDallo stesso pannello, conviene anche selezionare (sotto la voce _backend_) il tool grafico **Qt5**, che permette una migliore visualizzazione dei dati.\n\nA questo punto, è necessario riavviare Spyder per abilitare le impostazioni.\n\n## Utilizzo di Spyder per disegnare i dati su un grafico 2D\n\nPer disegnare dei dati, è ovviamente necessario prima di tutto crearli. Nei corsi che faccio, solitamente questi dati vengono misurati da un sistema di campionamento reale, tuttavia in questo corso genereremo questi dati direttamente da Python.\n\n### Generare dati in Python\n\nPer disegnare un grafico 2D, servono due serie numeriche, una per l'asse delle ascisse ($x$) e una per l'asse delle ordinate ($y$). Utilizzeremo il comando `arange` per ottenere una serie di numeri su un intervallo con campionamento regolare. Se, ad esempio, vogliamo generare una serie di dati nell'intervallo $[-1 ,  1]$ con passo di campionamento di $0.01$, useremo il comando\n\n```python\nx = arange(-1,1,0.01)\n```\n\nAndiamo poi a generare la serie per l'asse $y$. Facciamo in modo di disegnare la bisettrice di primo e terzo quadrante, che si ottiene dalla banalissima equazione $y=x$. In Spyder, basta digitare\n\n```python\ny = x\n```\n\n### Il comando `plot`\n\nA questo punto, possiamo disegnare i nostri dati usando il comando `plot`, come segue\n\n```python\nplot(x,y)\n```\n\nChe aprirà una finestra con il grafico che abbiamo realizzato.\n\n![Esempio Plot](./plot-retta.png)\n\n### Dare un titolo al grafico e dei nomi agli assi\n\nIl grafico realizzato non è ovviamente dei migliori. In Spyder, possiamo però anche dare un titolo al grafico e agli assi, in modo da dare informazioni al lettore su che tipo di dati sta visualizzando. Per fare questo, useremo i comandi `title`, `xlabel` e `ylabel`.\n\nPer fare questo, ritorniamo alla finestra di Spyder **senza chiudere la finestra dell'immagine**, e digitiamo i seguenti comandi\n\n```python\ntitle('Esempio di un semplice grafico in Spyder')\nxlabel('Ascisse (x)')\nylabel('Ordinate (y)')\n```\n\nSe ritorniamo alla finestra del grafico, vedremo che questo è cambiato in accordo con i nostri comandi.\n\n![Esempio labels e titolo](./titlexy.png)\n\n### Stile del disegno\n\nSpyder permette anche di disegnare i grafici con stile diversi, sia per questione estetiche, ma anche per diversificare diverse linee che vengono visualizzate sullo stesso grafico.\n\nPer dimostrare questo, creiamo altre due serie di punti, per disegnare le funzioni $y=x^2$ e $y=x^3$. Ricordate che in python, l'operatore _elevamento a potenza_ è rappresentato dal simbolo `**`.\n\n```python\ny2 = x**2\ny3 = x**3\n```\n\nOgni linea disegnata com plot può avere un marker e un colore. I colori si indicato con una lettera, ad esempio `r` sta per _rosso_, `k` sta per _nero_, ecc.\nI maker si indicato con uno o più simboli, ad esempio `--` sta per _tratteggiato_ e `.` sta per _puntinato_. Trovare [qui tutti i colori disponibili](http://matplotlib.org/api/colors_api.html) e [qui tutti i maker disponibili](http://matplotlib.org/api/markers_api.html).\n\nVediamo come utilizzare i maker. Torniamo nuovamente alla finestra di Spyder (senza chiudere quella del grafico), e disegniamo la parabola in rosso tratteggiato e la cubica in blu puntinato:\n\n```python\nplot(x,y2, 'r--')\nplot(x,y3, 'b.')\n```\n\n![Esempio marks](./marks.png)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-04-06-breve-introduzione-all-utilizzo-di-spyder-per-il-plot-dei-dati-a-livello-scientifico/index.md",
    frontMatter: {
      path: "/2017/04/06/breve-introduzione-all-utilizzo-di-spyder-per-il-plot-dei-dati-a-livello-scientifico/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2017-04-06T00:00:00.000Z",
      publishedReadable: "6 Apr 2017",
      featured: false,
      tags: ["Fisica", "Spyder", "Plot"],
      title:
        "Breve Introduzione all'utilizzo di Spyder per il Plot dei dati a livello scientifico",
      description:
        "Una brevissima guida che mostra come utilizzare Spyder per il plot dei dati a livello scientifico",
      href: "/2017/04/06/breve-introduzione-all-utilizzo-di-spyder-per-il-plot-dei-dati-a-livello-scientifico/",
      image:
        "/content/blog/it/2017-04-06-breve-introduzione-all-utilizzo-di-spyder-per-il-plot-dei-dati-a-livello-scientifico/marks.png",
      imagePath:
        "/content/blog/it/2017-04-06-breve-introduzione-all-utilizzo-di-spyder-per-il-plot-dei-dati-a-livello-scientifico",
    },
  },
  {
    content:
      '\nQuesto post è da supporto al mio intervento del 6 Aprile alla conferenza [PyCon8](https://www.pycon.it/it/). Qui trovate direttamente le slides del mio intervento, alcuni link utili per approfondire e il codice che userò da copiare-incollare durante il training.\n\n<iframe src="https://docs.google.com/presentation/d/1pUYHZh06zipMxKi7ZHoSzde1qhkqY9Y7KOWaIXwrokY/embed?start=false&loop=false&delayms=3000" frameborder="0" width="480" height="389" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>\n\n## Link per i Download\n\n- [Anaconda](https://www.continuum.io/downloads)\n- [Arduino](https://www.arduino.cc/en/Main/Software)\n- [Nanpy Firmware](https://github.com/ludusrusso/nanpy-firmware)\n\n## Articoli\n\nQuesto training è basato sugli articoli che link qui sotto:\n\n- [Circuito RC](http://www.ludusrusso.cc/posts/2017-02-21-un-laboratorio-di-fisica-con-python-e-arduino-circuito-rc-v2)\n- [Led e Costante di Planck 1](http://www.ludusrusso.cc/posts/2017-02-22-misurare-la-costante-di-plank-con-arduino-e-python-parte-1)\n- [Led e Costante di Planck 2](http://www.ludusrusso.cc/posts/2017-03-21-misurare-la-costante-di-plank-con-arduino-e-python-parte-2)\n- [Led e Costante di Planck 3](http://www.ludusrusso.cc/posts/2017-03-23-misurare-la-costante-di-planck-con-arduino-e-python-parte-3)\n- [Esopianeti](http://www.ludusrusso.cc/posts/2017-03-26-come-vengono-scoperti-gli-esopianeti-un-semplice-esperimento-con-arduino-e-python)\n\n## Link Utili\n\n- [Corso Arduino Michele Maffucci](http://www.maffucci.it/area-studenti/arduino/)\n- [Introduzione a Spyder per il plot dei dati](http://www.ludusrusso.cc/posts/2017-04-06-breve-introduzione-all-utilizzo-di-spyder-per-il-plot-dei-dati-a-livello-scientifico)\n\n## Codice\n\n### Slide 23\n\n```python\ndef rc_simulation(t, tau):\n    return 5*(1-np.exp(-1/tau * t))\n\ntau = 0.1\nt = np.arange(0,1,0.001)\nv = rc_simulation(t, tau)\nplot(t,v)\n```\n\n### Slide 25\n\n```python\nfrom datetime import datetime\nfrom nanpy import ArduinoApi, SerialManager\nfrom time import sleep\n\n# connessione ad arduino sulla porta seriale specifica\nconnection = SerialManager(device=\'/dev/cu.usbmodem1461\')\na = ArduinoApi(connection=connection)\n\n# scarichiamo il condenatore\na.pinMode(2, a.OUTPUT)\na.digitalWrite(2, a.LOW)\nsleep(2)\n\n# carichiamo il condensatore e misuriamo l\'andamento\nvm, tm = [], []\na.digitalWrite(2, a.HIGH)\nfor i in range(0,50):\n    tm.append(datetime.now())\n    vm.append(5.0*a.analogRead(14)/1023.0)\n\n# convertiamo i dati in numpy\nts = tm[0]\ntm = [(i-ts).total_seconds() for i in  tm]\n```\n\n### Slide 26\n\n```python\ntm = np.array(tm)\nvm = np.array(vm)\n\nfrom scipy.optimize import curve_fit\npopt, pcov = curve_fit(rc_simulation, tm, vm)\n\n```\n\n### Slide 34\n\n```python\ndef diode_approx(v, VD, RD):\n    i = np.array(v)\n\n    for k in range(len(v)):\n        if v[k] < VD:\n            i[k] = 0\n        else:\n            i[k] = (v[k]-VD)/RD\n    return i\n\nmask = v > 0.7\nRD, VD = polyfit(i[mask],v[mask],1)\n```\n\n### Slide 37\n\n```python\ndef characterize_led():\n    a.pinMode(6, a.OUTPUT)\n\n    from datetime import datetime\n    a.analogWrite(6, 0)\n    sleep(5)\n    ts = datetime.now()\n    v, i = [], []\n    for I in range(0,255,1):\n        a.analogWrite(6, I)\n        O = a.analogRead(14)\n        v_d = O * 5/1023.0\n        v_in = I * 5.0/255.0\n        i_in = (v_in-v_d)/R\n        v.append(v_d)\n        i.append(i_in)\n        sleep(0.01)\n\n    i = numpy.array(i)\n    v = numpy.array(v)\n    return v, i\n```\n\n### Slide 48\n\n```python\nfrom nanpy import ArduinoApi, SerialManager\n...\na = ArduinoApi(connection=connection)\n\ndef luxmeter():\n    v = a.analogRead(14) * 5.0/1023.0\n    R = (5-v)/v*10e3\n    return R\n```\n\n### Slide 49\n\n```python\ndef plot_lux(T):\n    from datetime import datetime, timedelta\n    start_time = datetime.now()\n    stop_time = start_time + timedelta(0, T)\n\n    times = []\n    luxs = []\n\n    while datetime.now() < stop_time:\n        L, R = luxmeter()\n        times.append((datetime.now() - start_time).total_seconds())\n        luxs.append(L)\n\n    return times, luxs\n```\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-04-05-intervento-a-pycon-8-costruiamo-un-laboratorio-di-fisica-con-arduino-e-python/index.md",
    frontMatter: {
      path: "/2017/04/05/intervento-a-pycon-8-costruiamo-un-laboratorio-di-fisica-con-arduino-e-python/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-04-05T00:00:00.000Z",
      publishedReadable: "5 Apr 2017",
      featured: false,
      tags: ["Pycon", "Arduino", "Python", "Fisica"],
      title:
        "Intervento a Pycon 8 - Costruiamo un laboratorio di fisica con Arduino e Python",
      description: "",
      href: "/2017/04/05/intervento-a-pycon-8-costruiamo-un-laboratorio-di-fisica-con-arduino-e-python/",
      image:
        "/content/blog/it/2017-04-05-intervento-a-pycon-8-costruiamo-un-laboratorio-di-fisica-con-arduino-e-python/Schermata_2017-03-15_alle_00.23.13_y0hexu.png",
      imagePath:
        "/content/blog/it/2017-04-05-intervento-a-pycon-8-costruiamo-un-laboratorio-di-fisica-con-arduino-e-python",
    },
  },
  {
    content:
      '\nBenvenuto sul nostro sito Hotblack Robotics!\n\n![cloud robotics iot python](./InternetDeiRobot.svg)\n\nSe hai un Raspberry Pi 3 e vuoi **iscriverti gratis** come beta tester in piattaforma vai [qui](http://cloud.hotblackrobotics.com/register).\n\nSe vuoi **comprare** un kit robotico scrivici a **info@hotblackrobotics.com** e metti come oggetto "ACQUISTO"\n\nSe vuoi **acquistare** accessi per il robot in cloud remotizzato da AWS scrivici a **info@hotblackrobotics.com** e metti come oggetto "ROBOT AWS"\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-27-pycon-2017-links-info/index.md",
    frontMatter: {
      path: "/hbr/pycon-2017-links-and-info/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "1 min",
      published: "2017-03-27T15:01:39.000Z",
      publishedReadable: "27 Mar 2017",
      featured: false,
      tags: [],
      title: "Pycon 2017 - Links & Info",
      description: "",
      href: "/hbr/pycon-2017-links-and-info/",
      image: "/content/hbr/hotblack.jpg",
      imagePath: "/content/hbr/2017-03-27-pycon-2017-links-info",
    },
  },
  {
    content:
      "\nUn esopianeta (o pianeta extrasolare) è un pianeta che non appartiene al sistema solare, cioè un pianeta che orbita intorno ad una stella diversa dal sole.\n\n![Esopianeta con Arduino e Python](./exoplanet_in7ttp.png)\n\nOsserverare direttamente un esopianeta è quasi impossibile, a causa dell'elevata distanza che ci sapara dalle altre stelle. Infatti, dei circa 4 mila esopianeti attualmente conosciuti, solamente 22 sono stati osservati direttamente con il telescopio (trovate la lista completa [qui](https://en.wikipedia.org/wiki/List_of_directly_imaged_exoplanets)). E, in ogni caso, si tratta di pianeti molto grandi che orbitano molto distanti dalla loro stella madre.\n\nTutti gli altri pianeti sono stati scoperti grazie a metodi indiretti, cioè osservando gli effetti che la loro presenza causa sulla stella attorno a cui orbitano. Esistono veramente tantissimi metodi diversi di tipo indiretto, ma non è certamente lo scopo di questo articolo descriverli tutti (sono cose al di fuori delle mie competenze), ma per chi fosse interessato ad approfondire [Wikipedia offre una pagina molto approfondita sull'argomento](https://it.wikipedia.org/wiki/Metodi_di_individuazione_di_pianeti_extrasolari).\n\nIn questo articolo, prenderemo in esame il metodo di individuazione per **Transito**, che consiste semplicemente nel misurare un calo di luminosità della stella che si verifica quando il pianeta transita davanti alla stella stessa.\nIn seguito, con dei semplicissimi strumenti, riusciremo a ottenere dei dati molto simili a quelli che vengono ottenuti dai moderni telescopi quando misurano il transito di un pianeta.\n\n## Individuare un Esopianeta con il metodo per Transito\n\nCome già detto, questo metodo consiste nel misurare un piccolo calo di luminosità della stella dovuto al transito di un esopianeta davanti alla stella (rispetto al nostro punto di vista).\n\n![Metodo per Transito](./656348main_ToV_transit_diag_full.jpg)\n\nOvviamente questo metodo ha molte limitazione, prima tra tutte, funziona solo se l'orbita del pianeta è esattamente perpendicolare al nostro punto di vista (ciò riduce di tantissimo il numero di esopianeti che possono essere scoperti con questa tecnica). Tuttavia, ha l'enorme vantaggio di poter funzionare anche a grandissime distanze ed essere utilizzato da semplici telescopi. È quindi possibile scansionare contemporaneamente grandi porzioni di cielo e poi concentrarsi sulle stelle su cui si osservano cali di luminosità.\n\nLa seconda grande limitazione deriva dal fatto che questo metodo è soggetto a tantissimi falsi positivi, in quanto questi cali possono avere molteplici cause. Ovvialmente è possibile misurare cali di luminosità periodici, però questo tipo di conferma non è praticamente applicabile per pianeti con orbita molto grande (che inpiegano decine o centinaia di anni per concludere un periodo). Per questo motivo, molto spesso questa tecnica viene utilizzata insieme ad altri metodi per avere la sicurezza che si tratti di un esopianeta.\n\n## Misuratore di luminosità con Arduino e Python\n\nPrima di iniziare l'esperimento vero e proprio, dobbiamo però costruire un semplice sensore di luminosità utilizzando Arduino, una resistenza ed un fotoresistenza.\n\n### Fotoresistenza\n\nLe fotoresistenze sono dispositivi molto semplici ed economici. Si comportano come normali resistenze elettriche, solo che cambiano il proprio valore di resistenza in base alla quantità di luce che incide la loro superficie. Possono quindi essere usati come sensori di luminosità, misurandone la resistenza e quindi ricavando la luminosità da essa.\n\nPer ottenere una misura molto precisa della luminosità utilizzando una fotoresistenza è necessario calibrarla con un luxometro. Tuttavia, per l'esperimento che andrò qui a proporre, possiamo utilizzare i valori nominali (in quanto non è realmente importante la luminosità reale, ma solo la diminuzione della luminosità che andremo ad osservare).\n\nIn particolare, si può usare la seguente equazione per ottenere la luminosità (in lux) a partire dalla resitenza:\n\n$$\nL = b\\cdot R^{-\\alpha}\n$$\n\nDove $b = 1.25\\cdot 10^7$ e $\\alpha = 1.5$.\n\n### Costruiamo un Luxmetro con Arduino\n\nDalla equazione precente, siamo in grado di misurare la luminosità a partire dal valore della resistenza elettrica della fotoresistenza. Se riusciamo a misurare tale resistenza, siamo quindi in grado di misurare la luminosità!\n\nPer fortuna, misurare una resistenza con Arduino è molto facile, e ci viene in auto un semplice circuito chiamato _partitore di tensione_, illustrato in figura.\n\n![Partitore di tensione](./partitore_tensione_w0pueg.png)\n\nCon questa configurazione, sappiamo che la tensione $v$ dipende da $R$ e $R_1$ secondo la seguente equazione\n\n$$\nv = \\frac{R_1}{R+R_1}V\n$$\n\nDa cui, nota $R_1$ e misurando $v$ con Arduino, possiamo ricavare $R$ come segue\n\n$$\nR = \\frac{V-v}{v}R_1\n$$\n\n#### Circuito\n\nImplementiamo quindi il circuito con Arduino, utilizzando come resistenza $R_1$ una resistenza $R_1 = 10k\\Omega$ e come resistenza $R$ il nostro fotoresistore. Alimentiamo il circuito con i $5V$ di Arduino (in questo modo avremo $V=5V$) e usiamo il PIN A0 per misurare la tensione $v$.\n\n![Arduino Fotoreistore](./photoresistore_ai1iey.png)\n\n#### Codice\n\nAndiamo quindi ad implementare una semplice funzione in Python per leggere il valore $v$ e ricavarne prima la resistenza $R$ e poi la luminosità $L$.\nCome al solito, utilizzeremo la libreria **Nanpy**.\n\n```python\nfrom nanpy import ArduinoApi, SerialManager\nfrom time import sleep\n\nconnection = SerialManager(device='/dev/cu.usbmodem1461')\na = ArduinoApi(connection=connection)\n\ndef luxmeter():\n    v = a.analogRead(14) * 5.0/1023.0\n    R = (5-v)/v*10e3\n\n    alpha = 1.5\n    b = 1.25e7\n\n    L = b*R**(-alpha)\n    return L, R\n```\n\nCome vedete, nella riga `v = a.analogRead(14) * 5.0/1023.0` leggo il valore di $v$ tramite il PIN A0, convertendo il valore letto da _bit_ in $V$.\n\nA questo punto, posso calcolare il valore della resistenza $R$ e della luminosità $L$ con le equazioni viste sopra.\n\n#### Test\n\nPer verificare che tutto funzioni, eseguiamo il codice in _Spyder_ in modo da avere a disposizione la funzione `luxmeter` da linea di comando. A quel punto, possiamo provare a lanciare la funzione variando la luminosità della stanza dove ci troviamo, per verificare che i valori letti cambino.\n\nNel mio caso, ottengo i seguenti valori:\n\n- Stanza buia: $R=383k\\Omega$, $L=0.05lux$\n- Stanza illuminata: $R=10.3k\\Omega$, $L=12lux$\n- Torcia del cellulare vicino alla fotoresistenza: $R=503\\Omega$, $L=1107lux$\n\nNon avendo un luxometro in casa, non ho modo di verificare la correttezza di tali valori, però, almeno qualitativamente, i dati sembrano tornare.\n\n### Misuriamo l'andamento della luminosità nel tempo\n\nCon la funzione `luxmeter` appena realizzata, possiamo anche misurare e disegnare l'andamento della luminosità nel tempo.\n\nImplementiamo una seconda funzione che campiona i dati per un tempo $T$ (in secondi) definito come parametro, e plotta i dati nel tempo usando la funzione `plot`.\n\n```python\ndef plot_lux(T):\n    from datetime import datetime, timedelta\n    start_time = datetime.now()\n    stop_time = start_time + timedelta(0, T)\n\n    times = []\n    luxs = []\n\n    while datetime.now() < stop_time:\n        L, R = luxmeter()\n        times.append((datetime.now() - start_time).total_seconds())\n        luxs.append(L)\n\n    plot(times, luxs)\n```\n\nCon questa funzione, possiamo quindi disegnare come varia la luminosità nella stanza. Questo è un esempio ottenuto lanciando la funzione `plot_lux(10)` (quindi campionando per $10$ secondi) e muovendo casualemtne la torcia del cellulare sopra il sensore.\n\n![Luxometro casuale](./luxometro_casouale_ndyswi.png)\n\n## Simuliamo un esopianeta utilzzando una lampadina, una pallina ed un filo\n\nSiamo pronti a tornare a parlare del metodo di transito da cui eravamo partiti: un modo molto semplice per simulare gli effetti del transito di un esopianeta sulla luminosità della stella madre, è quello di utilizzare una pallina legata con uno spago che \"orbita\" attorno ad una lampadina accesa.\nIn questo modo, ogni volta che la pallina passa davanti alla lampadina, si verificherà subito un calo di luminosità della stessa.\n\n![Pallina lampadina Arduino](./WhatsApp_Image_2017-03-26_at_23.33.15_zry9c1.jpg)\n\nUtilizzando il luxometro appena costruito, possiamo quindi disegnare l'andamento della luminosità visto dalla fotoresistenza, e quindi visualizzare il calo di luminosità causato dal transito della pallina attorno alla lampadina. L'esperimento di per se è molto semplice:\nnel mio caso, ho usato una lampadina USB (che si attacca direttamente al computer, molto comoda da utilizzare), e una pallina da pingpong legata con uno spago. Ho fatto girare la pallina intorno alla lampadina tenendola per una mano, e ho eseguito il campionamento con $T=10s$, ottenendo il grafico qui sotto.\n\n![esopianeta simulato luce](./esopianeta_hea9nq.png)\n\nHo ripetuto lo stesso esperiendo però spegnendo la luce della camera, in modo da far risaltare meglio il transito:\n\n![esopianeta simulato buio](./esopianeta_scuro_j7cp3b.png)\n\nCome potete vedere, nel primo caso il salto di luminosità nel momento di passaggio va da $35.5lux$ a $32.5lux$ (circa il $10%$), mentre nel secondo caso, il salto (in percentuale) è molto più elevato ($>50\\%$) e la curva meno rumorosa. Ad ogni modo, da entrambi i grafici è possibilissimo stimare il periodo di rotazione della pallina.\n\nChe ve ne pare di questo esperimento? Avete provato a farlo? Ci siete riusciti? Non avremo certamente scoperto un nuovo esopianeta, ma in poco tempo e con pochissimo materiale siamo certamente riusciti a creare un interessantissimo esperimento didattico.\n\nAvete suggermienti/critiche? Mi trovate su facebook alla pagina [Ludus Russo](https://www.facebook.com/ludusrusso.cc/).\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-03-26-come-vengono-scoperti-gli-esopianeti-un-semplice-esperimento-con-arduino-e-python/index.md",
    frontMatter: {
      path: "/2017/03/26/come-vengono-scoperti-gli-esopianeti-un-semplice-esperimento-con-arduino-e-python/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "7 mins",
      published: "2017-03-26T00:00:00.000Z",
      publishedReadable: "26 Mar 2017",
      featured: false,
      tags: ["Fisica", "Arduino", "Python", "Esopianeti"],
      title:
        "Come vengono scoperti gli Esopianeti? Un semplice esperimento con Arduino e Python!",
      description: "",
      href: "/2017/03/26/come-vengono-scoperti-gli-esopianeti-un-semplice-esperimento-con-arduino-e-python/",
      image:
        "/content/blog/it/2017-03-26-come-vengono-scoperti-gli-esopianeti-un-semplice-esperimento-con-arduino-e-python/exoplanet_in7ttp.png",
      imagePath:
        "/content/blog/it/2017-03-26-come-vengono-scoperti-gli-esopianeti-un-semplice-esperimento-con-arduino-e-python",
    },
  },
  {
    content:
      "\r\nOra utilizziamo un po' di più l'hardware! Configuriamo un pin di input per dare il segnale ad un led per accendersi. Il codice a questo punto è molto semplice. Importiamo un messaggio nuovo che è Input. Questo è il messaggio che pubblicherà l'interruttore quando verrà premuto. Quindi abbiam un subscriber che rimane in ascolto, e ogni volta che l'interruttore viene premuto il subscriber richiamerà la funzione `on_input`. Dentro questa funzione in fine c'è un publisher che farà accendere i led a frequenze diverse. C'è un trick inoltre che è led_msg.led1 = self.cnt % 2 == 1. Questa è la versione compatta del if-then-else che abbiamo visto prima per cambiare continuamente stato al lede da true a false. La sintassi in modo compatto è dividi self.cnt per 2 se da resto 0 allora o (False) se no è 1 (True).\r\n\r\n```python\r\nimport dotbot_ros\r\nfrom dotbot_msgs.msg import Input, Led\r\nimport sys\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'input_node'\r\n    def setup(self):\r\n        self.cnt = 0\r\n        dotbot_ros.Subscriber('input', Input, self.on_input)\r\n        self.led_pub = dotbot_ros.Publisher('led', Led)\r\n        print 'Input Node Started'\r\n        sys.stdout.flush()\r\n\r\n    def on_input(self, msg):\r\n        if msg.input1 == True:\r\n            self.cnt += 1\r\n            led_msg = Led()\r\n            led_msg.led1 = self.cnt % 2 == 1\r\n            led_msg.led2 = (self.cnt/2) % 2 == 1\r\n            led_msg.led3 = (self.cnt/4) % 2 == 1\r\n            self.led_pub.publish(led_msg)\r\n            print \"pressed\"\r\n            sys.stdout.flush()\r\n```\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-24-implementiamo-un-subscriber-con-un-interruttore/index.md",
    frontMatter: {
      path: "/hbr/implementiamo-un-subscriber-con-un-interruttore/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "1 min",
      published: "2017-03-24T14:14:36.000Z",
      publishedReadable: "24 Mar 2017",
      featured: false,
      tags: [],
      title: "Implementiamo un subscriber con un interruttore",
      description: "",
      href: "/hbr/implementiamo-un-subscriber-con-un-interruttore/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-03-24-implementiamo-un-subscriber-con-un-interruttore",
    },
  },
  {
    content:
      '\r\n## Getting started\r\n\r\nQuesto piccolo tutorial spiega come configurare il robot la prima volta e attaccarsi in piattaforma!\r\nPrima cosa scaricate l\'immagine da copiare su SD da [questo link]({{ site.baseurl }}{% post_url /it/blog/2017-03-24-immagine-sd-per-la-cloud-e-configurazione %}).\r\n\r\nEstraete il file (ricordandovi il percorso) e copiate il .img (sui xx B) sulla vostra SD. Io uso in Windows un programma che si chiama Win32 Disk Imager e funziona bene ;) Il funzionamento del programma è semplicissimo, immettete il percorso della vostra immagine e premete "scrivi".\r\n\r\nDopo un po\' di minuti avrà finito.\r\n\r\nOra configuriamo il LED di check. Questo LED vi sarà utilissimo per capire quando il robot ha finito la fase di reboot e si è connesso correttamente.\r\nCollegate il + del LED (il filo più lungo ) al GPIO 21 e il - lo mettete a terra (vedi figura sotto).\r\n\r\n![](./RP2_Pinout.png)\r\n\r\n![](./schemaLEDcheck.png)\r\n\r\nOra inserite l\'SD nel Raspberry e prepariamoci a connetterlo ad internet!Accendete il Raspberry (alimentandolo). Se avete una rete "DotBot" vedrete che riavviando il robot si accenderà il vostro LED di check!\r\n\r\n## Il Circuito base per i LED, Interruttori e Motori\r\n\r\nPer prima cosa andate [qui](http://cloud.hotblackrobotics.com/cloud/sketch) e clonate il codice "example_driver". **Non dovete capire tutte le righe di codice**, basta aprirlo con "edit" e avviarlo con il tasto "run" in alto.\r\n\r\nOra costruite un circuito così.\r\n\r\n![](./schemaCompleto_bb.png)\r\n\r\nCollegando i fili per i MOTORI ai GPIO 16,19 (sinistra) e 20,26 (destra). I LED 1,2,3 ai GPIO 5,6,13 e gli INTERRUTTORI a 2 e 3.\r\n\r\nOttimo! Ora fate il test hardware con [http://cloud.hotblackrobotics.com/cloud/webgui/hwtest](http://cloud.hotblackrobotics.com/cloud/webgui/hwtest) e controllate che tutto funzioni e sia configurato correttamente.\r\n\r\n## Connettersi ad una rete diversa da DotBot\r\n\r\n![](./Getstart1.jpeg)\r\n\r\nCollegatelo al router della rete che volete configurare a cui è collegato il pc stesso e infine aprite una pagina web con Chrome.\r\n\r\n![](./Connect.jpeg)\r\n\r\nQuesta è una pratica che vi permette di configurare semplicemente il Raspebrry senza che voi dobbiate entrare nel Raspberry e digitare vari comandi in Linux!:)\r\n\r\nOra su Chrome andate su http://hotbot.local/wifi/schemes e si aprirà una schermata simile a questa. **NB** se il vostro robot ha un nome diverso perchè avete cambiato voi il nome in (ad. esempio blot) dovete modificare l\'indirizzo a cui accedere da hotbot al nome che avete scelto tipo http://nome_che_avete_scelto.local/wifi/schemes (ad esempio http://blot.local/wifi/schemes).\r\n\r\n![](./shcemes.PNG)\r\n\r\nPremete su "Configure" e si aprirà una schermata con la lista delle reti locali.\r\n\r\n![](./list.PNG)\r\n\r\nVoi ne selezionate una e digitate la password nella casella sottostante. Infine premete "Submit". Ci mette 1-2 minuti non temete! Aspettate fino a quando non vi arriva un pop-up di conferma. Poi ritornate su http://hotbot.local/wifi/schemes e premete connect sulla rete che avete appena configurato. Riavviate o staccando il cavo di alimentazione o [da piattaforma cloud](http://cloud.hotblackrobotics.com/cloud/robot) senza il cavo Ethernet. Aspettate fino a quando il LED non lampeggia...e siete connessi!\r\n\r\n![](./Connected.jpeg)\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-24-configurare-il-robot-dotbot/index.md",
    frontMatter: {
      path: "/hbr/configurare-il-robot-dotbot/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "3 mins",
      published: "2017-03-24T14:13:00.000Z",
      publishedReadable: "24 Mar 2017",
      featured: false,
      tags: [],
      title: "Configurare il robot DotBot",
      description: "",
      href: "/hbr/configurare-il-robot-dotbot/",
      image: "/content/hbr/hotblack.jpg",
      imagePath: "/content/hbr/2017-03-24-configurare-il-robot-dotbot",
    },
  },
  {
    content:
      '\n## Immagine SD\n\nScaricate qui l\'immagine.\n\n<a href="https://sourceforge.net/projects/hbrain/" type="button" class="btn btn-lg btn-info">Scarica l\'immagine</a>\n\n## Configurazione (Windows)\n\nScaricate da Internet **Win32DiskImager**.\n\n![](./Win32-Disk-Imager-1.png)\n\nInserite l\'SD dentro il PC e vi comparirà come nuovo dispositivo. A me prende il nome "G:".\n\nIn "Image file" andate ad inserire il percorso file dove avete l\'immagine e a fianco nella sezione "Device" mettete il dispositivo relativo alla vostra SD (nel mio caso G:).\n\nPremendo il pulsante "Write" iniziate a scrivere sulla SD!\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-24-immagine-sd-per-la-cloud-e-configurazione/index.md",
    frontMatter: {
      path: "/hbr/immagine-sd-per-la-cloud-e-configurazione/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "1 min",
      published: "2017-03-24T14:11:39.000Z",
      publishedReadable: "24 Mar 2017",
      featured: false,
      tags: [],
      title: "Immagine SD per la cloud e configurazione",
      description: "",
      href: "/hbr/immagine-sd-per-la-cloud-e-configurazione/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-03-24-immagine-sd-per-la-cloud-e-configurazione",
    },
  },
  {
    content:
      '\nBenvenuto sul nostro sito Hotblack Robotics!\n\n![cloud robotics iot](./InternetDeiRobot.svg)\n\nSe hai un Raspberry Pi 3 e vuoi **iscriverti gratis** come beta tester in piattaforma vai [qui](http://cloud.hotblackrobotics.com/register).\n\nSe vuoi **comprare** un kit robotico scrivici a **info@hotblackrobotics.com** e metti come oggetto "ACQUISTO"\n\nSe vuoi **acquistare** accessi per il robot in cloud remotizzato da AWS scrivici a **info@hotblackrobotics.com** e metti come oggetto "ROBOT AWS"\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-24-romecup-links-info/index.md",
    frontMatter: {
      path: "/hbr/romecup-links-and-info/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "1 min",
      published: "2017-03-24T14:10:01.000Z",
      publishedReadable: "24 Mar 2017",
      featured: false,
      tags: [],
      title: "RomeCup - Links & Info",
      description: "",
      href: "/hbr/romecup-links-and-info/",
      image: "/content/hbr/hotblack.jpg",
      imagePath: "/content/hbr/2017-03-24-romecup-links-info",
    },
  },
  {
    content:
      "\nEccomi qui per la terza ed ultima parte di questo tutorial sulla misura della costante di Planck utilizzando dei led colorati, Arduino e Python.\n\n![Misura della caratteristica di Led](./WhatsApp_Image_2017-03-22_at_00.29.13_qmfajj.jpg)\n\nSe vi siete persi le parti precedenti, le trovate ai seguenti link:\n\n- [Parte 1, modello dei Diodi in Python](http://www.ludusrusso.cc/posts/2017-02-22-misurare-la-costante-di-plank-con-arduino-e-python-parte-1)\n- [Parte 2, misura della caratteristica dei diodi](http://www.ludusrusso.cc/posts/2017-03-21-misurare-la-costante-di-plank-con-arduino-e-python-parte-2)\n\nUna volta modellata e misurata la caratteristica del led, come visto nei due tutorial precedenti, possiamo procedere alla stima della tensione di tensione di attivazione $V_D$ del singolo Led, e poi, alla misura della costante di Planck utilizzando la seguente approssimazione:\n\n$$\nV_D \\simeq \\frac{h\\gamma}{e}\n$$\n\nDove (ricordiamo) $\\gamma$ è la frequenza della radiazione emessa, $h$ è la costante di Planck e $e$ è la carica elettrica dell'elettrone (in valore assoluto).\n\n## Stima della tensione di attivazione $V_D$\n\nAlla fine del tutorial precendete, eravamo arrivati a disegnare la curva caratteristica di vari led colorati.\nTramite l'immagine disegnata in _iPython_ o _Spyder_, possiamo misurare in modo molto accurato il punto in cui la curva inizia a salire, utilizzando il puntatore del mouse del computer e leggendo la sua posizione nel grafico (visualizzata in basso a destra).\n\nAndiamo quindi a posizionare il mouse nel punto del grafico in cui la curva inizia a salire e prendiamo nota del valore $x$ indicato in basso a destra, come segnalato nella figura seguente\n\n![Misura di VD](./readVd_vekogd.png)\n\nCome da immagine, possiamo segnare la tensione $V_x = 2.52996V$.\n\nSalviamo questo valore in python\n\n```python\nVx = 2.52996V\n```\n\nRicordate che questo valore non è esattamente la tensione di attivazione del LED, in quanto non viene misurato a corrente nulla. Per ottenere un valore migliore di $V_D$, ci viene in aiuto l'approssimazione del diodo vista nel primo tutorial, formulata come segue:\n\n$$\ni^* =\n\\begin{cases}\n\t0 & \\text{se $v < V_D$} \\\\\n\t\\frac{1}{R_D}(v-V_D) & \\text{se $v > V_D$}\n\\end{cases}\n$$\n\ndove $V_D$ è detta tensione di attivazione, ed è una costante empirica che rappresenta la minima tensione a partire dalla quale il diodo inizia a condurre. $R_D$ approssima la resistenza interna al diodo.\n\nAdiamo quindi ad apprissimare i punti che sono maggiori della tensione trovata con una retta, ed ad intersecare questa retta con l'asse delle $x$. Il punto di intersezione sarà la nostra migliore misura della tensione di arrivazione $V_D$.\n\nCome visto nel primo tutorial, fortunatamente, abbiamo già pronta una funzione per esegure l'approssimazione. Il tutto si fa eseguente queste due linee di codice:\n\n```python\nmask = v > Vx\nRD, VD = polyfit(i[mask],v[mask],1)\n```\n\nDove il valore di ritorno `VD` è esattamente il valore $V_D$ che ci interessa.\n\nPer verificare che l'approssimazione sia corretta, andiamo a disegnarla sovrapposta al grafico della carattersticare reale.\n\nPer prima cosa, definiamo la funzione di approssimazione in Python\n\n```python\ndef diode_approx(v, VD, RD):\n    i = np.array(v)\n\n    for k in range(len(v)):\n        if v[k] < VD:\n            i[k] = 0\n        else:\n            i[k] = (v[k]-VD)/RD\n    return i\n```\n\ne usiamola per dignare la curva di approssimazione\n\n```python\nplot(v, diode_approx(v, VD, RD))\n```\n\nSe tutto va bene, otterrete un'immagine come la seguente\n\n![Diodo approssimazione](./approx_diodo_reale_mectuj.png)\n\nDato che i due grafici si sovrappongono perfettamente nella parte di crescita, possiamo salvare il valore $V_D$ ottenuto. Nel mio caso, ho visurato $V_D= 2.52V$.\n\n## Misura della costante di Planck\n\nA questo punto, siamo pronti per stimare la costante di Planck dalla misura ottenuta. Dobbiamo prima di tutto trovare il valore della lunghezza d'onda della luce emessa dal led. Ci sono infinte risorse online da cui attinere; da una breve ricerca su google ho trovato [questa pagina](http://www.theledlight.com/color_chart.html), da cui si può anche confrontare il colore del led reale con il colore riportato accanto alla lunghezza d'onda.\n\nNel mio caso, il led utilizzato risulta essere di colore \"super blue\", con lunghezza d'onda $\\lambda=470nm$. Ricordo che la frequenza $\\gamma$ di una radiazione è legata alla sua lunghezza d'onda $\\lambda$ dalla seguente relazione\n\n$$\n\\gamma\\cdot\\lambda = c\n$$\n\nDove $c$ è la velocità della luce nel vuoto.\n\nPossiamo finalmente stimare la costante invertendo l'equazione sopra riportata:\n\n$$\nh \\simeq V_D \\cdot \\frac{e}{\\gamma} = V_D \\cdot \\frac{e\\cdot \\lambda}{c}\n$$\n\nRicodando che\n\n- $c = 3\\cdot10^8\\frac{m}{s}$\n- $e = 1.621\\cdot 10^{-19} C$\n\nOtteniamo come valore\n\n$$\nh = 6.40 \\cdot 10^{-34} Js\n$$\n\nConfrontando questo valore sperimentale con uno delle misure più precise disponibile per la costante di Planck: $h=6.62\\cdot 10^{-34}$ otteniamo un errore di circa il $3\\%$ (non male no? Con gli altri led mi è andata peggio).\n\n## Misure con differenti Led\n\nPossiamo eseguire la stessa procedura su tutti gli altri Led colorati che abbiamo a dispozione. Dai miei esperimenti, ho ottenuto i seguenti valori:\n\n![Tabella valori](./Schermata_2017-03-24_alle_00.22.19_mrjd5a.png)\n\nNotare che, rispetto al led blu (che per caso è stato il primo led con cui ho eseguito il calcolo), le altre misure risultano più lontane rispetto alla stima precisa della costante di Planck. Tuttavia, tutte le misure rientrano all'interno di un errore minore del 20%, che non è decisamente male considerando gli strumenti utilizzati.\n\n## Ora tocca a voi\n\nProvate ad eseguire questo esperimento con i vostri led colorati per vedere se ottenete risultati simili. Cosa cambia? Riuscite ad ottenere misure simili alla mia?\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-03-23-misurare-la-costante-di-planck-con-arduino-e-python-parte-3/index.md",
    frontMatter: {
      path: "/2017/03/23/misurare-la-costante-di-planck-con-arduino-e-python-parte-3/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-03-23T00:00:00.000Z",
      publishedReadable: "23 Mar 2017",
      featured: false,
      tags: [
        "Tutorial",
        "Arduino",
        "Fisica",
        "Led",
        "Diodo",
        "Python",
        "Planck",
      ],
      title: "Misurare la costante di Planck con Arduino e Python - Parte 3",
      description: "",
      href: "/2017/03/23/misurare-la-costante-di-planck-con-arduino-e-python-parte-3/",
      image:
        "/content/blog/it/2017-03-23-misurare-la-costante-di-planck-con-arduino-e-python-parte-3/readVd_vekogd.png",
      imagePath:
        "/content/blog/it/2017-03-23-misurare-la-costante-di-planck-con-arduino-e-python-parte-3",
    },
  },
  {
    content:
      "\nDopo una lunga pausa, dovuta principalmente al lavoro necessario per la consegna della tesi che mi ha preso tutto il tempo libero delle ultime due settimane, al mio lavoro con HotBlack Robotics che si fa sempre più denso, e ad alcuni progetti che sto facendo partire di cui parlerò a breve, ecco che finalmente trovo il tempo per riprendere in mano questo tutorial lasciato a metà.\n\n![Misura della caratteristica di Led](./WhatsApp_Image_2017-03-22_at_00.29.13_qmfajj.jpg)\n\nPer chi si fosse perso la prima parte (più teorica), può trovarla [cliccando qui](http://www.ludusrusso.cc/posts/2017-02-22-misurare-la-costante-di-plank-con-arduino-e-python-parte-1). In questa seconda parte iniziamo con il vero smanettamente con Aruduino.\n\n## Misura della caratteristica dei Led con Arduino e Nanpy\n\nIniziamo subito a vedere come è possibile misurare la caratteristica reale di un led sfruttando Arduino, Nanpy e un paio di componente (una resistenza e un condensatore).\n\nIn particolare, per misurare la caratteristica del Led (o di un qualsiasi componente), dobbiamo misurare contemporaneamente i valori di corrente e tensione che attraversano il Led stesso, andando a variare nel tempo una di queste due grandezze e misure l'andamento dell'altra.\n\nRiprendendo l'idea del Prof. Alfonso d'Ambrosio, ho utilizzato il semplice circuito sottostante per la misura di queste grandezze con il metodo volt-amperometrico\n\n![Circuito LED](./citcuito_jhoxnp.png)\n\n### Come funziona\n\nL'idea alla base è molto semplice: con Arduino, impostiamo la tensione $V_{in}$ e misuriamo la tensione $v_d$. In questo modo, possiamo variare la tensione in ingresso al circuito e misurare la tensione sul condensatore.\n\nPer misurare la corrente, possiamo sfruttare proprio la tesistenza $R$ (di valore noto). Infatti, $i_{in}$ è semplicemente misurabile con la formula\n\n$$\ni_{in} = \\frac{V_{in} - v_d}{R}\n$$\n\nIl condensatore $C$ si trova in quella posizione per le sue capacità di filtro. Infatti ricordiamo che Arduino non è in grado di generare una tensione variabile, ma sfrutta il [metodo PWM](https://it.wikipedia.org/wiki/Pulse-width_modulation). Il condensatore quindi è necessario per filtrare la tensione in ingresso.\n\nNel nostro esperimento, supponiamo (un'approssima quasi vera) che tutta la corrente $i_{in}$ fluisce all'interno del Diodo Led, in altre parole, supponiamo che\n\n$$\ni_{in} = i_d\n$$\n\n### Implementazione in Arduino\n\nUtilizzando Arduino ed una breadboard, implementiamo il circuito sopra indicato. Nel mio circuito ho utilizzato i seguenti componenti:\n\n- Resistenza $R=1k\\Omega$\n- Condensatore elettrolitico $C=100\\mu F$\n- Arduino UNO\n- Breadboard\n\nUsiamo come input il Pin6 di Arduino, e come lettura il Pin A0, come indicato in figura.\n\n![Schema Arduino](./ledmeas_w1obv6.png)\n\n### Codice di Acquisizione\n\nAndiamo quindi ad implementare una funzione per l'aquisizione dei dati.\n\nLa funzione deve generare come input tutti i valori di tensione possibili, utilizando il comando `analogWrite` sul Pin 6 (ricordo che i valori di questa funzione sono codificati su 8 bit: $0 \\rightarrow 0V$, $253 \\rightarrow 5V$).\n\nPer ogni valore, deve misurare la tensione sul Pin A0, usando la funzione `analogRead`, che (a differenza della precedente), è codificata su 10bit: $0 \\rightarrow 0V$, $1023 \\rightarrow 5V$).\n\nPer ogni coppia di valori $I, O$, andare a misurare le grandezze $V_{in}$, $v_d$ e $i_{in}$, usando le seguenti equzioni:\n\n$$\nV_{in} = \\frac{5V}{255} \\cdot I\n$$\n\n$$\nv_d = \\frac{5V}{1023} \\cdot O\n$$\n\n$$\ni_{in} = \\frac{V_{in} - v_d}{R}\n$$\n\nImplementiamo questa funzione all'interno di un file `led.py`\n\n```python\nfrom nanpy import ArduinoApi, SerialManager\nfrom time import sleep\n\nimport numpy\n\n\nconnection = SerialManager(device='/dev/cu.usbmodem1461')\na = ArduinoApi(connection=connection)\n\nR = 1e3\n\ndef characterize_led():\n    a.pinMode(6, a.OUTPUT)\n\n    from datetime import datetime\n    a.analogWrite(6, 0)\n    sleep(5)\n    ts = datetime.now()\n    v, i = [], []\n    for I in range(0,255,1):\n        a.analogWrite(6, I)\n        O = a.analogRead(14)\n        v_d = O * 5/1023.0\n        v_in = I * 5.0/255.0\n        i_in = (v_in-v_d)/R\n        v.append(v_d)\n        i.append(i_in)\n        sleep(0.01)\n\n    i = numpy.array(i)\n    v = numpy.array(v)\n    return v, i\n```\n\n### Aquisiamo i dati\n\nUna volta implementata la funzione, possiamo aprire una shell python usando il comando `ipython --pylab` (o alternativamente usando un IDE come Spyder) ed eseguire i seguenti comandi\n\n```python\nfrom led import characterize_led\nv, i = characterize_led()\nplot(v, i)\n```\n\nSe tutto è andato bene, dovrette ottenere un grafico simile a seguente (in questo caso ho usato un Led Blu).\n\n![led blu caratteristica](./ledblue_ezorqw.png)\n\nNotiamo subito una cosa molto diversa dal caso ideale: quando il led non couduce (è spento), in realtà passa una corrente, molto piccola, nel circuito ($i_in < 0.5mA$). Questa corrente è dovuta alle resistenze interne del condesatore C.\n\nTuttavia, è facilissimo trovare la tensione di attivazione del Diodo Led, che in questo caso è di circa $V_D = 2.5V$.\n\nCambiando il led e rieseguendo il codice, potete disegnare sullo stesso grafico le caratteristiche di led colorati diversi. Nell'immagine successiva, trovate le caratteristiche di 4 led (Rosso, Verde, Giallo, Blu) generati dal seguente codice (cambiando manualmente i led).\n\n```python\nfrom led import characterize_led\n\n# Inserisco led blu\nvb, ib = characterize_led()\nplot(vb, ib, 'b')\n\n# Inserisco led rosso\nvr, ir = characterize_led()\nplot(vr, ir, 'r')\n\n# Inserisco led giallo\nvy, iy = characterize_led()\nplot(vy, iy, 'y')\n\n# Inserisco led verde\nvg, ig = characterize_led()\nplot(vg, ig, 'g')\n```\n\n![led tutti caratteristica](./leds_klmwzq.png)\n\nNotare che per ogni led misuriamo una corrente molto bassa in ingresso prima che il led si accenda. Si noti anche che i led verde e giallo hanno una caratteristica quasi identica.\n\n## Conclusioni seconda Parte\n\nConcludo la seconda parte di questa guida a questo punto. Con la promessa che la prossima (e ultima) parte verrà pubblicata a breve.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-03-21-misurare-la-costante-di-planck-con-arduino-e-python-parte-2/index.md",
    frontMatter: {
      path: "/2017/03/21/misurare-la-costante-di-planck-con-arduino-e-python-parte-2/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-03-21T00:00:00.000Z",
      publishedReadable: "21 Mar 2017",
      featured: false,
      tags: ["Tutorial", "Arduino", "Fisica", "Led", "Diodo", "Python"],
      title: "Misurare la costante di Planck con Arduino e Python - Parte 2",
      description: "",
      href: "/2017/03/21/misurare-la-costante-di-planck-con-arduino-e-python-parte-2/",
      image:
        "/content/blog/it/2017-03-21-misurare-la-costante-di-planck-con-arduino-e-python-parte-2/WhatsApp_Image_2017-03-22_at_00.29.13_qmfajj.jpg",
      imagePath:
        "/content/blog/it/2017-03-21-misurare-la-costante-di-planck-con-arduino-e-python-parte-2",
    },
  },
  {
    content:
      "\n## NUOVI ORARI\n\n**Per problemi logistici, il corso di Stampa 3D è stato cancellato e il corso di Arduino è stato spostato interamente al 14 Aprile 2017, ore 9:00-12:30, 14.30-18.00**\n\nIn occasione delle vacanze di Pasqua 2017, il Liceo G. Stampacchia organizza due corsi tenuti da me su Arduino e stampa 3D.\nSi è scelto di creare due corsi distinti in modo da dare la libertà a chiunque di partecipare solamente alle tematiche che più gli interessano, considerando anche il poco tempo a disposizione e il periodo. Ciò non toglie che gli interessati possano partecipare ad entrambi i corsi.\n\n![Locandina Corso](./Schermata_2017-03-20_alle_20.40.18_w7axia.png)\n_Per info scrivete a ludus.russo@gmail.com_\n\n**Corso Introduttivo ad Arduino e Physical Computing\n14 Aprile 2017, ore 9:00-12:30, 14.30-18.00\nLiceo Scientifico G. Stampacchia - Tricase (LE)\nPrezzo 25€ (Include un Arduino Starter Kit per ogni partecipante)**\n\n**Corso Introduttivo alla progettazione e Stampa 3D (Cancellato)\nLiceo Scientifico G. Stampacchia - Tricase (LE)\nPrezzo 25€ (Include la stampa di un pezzo progettato durante il corso)**\n\n## Corso Introduttivo ad Arduino e Physical Computing\n\nIl focus del corso è quello di fornire le nozioni di base per la prototipazione elettronica e robotica al fine di fornire le competenze necessarie per sviluppare in autonomia o in corsi successivi sistemi di automazione civili ed industriale.\n\nTali competenze verranno fornite utilizzate la scheda elettronica Arduino costituito da un microcontrollore e da un’elettronica aggiunta, utile per creare rapidamente prototipi sia per scopi hobbistici e semiprofessionali ma soprattutto utilissima in campo didattico per l’apprendimento della programmazione.\n\n#### Cosa imparerò durante il corso:\n\n- Che cosa è Arduino e cosa vuol dire Physical Computing\n- Come programmare Arduino in C++\n- Come interfacciare Arduino con Sensore e Attuatori\n- Come sviluppare semplici progetti con Arduino\n- Come funziona l’ecosistema Arduino\n- Come essere autonomi nell’apprendimento di Arduino\n\n#### Kit Arduino in Dotazione\n\nIn dotazione ogni partecipante avrà un Kit Arduino compatibile (incluso nel prezzo) contenente i seguenti dispositivi:\n\n- Scheda Arduino UNO compatibile\n- Basetta di prototipazione (Breadboard)\n- Cavi Jumpers\n- Led Colorati\n- Sensoristica varia\n  - Photoresistori\n  - Termoresistori\n- Motori\n\n##### Perchè Arduino compatibile?\n\nIl costo del kit Arduino originale è di circa 80€, per ridurre al massimo i costi si è scelto di utilizzare un Kit clone di Arduino (ma 100% compatibile con la scheda originale).\n\n##### Hai già un Kit Arduino?\n\nSegnalo nei commenti in fase di iscrizione, ci metteremo d’accordo su come fare.\n\n## Corso Introduttivo alla progettazione e Stampa 3D\n\nIl focus del corso è quello di fornire le nozioni di base per la prototipazione meccanica sfruttando tecniche di prototipazione rapida FMD (solitamente nota come Stampa 3D) al fine di fornire le competenze necessarie per sviluppare in autonomia o in corsi successivi.\n\nTali competenze verranno fornite utilizzate sfruttando il software gratuito ThinkerCAD e una piccola ma potente stampante 3D Open Source.\n\nDurante il corso, ogni partecipante riuscirà a progettare e a stampare in 3D un piccolo oggetto reale.\n\n#### Cosa imparerò durante il corso:\n\n- Che cosa è la stampa 3D e cosa vuol dire Artigianato Digitale\n- Cosa si può fare con una stampante 3D\n- Come funziona una stampante 3D tipo FMD\n- Come realizzare un progetto in 3D partendo da un’idea\n- Disegnare oggetti in 3D con ThinkerCAD\n- Generare codici di Stampa con CURA/Repetier Host\n- Stampare un Oggetto\n\n## Partecipanti\n\nEntrambi i corsi sono rivolti a tutti gli interessati alle nuove tecnologie dell’Artigianato Digitale e vogliono essere guidati a fare il primo passo, quindi si rivolgono a tutti, studenti e non, ragazzi ed adulti a tutti coloro che hanno uno spirito maker.\n\n**Unico prerequisito necessario è la curiosità.**\n\nLa finalità del corso è permettere di gestire e progettare in autonomia le idee dei partecipanti.\n\n## Metodologie\n\nIl corsi si svolgeranno con metodologia laboratoriale, in modo cooperativo in aula, e l’intero processo di formazione sarà supportato da una piattaforma di formazione on-line, predisposta dal docente, sulla quale sarà realizzata una classe virtuale a cui saranno iscritti tutti i partecipanti al corso.\n\nIn questo modo sarà possibile sviluppare sperimentazioni didattiche, nonché fornire indicazioni di articoli di approfondimento e svolgimento di attività pratiche sull’uso di tecnologie che saranno illustrate nei momenti in presenza.\n\nSi cercherà di usare la tecnologia divertendosi, verrà stimolata la creatività la logica e l’autonomia ma anche la capacità di raggiungere un obiettivo e lavorare in team.\n\n## Requisiti tecnici\n\n- Un PC portatile abilitato a navigare in wi-fi, il computer potrà essere dotato di sistema operativo Windows, Mac o Linux, non è necessario disporre di computer con prestazioni elevate.\n\n- Il corso si svolgerà presso un laboratorio informatico attrezzato, quindi per chi non fosse dotato di portatile, sarà possibile utilizzare il computer messo a disposizione dell’organizzazione.\n\n## Modalità di iscrizione\n\nIl costo di ciascun corso è di 25€, inclusi i materiali di utilizzo che verranno poi lasciati ai partecipanti.\n\n# L’iscrizione al corso deve essere fatta on-line cliccando [qui](https://goo.gl/forms/Gv226pPZnTbWX3Xu1)\n\n**Avranno priorità di iscrizione al corso studenti e professori del Liceo Stampacchia.**\n\nIn questo blog potranno essere letti avvisi ed indicazioni utili per i corsisti.\n\n**Le iscrizioni termineranno in data 01/04/2017**\n\nI corsi si attiveranno al raggiungimento di 8 partecipanti. Il numero massimo di posti disponibili è 20.\n\nNel caso sopraggiungano impegni che non permettano la partecipazione al corso si prega di comunicare tempestivamente in modo da permettere ad altri di frequentare il corso.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-03-20-pasqua-al-liceo-stampacchia-di-tricase-corsi-di-arduino-e-stampa-3d/index.md",
    frontMatter: {
      path: "/2017/03/20/pasqua-al-liceo-stampacchia-di-tricase-corsi-di-arduino-e-stampa-3d/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-03-20T00:00:00.000Z",
      publishedReadable: "20 Mar 2017",
      featured: false,
      tags: ["Stampacchia", "Corsi", "Arduino", "3Dprint"],
      title:
        "Pasqua al Liceo Stampacchia di Tricase: Corsi di Arduino e Stampa 3D",
      description:
        "In occasione delle vacanze di Pasqua 2017, il Liceo G. Stampacchia organizza due corsi tenuti da me su Arduino e stampa 3D.",
      href: "/2017/03/20/pasqua-al-liceo-stampacchia-di-tricase-corsi-di-arduino-e-stampa-3d/",
      image:
        "/content/blog/it/2017-03-20-pasqua-al-liceo-stampacchia-di-tricase-corsi-di-arduino-e-stampa-3d/Schermata_2017-03-20_alle_20.40.18_w7axia.png",
      imagePath:
        "/content/blog/it/2017-03-20-pasqua-al-liceo-stampacchia-di-tricase-corsi-di-arduino-e-stampa-3d",
    },
  },
  {
    content:
      "\r\nQui vi spiegherò come modificare un robot comprato da Tiger e collegarlo in piattaforma! Nel mio caso ho comprato uno Spider Robot per ben 7 Euro!:)\r\n\r\nOltre questo avrete anche bisogno di:\r\n\r\n- un power bank per cellulare da 5 Volt io ho usato [questo](http://www.dx.com/p/cylinder-shaped-external-6000mah-emergency-power-battery-charger-for-iphone-cell-phone-silver-206652#.WFFUEh9ifCI) ma potete usare anche un power bank da 9 volt\r\n- un ponte ad H. Io ho usato [questo](http://eud.dx.com/product/hg7881-two-channel-motor-driver-board-dark-blue-2-5-12v-2-pcs-844407060) ma anche in questo caso potete scegliere quello che volete. Qualcuno li costruisce anche a mano mettendo insieme 4 transistor!\r\n- un Raspberry PI 3\r\n- cavetti con connettori femmina-femmina\r\n- fascette da idraulico\r\n- un pezzo di cartone ;)\r\n- un cavetto USB a microUSB da cellulare Android.\r\n\r\nE otterrete SpiderBot in cloud!\r\n\r\n![](./SpiderBotCloud2.jpeg)\r\n\r\nUna volta montato lo Spider Bot come dalle istruzioni di Tiger, prendete un pezzo di materiale rigido (io ho usato un cartone) e ne ritagliate un rettangolo per farci stare il Raspberry. Poi tagliate la parte inferiore in modo da creare una linguetta centrale che andrete a far passare dentro l'appiglio di plastica del robot. Lo ripiegate dentro e lo fissate, io ho usato una spillatrice.\r\n\r\nPoi come si vede in figura fissate il ponte ad H (hg7881) con una fascetta sul davanti del robot.\r\n\r\n![](./Cartone.jpeg)\r\n\r\nEffettuate i collegamenti. Il filo rosso (+) lo inserite nel mammut del Motor A di destra nel ponte ad H e il nero (terra) nel mammut di sinistra. Con un cacciavite chiudete i mammut per far bene contatto. A questo punto prendete dei cavetti femmina-femmina e, due di questi (il mio rosso e marrone) li usate come alimentazione del ponte ad H e altri due li mettete nei pin di controllo del Motor A.\r\n\r\n![](./ponteH.jpeg)\r\n\r\nScaricate l'immagine per il Raspberry da [qui]({{ site.baseurl }}{% post_url /it/blog/2017-03-24-immagine-sd-per-la-cloud-e-configurazione %}) e copiate sull'SD del Raspberry. Configurate il Raspberry che si possa connettere in cloud come nei tutorial precedenti. Ora montate con delle fascette il Raspberry sul supporto verticale insieme alla batteria!\r\n\r\n![](./Rasp.jpeg)\r\n\r\nOra facciamo i collegamenti. Secondo questo scema dei pin del raspberry collegate i due cavetti di alimentazione del ponte H ai pin 4 (+ 5V) e 6 (ground). Poi collegate i pin di controllo del motore ai pin 21 e 22. A questo punto basterà collegare il cavo USB-microUSB al Raspberry e funzionerà!\r\n\r\n![](<./RP2_Pinout%20(1).png>)\r\n\r\nPer farlo muovere collegatevi in piattaforma e usate l'app [Test Hardware](http://cloud.hotblackrobotics.com/cloud/webgui/hwtest). Impostate il valore 100, 100 sui motori (anche se di fatto ne controllate solo uno) e premete set motor. Vedrete che lo spider bot inizierà a muoversi! Ovviamente mettendo valori diversi si muoverà più o meno veloce e cambiando segno al valore impostato si muoverà al contrario. Prossimo tutorial con due Spiderbot costruiremo uno Spider Bot in grado di andare avanti, indietro e pure girare!\r\n\r\nPer informazioni **info@hotblackrobotics.com**\r\nPer la licenza da beta tester gratis registratevi [qui](http://cloud.hotblackrobotics.com/register).\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-16-come-collegare-un-robot-comprato-da-tiger-spider-robot-in-piattaforma-cloud/index.md",
    frontMatter: {
      path: "/hbr/come-collegare-un-robot-comprato-da-tiger-spider-robot-in-piattaforma-cloud-/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "3 mins",
      published: "2017-03-16T22:09:28.000Z",
      publishedReadable: "16 Mar 2017",
      featured: false,
      tags: [],
      title:
        "Come collegare un robot comprato da Tiger (Spider Robot) in piattaforma cloud !!",
      description: "",
      href: "/hbr/come-collegare-un-robot-comprato-da-tiger-spider-robot-in-piattaforma-cloud-/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-03-16-come-collegare-un-robot-comprato-da-tiger-spider-robot-in-piattaforma-cloud",
    },
  },
  {
    content:
      "\r\n## SpiderBot Cloud con controllo vocale!\r\n\r\nUna volta costruito lo SpiderBot come dalle istruzioni di Tiger, vi spiego come scrivere una semplice app per il controllo vocale! Il nostro SpiderBotCloud andrà avanti o indietro a seconda di ciò che direte!\r\nLeggetevi gli altri tutorial su questo sito per comprendere meglio le righe di codice che vi posterò qui.\r\nUna volta entrati in piattaforma da [qui](http://cloud.hotblackrobotics.com/cloud) e connesso il robot come spiegato [qui]({{ site.baseurl }}{% post_url /it/blog/2017-03-16-come-collegare-un-robot-comprato-da-tiger-spider-robot-in-piattaforma-cloud %}), andate in Sketches. Create in nuovo programma con \"New\" dando il nome del codice che preferite (o potete anche modificarne uno già esistente) e copiate il seguente codice:\r\n\r\n```python\r\n\r\nimport dotbot_ros\r\nfrom dotbot_msgs.msg import Speed\r\nfrom std_msgs.msg import String\r\nimport sys\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    def setup(self):\r\n        self.speed_pub = dotbot_ros.Publisher('speed', Speed)\r\n        dotbot_ros.Subscriber('speech', String, self.on_speech)\r\n        print 'setup'\r\n\r\n    #@dotbot_ros.on_topic('speech', String)\r\n    def on_speech(self, speech_msg):\r\n        speed_msg = Speed()\r\n        print speech_msg.data\r\n        sys.stdout.flush()\r\n        if speech_msg.data == 'avanti':\r\n            speed_msg.sx = 90\r\n            speed_msg.dx = 0\r\n            self.speed_pub.publish(speed_msg)\r\n        if speech_msg.data == 'dietro':\r\n            speed_msg.sx = -90\r\n            self.speed_pub.publish(speed_msg)\r\n```\r\n\r\nSalvate e avviate il programma! Se non ci sono errori andate sul menù in alto dove c'è la voce \"Apps\" e aprite l'[app di controllo vocale](http://cloud.hotblackrobotics.com/cloud/webgui/speech). Arriverrete su una pagina così (vi consigliamo di usare Chrome).\r\n\r\n![](./voiceRecognition.png)\r\n\r\nConnettete la web app con il tasto \"connect\" e premete il tasto centrale a forma di microfono per abilitare il controllo vocale. A questo punto dite ad alta voce \" Avanti\" e il robot andrà avanti e \"Dietro\" e il robot andrà indietro! :)\r\nPotete provare ad aprire il sito della Web App anche da cellulare e farlo funzionare su mobile!\r\n\r\nPer informazioni **info@hotblackrobotics.com**.\r\n\r\nPer la licenza da beta tester gratis registratevi [qui](http://cloud.hotblackrobotics.com/register).\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-16-spiderbot-cloud-con-controllo-vocale/index.md",
    frontMatter: {
      path: "/hbr/spiderbot-cloud-con-controllo-vocale/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "2 mins",
      published: "2017-03-16T22:05:00.000Z",
      publishedReadable: "16 Mar 2017",
      featured: false,
      tags: [],
      title: "SpiderBot Cloud con controllo vocale! ",
      description: "",
      href: "/hbr/spiderbot-cloud-con-controllo-vocale/",
      image: "/content/hbr/hotblack.jpg",
      imagePath: "/content/hbr/2017-03-16-spiderbot-cloud-con-controllo-vocale",
    },
  },
  {
    content:
      "\r\nDopo il tutorial \"Come collegare un robot comprato da Tiger (Spider Robot) in piattaforma cloud\" vi avevo promesso che avrei comprato un secondo ragno robotico da Tiger così da costruire un robot in grado di muoversi in ogni direzione.\r\nIl materiale utilizzato è lo stesso del tutorial precedente ma con una batteria power bank in più.\r\n\r\nLista:\r\n\r\n- 2 spider robot comprati da Tiger\r\n- 2 [power bank per cellulare da 5 Volt](http://www.dx.com/p/cylinder-shaped-external-6000mah-emergency-power-battery-charger-for-iphone-cell-phone-silver-206652#.WFpnUrbhB-V)\r\n- un ponte ad H. Io ho usato [questo](http://eud.dx.com/product/hg7881-two-channel-motor-driver-board-dark-blue-2-5-12v-2-pcs-844407060) ma anche in questo caso potete scegliere quello che volete. Qualcuno li costruisce anche a mano mettendo insieme 4 transistor!\r\n- un Raspberry PI 3\r\n- cavetti\r\n- fascette da idraulico\r\n- un pezzo di cartone ;)\r\n- 2 cavetti USB a microUSB (alimentatore per cellulare Android)\r\n\r\nPer prima cosa montate i due Spider Robot come dalle istruzioni di Tiger. Poi smontate una parte dei robot e uniteli insieme come in figura.\r\n\r\n![](./1.jpeg)\r\n\r\nUnite i cavetti di alimentazione dei motori ai connettori delle batterie. Dopo uniremo ai connettori delle batterie altri cavetti al ponte H.\r\nRitagliate un pezzo di cartone di questa forma con due linguette da inserire dentro i supporti di plastica dei due robot.\r\n\r\n![](./2.jpeg)\r\n\r\nPoi pinzate le linguette in modo da fissarle.\r\n\r\n![](./3.jpeg)\r\n\r\nA questo punto fissate con delle fascette da idraulico tutto il sistema composto da Raspberry pi + ponte ad H + le 2 batterie.\r\n\r\nCosì:\r\n![](./4.jpeg)\r\n![](./5.jpeg)\r\n\r\nOra effettuiamo i collegamenti.\r\n\r\nI pin del Raspberry sono:\r\n\r\n![](<./RP2_Pinout%20(1).png>)\r\n\r\nIl ponte ad H:\r\n\r\n![](./maxresdefault.jpg)\r\n\r\nOra collegate ogni alimentazione dei motori (motere A e motore B) ai rispettivi mammut del ponte ad H. Poi collegate il controllo dei motori (A-1A, A-1B e B-1A, B-1B) con i GPIO 9,25 (pin 21,22 o contando 10 dal basso) e GPIO 22,23 (pin 15,16 o contando 13 dal basso)del Raspberry. Infine l'alimentazione la collegate a una delle due batterie (fate attenzione solo che abbia almeno 1 o 2 Ampere altrimenti i motori non hanno abbastanza potenza e non si muovono).\r\n\r\nOra configurate il Raspberry come da [http://hotblackrobotics.github.io/forum/support/13](http://hotblackrobotics.github.io/forum/support/13).\r\n\r\nE siete pronti a partire!\r\nSe volete usare il controllo vocale copiate il codice da qui e usatelo tramite la Web App come spiegato [qui]({{ site.baseurl }}{% post_url /it/blog/2017-03-16-spiderbot-cloud-con-controllo-vocale %}).\r\n\r\n```python\r\n\r\nimport dotbot_ros\r\nfrom dotbot_msgs.msg import Led\r\nfrom dotbot_msgs.msg import Speed\r\nfrom std_msgs.msg import String\r\nimport sys\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    def setup(self):\r\n        self.led_pub = dotbot_ros.Publisher('led', Led)\r\n        self.speed_pub = dotbot_ros.Publisher('speed', Speed)\r\n        dotbot_ros.Subscriber('speech', String, self.on_speech)\r\n        print 'setup'\r\n\r\n    #@dotbot_ros.on_topic('speech', String)\r\n    def on_speech(self, speech_msg):\r\n        led_msg = Led()\r\n        speed_msg = Speed()\r\n        print speech_msg.data\r\n        sys.stdout.flush()\r\n        if speech_msg.data == 'avanti':\r\n            led_msg.led1 = True\r\n            speed_msg.sx = 100\r\n            speed_msg.dx = 100\r\n            self.led_pub.publish(led_msg)\r\n            self.speed_pub.publish(speed_msg)\r\n        elif speech_msg.data == 'sinistra':\r\n            speed_msg.sx = -100\r\n            speed_msg.dx = 100\r\n            self.speed_pub.publish(speed_msg)\r\n        elif speech_msg.data == 'destra':\r\n            speed_msg.sx = 100\r\n            speed_msg.dx = -100\r\n            self.speed_pub.publish(speed_msg)\r\n        elif speech_msg.data == 'indietro':\r\n            speed_msg.sx = -100\r\n            speed_msg.dx = -100\r\n            self.speed_pub.publish(speed_msg)\r\n        elif speech_msg.data == 'fermo':\r\n            led_msg.led1 = False\r\n            speed_msg.sx = 0\r\n            speed_msg.dx = 0\r\n            self.led_pub.publish(led_msg)\r\n            self.speed_pub.publish(speed_msg)\r\n```\r\n\r\nPer informazioni **info@hotblackrobotics.com**. Per la licenza da beta tester gratis registratevi [qui](http://cloud.hotblackrobotics.com/register).\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-16-spiderbotcloud-20-la-vendetta-2-gradi-di-liberta-e-controllo-vocale/index.md",
    frontMatter: {
      path: "/hbr/spiderbot-cloud-20-la-vendetta-2-gradi-di-liberta-e-controllo-vocale/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "3 mins",
      published: "2017-03-16T22:03:56.000Z",
      publishedReadable: "16 Mar 2017",
      featured: false,
      tags: [],
      title:
        "SpiderBot Cloud 2.0 la vendetta - 2 gradi di libertà e controllo vocale",
      description: "",
      href: "/hbr/spiderbot-cloud-20-la-vendetta-2-gradi-di-liberta-e-controllo-vocale/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-03-16-spiderbotcloud-20-la-vendetta-2-gradi-di-liberta-e-controllo-vocale",
    },
  },
  {
    content:
      "\r\nAnalizziamo il codice di `dotbot_led_cnt`.\r\nSe volete copiarlo qui:\r\n\r\n```\r\nimport dotbot_ros\r\nfrom dotbot_msgs.msg import Led\r\nimport sys\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'led_cnt'\r\n    def setup(self):\r\n        self.led_pub = dotbot_ros.Publisher('led', Led)\r\n        self.loop_rate = dotbot_ros.Rate(2)\r\n        self.cnt = 0\r\n        print 'setup'\r\n\r\n    def loop(self):\r\n        self.cnt += 1\r\n        msg = Led()\r\n        if self.cnt % 2 == 0:\r\n            msg.led1 = True\r\n        else:\r\n            msg.led1 = False\r\n        self.led_pub.publish(msg)\r\n        print 'cnt', self.cnt\r\n        sys.stdout.flush()\r\n```\r\n\r\nIniziamo ad analizzare alcune righe di codice.\r\nQueste prime righe significano che alcune librerie di Python devono essere aggiunte, in particolare il messaggio di tipo **Led** deve esssere importato nel codice.\r\n\r\n```\r\nfrom dotbot_msgs.msg import Led\r\n```\r\n\r\nPoi dichiariamo il Nodo, con la dicitura `class Node(dotbot_ros.DotbotNode):` e il nome del nodo con `node_name = 'led_cnt'` .\r\nIn seguito abbiamo due funzioni principali una ` def setup(self):` chiamata solo una volta all'inizio dell'esecuzione del programma e un'altra che viene eseguita all'infinito ` def loop(self):`. Quest'ultima viene eseguita ad una frequenza impostata nella funzione setup con il comando `self.loop_rate = dotbot_ros.Rate(2)`.NOTA BENE self è una parola magica che non va mai dimenticata! In questo caso la frequenza è di 2Hz. **NOTA BENE se non impostate la frequenza con questo comando la funzione loop non sarà mai richiamata!**\r\n\r\nCon la funzione `self.led_pub = dotbot_ros.Publisher('led', Led)` definiamo un Publisher che pubblica sul topic \"led\" il messaggio di tipo Led.\r\n\r\nNella funzione loop invece istanziamo il messaggio msg di tipo Led con `msg = Led()`, gli assegniamo un valore che alterna tra True e False. Incrementiamo all'inizio del loop la variabile `self.cnt += 1`. Poi entriamo nel if e calcoliamo il resto di self.cnt diviso per 2 con l'operatore %. Se il resto è uguale a 0 allora riempiamo il messaggio msg con True e il led si accenderà altrimenti il contrario.\r\nInfine pubblichiamo il messaggio con `self.led_pub.publish(msg)` scriviamo a schermo il valore di cnt. La funzione sys.stdout.flush() serve a scrivere a schermo.\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-16-analizziamo-il-codice-del-primo-esempio-blink-led/index.md",
    frontMatter: {
      path: "/hbr/analizziamo-il-codice-del-primo-esempio-blink-led/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "2 mins",
      published: "2017-03-16T22:01:37.000Z",
      publishedReadable: "16 Mar 2017",
      featured: false,
      tags: [],
      title: "Analizziamo il codice del primo esempio - blink LED",
      description: "",
      href: "/hbr/analizziamo-il-codice-del-primo-esempio-blink-led/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-03-16-analizziamo-il-codice-del-primo-esempio-blink-led",
    },
  },
  {
    content:
      '\r\nOk, abbiamo visto la parte teorica e ora è il momento di buttarsi nel vivo della programmazione! Questo tutorial spiega **una volta che il robot è configurato correttamente** come programmarlo (altrimenti seguite [**il tutorial di configurazione del kit minimale**](http://hotblackrobotics.github.io/forum/support/6)).\r\n\r\n## Connettete il robot\r\n\r\nQuando entrate nella piattaforma (una volta effettuato il login) apparirà una schermata simile a questa.\r\n\r\n![](./login.PNG)\r\n\r\nInserite quindi il nome del robot, nel mio caso è **hotbot** con l\'aggiunta ".local", "hotbot.local" e premete il pulsante "Cerca Robot". A questo punto inizierà la ricerca del robot nella vostra rete locale. E\' assolutamente necessario che il computer (o smartphone/tablet) sia connesso alla stessa rete locale del robot altrimenti non lo troverà mai! L\'interfaccia vi risponderà in caso di successo con "Robot trovato" e tutti i dati relativi al robot: il nome, il master (questo è il nodo centrale di ROS) e l\'indirizzo IP.\r\n\r\n![](./robot_trovato.PNG)\r\n\r\n## L\'IDE di sviluppo\r\n\r\nAndate su http://hotblackrobotics.github.io/cloud/sketch/ e troverete due sezioni: una "Programs", sono i vostri programmi e "Examples" sono gli esempi che trovate già in piattaforma. Questi potete visualizzarli col tasto "View" e clonarli nella vostra sezione "Programs" così che possiate modificarli ed utilizzarli. Notate che per clonarli premete sul tasto "Clone" e su questo c\'è il numero di volte che è stato clonato. Questo per dare una specie di indice di popolarità sui programmi più clonati, e quindi più apprezzati :) vedremo dopo che, se volete, anche i vostri programmi possono essere condivisi agli altri utenti in piattaforma e più volte il vostro programma sarà clonato più significa che avete fatto un ottimo lavoro!\r\n\r\n![](./programs.PNG)\r\n\r\nQuindi per iniziare col primo esempio clonate `dotbot_led_cnt` dalla sezione examples vedrete che comparirà in programs. Premete a questo punto sul pulsante "edit" e vedrete che potete visualizzare il codice.\r\n\r\n![](./dotbotledcnt.PNG)\r\n\r\nIn alto a destra troverete questi pulsanti molto utili:\r\n\r\n![](./pulsanti_edit.PNG)\r\n\r\n- run: esegue il codice sul robot connesso (ricordatevi sempre però prima di premere questo pulsante di salvare! - pulsante successivo)\r\n- save: salva le modifiche del codice\r\n- shell: apre una shell e ti dice cosa sta succedendo, importante anche in caso di debug\r\n- download: vi permette di scaricare il codice\r\n- edit info: vi permette di cambiare nome del programma, aggiungere una breve descrizione al programma es "questo codice fa accendere un led" e se volete rendere pubblico il vostro codice. Rendere pubblico significa che altri utenti lo possono visualizzare e poi clonare nel proprio profilo\r\n\r\nOra (salvate per sicurezza col tasto save) ed eseguite il codice "led_cnt" con il tasto esegui. Si aprirà la shell che vi comunicherà che il nodo è in esecuzione "node running".\r\nA questo punto per verificare che il programma effettivamente sta funzionando, ritornate nella finestra "ROS". Andate nella sezione "Topics List" e premete il pulsante "echo" nel topic "/hotbot/led" (ovvviamente hotbot è il robot di default se nel vostro caso avete un altro nome sarà diverso - ad es. dotbot ecc). Si aprirà sotto una finestra che visualizza i messaggi in tempo reale che stanno passando nel topic, in questo caso è un messaggio composto da tre campi "led1", "led2" e "led" perchè vogliamo con un messaggio solo controllare i 3 led del robot. Vederete che il campo del led1 cambia continuamente alternando true/false facendo così accenderlo e spegnerlo.\r\n\r\n![](./led_topic.PNG)\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-16-iniziamo-a-programmare/index.md",
    frontMatter: {
      path: "/hbr/iniziamo-a-programmare/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "3 mins",
      published: "2017-03-16T22:00:37.000Z",
      publishedReadable: "16 Mar 2017",
      featured: false,
      tags: [],
      title: "Iniziamo a programmare!",
      description: "",
      href: "/hbr/iniziamo-a-programmare/",
      image: "/content/hbr/hotblack.jpg",
      imagePath: "/content/hbr/2017-03-16-iniziamo-a-programmare",
    },
  },
  {
    content:
      "\r\nUn breve post per informarci su come installare nuove librerie Python sul robot utilizzabili dalla nostra interfaccia grafica.\r\n\r\n<strong>A breve sarà possibile installare nuove librerie direttamente dalla webapp</strong>\r\n\r\n## Accedere al Raspberry via SSH\r\n\r\nPer prima cosa, è necessario accedere via SSH al Raspberry su cui si vuole installare la nuova libreria.\r\n\r\nPer farlo, da mac o linux si può semplicemente eseguire la seguente linea di comando dal terminale\r\n\r\n```\r\nssh root@<ip robot>\r\n```\r\n\r\nesempio:\r\n\r\n```\r\nssh root@192.168.0.3\r\n```\r\n\r\ned inserire la password `raspberry`\r\n\r\nDa Windows, si può usare un client come [putty](http://www.putty.org/) inserendo come nome utente `root` e come password `raspberry`.\r\n\r\nL'indirizzo IP del raspberry lo trovate sulla piattaforma\r\n\r\n## Accedere al Virtualenv\r\n\r\nUna volta entrati, eseguite il seguente codice per accedere al virtualenv della piattaforma:\r\n\r\n```\r\nworkon ros\r\n```\r\n\r\nVedrete apparire la stringa `(ros)` all'inizio della shell.\r\n\r\n## Installare il pacchetto Python\r\n\r\nPer installare un pacchetto, eseguite la linea di codice\r\n\r\n```\r\npip install <nome pacchetto>\r\n```\r\n\r\nesempio\r\n\r\n```\r\npip install telepot\r\n```\r\n\r\nOppure eseguite i comandi come da documentazione del pacchetto richiesto.\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-16-installare-nuove-librerie-sul-hbrain-temporaneamente/index.md",
    frontMatter: {
      path: "/hbr/installare-nuove-librerie-sul-hbrain-temporaneamente/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-03-16T17:04:59.000Z",
      publishedReadable: "16 Mar 2017",
      featured: false,
      tags: [],
      title: "Installare nuove librerie sul HBRain (temporaneamente)",
      description: "",
      href: "/hbr/installare-nuove-librerie-sul-hbrain-temporaneamente/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-03-16-installare-nuove-librerie-sul-hbrain-temporaneamente",
    },
  },
  {
    content:
      '\r\nLa base tecnologica su cui si basa la piattaforma di cloud robotics è [ROS (Robotic Operating System)](http://wiki.ros.org/it). ROS è un framework software open source che permette lo sviluppo e la programmazione di robot. Fornisce le stesse funzioni di un sistema operativo come: astrazione dell\'hardware, controllo dei dispositivi tramite driver, comunicazione tra processi, gestione delle applicazioni e altre funzioni di uso comune. Si presta particolarmente bene alle nostre esigenze legate all\'internet delle cose poichè è un **sistema distribuito**, il che significa che diversi programmi sono distribuiti su robot differenti e comunicano tutti tramite la piattaforma.\r\n\r\nInoltre è particolarmente interessante perchè è utilizzato da tutti i principali sviluppatori software al mondo (sia accademici che industriali) come ad esempio Google, Stanford, ETH, MIT ecc.. Tant\'è che è diventato lo _standard de fact0_.\r\nDi conseguenza ha un enorme community molto competente pronta a risolvere problemi e bachi ad ogni momento e lo sviluppo di codice open source rende la comunità molto attiva.\r\n\r\nIniziamo a vedere come funziona!\r\n\r\nUn’applicazione ROS è una rete di processi che scambiano dati in una rete di comunicazione composta da macchine diverse (gli oggetti dell\'Internet dell cose o i robot).\r\n\r\n- Nodo: un singolo processo (programma in esecuzione) all’interno della rete ROS\r\n- Messaggio: struttura dati con cui usata per lo scambio di informazioni. Un messaggio può essere di diversi formati sia standard che custom. Ad esempio un messaggio che contiene un semplice intero sarà fatto così { int32 x }\r\n- Topic: canale all’interno del quale due o più nodi si scambiano messaggi. Immaginate un topic come un canale di comunicazione dove i messaggi vengono trasmessi. Ogni topic usa il carattere _slash_ prima del nome del topic (/nome_del_topic) ad esempio /chatter il topic dove due nodi si scambiano un semplice messaggio {String s}. La caratteristica importante e la potenzialità dei topic è che qualunque nodo può ascoltare (subscribe) o inviare messaggi (publish) sullo stesso topic in modo asincrono.\r\n\r\n![](./ROScomm.png)\r\n\r\nNell\'immagine sopra un esempio di comunicazione tra nodi attraverso i diversi topic. I nodi sono le figure ovali e i topic le frecce.\r\nRivediamo ora meglio i vari attori in piattaforma!\r\n\r\n## Effettuate l\'accesso alla piattaforma\r\n\r\nAndate sul sito di Hotblack Robotics (http://hotblackrobotics.github.io/) ed entrate nella piattaforma http://hotblackrobotics.github.io/login?next=%2Fcloud%2F. Inserite le vostre credenziali e siete in cloud!\r\n\r\n![](./cloudplatform.PNG)\r\n\r\nLa parte relativa la spiegazione di ROS la trovate nel menù in alto a sinistra sotto la voce "ROS".\r\n\r\n![](./Entratiincloud.PNG)\r\n\r\n## Nodi\r\n\r\nUn nodo è un processo (un programma in esecuzione) all’interno della rete ROS che esegue calcoli.\r\n\r\n- Ogni nodo è identificato da un nome unico nella rete\r\n- I nodi si scambiano messaggi per interagire tra loro tramite i topic\r\n- Ad ogni nodo è associato un compito. Due categorie\r\n  - Driver (controlla un sensore o attuatore\r\n  - Elaborazione (esegue calcoli)\r\n\r\nIn piattaforma trovate sempre sotto la voce "ROS" (http://hotblackrobotics.github.io/cloud/webgui/console) sotto la voce "Nodes List" la lista dei nodi attivi.\r\n\r\n![](./nodi.PNG)\r\n\r\n## Topic\r\n\r\nI topic sono i canali attraverso i quali i nodi comunicano nella rete.\r\n\r\n- Ogni topic è identificato da un nome unico\r\n- Un nodo che invia dati su un topic è detto _publisher_\r\n- Un nodo che riceve dati su un topic è detto _subscriber_\r\n\r\nSotto alla sezione "Nodes List" trovate la lista dei topic ("Topics List").\r\n\r\n![](./topics.PNG)\r\n\r\n## I messaggi\r\n\r\nI messaggi sono i tipi di dati che vengono inviati attraverso il topic\r\n\r\n- Informano i nodi su come interpretare i bites scambiati nei topic\r\n- Ad ogni topic è associato un messaggio specifico\r\n- Possono essere tipi semplici (**int, float, bool**) o **strutture dati**\r\n\r\n## Namespace\r\n\r\nPer distinguere nodi e topic con lo stesso nome si usano i namespace.\r\n\r\n- Prefisso da applicare ai topic e nodi\r\n- Definiscono una sottorete della rete ROS\r\n- Utili per distinguere lo stesso nodo/topic riferito a macchine diverse ma con la stessa funzione\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-03-14-il-fondamento-della-piattaforma-di-cloud-robotics-robotics-operating-system/index.md",
    frontMatter: {
      path: "/hbr/il-fondamento-della-piattaforma-di-cloud-robotics-robotics-operating-system/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2017-03-14T22:54:50.000Z",
      publishedReadable: "14 Mar 2017",
      featured: false,
      tags: [],
      title:
        "Il fondamento della piattaforma di Cloud Robotics: Robotics Operating System ",
      description: "",
      href: "/hbr/il-fondamento-della-piattaforma-di-cloud-robotics-robotics-operating-system/",
      image: "/content/hbr/hotblack.jpg",
      imagePath:
        "/content/hbr/2017-03-14-il-fondamento-della-piattaforma-di-cloud-robotics-robotics-operating-system",
    },
  },
  {
    content:
      "\nChi mi segue, conosce la mia grande passione per il mondo dei Makers e per la programmazione (specialmente in Python).\n\nDa un po' di tempo, sto cercando di fondere le mie passioni, aprendo il [mio blog](http://www.ludusrusso.cc/) e con la mia startup [HotBlack Robotics](http://www.hotblackrobotics.com/).\nCosa c'è di meglio quindi di una conferenza su Python per diffondere i miei interessi e per conoscerci?\n\n![PyCon 8](./Schermata_2017-03-15_alle_00.23.13_y0hexu.png)\n\nMi troverete quest'anno a [PyCon 8](http://www.pycon.it) con ben due trainig.\n\n## Costruiamo un laboratorio di Fisica con Arduino e Python - Giovedì 6 Aprile, ore 15:30 - 18:30\n\nLe recenti tecnologie utilizzate in ambito making (Arduino e Raspberry Pi) sono molto apprezzate in ambito didattico in quanto permettono, a bassissimo costo, di realizzare esperimenti di elettronica e di fisica in modo semplice. Inoltre, Python è sempre più apprezzato per l’elaborazione dei dati in ambito scientifico grazie alla sua semplicità e alla disponibilità di numerosi tool Open Source sviluppati per la programmazione scientifica.\nQuesto training si propone di utilizzare l’accoppiata Python e Arduino per sviluppare un laboratorio di fisica che possa essere utilizzato nelle scuole superiori per proporre esperimenti più o meno complessi in vari ambiti della fisica (meccanica, elettromagnetismo, ecc.). Questo lavoro nasce da un’esperienza fatta da me per il Liceo Scientifico G. Stampacchia di Tricase (LE). Liceo in cui ho studiato e con cui sto portando avanti alcune esperienze didattiche.\n\n### Scopo del training\n\nIl training è rivolto a insegnanti di fisica di scuole superiori e ad appassionati di fisica e programmazione. Il corso si propone di presentare alcuni esempi su come utilizzare la scheda Arduino e il linguaggio di programmazione Python per acquisire e analizzare dati dal mondo fisico. I partecipanti del training potranno progettare dei semplici esperimenti scientifici di fisica con tecnologie a basso costo.\n\n### Materiale\n\nI partecipanti del corso dovranno essere muniti di un PC o Mac con installato il software Spyder e l’IDE Arduino, che possono essere gratuitamente scaricati dai seguenti link:\nSpyder: https://pythonhosted.org/spyder /installation.html\nIDE Arduino: https://www.arduino.cc/en/Main/Software\n\n### Programma:\n\nIl programma del training è così organizzato:\n\n- Introduzione\n- Introduzione a Python e alla scheda di prototipazione Arduino\n- Installazione dei Tool necessari\n- Esperimento 1: circuito RC\n- Esperimento 2: misura della costante di Plank con un LED\n- Esperimento 3: Simuliamo un esopianeta\n- Conclusioni e Domande\n\n## Costruiamo L'Internet dei Robot - Domenica 9 Aprile - 9:00 - 13:00\n\nLa Cloud Robotics è una nuova tecnologia che parte dall’idea di connettere i robot ad internet. Grazie al Cloud, i robot sono più intelligenti ma anche più economici, in quanto possono demandare parte della loro “intelligenza” in remoto. La Cloud Robotics è legata al mondo dell’Internet of Things, e può essere vista come quella tecnologia che lega tra di loro la robotica e l’internet delle cose: da qui il nome Internet dei Robot.\n\nLo scopo del training è quello di introdurre i partecipanti alla programmazione di applicazioni robotiche connesse, sfruttando ROS (Robot Operating System) e la piattaforma HBR Cloud.\n\nROS, lo standard di fatto per lo sviluppo di applicazioni robotiche connesse, è un framework per la programmazione di Robot completamente Open Source. Offre API in Python che permettono, in modo semplice ed intuitivo, di mettere in comunicazione vari Robot tra di loro per mezzo di una connessione WiFi.\nHBR Cloud è una piattaforma di cloud robotics sviluppata da HotBlack Robotics. Lo scopo è fornire un’infrastruttura per la gestione e sviluppo di applicazioni robotiche e permettere agli sviluppatori di programmare i robot in modo semplice.\nIl workshop sarà incentrato sui DotBot, piccoli robottini Open Source che sono completamente compatibili con la piattaforma HBR. I robot (che verranno forniti dagli organizzatori) sono programmabili attraverso una WebApp sfruttando la libreria DotBot-ROS: una versione semplificata di ROS.\n\nIl workshop è aperto a Makers e Appassionati di tecnologie interessati alla robotica ed all’hacking. Ad ogni partecipante verrà fornito un account gratuito come beta tester per l’utilizzo della piattaforma di HBR Cloud.\n\n### Materiale:\n\n- Un computer portatile con connessione Wi-Fi con installato Google Chrome.\n- (Opzionale) un raspberry Pi con scheda SD su cui installare una propria versione di DotBot-Brain.\n\n### Programma:\n\n- Motivazioni (30min)\n  - Cos’è l’Internet of Things e cosa vuol dire Cloud Robotics. Perché abbiamo coniato il termine Internet dei Robot?\n  - Introduzione a ROS (Robot Operative System): scopo, finalità e funzionamento\n  - Introduzione al Raspberry Pi\n  - Perché progettare DotBot-R?\n- Introduzione a DotBot-ROS (60min)\n  - Utilizzo dell’IDE\n  - libreria gpiozero\n  - libreria DotBot-ROS\n- Esperimenti su DotBot-ROS (2.5h)\n  - Programmiamo un joystick via WebAPP!\n  - Facciamo Intergire i Robot!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-03-14-ci-vediamo-a-pycon-8/index.md",
    frontMatter: {
      path: "/2017/03/14/ci-vediamo-a-pycon-8/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-03-14T00:00:00.000Z",
      publishedReadable: "14 Mar 2017",
      featured: false,
      tags: ["Pycon"],
      title: "Ci vediamo a PyCon 8",
      description:
        "Mi troverete a PyCon 8 a Firenze per due workshop interattivi tra il 6 e il 9 Aprile",
      href: "/2017/03/14/ci-vediamo-a-pycon-8/",
      image:
        "/content/blog/it/2017-03-14-ci-vediamo-a-pycon-8/Schermata_2017-03-15_alle_00.23.13_y0hexu.png",
      imagePath: "/content/blog/it/2017-03-14-ci-vediamo-a-pycon-8",
    },
  },
  {
    content:
      "\nIn attesa di trovare il tempo per finire la seconda parte del mio tutorial sui led,\nscrivo questo breve tutorial per aiutare il mio amico Francesco a realizzare il suo progetto che prevede di utilizzare un Raspberry ed un Arduino per leggere dati di temperatura da un sensore DHT11.\n\n![DHT e Arduino](./WhatsApp_Image_2017-03-13_at_19.02.01_f7vjmy.jpg)\n\nGli ho subito suggerito di utilizzare Nanpy per gestire la comunicazione tra Arduino e Raspberry, tuttavia è venuto fuori che la libreria Nanpy non gestisce il sensore in questione di default (anche se è abilitata a farlo). Bisogna quindi avere una attimo di pazienza per abilitare ed usare il sensore.\n\nVediamo insieme come fare!\n\n##1. Scarichiamo nanpy-firmware\n\nPer prima cosa, è necessario scaricare il firmware di Nanpy da [qui](https://github.com/nanpy/nanpy-firmware).\n\n##2. Abilitiamo il sensore DHT\n\nUna volta scaricato il firmware, apriamo la cartella ad editare il file `sample_cgf.h`\n\nIn particolare, modifichiamo la linea 65\n\n```\n#define USE_DHT                                     0\n```\n\nfacendola diventare\n\n```\n#define USE_DHT                                     1\n```\n\nUna volta effettuata la modifica, copiamo questo file nella cartella `Nanpy` dandogli come nome `Nanpy/cfg.h` (per i più esperti, possiamo eseguire lo script `configure.sh`, che fa l'operazione di cui sopra).\n\n##3. Importiamo le librerie in Arduino\n\nA questo punto, non dobbiamo far altro che importare la cartella come libreria nell'IDE di Arduino. Insieme a questa, vanno anche importate due altre librerie da cui la gestione del sensore DHT deriva. Queste librerie sono\n\n- [DHT Sensor Library](https://github.com/adafruit/DHT-sensor-library)\n- [Adafruit Unified Sensor Driver](https://github.com/adafruit/Adafruit_Sensor)\n\nChe devono essere scaricate dai link sopra e incluse come libreria di Arduino.\n\n##4. Installiamo i Driver\n\nSiamo pronti ad installare i driver! Per farlo, apriamo il file **Nanpy.ino** che si trova all'interno della libreria _nanpy-firmware_ ed eseguiamola su Arduino! Una volta installato, siamo pronti ad eseguire il nostro programma su Python!\n\n##5. Circuito\n\nSviluppiamo un semplicissimo circuito per leggere i dati dal sensore. Io userò un sensore DHT22 (è uguale con un DHT11).\n\n![Circuito DHT](./arduino-dht22-temperature-hookup_oh726w.svg)\n\nIn particolare, dobbiamo collegare il PIN data del DHC (il secondo da sinistra) al PIN 2 di Arduino e all'alimentazione (5V) attraverso una resistenza da $10k\\Omega$.\n\n##6. Scriviamo un semplice programma Python\n\nPerfetto, a questo punto, siamo pronti a scrivere il nostro programma python per leggere i sensori.\n\nRicordate, se non lo avete già fatto, di installare **Nanpy** come indicato [qui](http://www.ludusrusso.cc/posts/2017-02-19-python-arduino-nanpy).\n\nA questo punto, possiamo implementare il codice. Sotto trovate un brevissimo esempio che vi mostra come leggere la temperatura dal Sensore.\n\n```python\n#!/usr/bin/env python\n\n# Esempio di Utilizzo di DHT con Nanpy\n\nfrom nanpy import DHT, SerialManager\n\n# Creo una connessione sulla porta a cui è collegato Arduino\n# e instanzio l'oggetto dht.\nconnection = SerialManager(device='/dev/cu.usbmodem1461')\ndht = DHT(2, DHT.DHT22, connection=connection)\n\n# DHT:\n#\tprimo parametro: pin a cui è connesso\n#  secondo parametro: tipo di sensore DHT.DHT22 o DHT.DHT11\n#  terzo parametro: oggetto connection manager\n\n\n# Con l'oggetto dht, posso leggere i valori di temperatura e umidità\n# dht.readTemperature(False) ritorna la temperatura in Gradi Centigradi\n# dht.readTemperature(True) ritorna la temperatura in Gradi Farenite\n# dht.readHumidity() ritorna l'umidità\n\nprint(\"Temperatura: %.2f gradi Celcius\" % dht.readTemperature(False))\nprint(\"Umidita': %.2f %%\" % dht.readHumidity())\n```\n\n##7. Utilizzo delle altre funzioni della libreria Nanpy insieme a DHT.\n\nSe volessimo utilizzare altre funzioni della libreria Nanpy, dobbiamo creare un secondo oggetto di tipo `ArduinoApi` e usarlo normalmente. Come nel programma sotto che accende e spegne un led e utilizza DHT per leggere l'umidità.\n\n```python\nfrom nanpy import DHT, SerialManager, ArduinoApi\nfrom time import sleep\n\nconnection = SerialManager(device='/dev/cu.usbmodem1461')\n\ndht = DHT(2, DHT.DHT22, connection=connection)\na = ArduinoApi(connection=connection)\n\na.pinMode(13, a.OUTPUT)\n\n\nfor i in range(1000):\n    print(\"Umidita': %.2f %%\" % dht.readHumidity())\n    a.digitalWrite(13, (i + 1) % 2)\n    sleep(0.2)\n```\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-03-13-utilizzo-di-nanpy-con-il-sensore-di-temperatura-umidita-della-famiglia-dht/index.md",
    frontMatter: {
      path: "/2017/03/13/utilizzo-di-nanpy-con-il-sensore-di-temperatura-umidita-della-famiglia-dht/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2017-03-13T00:00:00.000Z",
      publishedReadable: "13 Mar 2017",
      featured: false,
      tags: ["Dht", "Nanpy", "Python", "Arduino", "Tutorial"],
      title:
        "Utilizzo di Nanpy con il sensore di temperatura/umidità della famiglia DHT",
      description:
        "Come utilizzare Nanpy col sensore DHT di temperatura e Umidità",
      href: "/2017/03/13/utilizzo-di-nanpy-con-il-sensore-di-temperatura-umidita-della-famiglia-dht/",
      image:
        "/content/blog/it/2017-03-13-utilizzo-di-nanpy-con-il-sensore-di-temperatura-umidita-della-famiglia-dht/WhatsApp_Image_2017-03-13_at_19.02.01_f7vjmy.jpg",
      imagePath:
        "/content/blog/it/2017-03-13-utilizzo-di-nanpy-con-il-sensore-di-temperatura-umidita-della-famiglia-dht",
    },
  },
  {
    content:
      '\nPrendo ispirazione da [questo post](http://www.lafucinadellescienze.it/wordpress/archives/3878) pubblicato dal prof. Alfonso d\'Ambrosio per sviluppare il prossimo esperimento di fisica basato su Python e Arduino.\n\n![led spyder python](./Schermata_2017-02-23_alle_00.20.38_r2bl4e.png)\n\nIn questo esperimento, misureremo la curva tensione corrente di alcuni diodi led colorati, verificandone l\'andamento esponezione. In seguito, useremo i dati raccolti per misurare sperimentalmente il valore di una delle costanti fondamentali dalla fisica: la [**costante di Planck**](https://it.wikipedia.org/wiki/Costante_di_Planck) $h$.\n\nPer ulteriori informazioni su come utilizzare e installare **Spyder** e la libreria **nanpy** per il controllo seriale di Arduino, rimando al mio [precedente post](http://www.ludusrusso.cc/posts/2017-02-19-python-arduino-nanpy).\n\n## Diodo LED\n\nUn Diodo LED è uno dei componenti più utilizzati in elettronica, ed è uno dei primi componenti elettronici che si affrontano quando si iniziano a fare i primi esperimenti in elettronica. Essenzialmente, un Led è un componente elettronico che emette radiazioni luminose di un colore noto quando alimentato.\n\n### Teoria e simulazione di un Diodo\n\nDa un punto di vista elettronico, il Led è un Diodo: una resistenza non lineare il cui andamento corrente-tensione (ideale) è logaritmico e può essere descritto dalla seguente equazione\n\n$$\ni = I_0\\left(e^{\\frac{v}{nV_T}} - 1 \\right)\n$$\n\nDove $i$ e $v$ sono, rispettivamente, corrente che attraversa il diodo e tensione ai suoi capi, mentre $I_0$ (corrente di saturazione) e $V_T$ (tensione termica) sono parametri che caratterizzano il diodo stesso.\n\nUtilizzando i valori tipici per queste due costanti ($I_0 = 10^{-12}A$ e $V_T = $25.85mV\\$), è possibile simulare un classico diodo di silicio in Python e Spyder. Lo script utilizzato è il seguente\n\n```python\nfrom pylab import *\n\ndef diode(v, I0, VT):\n    return I0*(exp(v/VT)-1)\n\nI0 = 1e-12\nVT = 25.85e-3\n\nv = arange(0, 0.73, 0.01)\nplot(v, diode(v, I0, VT))\n\nxlabel("$v [V]$")\nylabel("$i [A]$")\n```\n\nChe produce, come risultato\n\n![simulazione diodo al silicio](./diode_sim_roujei.png)\n\nIn prima approssimazione, la curva logaritmica di un diodo può essere approssimata con una funzione spezzata descritta come segue\n\n$$\ni^* =\n\\begin{cases}\n\t0 & \\text{se $v < V_D$} \\\\\n\t\\frac{1}{R_D}(v-V_D) & \\text{se $v > V_D$}\n\\end{cases}\n$$\n\ndove $V_D$ è detta tensione di attivazione, ed è una costante empirica che rappresenta la minima tensione a partire dalla quale il diodo inizia a condurre. $R_D$ approssima la resistenza interna al diodo.\n\nPer approssimare una curva logartimica, si può procedere in vari modi. Io suggerisco di utilizzare la funzione `polyfit` (che approssima una serie di punti con un polinomio) considerando solo i punti dei grafico in cui la curva inizia effettivamente a crescere. La selezione di questi punti viene fatta manualmente, ad esempio, selezionando tutti i punti per cui $v>0.7$, come nello script qui riportato\n\n```python\nmask = v > 0.7\nRD, VD = polyfit(i[mask],v[mask],1)\n```\n\nPer plottare questi dati, dobbiamo prima di tutto implementare una funzione che genera $i^*$ a partire da $v$:\n\n```python\nimport numpy as np\n\ndef diode_approx(v, VD, RD):\n    i = np.array(v)\n\n    for k in range(len(v)):\n        if v[k] < VD:\n            i[k] = 0\n        else:\n            i[k] = (v[k]-VD)/RD\n    return i\n```\n\ne a questo punto, possiamo plottare insieme i due grafici, ottenendo quanto riportato in figura\n\n![approssimazione diodo](./diode_sim_approx_nwyysq.png)\n\n### Teoria sul LED\n\nCapiti i diodi, possiamo finalmente parlare di LED. Essenzialmente un diodo Led è un Diodo che emette fotoni (luce) di un particolare colore se polarizzato. La caratteristica dei diodi LED è che la tensione $V_D$ dipende dalla frequenza luminosa emessa, ed è esprimibile in questo modo:\n\n$$\nV_D \\simeq \\frac{h\\gamma}{e}\n$$\n\nDove $\\gamma$ è la frequenza della radiazione emessa, $h$ è la costante di Planck e $e$ è la carica elettrica dell\'elettrone (in valore assoluto).\n\nÈ quindi facile capire che, conoscendo la carica elettrica dell\'elettrone, è possibile ottenere una stima della costante di Planck misurando la tensione $V_D$ di led di diverso colore.\n\n## Conclusione prima parte\n\nPer adesso mi fermo qui, per non far diventare questo tutorial troppo lungo! Nel prossimo tutorial, vedremo come utilizzare la teoria presentata oggi per caratterizzare sperimentalmente un led con Arduino e Python e misurare la costante di Planck in modo sperimentale.\n\nSotto trovate il codice completo utilizzato in questo tutorial.\n\n```python\nfrom pylab import *\nimport numpy as np\n\ndef diode(v, I0, VT):\n    return I0*(exp(v/VT)-1)\n\ndef diode_approx(v, VD, RD):\n    i = np.array(v)\n\n    for k in range(len(v)):\n        if v[k] < VD:\n            i[k] = 0\n        else:\n            i[k] = (v[k]-VD)/RD\n    return i\n\n\nI0 = 1e-12\nVT = 25.85e-3\n\nv = arange(0, 0.79, 0.01)\ni = diode(v, I0, VT)\n\nplot(v, i)\n\nxlabel("$v [V]$")\nylabel("$i [A]$")\n\n\ndef diode_approx(v, VD, RD):\n    i = np.array(v)\n\n    for k in range(len(v)):\n        if v[k] < VD:\n            i[k] = 0\n        else:\n            i[k] = (v[k]-VD)/RD\n    return i\n\nmask = v > 0.7\nRD, VD = polyfit(i[mask],v[mask],1)\nplot(v, diode_approx(v, VD, RD))\n```\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-02-22-misurare-la-costante-di-planck-con-arduino-e-python-parte-1/index.md",
    frontMatter: {
      path: "/2017/02/22/misurare-la-costante-di-planck-con-arduino-e-python-parte-1/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-02-22T00:00:00.000Z",
      publishedReadable: "22 Feb 2017",
      featured: false,
      tags: ["Led", "Arduino", "Tutorial", "Python", "Fisica", "Diodo"],
      title: "Misurare la costante di Planck con Arduino e Python - Parte 1",
      description: "",
      href: "/2017/02/22/misurare-la-costante-di-planck-con-arduino-e-python-parte-1/",
      image:
        "/content/blog/it/2017-02-22-misurare-la-costante-di-planck-con-arduino-e-python-parte-1/Schermata_2017-02-23_alle_00.20.38_r2bl4e.png",
      imagePath:
        "/content/blog/it/2017-02-22-misurare-la-costante-di-planck-con-arduino-e-python-parte-1",
    },
  },
  {
    content:
      "\nCome premesso, ripropongo oggi l'esperimento sul circuito $RC$ presentato in [questo post](http://www.ludusrusso.cc/posts/2017-01-04-arduino-python-lab-fisica-1) e rivisto utilizzando l'IDE di programmazione scientifica **Spyder** e la libreria per sviluppare programmi Arduino in Python **nanpy**.\n\n![Spyder + Nanpy + RC](./Schermata_2017-02-21_alle_03.09.44_gxveep.png)\n\nPer info sull'accoppiata e su come installare il tutto, rimando al mio [precedente post](http://www.ludusrusso.cc/posts/2017-02-19-python-arduino-nanpy).\n\n## Teoria sul circuito $RC$\n\nIl circuito $RC$ è un semplice circuito elettronico composto da un condensatore (di capacità $C$) in serie ad una resistenza (di valore $R$).\n\nQuando un circuito $RC$ inizialmente spento viene alimentato ad una tensione $V_\\infty$, si può verificare che l'andamento nel tempo della tensione ai capi del condensatore rispetta la legge\n\n$$\nv(t) = V_\\infty \\cdot \\left(1-e^{-\\frac{t}{RC}}\\right)\n$$\n\nIl valore $\\tau = RC$ è anche detto _costante di tempo_.\n\n## Tolleranze dei Componenti\n\nNell'esperimento che proponiamo oggi, considereremo anche le tolleranze che abbiamo sui componenti elettronici che useremo.\nIn fisica è noto e accettato dalla comunità l'impossibilità di ottenere misure esatte. Ogni misura ottenuta si trova quindi all'interno di un insieme numerico (range di incertezza) di valori accettabili.\n\nSimilmente, riguardo ai componenti elettronici commerciali, è impossibile per i produttori creare componenti sempre uguali: per questo motivo, al valore _nominale_ di un componente è sempre associato una tolleranza, che ne definisce il range di incertezza.\n\nFacciamo un esempio: se prendiamo un resistore $R$ di valore nominale $100k\\Omega$ e tolleranza $5\\%$, sappiamo che la misura reale della resistenza del componente sarà all'interno del range $100\\Omega\\pm5\\% = [95 - 105]\\Omega$.\n\n## Scopo dell'esperimento\n\nLo scopo dell'esperimento è verificare che la legge delle carica del condensatore è rispettata.\nIl procedimento adottato sarà il seguente:\n\n- Utilizziamo la legge della carica del condensatore per simulare l'andamento (considerando le tolleranze dei componenti).\n- Misuriamo la carica di un condensatore di un circuito $RC$ reale.\n- Confrontiamo la simulazione con i dati reali verificando che la misura ricade all'interno del range di incertezza dei componenti.\n- Otteniamo una misura più precisa della costante di tempo $\\tau$ utilizzando Python.\n\n## Circuito\n\nIl circuito sviluppato è mostrato nella figura seguente.\nIl materiale utilizzato è qui riportato:\n\n- Arduino UNO.\n- Condensatore Elettrolitico $C=100\\mu F \\pm 50\\%$).\n- Resistore (nel mio caso con $R=200\\Omega\\pm5\\%$).\n- Breadboard.\n\nImportante: dato che Arduino (specialmente quando comunica in seriale) non è capace di acquisire dati ad una frequenza molto elevata, per riuscire a prendere un numero adeguato di dati conviene scegliere valori di $R$ e $C$ abbastanza elevati, in modo da avere constanti di tempo dell'ordine di qualche di qualche decina di millisecondi. Nel mio caso, ho scelto $\\tau=RC=0.02s$ nominale.\n\n![RC-Scheme](./RC.png)\n\nEssendo il condensatore che ho utilizzato elettrolitico, i suoi terminali sono polarizzati, ossia è necessario collegare il terminale positivo (anodo) ad un punto del circuito avente potenziale più elevato rispetto al punto di collegamento del terminale negativo (catodo). Nel caso si utilizzi un condensatore ceramico, non è importante la polarità!\n\nColleghiamo quindi il catodo ($-$) del condensatore al PIN GND di Arduino ,e l'anodo ($+$) tramite breadboard al pin $A0$. Colleghiamo inoltre, per mezzo di una resistenza, l'anodo del condensatore al PIN $2$ di Arduino.\n\n## Simulazione\n\nPer simulare l'andamento della tensione $v(t)$ dobbiamo considerare il parametro $\\tau = RC$. Date le tolleranze dei due circuiti, possiamo stimare la costante di tempo come\n\n$$\n\\tau = 0.02s \\pm 55\\% \\in [0.09, 0.31]s\n$$\n\nAndremo, quindi, a simulare 3 curve, rappresentate dalla $\\hat{\\tau} = 0.02s$ nominale, e dai valori minimo e massimo che essa può assumere: $\\tau_m = 0.009s$ e $\\tau_M = 0.031s$.\nIn questo esperimento non andremo a considerare le altre incertezze, come quella sulla tensione di carica $V_\\infty$ o dell'incertezze sulle misure dei sensori.\n\nPer disegnare le tre curve, implementiamo una funzione in Python che calcola i valori della curva data i campioni di tempo in forma di vettore e il valore di $tau$ da utilizzare\n\n```python\ndef v_s(t, tau):\n    return 5*(1-np.exp(-1/tau * t))\n```\n\nAndremo quindi ad utilizzare questa funzione all'interno di uno script in **Spyder**.\n\n```python\nfrom pylab import *\nimport numpy as np\n\ndef v_s(t, tau):\n    return 5*(1-np.exp(-1/tau * t))\n\nt = arange(0,0.2,0.0001)\ntau = 0.02\neps_tau = 0.55\ntau_m, tau_M = tau-eps_tau*tau, tau+ eps_tau*tau\n\nplot(t, v_s(t, tau), 'k-')\nplot(t, v_s(t, tau_m),'k--')\nplot(t, v_s(t, tau_M),'k--')\n```\n\nIl cui output sarà il seguente\n\n![Simulazione RC](./sim_rc_rwjncu.png)\n\nSi noti che la simulazione viene fatta fino a $0.2s$. Questo valore è calcolato in modo da essere molto più grande (circa 10 volte) la costante di tempo stimata.\n\n## Campionamento del Circuito RC\n\nA questo punto, utilizziamo **nanpy** per campionare i dati utilizzando il seguente script\n\n```python\n\nfrom datetime import datetime\nfrom nanpy import ArduinoApi, SerialManager\nfrom time import sleep\n\n# connessione ad arduino sulla porta seriale specifica\nconnection = SerialManager(device='/dev/cu.usbmodem1461')\na = ArduinoApi(connection=connection)\n\n# scarichiamo il condenatore\na.pinMode(2, a.OUTPUT)\na.digitalWrite(2, a.LOW)\nsleep(2)\n\n# carichiamo il condensatore e misuriamo l'andamento\na.digitalWrite(2, a.HIGH)\nts = datetime.now()\nvm, tm = [], []\nfor i in range(0,50):\n    vm.append(5.0*a.analogRead(14)/1023.0)\n    tm.append(datetime.now())\nprint 'stop'\n\n# convertiamo i dati in numpy\ntm = [(i-ts).total_seconds() for i in  tm]\ntm = np.array(tm)\nvm = np.array(vm)\n\n# plot\nplot(tm,vm, '.')\n```\n\nQuesto semplice script, dopo aver scaricato il condensatore, prevede a misurare la carica sul condensatore nel tempo, salvando anche i valori temporali in cui questi dati vengono campionati.\n\nAlla fine, plotta i valori misura nel tempo, ottenendo questo risultato.\n\n![Misura RC](./meas_rc_qdrv39.png)\n\nCome si può vedere dal grafico, l'andamento dei campioni è molto simile ad una curva esponenziale negativa.\n\nCome sopra, abbiamo fatto in modo che il campionamento vada avanti per circa 10 volte la stima della costante di tempo. Questo viene fatto modificando il numero di campioni all'interno del ciclo `for`.\n\n## Verifica della legge della carica del circuito e misura sperimentale di $\\tau$\n\nNon ci resta che verificare se la legge fisica di carica del condensatore è effettivamente verificata. Per fare questo, per prima cosa è necessario verificare che i campioni siano all'interno delle due curve simulate con i valori limite di $\\tau$ considerando le tolleranze. Per fare questo, basta eseguire di seguito i due script ripostati sopra in modo da sovrapporre i plot, ottenendo un risultato simile a questo:\n\n![Verifica RC](./ver_rc_qz1svo.png)\n\nIn cui si può effettivamente vedere che l'andamento stimato è rispettato.\n\nPer ultimo, verifichiamo che l'andamento dei campioni sia effettivamente ben approssimato da una curva esponenziale decrescente, e calcoliamo il $tau^*$ che meglio approssima questi campioni.\n\nPer far questo, possiamo utilizzare un interessante modulo chiamato `from scipy.optimize` ed in particolare la funzione `curve_fit` contenuta al suo interno.\n\nCon le seguenti linee di codice, chiediamo alla funzione `curve_fit` di calcolare il miglior `tau` che meglio approssima i dati campionati (`tm` e `vm`), utilizzando la funzione `v_s` implementata prima.\n\n```python\nfrom scipy.optimize import curve_fit\npopt, pcov = curve_fit(v_s, tm, vm)\n```\n\nLa funzione ritorna due valori:\n\n- `popt` è un array contenente il set di parametri di `v_s` che meglio approssima i dati (in questo caso, dato che l'unico parametro utilizzato è $\\tau$, `popt` conterrà un solo elemento).\n- `pcov` contiene l'errore di approssimazione\n\nPossiamo quindi utilizzare questi dati per estrapolare una misura più precisa del tau reale $\\tau^*$ e quindi la curva che meglio approssima i valori ottenuti.\n\nOtteniamo quindi\n\n- $\\tau^* = 0.028 \\in [0.09, 0.31]$ compatibile con il range di valori stimato all'inizio\n- Un errore molto piccolo $\\epsilon = 1.62\\cdot 10^{-7}$\n\nChe producono la curva rossa nel seguente grafico\n\n![Stima tau RC](./all_rc_fepxbe.png)\n\n## Codice Completo\n\nDi seguito vi riporto il codice completo utilizzato nel tutorial\n\n```python\n# -*- coding: utf-8 -*-\n\nfrom pylab import *\nimport numpy as np\nfrom nanpy import ArduinoApi, SerialManager\nfrom time import sleep\n\ndef v_s(t, tau):\n    return 5*(1-np.exp(-1/tau * t))\n\nt = arange(0,0.2,0.0001)\ntau = 0.02\neps_tau = 0.55\ntau_m, tau_M = tau-eps_tau*tau, tau+ eps_tau*tau\n\nplot(t, v_s(t, tau), 'k-')\nplot(t, v_s(t, tau_m),'k--')\nplot(t, v_s(t, tau_M),'k--')\n\nconnection = SerialManager(device='/dev/cu.usbmodem1461')\na = ArduinoApi(connection=connection)\n\na.pinMode(2, a.OUTPUT)\na.digitalWrite(2, a.LOW)\nsleep(2)\n\nprint 'start'\n\nfrom datetime import datetime\n\na.digitalWrite(2, a.HIGH)\nts = datetime.now()\n\nvm, tm = [], []\nfor i in range(0,50):\n    vm.append(5.0*a.analogRead(14)/1023.0)\n    tm.append(datetime.now())\nprint 'stop'\n\ntm = [(i-ts).total_seconds() for i in  tm]\n\ntm = np.array(tm)\nvm = np.array(vm)\n\nplot(tm,vm, '.')\n\nfrom scipy.optimize import curve_fit\npopt, pcov = curve_fit(v_s, tm, vm)\n\ntau_star = popt[0]\nepsilon = pcov[0]\nplot(t, v_s(t, tau_star),'r')\n```\n\n## Conclusioni\n\nCome potete vedere, utilizzando questi strumenti si può, in pochissimo tempo e con pochissimo materiale, sviluppare un esperimento di elettrotecnica semplice ma completo. È ovviamente possibile complicare a piacere questo esperimento aggiungendo nuovi componenti elettrici al circuito o utilizzando componenti di valori diversi.\n\nCome al solito, gli interessati possono contattarmi sulla mia pagina [facebook](https://www.facebook.com/ludusrusso.cc/?fref=ts) per commenti e/o consigli.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-02-21-un-laboratorio-di-fisica-con-python-e-arduino-circuito-rc-v2/index.md",
    frontMatter: {
      path: "/2017/02/21/un-laboratorio-di-fisica-con-python-e-arduino-circuito-rc-v2/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "7 mins",
      published: "2017-02-21T00:00:00.000Z",
      publishedReadable: "21 Feb 2017",
      featured: false,
      tags: ["Fisica", "Arduino", "Python", "Spyder", "Nanpy", "Tutorial"],
      title: "Un laboratorio di Fisica con Python e Arduino - Circuito RC v2",
      description: "",
      href: "/2017/02/21/un-laboratorio-di-fisica-con-python-e-arduino-circuito-rc-v2/",
      image:
        "/content/blog/it/2017-02-21-un-laboratorio-di-fisica-con-python-e-arduino-circuito-rc-v2/Schermata_2017-02-21_alle_03.09.44_gxveep.png",
      imagePath:
        "/content/blog/it/2017-02-21-un-laboratorio-di-fisica-con-python-e-arduino-circuito-rc-v2",
    },
  },
  {
    content:
      "\r\nEcco un semplice tutorial per spiegare un po' meglio come funzionano le Web App. Innanzitutto con il termine Web App intendiamo le applicazioni web che potete trovare nella tendina \"Apps\" in piattaforma. Queste Web App sono fatte da noi come esempio, ma ovviamente il codice è open source e in questo tutorial vi spiegheremo come potrete scrivere le vostre Web App. Attenzione però le Web App che andrete a scrivere (per motivi di sicurezza) saranno utilizzabili solo in locale sul vostro computer!\r\n\r\n![](./Schermata_2017-02-20_alle_18.36.52_txfrza.png)\r\n\r\nIniziamo a vedere il codice per una Web App di un publisher e subscriber in ROS. Aprite un documento di testo sul vostro pc e chiamatelo \"pubsub.html\". Poi copiate e incollate il seguente codice.\r\n\r\n```\r\n<!DOCTYPE html>\r\n<html>\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n\r\n<script type=\"text/javascript\" src=\"http://cdn.robotwebtools.org/EventEmitter2/current/eventemitter2.min.js\"></script>\r\n<script type=\"text/javascript\" src=\"http://cdn.robotwebtools.org/roslibjs/current/roslib.min.js\"></script>\r\n<script type=\"text/javascript\" src=\"http://hotblackrobotics.github.io/cloud/webgui/static/js/initros.js\"></script>\r\n<script type=\"text/javascript\">\r\n\r\nstart_ros('192.168.0.104', 'hotbot', '192.168.0.104:9090', 'None');\r\n\r\n\r\n</script>\r\n<script type=\"text/javascript\" type=\"text/javascript\">\r\n\r\n  // Publishing a Topic\r\n  // ------------------\r\n\r\n  var cmdVel = new ROSLIB.Topic({\r\n    ros : ros,\r\n    name : '/' + robot.name  + '/command_velocity',\r\n    messageType : 'geometry_msgs/Twist'\r\n  });\r\n\r\n  var twist = new ROSLIB.Message({\r\n    linear : {\r\n      x :100,\r\n      y : 100,\r\n      z : 0\r\n    },\r\n    angular : {\r\n      x : 0,\r\n      y : 0,\r\n      z : 0\r\n    }\r\n  });\r\n  cmdVel.publish(twist);\r\n\r\n  // Subscribing to a Topic\r\n  // ----------------------\r\n\r\n  var listener = new ROSLIB.Topic({\r\n    ros : ros,\r\n    name : '/' + robot.name  + '/listener',\r\n    messageType : 'std_msgs/String'\r\n  });\r\n\r\n  listener.subscribe(function(message) {\r\n    console.log('Received message on ' + listener.name + ': ' + message.data);\r\n  });\r\n\r\n</script>\r\n</head>\r\n\r\n<body>\r\n  <h1>Controlla ROS Console</h1>\r\n  <p>Sto pubblicando un messaggio su '/< nome_del_tuo_robot >/command_velocity'</p>\r\n  <p>E ascoltando su '/< nome_del_tuo_robot >//listener' un messaggio (guarda nella console del tuo browser) </p>\r\n\r\n</body>\r\n</html>\r\n```\r\n\r\nDovete modificare l'indirizzo IP del robot quando usate questa funzione `start_ros('192.168.0.104', 'hotbot', '192.168.0.104:9090', 'None'); `.\r\nUna volta connesso, nel mio caso ho ricevuto l'indirizzo IP 192.168.0.104 e il robot si chiama \"hotbot\". Poi andiamo a dichirare un publisher, che pubbblica sul topic relativo al nome del vostro robot `/<nome del vostro robot>/command_velocity` un tipo di messaggio geometry_msgs/Twist.\r\n\r\n```javascript\r\nvar cmdVel = new ROSLIB.Topic({\r\n  ros: ros,\r\n  name: \"/\" + robot.name + \"/command_velocity\",\r\n  messageType: \"geometry_msgs/Twist\",\r\n})\r\n```\r\n\r\nRiempiamo il messaggio così\r\n\r\n```javascript\r\nvar twist = new ROSLIB.Message({\r\n  linear: {\r\n    x: 100,\r\n    y: 100,\r\n    z: 0,\r\n  },\r\n  angular: {\r\n    x: 0,\r\n    y: 0,\r\n    z: 0,\r\n  },\r\n})\r\n```\r\n\r\ne lo pubblichiamo\r\n\r\n```javascript\r\ncmdVel.publish(twist)\r\n```\r\n\r\nPer quanto riguara il subscriber, lo dichiariamo che rimanga in ascolto sul topic `'/<nome del vostro robot>/listener'` (messaggio std_msgs/String).\r\nE la funzione di call back:\r\n\r\n```javascript\r\nlistener.subscribe(function (message) {\r\n  console.log(\"Received message on \" + listener.name + \": \" + message.data)\r\n})\r\n```\r\n\r\nVedrete il risultato della funzione call back sul browser premendo col tasto destro del mouse e andando su console.\r\nFacile no? ;)\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-20-come-creare-una-semplice-web-app-per-interagire-con-il-vostro-robot/index.md",
    frontMatter: {
      path: "/hbr/come-creare-una-semplice-web-app-per-interagire-con-il-vostro-robot/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "2 mins",
      published: "2017-02-20T18:03:13.000Z",
      publishedReadable: "20 Feb 2017",
      featured: false,
      tags: [],
      title:
        "Come creare una semplice Web App per interagire con il vostro robot",
      description: "",
      href: "/hbr/come-creare-una-semplice-web-app-per-interagire-con-il-vostro-robot/",
      image:
        "/content/hbr/2017-02-20-come-creare-una-semplice-web-app-per-interagire-con-il-vostro-robot/Schermata_2017-02-20_alle_18.36.52_txfrza.png",
      imagePath:
        "/content/hbr/2017-02-20-come-creare-una-semplice-web-app-per-interagire-con-il-vostro-robot",
    },
  },
  {
    content:
      "\nCiao a tutti, finalmente riesco a trovare un po' di tempo per scrivere sul blog, che è stato trascurato a causa di vari impegni (tesi di PhD, StartUp, ecc.).\n\n![Python Nanpy Arduino](./nanpy_wyg6az.png)\n\nDurante la ricerca del sistema migliore per sviluppare la mia idea di laboratorio di fisica basata su Python e Arduino, mi sono imbattuto in un interessantissimo progetto chiamato [**nanpy**](https://github.com/nanpy/nanpy), che essenzialmente permette di programmare via Python un Arduino connesso in Seriale al Computer.\n\n## Idea Base di Nanpy\n\nCerco brevemente di spiegare di cosa si tratta e coma funziona. Nanpy è l'insieme di due cose:\n\n- un protocollo seriale che permette di inviare comandi ad Arduino\n- una libreria Python che sfrutta questo protocollo\n\nIn poche parole, il nostro Arduino diventa uno _slave_, cioè non è più un dispositivo indipendente ma necessita di un computer vero e proprio che continuamente impartisce comandi che lui poi esegue! Questi comandi vengono mandati in Python.\n\nOvviamente questo metodo porta sia vantaggi che svantaggi. Gli svantaggi, come è ovvio, sono il fatto che non possiamo più utilizzare Arduino come un dispositivo separato dal computer. Nel nostro caso, questo non è un problema, in quanto il nostro scopo principale è quello di usare Arduino come scheda di acquisizione dati, che verranno comunque e sempre poi analizzati da un computer.\n\nUn altro grosso svantaggio è il fatto che la comunicazione seriale fa da collo di bottiglia per la velocità del programma. Ma anche in questo caso, finchè non si ha la necessità di eseguire un programma molto velocemente, il problema è trascurabile.\n\nI principali vantaggi sono che non dobbiamo più scrivere codice Arduino per ogni esperimento di fisica (a meno che questo non richieda dei compiti particolari, ma per il momento non succederà!) e possiamo sfruttare un singolo programma sviluppato in Python.\n\n## Installazione del Firmware Nanpy su Arduino\n\n**Nanpy-Firmware** è il programma che gira su Arduino in grado di comunicare via Seriale con la libreria Nanpy.\n\nPer installarlo, prima di tutto è necessario scaricare il firmware da [questo link](https://github.com/nanpy/nanpy-firmware).\n\nUna volta scaricata questa cartella, al suo interno troverete una cartella **Nanpy** con all'interno un file chiamato **Nanpy.ino**.\n\n![File Nanpy](./Schermata_2017-02-19_alle_20.12.23_jgk8o4.png)\n\nAprite questo file nell'IDE di Arduino e lanciate il programma.\n\n![Arduino Nanpy firmware](./Schermata_2017-02-19_alle_20.12.43_eahnpl.png)\n\nA me da un bel po' di warning di compilazione, ma l'installazione ed esecuzione su una scheda Arduino UNO non da nessun problema.\n\n## Installazione della libreria Nanpy (su Spyder)\n\nL'installazione della libreria **nampy** avviene tramite il package manager **pip** fornito da Python. Per installarla, quindi, basta eseguire, da linea di comando, l'istruzione\n\n```bash\npip install nampy\n```\n\nSe volete installare Nanpy su **Spyder**, l'IDE Python open source per la programmazione scientifica, basta esegure l'istruzione\n\n```python\n!pip install nampy\n```\n\nall'interno della console iPython.\n\n## Programma di esempio: Blink Arduino\n\nUna volta installati libreria e firmware su Arduino, siamo pronti a scrivere il nostro primo programma Nanpy. Trattandosi di Arduino, come primo programma implementeremo un semplice programma che accende e spegne un LED (il classico Blink).\n\nCome IDE, utilizzerò Spyder, ma ad ogni modo è possibilissimo implementare il programma con un qualsiasi IDE.\n\n![Spyder](./Schermata_2017-02-19_alle_20.00.20_hljq5v.png)\n\nUna volta aperto Spyder, creiamo un nuovo file e implementiamo il seguente codice\n\n```python\nfrom nanpy import ArduinoApi, SerialManager\nfrom time import sleep\n\nconnection = SerialManager(device='/dev/cu.usbmodem1421')\na = ArduinoApi(connection=connection)\n\na.pinMode(13, a.OUTPUT)\n\nwhile True:\n    a.digitalWrite(13, 0)\n    sleep(0.2)\n    a.digitalWrite(13, 1)\n    sleep(0.2)\n```\n\n![Spyder Blink test](./Schermata_2017-02-19_alle_20.04.46_xku6pa.png)\n\nSalviamo il file dandogli il nome `blink.py` ed eseguiamolo. In fase di esecuzione, se tutto va bene, il vostro Arduino inizierà ad Accendere e Spegnere il led L (quello montato direttamente sulla scheda). Vedrete anche i led TX e RX lampeggiare, in quanto la comunicazione seriale sarà attiva, come spiegato sopra.\n\nPer spegnere il programma, basta premere i tasti CTRL-C!\n\n## Conclusioni\n\nHo fatto altri esperimenti con Nanpy che riporterò qui a breve. La mia idea, da qui in avanti, sarà di iniziare a sviluppare piccoli esperimenti di fisica utilizzando l'accoppiata Spyder e Arduino per mezzo della libreria Nanpy. Il primo esperimento (a cui sto già lavorando) che riporterò qui sarà lo stesso proposto in [questo post](http://www.ludusrusso.cc/posts/2017-01-04-arduino-python-lab-fisica-1) ma sviluppato sfruttando queste librerie!\n\nCome al solito, per domande e suggerimenti contattatemi tramite [facebook](https://www.facebook.com/ludusrusso.cc/?fref=ts)!\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-02-19-python-arduino-nanpy/index.md",
    frontMatter: {
      path: "/2017/02/19/python-arduino-nanpy/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-02-19T00:00:00.000Z",
      publishedReadable: "19 Feb 2017",
      featured: false,
      tags: ["Arduino", "Python", "Nanpy", "Tutorial"],
      title: "Python + Arduino = Nanpy",
      description: "Programmare Arduino in Python con Nanpy",
      href: "/2017/02/19/python-arduino-nanpy/",
      image:
        "/content/blog/it/2017-02-19-python-arduino-nanpy/nanpy_wyg6az.png",
      imagePath: "/content/blog/it/2017-02-19-python-arduino-nanpy",
    },
  },
  {
    content:
      "\r\nIn questo tutorial vedremo come creare un semplice bot telegram in grado di controllare un robot in cloud.\r\n\r\n## Cosa serve?\r\n\r\nPer sviluppare questo progetto, vi servirà essere iscritti alla nostra piattaforma ed avere a disposizione un robot [reale](http://hotblackrobotics.github.io/blog/posts/2017-02-08-dotbot-tutorial-hardware) o [virtuale](http://hotblackrobotics.github.io/blog/posts/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o).\r\n\r\nQuesta volta, useremo un robot reale per dialogare con il robot! Ad ogni modo, potrete comunque richiedere il vostro robot virtuale per fare prove!\r\nSe volete utilizzare un robot virtuale scriveteci a **info@hotblackrobotics.com**!\r\n\r\nPer prima cosa, è importate iscriversi alla piattaforma e collegarsi al robot, potete seguire le istruzioni all'inizio di [questo tutorial](http://hotblackrobotics.github.io/blog/posts/2017-02-10-tutorial-usiamo-la-piattaforma-di-cloud-robotics-per-sviluppare-un-semplice-assistente-personale-robotico).\r\n\r\n## Creazione di un Bot Telegram\r\n\r\nPer prima cosa, è necessario configurare un bot telegram! Per farlo, telegram mette a disposizione un bot (chiamato **BotFather**) in grado di creare altri bot.\r\n\r\nAssicuriamoci di aver installato telegram sul nostro dispositivo e accediamo al [BotFather cliccando qui](https://telegram.me/BotFather). Una volta aperta la chat con **BotFather** lui ci informerà (in inglese) sulle azioni che possiamo fare.\r\n\r\n![BotFather primo contatto](./Schermata_2017-02-16_alle_13.50.11_cnqybw.png)\r\n\r\nPer creare un nuovo bot, inviamo il comando `/newbot`, a cui il **BotFather** risponderà chiedendo che nome dare al proprio bot\r\n\r\n![Diamo un nome al bot](./Schermata_2017-02-16_alle_13.50.05_ru42nq.png)\r\n\r\nUna volta scelto il nome (**BotFather** ci informa se il nome è già stato preso), verrà creato il nostro bot e ci verranno fornite due informazioni essenziali:\r\n\r\n- l'URL del bot, grazia al quale potremmo aprire la chat\r\n- il Token del bot (**da mantenere segreto**) che servirà per sviluppare il codice.\r\n\r\n![Bot Creato](./Schermata_2017-02-16_alle_13.50.19_zvxpdf.png)\r\n\r\nUna volta creato il bot, cliccando sull'URL, potremmo aprire la chat! Ovviamente adesso non succederà nulla perchè il bot non è ancora stato implementato.\r\n\r\n![Bot Chat](./Schermata_2017-02-16_alle_13.54.43_xnqcvr.png)\r\n\r\n## Creazione del nostro programma\r\n\r\nUna volta connessi, creiamo un nuovo programma chiamato _telebot_, seguendo le istruzioni di seguito.\r\n\r\nDopo esserci loggati in piattaforma, apriamo il tab **sketches**.\r\n![aprire sketches](./Schermata_2017-02-16_alle_13.44.25_zpckl8.png)\r\n\r\nCreiamo un nuovo sketch e apriamolo\r\n\r\n![nuovo sketch](./Schermata_2017-02-16_alle_13.44.32_zljmyj.png)\r\n![aprire sketch](./Schermata_2017-02-16_alle_13.44.37_toe9mx.png)\r\n\r\n## Implementiamo un semplice Bot\r\n\r\nA questo punto, siamo pronti ad implementare un semplicissimo bot che risponde alla nostra chat.\r\nNel programma appena crato, implementiamo il seguente codice.\r\n\r\n```python\r\nimport dotbot_ros\r\nimport telepot\r\n\r\nimport sys\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'bot'\r\n    TOKEN = \"INSERISCI QUI IL TUO TOKEN\"\r\n\r\n    def setup(self):\r\n        self.bot = telepot.Bot(self.TOKEN)\r\n        self.bot.message_loop(self.handle)\r\n\r\n    def handle(self, msg):\r\n        content_type, chat_type, chat_id = telepot.glance(msg)\r\n\r\n        if content_type == 'text':\r\n            cmd = msg['text'].split()\r\n            if cmd[0] == '/start':\r\n                self.bot.sendMessage(chat_id, \"ciao, benvenuto nella mia chat!\")\r\n            elif cmd[0] == '/ciao':\r\n                self.bot.sendMessage(chat_id, \"ciao, come stai?\")\r\n            else:\r\n                self.bot.sendMessage(chat_id, \"scusa, non capisco, conosco solo il comando '/ciao'\")\r\n        print msg\r\n        sys.stdout.flush()\r\n```\r\n\r\n**IMPORTANTE: ricordate di modificare la linea `TOKEN = \"INSERISCI QUI IL TUO TOKEN\" ` inserendo il token del vostro robot tra i doppi apici**\r\n\r\n![codice bot implementato](./Schermata_2017-02-16_alle_14.12.49_il2g6h.png)\r\n\r\nUna volta implementato il programma, salviamo e lanciamo il codice! A questo punto, se tutto va bene, potremmo aprire la chat telegram col nostro bot e iniziare a dialogare con lui!\r\n\r\n![programma lanciato](./Schermata_2017-02-16_alle_14.12.41_b4jbal.png)\r\n\r\n![bot dialogo](./Schermata_2017-02-16_alle_14.09.45_dkn7v0.png)\r\n\r\n## Analizziamo il codice\r\n\r\nCome al solito, il nostro programma è composto da un nodo ROS, la funzione princiapale è la funzione `setup`, che si occupa di inizializzare il bot e creare una callback di gestione.\r\n\r\n```python\r\n    def setup(self):\r\n        self.bot = telepot.Bot(self.TOKEN)\r\n        self.bot.message_loop(self.handle)\r\n```\r\n\r\nIn particolare, la linea `self.bot = telepot.Bot(self.TOKEN)` crea il bot utilizzando il nostro token, mentre la seconda linea `self.bot.message_loop(self.handle)` dice che, ogni volta che un nuovo messaggio viene mandato al bot, bisogna chiamare la funzione `self.handle`.\r\n\r\nLa funzione `handle`, quindi, viene chiamata quando un nuovo messaggi è mandato alla nostra chat, ed.è implementata come segue:\r\n\r\n```python\r\n    def handle(self, msg):\r\n        content_type, chat_type, chat_id = telepot.glance(msg)\r\n\r\n        if content_type == 'text':\r\n            cmd = msg['text'].split()\r\n            if cmd[0] == '/start':\r\n                self.bot.sendMessage(chat_id, \"ciao, benvenuto nella mia chat!\")\r\n            elif cmd[0] == '/ciao':\r\n                self.bot.sendMessage(chat_id, \"ciao, come stai?\")\r\n            else:\r\n                self.bot.sendMessage(chat_id, \"scusa, non capisco, conosco solo il comando '/ciao'\")\r\n        print msg\r\n        sys.stdout.flush()\r\n```\r\n\r\nAlla funzione viene passato come parametro il messaggio mandato alla chat, contenuto nella variabile `msg`.\r\n\r\nPer prima cosa, è necessario estrarre informaizoni utili dalla chat, in particolare il `chat_id` (che identifica univocamente la chat aperta, in modo che il bot possa gestire più chat contemporaneamente), e il `content_type`, cioè il tipo di dati contenuti nel messaggio.\r\nQuesta operazione viene fatta dalla riga `content_type, chat_type, chat_id = telepot.glance(msg)`.\r\n\r\nA questo punto, dobbiamo verificare che il messaggio sia di tipo testuale (il bot al momento non sa gestire immagini, video o file). Facciamo quindi il check `if content_type == 'text':`.\r\n\r\nSe il messaggio è di tipo testuale, possiamo andare ad analizzarlo. Il messaggio sarà contenuto in una stringa `msg['text']` di testo. Possiamo dividere la stringa nelle parole contenute utilizzando il metodo `plit()`, come nella riga `cmd = msg['text'].split()`. In questo modo, se la stringa è `\"ciao come stai?\"`, la variabile `cmd` sarà uguale a `['ciao', 'come', 'stai?']`.\r\n\r\nOra possiamo analizzare la prima parola, rispondendo in modo diverso in base al valore di questa. Al momento, il robot risponde solamente a due parole: `/ciao` e `/start` (notare lo `/`). Questo viene fatto all'interno del costrutto `if ... elif ... else`.\r\n\r\nPer rispondere alla chat, utilizziamo il la riga `self.bot.sendMessage(chat_id, \"ciao, come stai?\") `, dove il primo parametro è l'id della chat stessa, mentre il secondo parametro è la stringa da mandare.\r\n\r\n### Esercizio\r\n\r\nProvate ad implemntare altri comandi!\r\n\r\n## Controlliamo il robot da chat telegram!\r\n\r\nUna volta capito come mandare comandi al robot, possiamo tranquillamente implementare dei comandi per farlo muovere. Per farlo, bisogna modificare il nostro programma come segue.\r\n\r\n1. Importare dalla libreria gpiozero l'oggetto Robot\r\n2. Creare un oggetto `Robot` nella funzione di `setup`\r\n3. Implementare i comandi nel costrutto `if ... elif ... else`\r\n4. Nei nuovi comandi, controllare i motori tramite l'oggetto Robot.\r\n\r\nIl nuovo codice implementato è il seguente\r\n\r\n```python\r\nimport dotbot_ros\r\nimport telepot\r\n\r\nfrom gpiozero import Robot\r\nimport time\r\nimport sys\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'bot'\r\n    TOKEN = \"INSERISCI QUI IL TUO TOKEN\"\r\n\r\n    def setup(self):\r\n        self.bot = telepot.Bot(self.TOKEN)\r\n        self.bot.message_loop(self.handle)\r\n        self.robot = Robot(left=(9, 10), right=(7, 8))\r\n\r\n\r\n    def handle(self, msg):\r\n        content_type, chat_type, chat_id = telepot.glance(msg)\r\n\r\n        if content_type == 'text':\r\n            cmd = msg['text'].split()\r\n            if cmd[0] == '/start':\r\n                self.bot.sendMessage(chat_id, \"ciao, benvenuto nella mia chat!\")\r\n            elif cmd[0] == '/ciao':\r\n                self.bot.sendMessage(chat_id, \"ciao, come stai?\")\r\n            elif cmd[0] == '/avanti':\r\n                self.bot.sendMessage(chat_id, \"ok, vado avanti\")\r\n                self.robot.forward()\r\n                time.sleep(0.5)\r\n                self.robot.stop()\r\n            elif cmd[0] == '/dietro':\r\n                self.bot.sendMessage(chat_id, \"ok, vado dietro\")\r\n                self.robot.backward()\r\n                time.sleep(0.5)\r\n                self.robot.stop()\r\n            elif cmd[0] == '/destra':\r\n                self.bot.sendMessage(chat_id, \"ok, giro a destra\")\r\n                self.robot.right()\r\n                time.sleep(0.5)\r\n                self.robot.stop()\r\n            elif cmd[0] == '/sinistra':\r\n                self.bot.sendMessage(chat_id, \"ok, giro a sinistra\")\r\n                self.robot.left()\r\n                time.sleep(0.5)\r\n                self.robot.stop()\r\n            else:\r\n                self.bot.sendMessage(chat_id, \"scusa, non capisco, conosco solo il comando '/ciao'\")\r\n        print msg\r\n        sys.stdout.flush()\r\n```\r\n\r\nProvate quindi a rilanciare il programma e far muovere un robot. Ecco qui un video che mostra il risultato finale!\r\n\r\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/uoY_GEP8YFw\" frameborder=\"0\" allowfullscreen></iframe>\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-16-tutorial-sviluppiamo-un-bot-telegram-in-ros/index.md",
    frontMatter: {
      path: "/hbr/tutorial-sviluppiamo-un-bot-telegram-in-ros/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2017-02-16T14:02:45.000Z",
      publishedReadable: "16 Feb 2017",
      featured: false,
      tags: [],
      title: "Tutorial - Sviluppiamo un Bot Telegram in ROS",
      description: "",
      href: "/hbr/tutorial-sviluppiamo-un-bot-telegram-in-ros/",
      image:
        "/content/hbr/2017-02-16-tutorial-sviluppiamo-un-bot-telegram-in-ros/Schermata_2017-02-16_alle_15.01.01_k4kh7s.png",
      imagePath:
        "/content/hbr/2017-02-16-tutorial-sviluppiamo-un-bot-telegram-in-ros",
    },
  },
  {
    content:
      '\r\nCiao a tutti, iniziamo con questo post una serie di tutorial più completi per lo sviluppo di semplici applicazioni Robotiche. In particolare, in questo tutorial vedremo come sfruttare la nostra piattaforma per sviluppare un\'applicazione che permetta di inviare comandi al robot tremite voce e ricevedere informazioni vocali dal robot stesso.\r\n\r\n## Cosa serve?\r\n\r\nPer sviluppare questo progetto, vi servirà essere iscritti alla nostra piattaforma ed avere a disposizione un robot [reale](http://hotblackrobotics.github.io/blog/posts/2017-02-08-dotbot-tutorial-hardware) o [virtuale (tramite la cloud)](http://hotblackrobotics.github.io/blog/posts/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o).\r\n\r\nIn questo tutorial, per semplicità, useremo un robot virtuale ma ovviamente si può benissimo utilizzare il robot reale!\r\n\r\nSe volete utilizzare un robot virtuale scriveteci a info@hotblackrobotics.com!\r\n\r\n## Iniziamo: accediamo alla piattaforma e colleghiamoci al Robot\r\n\r\nAccediamo al sito [hotblackrobotics.github.io](http://hotblackrobotics.github.io) ed effettuiamo il Login\r\n\r\n![sito hotblack robotics](./Schermata_2017-02-09_alle_17.24.27_o2js8p.png)\r\n\r\nEffettuiamo il Login con le nostre credenziali\r\n![Effettuo Login](./Schermata_2017-02-09_alle_17.24.36_ur1zvl.png)\r\n\r\nAccediamo alla piattaforma premendo sul tab _cloud_\r\n![Accesso alla piattaforma cloud](./Schermata_2017-02-09_alle_17.24.49_crt92p.png)\r\n\r\nA questo punto, possiamo collegarci al robot.. Insieriamo il nome o l\'indirizzo IP del robot e connettiamoci.\r\n\r\n![Inserimento IP Robot](./Schermata_2017-02-09_alle_18.05.03_gorkzs.png)\r\n\r\nUna volta cliccato "Cerca Robot", se tutto va bene, otterremo il seguente messaggio!\r\n\r\n![Robot Connesso](./Schermata_2017-02-09_alle_18.05.08_dwgqnj.png)\r\n\r\n## Creiamo il nostro programma\r\n\r\nUna volta connesso il robot, siamo pronti ad iniziare a sviluppare il programma! A questo punto andiamo sul tab _sketches_.\r\n\r\n![iniziamo a programmare](./Schermata_2017-02-10_alle_18.15.58_chnyyy.png)\r\n\r\nCreiamo un nuovo programma chiamato "assistente robotico" e successivamente premiamo il bottone "new".\r\n\r\n![assistente robbotico](./Schermata_2017-02-10_alle_18.18.40_elmjy5.png)\r\n\r\nApriamo il file con il tasto "edit" e scriviamo il seguente programma.\r\n\r\n```python\r\nimport dotbot_ros\r\nfrom std_msgs.msg import String\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = \'speech_bot_example\'\r\n\r\n    def setup(self):\r\n        self.pub_speech = dotbot_ros.Publisher(\'to_speech\', String)\r\n        dotbot_ros.Subscriber(\'speech\', String, self.on_speech)\r\n\r\n    def on_speech(self, msg):\r\n        if msg.data == \'ciao\':\r\n            self.pub_speech.publish("Ciao, come va?")\r\n        elif msg.data == \'mondo\':\r\n            self.pub_speech.publish("Vuoi dire Ciao Mondo?")\r\n```\r\n\r\n![programma](./Schermata_2017-02-10_alle_18.28.56_jh1gsi.png)\r\n\r\nNel programma stiamo definendo un _Publisher_ di nome `pub_speech` che pubblica sul topic `to_speech` e invia un messaggio di tipo "String" ed un _Subscriber_ che richiama la call back `on_speech` chiamata ogni volta che sul topic `speech` arriva un messaggio di tipo "String". Ora aprendo la Web App "Speech Rec" e abbilitando il microfono del vostro computer, tramite il tasto centrale, quando pronuncicamo la parola "ciao" il robot ci risponderà "Ciao, come va?" e pronunciando "mondo" il robot risponderà "Vuoi dire ciao mondo?".\r\n\r\nNB: ovviamente dovrete inserire nella casella "inserisci" le parole "ciao" e "mondo" altrimenti il robot non riconoscerà le parole!\r\n\r\n![](./Schermata_2017-02-10_alle_18.41.50_ury16w.png)\r\n\r\nProvate ad inserire altre parole e personalizzate il vostro assistente robotico!\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-10-tutorial-usiamo-la-piattaforma-di-cloud-robotics-per-sviluppare-un-semplice-assistente-personale-robotico/index.md",
    frontMatter: {
      path: "/hbr/tutorial-usiamo-la-piattaforma-di-cloud-robotics-per-sviluppare-un-semplice-assistente-personale-robotico/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "2 mins",
      published: "2017-02-10T17:48:31.000Z",
      publishedReadable: "10 Feb 2017",
      featured: false,
      tags: [],
      title:
        "Tutorial - Usiamo la piattaforma di Cloud Robotics per sviluppare un semplice assistente personale Robotico",
      description:
        "Usiamo la piattaforma di Cloud Robotics per sviluppare un semplice assistente personale Robotico",
      href: "/hbr/tutorial-usiamo-la-piattaforma-di-cloud-robotics-per-sviluppare-un-semplice-assistente-personale-robotico/",
      image:
        "/content/hbr/2017-02-10-tutorial-usiamo-la-piattaforma-di-cloud-robotics-per-sviluppare-un-semplice-assistente-personale-robotico/Schermata_2017-02-10_alle_18.41.50_ury16w.png",
      imagePath:
        "/content/hbr/2017-02-10-tutorial-usiamo-la-piattaforma-di-cloud-robotics-per-sviluppare-un-semplice-assistente-personale-robotico",
    },
  },
  {
    content:
      '\r\nDa quando abbiamo iniziato a mostrare in giro la nostra piattaforma di Cloud Robotics, sempre più gente mi fa questa domanda: **Ma quindi, cosa si può fare con la piattaforma di Cloud robotics?**.\r\n\r\nScrivo questo post per avere un punto di riferimento a cui rimandare le persone che me la fanno (da buon informatico preferisco fare copia incolla che rifare ogni volta le stesse cose)....\r\n\r\nEcco una lista delle cose che attualmente la nostra piattaforma può fare :)\r\n\r\n1. Programmazione remota di Robot\r\n2. Controllo remoto\r\n3. Riconoscimento e Sintesi Vocale\r\n4. Applicazioni Multi Robot\r\n5. Streaming Video e Computer Vision\r\n6. Applicazioni di Robotica di Servizio\r\n\r\n### Programmazione remota di Robot\r\n\r\nLa prima cosa che vedete della nostra piattaforma è un editor di testo che permette di sviluppare codice python e ROS in modo semplice e veloce, utilizzando un\'interfaccia internet che permette anche di programmare remotamente il robot se raggiungibile tramite IP pubblico.\r\n\r\n![Interfaccia Cluod Robotics](./Schermata_2017-02-08_alle_17.27.39_sl8vdb.png)\r\n\r\nÈ anche possibile utilizzare dei Robot Virtuali in Cloud appositamente sviluppati per inziare a sviluppare in ROS senza avere necessariamente un hardware reale a disposizione, [trovate info qui](http://hotblackrobotics.github.io/blog/posts/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o)\r\n\r\nPerchè abbiamo scelto di utilizzare ROS?\r\nI motivi sono due (più un terzo che però deriva dalla nostra esperienza):\r\n\r\n1. È uno standard a livello accademico e industriale (Google/TIM assumono se sai programmare in ROS)\r\n2. È stato sviluppato appositamente per la robotica\r\n3. (opzionale) Io e Gabriele lo abbiamo studiato ed utilizzato per anni!\r\n\r\nConoscere ROS è quindi una _skill_ che (secondo noi) sarà importante avere nel mondo lavorativo del futuro prossimo, un po\' come adesso saper programmare Android/iOS apre tantissime possibilità nel mondo del lavoro!\r\n\r\n### Controllo Remoto\r\n\r\nCon controllo remoto, intendo la possibilità di controllare il robot mandado comandi tramite internet, o almeno all\'interno di una rete locale. È stata una delle prime applicazioni che abbiamo sviluppato, perchè molte semplice da implementare con ROS ma anche di super effetto!\r\n\r\nAbbiamo sviluppato (e stiamo sviluppando) diverse modalità di interazione con il robot, come ad esempio:\r\n\r\n- JoyStick Virtuale\r\n- Controllo da Tastiera\r\n- Controllo da Cellulare con sensori di movimento\r\n\r\n### Riconoscimento e Sintesi Vocale\r\n\r\nAnche in questo caso, applicazioni molte semplice da implementare ma che fa capire benissimo le potenzialità. Seguendo i tutorial qui sotto, potete creare un vero e proprio assistente virtuale che controlla il vostro robot.\r\n\r\n- Riconoscimento vocale (TO DO)\r\n- [Sintesi vocale](http://hotblackrobotics.github.io/blog/posts/2017-02-02-hb-cloud-tutorial-speech-bot)\r\n\r\n### Hardware Abstraction\r\n\r\nA parte il nome che sembra complicato, l\'idea dell\'Hardware Abstrction è che la Cloud Robotics riesce ad isolare l\'hardware dal software in un\'applicazione robotica..\r\n\r\nMa cosa vuol dire?\r\n\r\nIn parole semplici: che voi potete progettare il vostro Hardware e utilizzare tutte le applicazioni già pronte in piattaforma senza dover implementare da zero tutto il software e l\'intelligenza..\r\n\r\nIn parole tecniche: La Cloud Robotics è un protocollo che permette a tutti i dispositivi di parlare la stessa lingua..\r\n\r\nQuesto è il nostro progettino natalizio.\r\n\r\n<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/h13exqL9tbw" frameborder="0" allowfullscreen></iframe>\r\n\r\n### Applicazioni di Robotica di Servizio\r\n\r\nQuando diventerete bravi, potrete sviluppare la vostra applicazioni di [Robotica di Servizio e diventare dei veri e proprio RobotDeveloper](http://hotblackrobotics.github.io/blog/posts/2017-01-25-robotica)\r\n\r\nVi linko alcuni video di applicazioni sviluppate negli anni da noi:\r\n\r\n#### Robot@CED\r\n\r\n<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/HlUB0oHuXrc" frameborder="0" allowfullscreen></iframe>\r\n\r\n<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/VH0q-UsDiQY" frameborder="0" allowfullscreen></iframe>\r\n\r\n#### PARLOMA\r\n\r\n<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/6MGJb_GqauU" frameborder="0" allowfullscreen></iframe>\r\n\r\n<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/GS6_jwnSgWA" frameborder="0" allowfullscreen></iframe>\r\n\r\n<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/EJ5-uBt7rHs" frameborder="0" allowfullscreen></iframe>\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-08-cosa-si-puo-fare-con-la-nostra-piattaforma-di-cloud-robotics/index.md",
    frontMatter: {
      path: "/hbr/cosa-si-puo-fare-con-la-nostra-piattaforma-di-cloud-robotics/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2017-02-08T16:52:09.000Z",
      publishedReadable: "8 Feb 2017",
      featured: false,
      tags: [],
      title: "Cosa si può fare con la nostra piattaforma di Cloud Robotics",
      description:
        "Ecco alcune cosa che è possibile fare con la nostra piattaforma di Cloud Robotics",
      href: "/hbr/cosa-si-puo-fare-con-la-nostra-piattaforma-di-cloud-robotics/",
      image:
        "/content/hbr/2017-02-08-cosa-si-puo-fare-con-la-nostra-piattaforma-di-cloud-robotics/Schermata_2017-02-08_alle_17.27.39_sl8vdb.png",
      imagePath:
        "/content/hbr/2017-02-08-cosa-si-puo-fare-con-la-nostra-piattaforma-di-cloud-robotics",
    },
  },
  {
    content:
      "\r\nQui di seguito un breve tutorial su come assemblare il robot Dotbot. In questo tutorial ci dedichiamo ad assemblare il robot. Inoltre sono linkate le parti da stampare in 3D. **Un grazie speciale a Michele Maffucci da cui ho preso gran parte (o quasi tutto) per questo tutorial!** Vedi gli altri tutorial per la configurazione e la programmazione dei dotbot.\r\n\r\n## La lista delle parti meccaniche\r\n\r\nLe parti si possono stampare con una stampante 3D (noi abbiamo usato una ShareBot e stampiamo in PLA) e i link ai file STL sono in blu.\r\n\r\n- 2 X [db-ball_caster.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/db-ball_caster.stl)\r\n\r\n- 1 X [db-bottom.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/db-bottom.stl)\r\n- 1 X [db-breadboard.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/db-breadboard.stl)\r\n\r\n- 1 X [db-supports.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/db-supports.stl) [**il file è unico ma i supporti per il motori da stampare sono 4**]\r\n\r\n- 1 X [db-top.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/db-top.stl)\r\n\r\n- 8 x supporti rettangolari [db-rect.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/v04-db-dist-25-mm.stl)\r\n\r\n- 1 X [db-supports.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/db-supports.stl) [**il file è unico ma i supporti per il motori da stampare sono 4**]\r\n\r\n- 1 X [db-top.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/db-top.stl)\r\n\r\n- 8 x supporti rettangolari [db-rect.stl](https://github.com/sgabello1/Dotbot-Kit-e-Tutorial/blob/master/v04-db-dist-25-mm.stl)\r\n\r\n- 4 x bulloncini di supporto al Raspberry\r\n\r\n## La lista dei componenti\r\n\r\n- 4 viti M3 da 30 mm\r\n\r\n- 4 viti M2 da 16 mm\r\n\r\n- 14 viti M3 da 16 mm\r\n\r\n- 2 viti M3 da 10 mm\r\n\r\n- 18 bulloni M3\r\n\r\n- 4 bulloni M2\r\n\r\n- 2 biglie di vetro\r\n\r\n- 2 motorini CC e 2 ruote [link per acquistarli](http://www.volumerate.com/product/3-7-2v-dual-axis-tt-gear-motor-65mm-blue-rubber-wheel-for-smart-car-844443000)\r\n\r\n- 1 scheda driver motori [link per acquistarli](http://www.volumerate.com/product/hg7881-two-channel-motor-driver-board-dark-blue-2-5-12v-2-pcs-844407060)\r\n\r\n- 1 batteria power bank [link per acquistarli](https://www.amazon.it/RAVPower-Caricabatterie-Tecnologia-Universale-Smartphone/dp/B00YA01MC6/ref=sr_1_22?ie=UTF8&qid=1479834997&sr=8-22&keywords=batteria+esterna)\r\n\r\n- 1 breadboard da 400 fori\r\n\r\n- 1 una batteria alcalina da 9 Volt (opzionale - per alimentare i motori in parallelo al Raspberry)\r\n\r\n- LED, interruttori, resistenze, fili per i collegamenti sulla breadboard\r\n\r\nIl kit smontato e con tutti i suoi componenti sarà più o meno così:\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2010.21.55.jpeg)\r\n\r\nIniziamo a montare!\r\n\r\n## 1 - Montaggio dei motori\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2010.27.45.jpeg)\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2010.27.45_2.jpeg)\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2010.27.45_1.jpeg)\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2010.47.18.jpeg)\r\n\r\nCon le viti M3X30.\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2010.47.18_1.jpeg)\r\n\r\n## 2 - Montaggio delle ruote ominidirezionali realizzate con delle biglie di vetro##\r\n\r\nIniziamo a montare le ruote omnidirezionali.\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.12.05.jpeg)\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.12.05_1.jpeg)\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.12.05.jpeg)\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.12.05_1.jpeg)\r\n\r\nPoi montiamo i supporti con le viti M3X16, dalla parte della ruota omnidirezionale e M3X10 dalla parte della flangia.\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.12.05_4.jpeg)\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.12.05_3.jpeg)\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.12.05_2.jpeg)\r\n\r\nE infine otterremo questo:\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.37.35.jpeg)\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.37.35.jpeg)\r\n\r\n## 3 - Montaggio batterie - Inserimento driver motori - Inserimento giunti stampati in 3d per secondo livello##\r\n\r\nMontate il driver motori inserendo i 4 cavi dei motori dentro i mammut della scheda driver. L'ordine non è importante perchè determina il verso che aggiusterete in fase di test. NB: testate invece con la batteria che i motori funzionino correttamente e non abbiano problemi.\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.50.00.jpeg)\r\n\r\nMontate la batteria con due fascette.\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2011.57.56.jpeg)\r\n\r\nE infine i supporti verticali per il piano superiore.\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2012.15.27.jpeg)\r\n\r\n## 4 - Fissaggio breadboard\r\n\r\n![](./WhatsApp%20Image%202017-01-11%20at%2012.17.04.jpeg)\r\n![](./WhatsApp%20Image%202017-01-11%20at%2012.23.47.jpeg)\r\n\r\nOra avvitiamo il Raspberry e la parte superiore! E' più comodo se sotto il Raspberry mettete dello spessore, nel mio caso ho messo dei distanziali di plastica. **ATTENZIONE state attenti a montare il Raspberry dalla parte giusta, ovvero con l'alimentazione che guarda verso l'esterno e non verso la bread board e mettete i supporti circolari (bulloni di supporto) sotto il Raspberry come in figura.**\r\n\r\n![](./WhatsApp%20Image%202017-01-16%20at%2018.06.11.png)\r\n\r\n# 6 -Montate il circuito e fate i collegamenti\r\n\r\nAllacciate con delle fascette la batteria alcalina da 9v e con questa alimentate la scheda motori. I fili di alimentazione vanno collegati nei due pin centrali della scheda GND e VCC.\r\n\r\nOra inserite i fili di comando dei motori. Sono due per motore, tenendo conto che i pin del driver (c'è scritto comunque sopra) sono disposti cosi:\r\n\r\n- pin 1 e 2 - controllo motore 1\r\n- pin 3 e 4 - ground e alimentazione\r\n- pin 5 e 6 - controllo motore 2\r\n\r\n![](./maxresdefault.png)\r\n\r\nIl raspberry ha i pin configurati così:\r\n\r\n![](./RP2_Pinout.png)\r\n\r\nNel nostro caso abbiamo i pin 3,5 per gli input e 4,6 Power e Ground per alimentare la breadboard. Collegate ogni alimentazione dei motori (motore A e motore B) ai rispettivi mammut del ponte ad H. Poi collegate il controllo dei motori (A-1A, A-1B e B-1A, B-1B) con i GPIO 9,25 (pin 21,22 o contando 10 dal basso) e GPIO 22,23 (pin 15,16 o contando 13 dal basso)del Raspberry. LED 1 GPIO 4 (pin 7).\r\nI pin 7,11,12 per i LED.\r\n\r\nE otterete finalmente DotBot!\r\n![](<./WhatsApp%20Image%202017-01-18%20at%2012.34.06%20(1).jpeg>)\r\n![](<./WhatsApp%20Image%202017-01-18%20at%2012.34.06%20(4).jpeg>)\r\n![](./avogadro3.jpeg)\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-08-dotbot-tutorial-hardware/index.md",
    frontMatter: {
      path: "/hbr/tutorial-hardware-come-costruire-il-robot-dotbot/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "4 mins",
      published: "2017-02-08T13:28:57.000Z",
      publishedReadable: "8 Feb 2017",
      featured: false,
      tags: [],
      title: "Tutorial hardware - Come costruire il robot Dotbot",
      description: "",
      href: "/hbr/tutorial-hardware-come-costruire-il-robot-dotbot/",
      image:
        "/content/hbr/2017-02-08-dotbot-tutorial-hardware/WhatsApp%20Image%202017-01-11%20at%2010.21.55.jpeg",
      imagePath: "/content/hbr/2017-02-08-dotbot-tutorial-hardware",
    },
  },
  {
    content:
      '\r\nMolti di voi vorrebbero iniziare subito a programmare in ROS tramite la piattaforma cloud ma sono bloccati (purtroppo) da rognosi problemi hardware. Probabilmente la scheda motori non funziona correttamente o state aspettando ancora il Raspberry Pi o un componente da qualche fornitore.\r\n\r\nPerchè quindi non saltate questo passaggio e iniziate a programmare subito in ROS con un robot remotizzato in cloud? Cosa significa esattamente lo affronteremo in questo post. In pratica potete iniziare ad usare la piattaforma soltanto con il vostro pc e una qualsiasi connessione internet (senza Raspberry Pi e altri dispositivi)! E... tutto ciò che abbiamo visto su come configurare una rete per Dotbot? Beh, ora abbiamo accesso ad un Dotbot in cloud!\r\n\r\nIn pratica tutto quello che avete visto funzionare su Dotbot è da oggi disponibile in piattaforma cloud e accessibile tramite browser. Vi spiego com\'è possibile, sul Raspberry Pi di Dotbot c\'è una versione di Linux con installato ROS che è configurato per collegarsi alla nostra piattaforma cloud. Quello che abbiamo fatto è prendere un computer Linux accessibile da Internet ed installarci sopra tutto il software che solitamente installiamo su Dotbot. Per i più tecnici in pratica abbiamo comprato un\'istanza cloud da Amazon Web Services ed installato l\'immagine Dotbot esattamente come facciamo su Raspberry, questa si che è cloud robotics!\r\n\r\n![cloud robotics amazon](./istanza_cloud_1_tdt5ho.jpg)\r\n\r\nLo schema sopra riassume questi concetti e vi mostra come i due mondi si interfacciano tramite la piattaforma. La cosa che più mi affascina della filosofia cloud è che si confonde la differenza tra mondo "fisico", ovvero ciò che possiamo "toccare", con quello cloud. Infatti a qualcuno verrebbe da pensare che in sostanza abbiamo creato soltanto un sofisticato simulatore.. no, niente di più sbagliato! Il robot in cloud, DotbotCloud, esiste davvero ed è esattamente come Dotbot. L\'unica differenza è che il computer Linux di DotbotCloud è una macchina virtuale remotizzata da Amazon e nessuno con certezza può sapere fisicamente dove si trovi. Inoltre ovviamente non può avere nessun tipo di interazione con il mondo fisico. In pratica è come se DotbotCloud vivesse in un mondo parallelo. Quello che possiamo fare è usarlo come fosse un robot normale per poi riportare il nostro software su un robot "concreto" e il funzionamento sarà lo stesso! Vediamo subito cosa ci possiamo fare.\r\n\r\n## Primi passi con Dotbot in cloud\r\n\r\nEntriamo in piattaforma (effettuando il login) e cerchiamo il robot in cloud con il tasto "cerca robot". Nel mio caso ho un indirizzo ip così _54.191.14.121:8080_(**contattatemi per ottenere la vostra istanza** ) .\r\n\r\n![](./Schermata_2017-02-03_alle_18.07.33_blhaox.png)\r\n\r\nOra andiamo nella "ROS console" e vediamo cosa succede. Notiamo subito che ci sono i nodi attivi di "default" nella sezione "Node List" ( `/rosapi, /rosbridge_websocket, /rosout`) e "Topic List" (`/rosout` e `/rosout_agg` )\r\n\r\n![ros cloud](./Schermata_2017-02-08_alle_15.58.20_ovkqy6.png)\r\n\r\nPoi se apriamo la Web App in un altro tab [http://hotblackrobotics.github.io/cloud/webgui/turtle](http://hotblackrobotics.github.io/cloud/webgui/turtle) ritornando su "ROS Console" un nuovo topic nella sezione "Topic List" apparirà (command_velocity).\r\n\r\n![](./Schermata_2017-02-08_alle_16.07.55_othgq2.png)\r\n\r\nOvviamente non potendo "vedere" un robot in cloud abbiamo implementato una Web App, ereditata da ROS che si chiama Turtlesim, per visualizzare i movimenti del robot in tempo reale. Il robot prende la forma di una tartaruga su uno sfondo blu.\r\n\r\n![cloud robotics](./Schermata_2017-02-08_alle_15.54.17_jo2ge9.png)\r\n\r\nScriviamo allora un semplice nodo ROS per far muovere il robot! Usiamo il topic di cui vi accennavo in precedenza `command_velocity` pubblicando le posizioni geometriche per fargli percorrere un percorso a spirale.\r\n\r\n```\r\nimport dotbot_ros\r\nimport sys\r\nimport os\r\nfrom geometry_msgs.msg import Twist\r\nimport math\r\nimport rospy\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = \'cloud_robot_pub\'\r\n\r\n    def setup(self):\r\n        self.loop_rate = dotbot_ros.Rate(10)\r\n        self.pub_position = dotbot_ros.Publisher(\'command_velocity\', Twist)\r\n        self.msg = Twist()\r\n        self.count = 0.0\r\n\r\n    def loop(self):\r\n            print \'Spirale\' , self.count\r\n            self.msg.linear.x =  self.count\r\n            self.msg.angular.z = 5\r\n            self.pub_position.publish(self.msg)\r\n            self.count = self.count + 1\r\n            sys.stdout.flush()\r\n            if self.count > 500:\r\n                print \'DONE\' , self.count\r\n                rospy.signal_shutdown("fine")\r\n```\r\n\r\nIl codice è sostanzialmente un publisher del messaggio `Twist` sul topic `\'command_velocity\'`. Il messaggio Twist è un messaggio standard di ROS (da geometry_msgs) che può risultare all\'inizio difficile da comprendere. In realtà noi siamo interessati a solo due parametri `msg.linear.x`, che fa avanzare il robot se positivo, e `msg.angular.z` che lo fa girare in verso antiorario se positivo. Vi chiederete perchè "z"? E\' soltanto una convenzione, in ROS il messaggio Twist per chi fosse interessato è composto così\r\n\r\n```\r\nVector3  linear\r\nVector3  angular\r\n```\r\n\r\ndove _linear_ e _angular_ sono lo spostamento e la rotazione sui relativi assi x,y,z. L\' asse z esce dal piano del computer (in questa visualizzazione), x va da destra a sinistra e y dall\'alto in basso.\r\n\r\n```\r\nfloat64 x\r\nfloat64 y\r\nfloat64 z\r\n```\r\n\r\nIn realtà tutte queste convenzioni non sono così importanti nella nostra applicazione perchè tanto operiamo solo sui parametri "avanti" e "gira". Facciamo partire il programma e il robot (visualizzato come tartaruga) inizierà a muoversi!\r\n\r\nIl robot in cloud è on-line in piattaforma e se volete provarlo non esitate a contattarci a **info@hotblackrobotics** oppure scrivete direttamente a me **ermacora.gabriele@gmail.com**! Mi farebbe moltissimo piacere sentirci su Skype per spiegarvi i primi passi con la cloud robotics e sentire le vostre opinioni a riguardo il mio id è gabriele.ermacora86 (ho visto che molti hanno problemi nella fase iniziale).\r\nPer le istanze però dovete sapere che purtroppo paghiamo un abbonamento cloud su Amazon e dobbiamo chiedervi di pagare una fee di iscrizione di **2 Euro** (da cui in realtà non facciamo lucro ma è solo per rientrare un minimo nelle spese).\r\n\r\nBuona cloud robotics! ;)\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o/index.md",
    frontMatter: {
      path: "/hbr/non-avete-un-robot-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o-da-cellulare/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "4 mins",
      published: "2017-02-03T17:59:59.000Z",
      publishedReadable: "3 Feb 2017",
      featured: false,
      tags: [],
      title:
        "Non avete un robot? C'è il robot in cloud accessibile da remoto tramite il vostro PC o da cellulare",
      description:
        "Non avete un robot? C'è il robot in cloud accessibile da remoto tramite il vostro PC o cellulare",
      href: "/hbr/non-avete-un-robot-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o-da-cellulare/",
      image:
        "/content/hbr/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o/istanza_cloud_1_tdt5ho.jpg",
      imagePath:
        "/content/hbr/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o",
    },
  },
  {
    content:
      '\nMolti di voi vorrebbero iniziare subito a programmare in ROS tramite la piattaforma cloud ma sono bloccati (purtroppo) da rognosi problemi hardware. Probabilmente la scheda motori non funziona correttamente o state aspettando ancora il Raspberri Pi o un componente da qualche fornitore. Perchè quindi non saltate questo passaggio e iniziate a programmare subito in ROS con un robot remotizzato in cloud? Cosa significa esattamente lo affronteremo in questo post, ma in breve significa che potete iniziare ad usare la piattaforma soltanto con il vostro pc e una qualsiasi connessione internet (senza Raspberry Pi e altri dispositivi)! E... tutto ciò che abbiamo visto su come configurare una rete per Dotbot? Beh, ora abbiamo accesso ad un Dotbot in cloud!\n\nIn pratica tutto quello che avete visto funzionare su Dotbot è da oggi disponibile in piattaforma cloud e accessibile tramite browser. Vi spiego com\'è possibile, sul Raspberry Pi di Dotbot c\'è una versione di Linux con installato ROS che è configurato per collegarsi alla nostra piattaforma cloud. Quello che abbiamo fatto è prendere un computer Linux accessibile da Internet ed installarci sopra tutto il software che solitamente installiamo su Dotbot. Per i più tecnici in pratica abbiamo comprato un\'istanza cloud da Amazon Web Services ed installato l\'immagine Dotbot esattamente come facciamo su Raspberry, questa si che è cloud robotics!\n\n![cloud robotics amazon](./istanza_cloud_1_tdt5ho.jpg)\n\nLo schema sopra riassume questi concetti e vi mostra come i due mondi si interfacciano tramite la piattaforma. La cosa che più mi affascina della filosofia cloud è che si confonde la differenza tra mondo "fisico", ovvero ciò che possiamo "toccare", con quello cloud. Infatti a qualcuno verrebbe da pensare che in sostanza abbiamo creato soltanto un sofisticato simulatore.. no, niente di più sbagliato! Il robot in cloud, DotbotCloud, esiste davvero ed è esattamente come Dotbot. L\'unica differenza è che il computer Linux di DotbotCloud è una macchina virtuale remotizzata da Amazon e nessuno con certezza può sapere fisicamente dove si trovi. Inoltre ovviamente non può avere nessun tipo di interazione con il mondo fisico. In pratica è come se DotbotCloud vivesse in un mondo parallelo. Quello che possiamo fare è usarlo come fosse un robot normale per poi riportare il nostro software su un robot "concreto" e il funzionamento sarà lo stesso! Vediamo subito cosa ci possiamo fare.\n\n## Primi passi con Dotbot in cloud\n\nEntriamo in piattaforma (effettuando il login) e cerchiamo il robot in cloud con il tasto "cerca robot". Nel mio caso ho un indirizzo ip così _54.191.14.121:8080_ .\n\n![cloud robotics](./Schermata_2017-02-03_alle_18.07.33_blhaox.png)\n\nOra andiamo nella "ROS console" e vediamo cosa succede.\n\n![ros cloud](./Schermata_2017-02-03_alle_18.52.51_fags1l.png)\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o-cellulare/index.md",
    frontMatter: {
      path: "/hbr/avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o-cellulare/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "2 mins",
      published: "2017-02-03T17:58:13.000Z",
      publishedReadable: "3 Feb 2017",
      featured: false,
      tags: [],
      title:
        "Avete problemi hardware? C'è il robot in cloud accessibile da remoto tramite il vostro PC o cellulare",
      description:
        "Avete problemi hardware? C'è il robot in cloud accessibile da remoto tramite il vostro PC o cellulare",
      href: "/hbr/avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o-cellulare/",
      image:
        "/content/hbr/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o-cellulare/istanza_cloud_1_tdt5ho.jpg",
      imagePath:
        "/content/hbr/2017-02-03-avete-problemi-hardware-ce-il-robot-in-cloud-accessibile-da-remoto-tramite-il-vostro-pc-o-cellulare",
    },
  },
  {
    content:
      '\r\nUn\'applicazione cloud interessante e molto divertente è far parlare il vostro robot!\r\nTecnicamente si chiama TTS - [text to speech](https://en.wikipedia.org/wiki/Speech_synthesis), o _sintesi vocale_. I sistemi TextToSpeech (letteralmente da testo a voce) consistono appunto nel convertire un testo e riprodurlo da un sintetizzatore vocale tramite un computer. Ovviamente le applicazioni nella robotica sono tantissime, quello che faremo è dare le basi per costruire un assistente robotico con cui potrete dialogare!\r\n\r\nIniziamo quindi a far "parlare" il computer tramite ROS. Apriamo la Web App "Speech Rec", che trovate su [http://hotblackrobotics.github.io/cloud/webgui/speech](http://hotblackrobotics.github.io/cloud/webgui/speech) oppure nella tendina "Apps". Questa Web App l\'abbiamo già vista in precedenza quando usavamo il controllo vocale. Prima con questa Web App potevamo impartire ordini al robot tramite la nostra voce, ora invece usiamo il sintetizzatore vocale per ottenere una risposta o un feedback. In questa Web App abbiamo un modulo in javascript in grado di sintetizzare la voce umana. Premendo sul tasto "Bot" il computer ci accoglierà con un caloroso "Eccomi!". Da questo momento vedrete nella sezione "Console ROS" la creazione di un nuovo topic `/<nome_del_vostro_robot>/to_speech`.\r\n\r\n![speech recognition cloud web app ](./web%20app%202.png)\r\n\r\nOra basterà scrivere un nodo ROS che pubblica sul nodo `/<nome_del_vostro_robot>/to_speech` una stringa e il vostro computer parlerà! Lo schema concettuale di funzionamento da ROS alla Web App in Javascript è come in figura.\r\n\r\n![ROS speech recognition cloud](./ROSspeech4444.png)\r\n\r\nIl nodo ROS è un semplice publisher di stringhe in tempi diversi. Una volta pubblicate tutte le stringhe terminiamo il nodo in modo da lasciare tutti i processi puliti con `rospy.signal_shutdown("spegniti")`.\r\n\r\n```python\r\nimport dotbot_ros\r\nfrom std_msgs.msg import String\r\nimport rospy\r\nfrom time import sleep\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = \'text_to_speech_node\'\r\n\r\n    def setup(self):\r\n        self.pub_voice = dotbot_ros.Publisher(\'to_speech\', String)\r\n        sleep(0.5)\r\n        self.pub_voice.publish("ciao")\r\n\r\n        sleep(1)\r\n        self.pub_voice.publish("mi chiamo chat bot")\r\n\r\n        sleep(1)\r\n        self.pub_voice.publish("sono un\'applicazione di intelligenza artificiale")\r\n        sleep(0.5)\r\n\r\n        rospy.signal_shutdown("nodo terminato")\r\n```\r\n\r\nOvviamente la cosa interessante è combinare poi le due funzionalità della Web App. Quindi in input interpretare i comandi vocali della tua voce, processarli e dare in output una risposta. Concettualmente si può schematizzare così.\r\n\r\n![bot ROS speech Text to Speech](./botSpeechROS2.png)\r\n\r\nPotete scrivere un nodo ROS, che nel mio schema ho chiamato "Bot", che quando dite una parola lui risponde di conseguenza! Prossimamente come scrivere un Bot con un po\' di intelligenza artificiale!\r\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-02-02-hb-cloud-tutorial-speech-bot/index.md",
    frontMatter: {
      path: "/hbr/hb-cloud-tutorial-speech-bot-come-far-parlare-il-vostro-robot/",
      author: {
        id: "sgabello",
        name: "Gabriele Ermacora",
        bio: "Dev Passionate",
        profile: "/imgs/authors/sgabello.jpg",
      },
      readTime: "2 mins",
      published: "2017-02-02T15:59:55.000Z",
      publishedReadable: "2 Feb 2017",
      featured: false,
      tags: [],
      title: "HB Cloud Tutorial - Speech Bot: come far parlare il vostro robot",
      description:
        'Le basi per costruire un "dialogo" con il vostro robot sfruttando le funzionalità di sintesi e riconoscimento vocale.',
      href: "/hbr/hb-cloud-tutorial-speech-bot-come-far-parlare-il-vostro-robot/",
      image:
        "/content/hbr/2017-02-02-hb-cloud-tutorial-speech-bot/talking-robot-cartoon-38038488.jpg",
      imagePath: "/content/hbr/2017-02-02-hb-cloud-tutorial-speech-bot",
    },
  },
  {
    content:
      "\nVi presento la mia startup: ecco come riusciamo a insegnare la Cloud Robotics con Python e ROS.\n\nRecentemente ho pochissimo tempo per scrivere articoli su questo blog. Non che non mi stia più interessando alla divulgazione, ma anzi, la mia attività di divulgazione si è fatta (e lo sarà per le prossime settimane) molto intensa in modalità offline.\n\n![Python e DotBot spiegazione Avogadro](./IMG_20170118_114658-PANO_ye4xbh.jpg)\n\nVolevo condividere il mio lavoro con la startup che ho fondato insieme al mio socio Gabriele: HB Robotics.\n**HB Robotics** ha una storia lunga che non vi racconterò in questa sede, se però qualcuno (che conosce l'inglese) è interessato può trovare tutti i dettagli [qui](http://mars42.org/blog/2017/1/4/hotblack-robotics-story).\n\n## Che cosa facciamo?\n\nCon HB Robotics, abbiamo sviluppato una piattaforma di Cloud Robotics che permette di programmare dei robot connessi ad internet in modo semplice e veloce! Il tutto si sviluppa sull'[idea (e sulla nostra idea) di **Cloud Robotics**](http://www.hotblackrobotics.com/blog/posts/2017-01-12-introduzione-e-visione-tecnologica-cloud-robotics-e-internet-delle-cose-l-internet-dei-robot).\n\nAbbiamo iniziato un percorso di sperimentazione in una scuola di Torino: l'ITIS Avogadro, [in cui lavoreremo da qui fino a fine Aprile con 3 classi quarte](http://www.hotblackrobotics.com/blog/posts/2017-01-16-hb-robotics-allalternanza-scuola-lavoro-nellitis-avogadro).\n\nDurante questo periodo, gli studenti potranno utilizzare la piattaforma di Cloud Robotics che sto sviluppando insieme al mio socio Gabriele. Abbiamo scelto come framework principale ROS (Robot Operating System) e come linguaggio di programmazione Python.\n\nSe qualcuno è interessato a questo lavoro, trovate tutte le info [qui](http://www.hotblackrobotics.com/index).\n\nSto, inoltre, scrivendo un po' di tutorial che spiegano come utilizzare la piattaforma in accoppiata con Python. Trovate tutto [qui](http://www.hotblackrobotics.com/blog/categories/Tutorial/).\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-23-hb-robotics-con-python-impariamo-la-cloud-robotics/index.md",
    frontMatter: {
      path: "/2017/01/23/hb-robotics-con-python-impariamo-la-cloud-robotics/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-01-23T00:00:00.000Z",
      publishedReadable: "23 Gen 2017",
      featured: false,
      tags: ["Hbrobotics", "Robotics", "Ros"],
      title: "HB Robotics: con Python impariamo la Cloud Robotics",
      description:
        "Vi presento la mia startup: ecco come riusciamo a insegnare la Cloud Robotics con Python e ROS.",
      href: "/2017/01/23/hb-robotics-con-python-impariamo-la-cloud-robotics/",
      image:
        "/content/blog/it/2017-01-23-hb-robotics-con-python-impariamo-la-cloud-robotics/IMG_20170118_114658-PANO_ye4xbh.jpg",
      imagePath:
        "/content/blog/it/2017-01-23-hb-robotics-con-python-impariamo-la-cloud-robotics",
    },
  },
  {
    content:
      "\r\nI Motori sono una delle parti essenziali dei robot. In questo tutorial, vedremo come è possibile in modo semplice ed intuitivo implementare un programma in Python che controlla i motori in base a comandi inviati via Wifi al Robot.\r\n\r\n![](./IMG_20170120_172801_ufb9qy.jpg)\r\n\r\nEcco nel dettaglio cosa vedremo:\r\n\r\n- Come gestire una coppia di motori in **gpiozero**.\r\n- Come sottoscriversi ad un topic ROS sfruttando le **callback**.\r\n\r\n## Circuito\r\n\r\nColleghiamo i motori al driver. L'alimentazione del driver va collegata alla batteria da 9V, ricordandoci di mettere in comune la massa della batteria con quella del raspberry.\r\n\r\nLe due fasi dei motori, vanno collegate, rispettivamente, ai GPIO 16,19 (sinistra) e 20,26 (destra).\r\n\r\n> **Importante: Ricordate di mettere in comune la massa (GND) dell'alimentazione dei motori con la massa del Raspberry Pi.**\r\n\r\n![schema motori raspberry](./motori_bb_fdxui2.png)\r\n\r\n## Scriviamo il Codice\r\n\r\nPer utilizzare i motori, useremo l'oggetto `Robot` della libreria **gpiozero**, che è in grado di gestire il movimento di un semplice robot a due ruote.\r\n\r\n## Programma di test\r\n\r\nPer prima cosa, testiamo che i motori funzionino lanciando un semplice programma di test. Questo programma sfrutta solo la funzione Setup\r\nScriviamo un brevissimo programma che controlla il robot facendogli fare semplici movimenti.\r\n\r\nPer creare l'oggetto `Robot` dobbiamo passare al costruttore le coppie di PIN GPIO a cui sono collegati i due motori, sfruttando i parametri `left` e `right`:\r\n\r\n```python\r\nself.robot = Robot(left=(16, 19), right=(20, 26))\r\n```\r\n\r\nUna volta inizializzato, possiamo sfruttare le funzioni `Robot.left`, `Robot.right`, `Robot.forward` e `Robot.backward` per farlo muovere, rispettivamente, a destra, sinistra, avanti e indietro. E la funzione `Robot.stop` per farlo fermare. Utilizziamo inoltre la funzione `time.sleep` della libreria `time` per far prolungare una certa azione nel tempo al robot.\r\n\r\nIl tutto, può essere utilizzato come nel seguente programma per testare che i motori si muovino correttamente. Si noti che `time.sleep` chiede come unico parametro il tempo di attesa in secondi.\r\n\r\n```python\r\nimport dotbot_ros\r\nfrom gpiozero import Robot\r\n\r\nimport time\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'test_motor'\r\n\r\n    def setup(self):\r\n        self.robot = Robot(left=(16, 19), right=(20, 26))\r\n\r\n        self.robot.forward()\r\n        time.sleep(1)\r\n\r\n        self.robot.backward()\r\n        time.sleep(1)\r\n\r\n        self.robot.left()\r\n        time.sleep(1)\r\n\r\n        self.robot.right()\r\n        time.sleep(1)\r\n\r\n        self.robot.stop()\r\n```\r\n\r\nUna volta lanciato questo programma, il robot dovrebbe iniziare a muoversi prima avanti e poi indietro, per poi girare a destra e a sinistra.\r\nSe qualcosa non funziona, controllate che i motori siano alimentati e che le masse siano messe in comune.\r\n\r\n## Sottoscriviamo ad un Topic ROS e usiamo le Callback\r\n\r\nControllare il robot in questo modo non gli permette di essere nè più nè meno di un semplice giocattolo. Proviamo quindi a fare qualcosa di più interessante: controllare il robot attraverso un topic.\r\n\r\nPer farlo, sottoscriviamoci ad un topic chiamato `speed` di tipo `std_msgs/Int16MultiArray`. Per farlo, per prima cosa, dobbiamo capire cos’è e come si usa una funzione di callback.\r\n\r\n### Funzioni di Callback\r\n\r\nCome già spiegato in precedenza, una funzione di **callback** è una funzione che non viene esplicitamente chiamata dal nostro programma, ma è automaticamente eseguita al verificarsi di un certo evento _asincrono_ (cioè un evento che è generato al di fuori del nostro programma).\r\n\r\nROS sfrutta la callback come meccanismo per intercettare i messaggi inviati da su topic al quale il nodo è sottoscritto, e per processare i dati in modo immediato e istantaneo. In particolare, ROS chiede al programmatore di implementare una funzione di callback per ogni topic a cui il nodo è sottoscritto, e chiama automaticamente questa funzione ogni qualvolta un messaggio è invitato sul topic.\r\n\r\n### Implementiamo la funzione di callback per il topic `speed`\r\n\r\nRicapitolando: il nostro nodo si deve sottoscrivere al topic Speed, in cui vengono mandati comandi di velocità per il robot. Ogni volta che un messaggio viene inviato sul topic, il nodo deve processare il messaggio e controllare i motori di conseguenza.\r\n\r\nAndiamo quindi ad implementare una funzione di callback, chiamata `on_speed`. Questa funzione (come tutte le funzioni di callback) avrà la seguente forma:\r\n\r\n```python\r\ndef on_speed(self, msg):\r\n    pass\r\n```\r\n\r\nI due parametri che la funzione prende sono `self` (che rappresenta il nodo) e `msg`, che conterrà il messaggio scambiato dal topic.\r\n\r\nIl messaggio `std_msgs/Int16MultiArray` contiene due valori (`data[0]` e `data[1]` rispettivamente per il motore destro e sinistro) che possono variare tra `-255` e `255`. La convenzione è che `255` è il massimo valore di velocità in avanti, `-255` è il massimo all'indietro, `0` significa velocità nulla e ogni altro valore è un valore intermedio tra queste velocità.\r\n\r\nAnche la classe `Robot` funziona in modo simile, ma i valori di velocità delle ruote possono variare tra `-1.0` (massima velocità all'indietro) e `1.0` (massima velocità in avanti). La prima cosa che dovrò fare la funzione, quindi, è convertire questi valori e controllare che i valori finali siano nell'intervallo `[-1, 1]`.\r\n\r\n```python\r\ndef on_speed(self, msg):\r\n    v_dx = msg.data[0]/255.0\r\n    v_sx = msg.data[1]/255.0\r\n\r\n    #controllo che v_dx sia nel range [-1,1]\r\n    if v_dx > 1.0:\r\n        v_dx = 1.0\r\n    elif v_dx < -1.0:\r\n        v_dx = -1.0\r\n\r\n    #controllo che v_sx sia nel range [-1,1]\r\n    if v_sx > 1.0:\r\n        v_sx = 1.0\r\n    elif v_sx < -1.0:\r\n        v_sx = -1.0\r\n```\r\n\r\nUna volta generati i due comandi di velocità (`v_dx` e `v_sx`), aggiungiamo una stringa per stamparne a video i valori finali utilizzando la funzione `print`:\r\n\r\n```python\r\ndef on_speed(self, msg):\r\n       #...\r\n       print 'v_dx', v_dx\r\n       print 'v_sx', v_sx\r\n       sys.stdout.flush()\r\n       #...\r\n```\r\n\r\nRicordate di aggiungere sempre la linea di codice `sys.stdout.flush()` (e importare il modulo `sys` con la stringa `import sys` per forzare la stampa effettiva sulla shell di DotBot-ROS.\r\nOra non ci resta che settare questi valori per far muovere le ruote. Per farlo, ci viene incontro un utilissimo parametro dell'oggetto `Robot`: `Robot.value`, che si usa nel seguente modo:\r\n\r\n```python\r\nself.robot.value = (v_sx, v_dx)\r\n```\r\n\r\nIn particolare, questo parametro vuole entrambi i comandi di velocità contemporaneamente tra parentesi tonde (in python questa struttura si chiama `Tupla`) e, appena settato, automaticamente controlla le ruote con i valori richiesti!\r\n\r\nLa funzione `on_speed`, quindi, verrà completata in questo modo:\r\n\r\n```python\r\ndef on_speed(self, msg):\r\n    v_dx = msg.data[0]/255.0\r\n    v_sx = msg.data[1]/255.0\r\n\r\n    #stampo a video i valori di v_dx e v_sx\r\n    print 'v_dx', v_dx\r\n    print 'v_sx', v_sx\r\n    sys.stdout.flush()\r\n\r\n    #controllo che v_dx sia nel range [-1,1]\r\n    if v_dx > 1.0:\r\n        v_dx = 1.0\r\n    elif v_dx < -1.0:\r\n        v_dx = -1.0\r\n\r\n    #controllo che v_sx sia nel range [-1,1]\r\n    if v_sx > 1.0:\r\n        v_sx = 1.0\r\n    elif v_sx < -1.0:\r\n        v_sx = -1.0\r\n\r\n    #controllo del robot\r\n    self.robot.value = (v_dx, v_sx)\r\n```\r\n\r\n### Sottoscrizione al topic\r\n\r\nUna volta implementata la funzione di callback, non ci resta che sottoscriverci al topic `speed` per poterla correttamente utilizzare. Per farlo, nella funzione `setup`, aggiungiamo la seguente linea di codice:\r\n\r\n```python\r\ndotbot_ros.Subscriber(\"speed\", Int16MultiArray, self.on_speed)\r\n```\r\n\r\nricordandoci di importare l'oggetto `Int16MultiArray` da `std_msgs.msg`\r\n\r\n```python\r\nfrom std_msgs.msg import Int16MultiArray\r\n```\r\n\r\n### Codice completo\r\n\r\nEcco il codice completo del nostro programma\r\n\r\n```python\r\nimport dotbot_ros\r\nimport sys\r\nfrom gpiozero import Robot\r\nfrom std_msgs.msg import Int16MultiArray\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'example_motor'\r\n\r\n    def setup(self):\r\n        self.robot = Robot(left=(16, 19), right=(20, 26))\r\n        dotbot_ros.Subscriber(\"speed\", Int16MultiArray, self.on_speed)\r\n\r\n    def on_speed(self, msg):\r\n        v_dx = msg.data[0]/255.0\r\n        v_sx = msg.data[1]/255.0\r\n\r\n        #controllo che v_dx sia nel range [-1,1]\r\n        if v_dx > 1.0:\r\n            v_dx = 1.0\r\n        elif v_dx < -1.0:\r\n            v_dx = -1.0\r\n\r\n        #controllo che v_sx sia nel range [-1,1]\r\n        if v_sx > 1.0:\r\n            v_sx = 1.0\r\n        elif v_sx < -1.0:\r\n            v_sx = -1.0\r\n\r\n        #controllo del robot\r\n        self.robot.value = (v_dx, v_sx)\r\n```\r\n\r\nPer inviare comandi di velocità, possiamo utilizzare l'app di test della nostra piattaforma.\r\n\r\n## Esercizi\r\n\r\nVi suggerisco alcuni esercizi per migliorare il codice.\r\n\r\n### Esercizio 1: Robot Joystick\r\n\r\nLa webapp joystic manda messaggi di tipo `geometry_msgs/Vector3` sul topic `joy` contenenti due variabili `msg.x` e `msg.y` che contengolo la posizione del joystick in coordinate cartesiane. Si modifichi il programma in modo da intercettare questo messaggio e far muovere il robot in base alla posizione del joystick.\r\n\r\n### Esercizio 2: Stop del robot dopo N secondi\r\n\r\nUn problema che (in base alle preferenze) potrebbe essere risolto o no, rigurda il fatto che se viene impostato un comando di velocità, il robot continuerà a muoversi finchè non gli viene impostato il comando di velocità `(0,0)`.\r\n\r\nSi provi a migliorare il programma in modo che il robot si fermi dopo _N_ secondi (sceliti da programmatore) dall'ultimo comando di velocità ricevuto.\r\n\r\nPer farlo suggerisco di utilizzare i seguenti accorgimenti:\r\n\r\n1. Creare una variabile che contiene il tempo di esecuzione dell'ultima chiamata della funzione di callback. Usando la funzione `datetime.datetime.now`.\r\n2. Settare l'esecuzione della funzione `loop` a frequenza alta (ad esempio, 20Hz).\r\n3. Nella funzione loop, controllare che la differenza in secondi tra l'ultima volta che è stata eseguita la funzione `on_speed` e il tempo attuale sia maggiore di N\r\n4. In caso affermativo, utilizzare la funzione `Robot.stop` per stoppare il robot.\r\n\r\nVi riporto, sotto, un esempio per ottenere la differenza in secondi tra due tempi\r\n\r\n```python\r\nfrom datetime import datetime\r\nimport time\r\n\r\nx = datetime.now()\r\ntime.sleep(2)\r\ny = datetime.now()\r\nseconds = (y-x).total_seconds()\r\n# 2.003452\r\n```\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-01-20-hb-cloud-tutorial-3-i-motori/index.md",
    frontMatter: {
      path: "/hbr/hb-cloud-tutorial-3-i-motori/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "7 mins",
      published: "2017-01-20T20:27:06.000Z",
      publishedReadable: "20 Gen 2017",
      featured: false,
      tags: [],
      title: "HB Cloud Tutorial #3 - I Motori",
      description:
        "I Motori sono una delle parti essenziali dei robot. In questo tutorial, vederemo come è possibile in modo semplice ed intuitivo implementare un programma in Python che controlla i motori in base a comandi inviati via Wifi al Robot.",
      href: "/hbr/hb-cloud-tutorial-3-i-motori/",
      image:
        "/content/hbr/2017-01-20-hb-cloud-tutorial-3-i-motori/IMG_20170120_172801_ufb9qy.jpg",
      imagePath: "/content/hbr/2017-01-20-hb-cloud-tutorial-3-i-motori",
    },
  },
  {
    content:
      "\r\nRieccomi con il secondo tutorial legato all'uso dei bottoni per il robot **DotBot-ROS**. In questo tutorial, vedremo come configurare ed utilizzare in Python un bottone attaccato ad un pin GPIO del Raspberry Pi 3.\r\n\r\n![DotBot bottone tutorial ROS Raspberry](./IMG_20170120_172631_aupgbk.jpg)\r\n\r\nCome al solito, scrivo questo tutorial come materiale di supporto per il corso che stiamo facendo presso l'ITIS Avogadro di Torino.\r\n\r\n## Scopo del Tutorial\r\n\r\nAlla fine di questo tutorial, sapremo configurare ed utilizzare un bottone utilizzando le librerie **gpiozero** e **dotbot_ros**. In particolare, affronteremo i seguenti argomenti:\r\n\r\n- Uso della libreria **gpiozero** per interfacciarsi con un bottone e leggerne lo stato\r\n- Come stampare a video sulla shell di HBR Cloud\r\n- Uso della libreria **dotbot_ros** per pubblicare su un topic\r\n- Uso delle Callback\r\n\r\n## Il circuito elettronico\r\n\r\nCome al solito, prima di iniziare a sviluppare il codice è importante configurare il circuito. Per il momento, utilizzeremo un semplice circuito, molto semplice, basato su un Led e un Bottone. Il led collegato al pin **GPIO05**, mentre il bottone, al pin **GPIO02**. Trovate un'immagine che mostra la numerazione dei pin in questa figura:\r\n\r\n![Raspberry Pi Configurazione PIN](./RP2_Pinout.png)\r\n\r\n> Importante: Ricordate che la libreria **gpiozero** utilizza la numerazione dei pin colorata in Arancione.\r\n\r\nI componenti necessari sono i seguenti:\r\n\r\n- Led Colorato\r\n- Resistenza da 270Ohm\r\n- Pulsante\r\n- Cavetti per Breadboard\r\n\r\nColleghiamo il led e la resistenza in serie, attaccando l'anodo del Led al pin **GPIO05** e il catodo (attraverso la resistenza) a GND.\r\n\r\nColleghiamo una delle due fasi dell'interruttore al Pin **GPIO02** e l'altra fase a massa.\r\n\r\n![Circuito elettronico](./tutorial2_bb_rsp6yo.png)\r\n\r\n## Scriviamo il codice!\r\n\r\nCome al solito, partiamo dallo scheletro di un'applicazione, in cui impostiamo il nome del nodo come `button_example`\r\n\r\n```python\r\nimport dotbot_ros\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'button_example'\r\n\r\n    def setup(self):\r\n        pass\r\n\r\n    def loop(self):\r\n        pass\r\n```\r\n\r\nImportiamo i due oggetti che andremo ad utilizzare dalla libreria **gpiozero**: `Button` e `LED`, utilizzando la seguente stringa prima della dichiarazione del nodo\r\n\r\n```python\r\nfrom gpiozero import Button, LED\r\n```\r\n\r\n### Utilizzo del bottone\r\n\r\nPer il momento, utilizziamo solamente il bottone per visualizzare il suo stato (se chiuso o aperto) sfruttando la shell di **DotBot-ROS** e la funzione `print` di Python.\r\n\r\nPer prima cosa, dobbiamo inilizzare il bottone e settare la frequenza di iterazione della funzione `loop` (per ora settiamola a 10Hz). Andiamo quindi ad implementare la funzione `setup` come segue\r\n\r\n```python\r\n    def setup(self):\r\n        self.btn = Button(2) #GPIO 2\r\n        self.loop_rate = dotbot_ros.Rate(10)\r\n```\r\n\r\nCon la riga `self.btn = Button(2)` abbiamo creato un attributo chiamato `btn` al nostro nodo che gestisce un bottone collegato al pin `GPIO02` del raspberry.\r\n\r\nInvece, come già spiegato nel tutorial precedente, la riga `self.loop_rate = dotbot_ros.Rate(10)` setta a 10Hz la frequenza di iterazione di `loop`.\r\n\r\nA questo punto, possiamo implementare la funzione `loop` in modo che stampi a video lo stato del bottone. Per farlo, utilizziamo l'attributo `is_pressed` dell'oggetto `Button`, che restituisce `True` se il bottone è premuto, `False` altrimenti.\r\n\r\nPossiamo quindi utilizzare il costrutto `if`-`else` nella funzione `loop`:\r\n\r\n```python\r\n    def loop(self):\r\n        if self.btn.is_pressed:\r\n            print 'interruttore chiuso'\r\n        else:\r\n            print 'interruttore aperto'\r\n        sys.stdout.flush()\r\n```\r\n\r\n> Importante: Ogni qual volta viene utilizzata la funzione `print`, bisogna aggiungere la linea di codice `sys.stdout.flush()` (e importare il modulo `sys` con la stringa `import sys`. Questo serve a forzare la stampa effettiva sulla shell di **DotBot-ROS**.\r\n\r\nProviamo ad eseguire il codice e vedere cosa succede. Dovreste vedere un output sulla shell di questo tipo:\r\n\r\n![Shell Bottone Status](./Schermata_2017-01-20_alle_18.08.05_sshqv4.png)\r\n\r\n### Pubblichiamo lo stato del bottone su un topic ROS\r\n\r\nSe il programma precedente funziona, siamo pronti ad utilizzare una delle funzione principali di ROS: i **Topic**.\r\n\r\nUn topic è un canale di comunicazione che permette ai vari nodi di una rete ROS di scambiare informazioni. Un nodo può pubblicare o iscriversi ad un topic, in modo da mandare, o ricevere informazioni. Per ora ci focalizziamo sul pubblicare i dati.\r\n\r\nPer farlo, dobbiamo creare un oggetto `Publisher`, utilizzando il costruttore `dotbot_ros.Publisher(<Name>, <Type>)`. Dove il parametro _Name_ è una stringa che indica il nome del topic, mentre il parametro `Type` è un oggetto che indica il tipo di messaggio che viene scambiato all'interno del topic.\r\n\r\nIn questo semplice esempio, chiameremo il topic `button_status` e manderemo messaggi di tipo booleano. Per utilizzare il tipo `Bool` dei messaggi, prima di tutto dobbiamo importarlo dalla libreria `std_msgs.msg`, aggiungendo questa stringa all'inizio del programma\r\n\r\n```python\r\nfrom std_msgs.msg import Bool\r\n```\r\n\r\nPossiamo quindi creare l'oggetto publisher nella funzione setup\r\n\r\n```python\r\n    def setup(self):\r\n        #...\r\n        self.pub_btn_status = dotbot_ros.Publisher('button_status', Bool)\r\n        #...\r\n```\r\n\r\nA questo punto, possiamo utilizzarlo nella funzione `loop`. Modifichiamola nel modo seguente\r\n\r\n```python\r\n    def loop(self):\r\n        btn_status = self.btn.is_pressed\r\n        self.pub_btn_status.publish(btn_status)\r\n        if btn_status == True:\r\n            print 'interruttore chiuso'\r\n        else:\r\n            print 'interruttore aperto'\r\n        sys.stdout.flush()\r\n```\r\n\r\nIn particolare, abbiamo creato una nuova variabile chiamata `btn_status`, che contiene il valore dello stato del bottone. Con la riga `self.pub_btn_status.publish(btn_status)` diciamo all'oggetto pubblicatore di mandare un messaggio sul topic a cui si riferisce contenente il valore della variabile `btn_status`. Il resto della funzione non è stato modificato.\r\n\r\nA questo punto possiamo nuovamente testare il programma, per vedere se il topic ROS viene effettivamente utilizzato e i messaggi vengono mandati. Una volta lanciato il programma, accediamo al tab `ROS` della piattaforma online. Nella lista di topic, dovreste vedere un topic chiamato `/<nome del robot>/button_status`. Questo è il topic che abbiamo appena creato. Si noti che la piattaforma aggiunge automaticamente il _namespace_ del vostro robot ai topic che creeremo. Nel mio caso specifico, il topic si chiama `/polibot/button_status`. Premiamo quindi sul pulsante **Echo** riferito al topic in questione. Si aprirà un nuovo pannello che mostrerà in tempo reale i dati scambiati all'interno del topic.\r\n\r\n![Echo Topic Status](./Schermata_2017-01-20_alle_18.27.11_meep9b.png)\r\n\r\nProviamo a premere il bottone e vediamo se i valori inviati cambiano di conseguenza!!\r\n\r\n### Controllo del LED\r\n\r\nA questo punto, siamo pronti a completare la nostra applicazione utilizzando un Led. Voglio, in particolare, far si che ogni volta che il bottone venga premuto, il led cambi stato (utilizzando la funzione `toggle` vista nel tutorial precedente).\r\n\r\nPer farlo, utilizzeremo un concetto di programmazione chiamato `callback`. La `callback` è una funzione che non viene chiamata in modo esplicito dal programma, ma che viene chiamata al verificarsi di un evento. In particolare, quello che faremo è creare una callback che chiamerà la funzione `Led.toggle` quando si verifica l'evento di pressione del bottone.\r\n\r\nPrima di tutto, creiamo il nostro oggetto `LED` nella funzione `setup` utilizzando la linea di codice `self.led = LED(5)`. A questo punto, siamo pronti a settare la callback: per associare una funzione all'evento _pressione del pulsante_, dobbiamo settare il nome della funzione da richiamare all’attributo `Button.when_pressed`: `self.btn.when_pressed = self.led.toggle`. Sembra semplice vero? Eppure questo basta per far funzionare il tutto.\r\n\r\n```python\r\n    def setup(self):\r\n        #...\r\n        self.led = LED(5)\r\n        self.btn.when_pressed = self.led.toggle\r\n```\r\n\r\nSi noti che noi non andiamo a chiamare esplicitamente la funzione `self.led.toggle`, ma informiamo solo il programma di chiamarla quando l'evento `self.btn.when_pressed` si verifica.\r\n\r\nPossiamo a questo punto lanciare il programma e testare che tutto funzioni!\r\n\r\n### Codice completo\r\n\r\nQui trovate il codice completo appena realizzato\r\n\r\n```python\r\nimport dotbot_ros\r\nfrom gpiozero import LED, Button\r\nfrom std_msgs.msg import Bool\r\n\r\nimport sys\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'button_example'\r\n\r\n    def setup(self):\r\n        self.btn = Button(2)  #GPIO 2\r\n        self.loop_rate = dotbot_ros.Rate(10)\r\n        self.pub_btn_status = dotbot_ros.Publisher('button_status', Bool)\r\n\r\n        self.led = LED(5)\r\n        self.btn.when_pressed = self.led.toggle\r\n\r\n    def loop(self):\r\n        btn_status = self.btn.is_pressed\r\n        self.pub_btn_status.publish(btn_status)\r\n        if btn_status == True:\r\n            print 'interruttore chiuso'\r\n        else:\r\n            print 'interruttore aperto'\r\n        sys.stdout.flush()\r\n```\r\n\r\n## Esercizi\r\n\r\nProvate a migliorare il programma come segue.\r\n\r\n#### 1. Aggiungere un secondo pulsante\r\n\r\nAggiungete un nuovo pulsante su un pin GPIO a piacere e stampate a video gli stati di entrambi i pulsanti ad ogni iterazione.\r\n\r\n#### 2. Controllo del led con entrambi i pulsanti\r\n\r\nControllate il led utilizzando i due pulsanti. In particolare, fate in modo che il led si spenga premendo il primo pulsante, e si accenda premendo il secondo pulsante. Utilizzate le funzioni `led.on` e `led.off`.\r\n\r\n#### 3. Topic `btn1_and_btn2`\r\n\r\nCreate un secondo topic di tipo `Bool` chiamato `btn1_and_btn2`. Su questo topic, inviate l'informazione ottenuta dall'`AND` logico del valore dei due pulsanti.\r\n\r\nRicordo che in Pyton, l'`AND` logico tra due variabili `a` e `b` booleane si implementa con la seguente sintassi\r\n\r\n```python\r\na_e_b = a and b\r\n```\r\n\r\nFate la stessa cosa con l'`OR` logico.\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-01-20-hb-cloud-tutorial-2-uso-dei-bottoni/index.md",
    frontMatter: {
      path: "/hbr/hb-cloud-tutorial-2-uso-dei-bottoni/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "6 mins",
      published: "2017-01-20T18:26:22.000Z",
      publishedReadable: "20 Gen 2017",
      featured: false,
      tags: [],
      title: "HB Cloud Tutorial #2 - Uso dei Bottoni",
      description:
        "Rieccomi con il secondo tutorial legato all'uso dei bottoni per il robot **DotBot-ROS**. In questo tutorial, vedremo come configurare ed utilizzare in Python un bottone attaccato ad un pin GPIO del Raspberry Pi 3.",
      href: "/hbr/hb-cloud-tutorial-2-uso-dei-bottoni/",
      image:
        "/content/hbr/2017-01-20-hb-cloud-tutorial-2-uso-dei-bottoni/IMG_20170120_172631_aupgbk.jpg",
      imagePath: "/content/hbr/2017-01-20-hb-cloud-tutorial-2-uso-dei-bottoni",
    },
  },
  {
    content:
      "\r\nCiao a tutti, iniziamo oggi questa serie di tutorial per insegnare a programmare i robot DotBot-ROS dalla piattaforma di cloud robotics che stiamo sviluppando: **HB Cloud**.\r\n\r\n![roscore ROS shell](./led.png)\r\n\r\nQuesto primo tutorial è dedicato all'accensione e allo spegnimento del Led, e si basa sulla versione beta del sistema operativo **HBrain** (v0.3.2). Scrivo questo tutorial in preparazione al percorso di alternanza scuola lavoro con l'ITIS Avogadro di Torino. Se qualcuno volesse però provare per conto proprio ad utilizzare la piattaforma ci contatti in privato per ricevere supporto.\r\n\r\n## Cos’è HB Cloud?\r\n\r\n**HB Cloud** è una piattaforma di cloud robotics che stiamo sviluppando in **HB Robotics**. Lo scopo è quello di permettere a makers, studenti e non professionisti di imparare in modo semplice l'utilizzo di tecnologie innovative nel mondo della Cloud Robotics, ed in particolare su ROS.\r\n\r\nIl nostro scopo è quello di semplificare lo sviluppo e la gestione di applicazioni robotiche! **HB Cloud** si interfaccia automaticamente con **HBrain**, un sistema operativo da noi sviluppato per Raspberry Pi che include il framework ROS (Robot Operating System).\r\n\r\n## Scriviamo il primo codice per accendere un LED\r\n\r\n### Circuito Elettrico\r\n\r\nIl codice python per la gestione di un led è molto semplice, ma prima di tutto è importante sviluppare il circuito. Colleghiamo l'anodo del Led al Pin GPIO05 del Raspberry Pi. Colleghiamo il catodo ad uno degli estremi di una resistenza da 220Ohm, e mettiamo il secondo estremo della resistenza a massa.\r\n\r\n### Codice\r\n\r\nA questo punto, siamo pronti a scrivere un semplice programma per far blinkare il led, cioè per farlo accendere e spegnere in modo continuato ad una frequenza fissa. Adremo ad utilizzare le librerie python **gpiozero** e **dotbot_ros**.\r\n\r\n- **gpiozero** è una libreria che permette la gestione dei pin GPIO del Raspberry Pi\r\n- **dotbot_ros** è una versione semplificata di ROS appositamente sviluppata per l'applicazione.\r\n\r\n### Scheletro dell'applicazione\r\n\r\nLo scheletro dell'applicazione che andremo a sviluppare ha la seguente forma\r\n\r\n```python\r\nimport dotbot_ros\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'blink'\r\n\r\n    def setup(self):\r\n        pass\r\n\r\n    def loop(self):\r\n        pass\r\n```\r\n\r\nCome per arduino, dovremmo implementare due funzioni:\r\n\r\n- la funzione `setup`, che viene chiamata una volta all'inizio del programma.\r\n- la funzione `loop`, che viene chiamata in modo iterativo fino allo stop forzato del programma.\r\n\r\nBisogna inoltre settare la variabile di classe `node_name`, che rappresenta il nome del nodo che abbiamo sviluppato in ROS. In questo caso, il nostro nodo si chiamerà `blink`.\r\n\r\nNota Bene: In Python, la direttiva `pass` significa letteralmente `non fare niente`.\r\n\r\n### Configurazione della frequenza di Iterazione\r\n\r\nUtilizzando `dotbot_ros`, possiamo decidere in modo semplice a che frequenza far iterare la funzione `loop`. In altre parole, se settimano la frequenza di iterazione a (per esempio) 10Hz, loop verrà chiamata 10 volte al secondo.\r\n\r\nPer farlo, bisogna settare una variabile chiamata `self.loop_rate` all'interno della funzione `setup`. Se questa variabile non viene settata, la funzione loop non verrà mai chiamata.\r\n\r\nImplementiamo quindi la funzione `setup` in modo da settare `self.loop_rate` a 2Hz\r\n\r\n```python\r\n    def setup(self):\r\n        self.loop_rate = dotbot_ros.Rate(2)\r\n```\r\n\r\nPerfetto, adesso siamo certi che la funzione `loop` verrà chiamata 2 volte al secondo!\r\n\r\n### Importiamo l'oggetto LED la libreria gpiozero\r\n\r\nPossiamo ora iniziare ad usare la libreria **gpiozero** ed in particolare l'oggetto `LED`.\r\nPer farlo, prima di tutto, importiamolo con la seguente linea di codice\r\n\r\n```\r\nfrom gpiozero import LED\r\n```\r\n\r\nA questo punto siamo pronti ad inizializzare un oggetto di tipi `LED`. Ricordo che abbiamo collegato il nostro led al pin `GPIO05`. Nella funzione `setup` dovremo quindi creare un nuovo oggetto `self.led` associato al PIN numero 5\r\n\r\n```python\r\n    def setup(self):\r\n        self.loop_rate = dotbot_ros.Rate(2)\r\n        self.led = LED(5)\r\n```\r\n\r\nCome vedete, il tutto è molto semplice. Si noti che ho \"appeso\" l'oggetto appena creato (`led`) alla variabile `self`. In questo modo posso utilizzarlo all'interno delle altre funzioni della nostra classe `Node`, ed in particolare all'interno della funzione `loop`.\r\n\r\n### Blink del Led\r\n\r\nA questo punto non ci resta che far blinkare il led. Per farlo dobbiamo implementare un codice che faccia sì che il led si spenga se è acceso e viceversa ogni volta che la funzione `loop` viene chiamata. Per farlo, **gpiozero** mette a disposizione un utilissimo metodo di LED chiamata `LED.toggle()`, che non fa altro che fargli cambiare stato.\r\n\r\nImplementiamo la funzione `loop`, quindi, come segue\r\n\r\n```python\r\n    def loop(self):\r\n        self.led.toggle()\r\n```\r\n\r\n### Codice completo\r\n\r\nEcco il codice appena sviluppato\r\n\r\n```python\r\nimport dotbot_ros\r\nfrom gpiozero import LED\r\n\r\nclass Node(dotbot_ros.DotbotNode):\r\n    node_name = 'blink'\r\n\r\n    def setup(self):\r\n        self.led = LED(5)\r\n        self.loop_rate = dotbot_ros.Rate(2)\r\n\r\n    def loop(self):\r\n        self.led.toggle()\r\n```\r\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/hbr/2017-01-17-hb-cloud-tutorial-1-uso-dei-led/index.md",
    frontMatter: {
      path: "/hbr/hb-cloud-tutorial-1-uso-dei-led/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "4 mins",
      published: "2017-01-17T18:00:51.000Z",
      publishedReadable: "17 Gen 2017",
      featured: false,
      tags: [],
      title: "HB Cloud Tutorial #1 - Uso dei Led",
      description: "Iniziamo ad utilizzare la piattaforma di Cloud Robotics",
      href: "/hbr/hb-cloud-tutorial-1-uso-dei-led/",
      image: "/content/hbr/2017-01-17-hb-cloud-tutorial-1-uso-dei-led/led.png",
      imagePath: "/content/hbr/2017-01-17-hb-cloud-tutorial-1-uso-dei-led",
    },
  },
  {
    content:
      "\nUltimamente noto che su internet c'è molta confusione sui tools per effetturare backup e ripristino della SD del Raspberry Pi usando un Mac (quindi con MacOS). Questo tutorial lo scrivo principalmente come reminder per me, dopo aver sperimentato un po' di soluzioni in rete e visto quella che funziona meglio.\n\n![Copiare SD Mac Index](./main.jpg)\n\n## Passaggi generali\n\nSia che vogliamo clonare l'SD su mac, sia che vogliamo scrivere su SD un'immagine precedentemente backappata o scaricata dal web, è importante prima di tutto trovare il file rappresentante l'SD sul mac. Questo file ha un nome nella forma `diskN`, dove `N` è un numero intero (ad esempio `disk2` o `disk3`).\n\nPer scoprirlo, una volta inserita l'SD nel Mac, apriamo il programma **Utility Disco** e selezioniamo, sotto la voce `Esterni`, la nostra SD. Se non avete inserito altri dispositivi esterni di memoria (come chiavette USB o hard disk esterni) dovrebbe essere facile individuarlo in quanto sarà l'unico dispositivo riconosciuto come esterno.\n\nUna volta selezionata, si aprirà una finestra in cui è possibile vedere, sotto la voce `Dispositivo` il nome del file in questione. Nel mio caso è `disk2` come potete vedere nell'immagine sottostante.\n\n![Utiliti disco SD nome](./diskutil.png)\n\nUna volta scoperto il nome, appuntiamolo da qualche parte e procediamo in base a quello che vogliamo fare.\n\n## Backup SD\n\nIl backup è molto semplice: apriamo il terminale del mac e digitiamo il seguente comando:\n\n```\nsudo dd bs=4m if=/dev/r<nome SD> of=<nome sd backup>.img conv=notrunc,noerror\n```\n\nSi noti che, abbiamo aggiunto, davanti al nome dell'SD scoperto, la lettera `r` minuscola. Questo è importantissimo per velocizzare la copia dell'SD quando si lavora con il comando `dd`, ricordate sempre di metterlo. Nel mio caso, in cui voglio copiare la SD su un file chiamato `rasp_bk_01.img`, il comando sarà\n\n```bash\nsudo dd bs=4m if=/dev/rdisk2 of=rasp_bk_01.img conv=notrunc,noerror\n```\n\nL'opzione `bs=4m` informa il programma di copiare l'SD 4 megabit alla volta, mentre l'opzione `conv=notrunc,noerror` evita che il programma faccia inutili controlli sui dati dell'SD (attenzione, si evitino gli spazi in questa opzione!).\nDalle mie prove, questa configurazione è la più veloce in fase di backup della SD. Sul mio MacBook Pro riesco a copiare una SD di 16GB in circa 9min.\n\nLe opzioni `if` e `of` indicano, rispettivamente, il file di ingresso _input file_ e di uscita _output file_.\n\n## Ripristino SD dall'immagine\n\nIl ripristino della SD è molto simile al Backup, però è importante _smontare_ (in termine informatico) l'SD prima di iniziare a scriverci sopra dati. Per farlo, eseguiamo il comando\n\n```\ndiskutil unmountDisk /dev/<nome SD>\n```\n\nSi noti che, questa volta, non metto la lettera `r` davanti al nome. Nel mio caso, il comando sarà\n\n```\ndiskutil unmountDisk /dev/disk2\n```\n\nUna volta smontata, possiamo lanciare la procedura di copia. Il comando è simile a quello per il backup, ma le due opzioni `if` e `of` devono essere invertite:\n\n```\nsudo dd bs=4m of=/dev/r<nome SD> if=<nome sd backup>.img conv=notrunc,noerror\n```\n\nSi noti, di nuovo, che in questo caso uso la lettera `r` per velocizzare la procedura. Nel mio caso, il comando sarà\n\n```bash\nsudo dd bs=4m of=/dev/rdisk2 if=rasp_bk_01.img conv=notrunc,noerror\n```\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-13-copia-e-backup-di-sd-raspberry-da-macos/index.md",
    frontMatter: {
      path: "/2017/01/13/copia-e-backup-di-sd-raspberry-da-macos/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2017-01-13T00:00:00.000Z",
      publishedReadable: "13 Gen 2017",
      featured: false,
      tags: ["Tutorial", "Raspberry", "Utils", "Mac"],
      title: "Copia e Backup di SD Raspberry da macOS",
      description: "",
      href: "/2017/01/13/copia-e-backup-di-sd-raspberry-da-macos/",
      image:
        "/content/blog/it/2017-01-13-copia-e-backup-di-sd-raspberry-da-macos/main.jpg",
      imagePath:
        "/content/blog/it/2017-01-13-copia-e-backup-di-sd-raspberry-da-macos",
    },
  },
  {
    content:
      "\nEccomi qui con un brevissimo tutorial su come possiamo utilizzare [**Spyder**](http://www.ludusrusso.cc/posts/2017-01-12-spyder-un-altra-alternativa-in-python-a-matlab) per fare delle semplici simulazioni di fisica meccanica.\n\nCome primo esperimento ho scelto di lavorare sul moto parabolico, classico problema di fisica del liceo che voglio provare a risolvere e simulare in Python utilizzando il tool **Spyder**.\n\n![finestra di Spyder](./parabolico.png)\n\n## Scopo del tutorial\n\nQuello che voglio fare, quindi, è scrivere un semplice e veloce programmino che permette di simulare il moto parabolico 2D, in particolare permettendo di\n\n- calcolare gittata e tempo di volo;\n- disegnare il grafico della traiettoria.\n\n## Un po' di teoria\n\nSi definisce _moto parabolico_ il moto bidimensionale di un corpo soggetto alla forza di gravità che percorre una traiettoria parabolica.\n\nSe facciamo l'ipotesi che l'asse $X$ sia quello orizzontale e l'asse $Y$ quello verticale e che l'accelerazione di gravità agisca verso il basso, quindi nel verso negativo rispetto all'asse $Y$\n\nIl moto parabolico è la composizione bidimensionale di due moti distinti:\n\n- Un moto lineare uniforme $x(t) = v_x\\cdot t$ lungo l'asse orizzontale $X$\n- Un moto accelerato uniforme $y(t) = h_0 + v_y\\cdot t - \\frac{1}{2}gt^2$ lungo l'asse verticale $Y$\n\nIn forma vettoriale, scriveremo\n\n$$\np(t) = \\begin{pmatrix}x(t) \\\\ y(t)\\end{pmatrix} = \\begin{pmatrix} v_x\\cdot t \\\\ h_0 + v_y\\cdot t - \\frac{1}{2}gt^2\\end{pmatrix}\n$$\n\nDove $g$ è l'accelerazione di gravità, $h_0$ è l'altezza iniziale a cui viene lanciato il grave e $v_x$ e $v_y$ sono le componenti della velocità iniziale lungo i due assi $X$ e $Y$.\n\n$$\nv_0 = \\begin{pmatrix}v_x \\\\ v_y\\end{pmatrix}\n$$\n\nSolitamente si considera $t_0=0$ come istante di partenza e $x_0=0$ come posizione di partenza lungo l'asse $x$.\n\nSi noti che il moto parabolico termina quando si ha $y = 0$, si può quindi calcolare l'istante di tempo $t_f$ in cui il grave tocca terra ponendo\n\n$$\ny(t_f) = 0 \\rightarrow h_0 + v_y\\cdot t_f - \\frac{1}{2}g t_f ^2 = 0\n$$\n\nche si risolve, in $t_f$, ottenendo\n\n$$\nt_f=\\frac{v_y+\\sqrt{v_y^2+2gh_0}}{g}\n$$\n\nUna volta calcolato $t_f$ possiamo calcolare la posizione $x_f = x(t_f)$ che corrisponde al punto sul terreno in cui il grave tocca terra:\n\n$$\nx_f = v_x\\cdot t_f = v_x\\frac{v_y+\\sqrt{v_y^2+2gh_0}}{g}\n$$\n\nNon mi voglio addentrare su considerazioni fisiche e meccaniche e su semplificazioni della formula trovata, che si possono fare in casi particolari per cui $h_0=0$. Le soluzioni nella forma che abbiamo scritto fino ad ora bastano per poter risolvere il problema che ci siamo posti.\n\n## Simulazione in Python e Spyder\n\nUna volta scaricato e installato [**Spyder**](https://pythonhosted.org/spyder/installation.html) ci troveremo davanti ad una finestra simile a questa.\n\n![finestra di Spyder](./home.png)\n\nNella finestra indicata come _Editor_ (a me è mostrata sulla destra), possiamo andare ad implementare il codice che poi verrà eseguito da python. Sulla finistra indicata come _Console_ potremo interagine utilizzando la console dinamica iPython. Per il momento, limitiamoci ad utilizzare l'editor di testo per rendere il programma più leggibile.\n\n### Importiamo pyLab\n\nPer prima cosa, è importante importare tutti gli elementi di pyLab. pyLab è una suit python che include utilissimi moduli per l'analisi dei dati, come funzioni e costati matematiche (ad esempio `sin` o la costante $\\pi$ indicata con `pi`) o la libreria per plottare `plot`.\n\n```\nfrom pylab import *\n```\n\nA questo punto, possiamo definire alcune variabili e costanti che useremo nel codice. Prima di tutto, è importante definire l'accelerazione di gravità\n\n### Definiamo variabili e costanti\n\n```\ng = 9.81        #m/s**2\n```\n\ne i valori numerici di velocità e altenzza iniziale.\n\n```\nv0 = 10.        #m/s\nalpha = pi/3    #radianti\nh0 = 10.        #m\n\n```\n\nPreferisco indicare la velocità iniziale utilizzando il suo modulo $v_0$ e l'angolo di inclinazione $\\alpha$,\nda cui possiamo calcolare le componenti $v_x$ e $v_y$ che useremo nel codice\n\n```\nvx = v0*cos(alpha)\nvy = v0*sin(alpha)\n```\n\n### Calcoliamo tempo di volo e gittata\n\nA questo punto, possiamo calcolare il tempo $t_f$ e la posizione $x_f$ finali del moto\n\n```\ntf = (vy + sqrt(vy**2+2*g*h0))/g\nxf = vx*tf\n```\n\n### Simulazione\n\nA questo punto, possiamo scrivere il codice per la simulazione ed il disegno. Notiamo che non ha senso far prolungare la simulazione oltre il tempo $t_f$. Per questo motivo, simuleremo solo nell'intervallo $t \\in (0, t_f)$.\n\nPer farlo, generiamo un `array` di campioni di tempo in questo intervallo ad un passo predefinito e piccolo, ad esempio $\\Delta t = 0.01$ con il comando `arange`\n\n```\nt = arange(0,tf, 0.01)\n```\n\nAdesso possiamo calcolare i valori di $x(t)$ e $y(t)$ per ogni tempo nell'array definito implementando semplicemente le equazioni del moto\n\n```\nxt = vx*t\nyt = h0+vy*t-0.5*g*t**2\n```\n\nSi noti che Python sa che `t` e un array, e quindi genera come risultato degli array contenenti i valori delle equazioni ad ogni elemento di `t`. Comodo, no?\n\nA questo punto, possiamo finalmente _plottare_ (dall'inglese _plot_, cioè disegnare su un grafico) i due array.\n\n```\nplot(xt,yt)\n```\n\n### Codice completo\n\nQui sotto trovate il codice completo appena implementato\n\n```python\n# -*- coding: utf-8 -*-\n\"\"\"\nSpyder Editor\n\nThis is a temporary script file.\n\"\"\"\n\nfrom pylab import *\n\ng = 9.81        #m/s**2\n\nv0 = 10.        #m/s\nalpha = pi/3    #radianti\nh0 = 10.        #m\n\nvx = v0*cos(alpha)\nvy = v0*sin(alpha)\n\ntf = (vy + sqrt(vy**2+2*g*h0))/g\nxf = vx*tf\n\nt = arange(0,tf, 0.01)\nxt = vx*t\nyt = h0+vy*t-0.5*g*t**2\n\nplot(xt,yt)\n```\n\n### Lanciamo il programma\n\nUna volta implementato il codice, possiamo lanciare il programma premento sulla freccina verde in alto all'editor **Spyder**. Una volta fatto, se non ci sono errori, vedremo apparire il grafico della simulazione sulla _console_ del nostro programma.\n\n![lanciamo il programma in Spyder](./exec.png)\n\n## Conclusioni\n\nCome vedete, in pochissime linee di codice siamo riusciti a risolvere in moto automatico un classico problema di fisica meccanica di base. Essendo tutto calcolato dal programma, possiamo anche fare esperimenti cambiando l'angolo e il modulo della velocità iniziale e/o l'altezza $h_0$.\n\nBuona sperimentazione a tutti!\n\n## Ringraziamenti\n\nAlla stesura di questo documento hanno partecipato:\n\n- Prof. Basilio Bona\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-13-simuliamo-il-moto-parabolico-in-python-e-spyder/index.md",
    frontMatter: {
      path: "/2017/01/13/simuliamo-il-moto-parabolico-in-python-e-spyder/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "5 mins",
      published: "2017-01-13T00:00:00.000Z",
      publishedReadable: "13 Gen 2017",
      featured: false,
      tags: ["Fisica", "Python", "Scientific", "Spyder"],
      title: "Simuliamo il moto parabolico in Python e Spyder",
      description:
        "Un piccolo tutorial per iniziare ad utilizzare Spyder con Python",
      href: "/2017/01/13/simuliamo-il-moto-parabolico-in-python-e-spyder/",
      image:
        "/content/blog/it/2017-01-13-simuliamo-il-moto-parabolico-in-python-e-spyder/parabolico.png",
      imagePath:
        "/content/blog/it/2017-01-13-simuliamo-il-moto-parabolico-in-python-e-spyder",
    },
  },
  {
    content:
      "\nDopo il mio [post precedente su Canopy](http://www.ludusrusso.cc/posts/2017-01-09-canopy-una-pythonica-alternativa-a-matlab) un utente Facebook mi ha segnalato [**Spyder**](https://pythonhosted.org/spyder/), un altro tool molto interessante per l'analisi scientifica in Python!\n\n![Spyder Python Editor](./spyder.png)\n\nHo fatto un test molto molto veloce dell'utilizzo, ed effettivamente sembra essere molto simile a Canopy con l'unica differenza di essere un software completamente **Open Source**, cosa che prediligo molto.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-12-spyder-un-altra-alternativa-in-python-a-matlab/index.md",
    frontMatter: {
      path: "/2017/01/12/spyder-un-altra-alternativa-in-python-a-matlab/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2017-01-12T00:00:00.000Z",
      publishedReadable: "12 Gen 2017",
      featured: false,
      tags: ["Spyder", "Python", "Scientific"],
      title: "Spyder, un'altra alternativa in Python a Matlab",
      description:
        "Una velocissima prova del tool interattivo Spyder per l'analisi scientifica in Python",
      href: "/2017/01/12/spyder-un-altra-alternativa-in-python-a-matlab/",
      image:
        "/content/blog/it/2017-01-12-spyder-un-altra-alternativa-in-python-a-matlab/spyder.png",
      imagePath:
        "/content/blog/it/2017-01-12-spyder-un-altra-alternativa-in-python-a-matlab",
    },
  },
  {
    content:
      '\n![Canopy Main](./main.png)\n\nDa ingegnere meccatronico e informatico, sono abituato ad utilizzare Matlab, uno dei tool più importanti disponibili in ambito ingegneristico e scientifico. Durante la mia carriera universitaria (sia da studente che da dottorando) ho avuto modo di utilizzare Matlab in tantissimi corsi, da analisi dei segnali a robotica. Mi sono sempre interessato a cercare una valida alternativa OpenSource a questo programma, e ho sempre creduto che tutta la suite **matplotlib** fosse un buon compromesso... Questo finchè non mi sono imbattuto in **Canopy**.\n\n**Canopy** non è un progetto completamente Open, anche se è per la maggior parte composto da moduli Open Source ed è sviluppato dalla società _Enthought, Inc_. Potete scaricare una vesione gratuita molto completa dal bottone sotto, che essenzialmente include una serie di pacchetti Python Open per l\'analisi dei dati, un\'interfaccia interattiva di comando basata su iPython e pyLab, e un IDE di lavoro che sarà familiarissimo agli utilizzatori di MatLab.\n\n<a type="button" class="btn btn-info bnt-lg" href="https://store.enthought.com/downloads/#default"> Scarica Canopy</a>\n\n### Posso fare tutto quello che faccio con matlab con questo tool?\n\nOvviamente no, non credo ad esempio (o non ne conosco) che esistano alternative Python a Simulink & Co., però ho fatto un velocissimo test e molte delle cose che ho fatto abitualmente nei corsi con Matlab posso farle con Canopy!\n\n## Esempio di utlizzo\n\nUna volta installata l\'applicazione (si installa molto facilmente), apriamo il programma e vedremo la seguente schermata\n\n![Canopy Schermata Home](./home.png)\n\nSelezioniamo il pulsante **Editor** e accederemo ad un\'interfaccia molto simile a quella di matlab.\n\n![Canopy Editor](./editor.png)\n\nDalla linea di comando interattiva possiamo scrivere del codice Python con interfaccia pyLab. Ecco un brevissimo esempio per plottare a video una parabola.\n\nGeneriamo un vettore $x$ contenente numeri da $-1$ a $1$ con passo $0.01$\n\n```\nx = arange(-1,1,0.01)\n```\n\nGeneriamo i valori $y = x^2$ corrispondenti\n\n```\ny = x**2\n```\n\nPlottiamo i vettori $x$ e $y$\n\n```\nplot(x,y)\n```\n\nOtterremo il seguente grafico\n\n![Canopy Editor](./parabolaplot.png)\n\n## Considerazioni\n\nHo scoperto da poco questo interessantissimo tool, ho intenzione di utilizzarlo nel progetto di [fisica che sto realizzando per la mia scuola](http://www.ludusrusso.cc/posts/2017-01-04-arduino-python-lab-fisica-1)! Fatemi sapere se voi lo usate e se avete consigli!\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-09-canopy-una-pythonica-alternativa-a-matlab/index.md",
    frontMatter: {
      path: "/2017/01/09/canopy-una-pythonica-alternativa-a-matlab/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-01-09T00:00:00.000Z",
      publishedReadable: "9 Gen 2017",
      featured: false,
      tags: ["Python", "Canopy", "Tutorial"],
      title: "Canopy: una Pythonica alternativa a Matlab",
      description:
        "Presento questo interessante tool python che può essere considerato una buona alternativa a Matlab per l'analisi dei dati!",
      href: "/2017/01/09/canopy-una-pythonica-alternativa-a-matlab/",
      image:
        "/content/blog/it/2017-01-09-canopy-una-pythonica-alternativa-a-matlab/main.png",
      imagePath:
        "/content/blog/it/2017-01-09-canopy-una-pythonica-alternativa-a-matlab",
    },
  },
  {
    content:
      "\nChi ha letto i pochi articoli del blog che ho scritto, sa già che non sono solito utilizzare direttamente Raspberry Pi collegato ad un monitor, per una serie di motivi legati al fatto che il mio Raspberry è solitamente montato su un robot mobile.\n\nPer questo motivo cerco spesso varie soluzioni per la programmazione remota del Raspberry Pi. Solitamente mi trovo molto bene con l'utilizzo dell'accoppiata Vim+Tmux via SSH (magari farò un post sulla cosa), però recentemente ho iniziato ad utilizzare Atom come editor di testo principale, e oggi voglio parlarvi di [**Remote-Atom**](https://atom.io/packages/remote-atom), un plugin molto semplice che permette di editare file su una macchina remota utilizzando Atom.\n\n## Strumenti\n\nÈ necessario possedere un Raspberry Pi con abilitato SSH, inoltre serve installare Atom sul computer da cui si vogliono editare i file. Atom si scarica e installa molto semplicemente da questo [link](https://atom.io).\n\n## Configurazione di Remote Atom\n\nPer prima cosa, è necessario installare Remote-Atom, per farlo, accediamo al pannello Packages > Settings Views > Install Packages/Themes\n\n![](./install.png)\n\ne cerchiamo e installiamo il pacchetto **remote-atom**.\n\n![](./open-install.png)\n\nUna volta installato, dobbiamo attivare il server andando su Packages > Remote Atom > Start Server.\n\n![](./start-server.png)\n\n## Configurazione Raspberry Pi\n\nA questo punto siamo pronti a configurare il Raspberry Pi. Accediamo (via SSH o interfaccia grafica) al terminale del raspberry ed eseguiamo i seguenti comandi:\n\n```\nsudo curl -o /usr/local/bin/rmate https://raw.githubusercontent.com/aurora/rmate/master/rmate\nsudo chmod +x /usr/local/bin/rmate\nsudo ln -s /usr/local/bin/rmate /usr/local/bin/ratom\n```\n\nA questo punto siamo pronti ad utilizzare Atom.\n\n## Utilizzo\n\nPer utilizzare remote-atom, dobbiamo ricordarci di accedere via SSH al Raspberry Pi aggiungendo l'opzione `-R 52698:localhost:52698`. Ad esempio, nel mio caso che ho il Raspberry Pi collegato all'IP 192.168.0.12, utilizzerò il comando\n\n```\nssh -R 52698:localhost:52698 pi@192.168.0.12\n```\n\nUna volta dentro, per aprire un file, possiamo usare il comando\n\n```\nratom <filename>\n```\n\ne vedremo magicamente aprirsi il file in un nuovo pannello di Atom sul nostro desktop (che deve essere già aperto).\n\n![](./example.png)\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-07-utilizziamo-atom-come-editor-di-testo-remoto-su-raspberry-pi/index.md",
    frontMatter: {
      path: "/2017/01/07/utilizziamo-atom-come-editor-di-testo-remoto-su-raspberry-pi/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "2 mins",
      published: "2017-01-07T00:00:00.000Z",
      publishedReadable: "7 Gen 2017",
      featured: false,
      tags: ["Raspberry", "Atom", "Tutorial"],
      title: "Utilizziamo Atom come editor di testo remoto su Raspberry Pi",
      description:
        "Come usare Atom come editor di testo remoto per Raspberry Pi",
      href: "/2017/01/07/utilizziamo-atom-come-editor-di-testo-remoto-su-raspberry-pi/",
      image:
        "/content/blog/it/2017-01-07-utilizziamo-atom-come-editor-di-testo-remoto-su-raspberry-pi/example.png",
      imagePath:
        "/content/blog/it/2017-01-07-utilizziamo-atom-come-editor-di-testo-remoto-su-raspberry-pi",
    },
  },
  {
    content:
      "\nSolitamente, quando devo imparare ad utilizzare una nuova tecnologia, cerco di inventarmi un progetto interessante che potrebbe essere sviluppato con questa tecnologia e mi impegno a portarlo avanti fino alla fine. Quando ho iniziato ad interessarmi a Flask e Python, ho ideato il progetto che vi presento oggi, proprio per motivarmi ad imparare ad utilizzare bene questa libreria.\n\n![img1](./main.jpg)\n\n## Idea e Sviluppo\n\nL'idea di base era quella di sviluppare un semplice IDE web per Arduino, che mi permettesse di sviluppare codice su un Arduino direttamente connesso ad un Raspberry Pi (ormai sapete che utilizzo tantissimo entrambi questi Hardware), ma senza la scomodità di dover utilizzare direttamente l'interfaccia grafica del Raspberry Pi per programmare.\n\nQuindi lo scenario di utilizzo è il seguente (si vede che sono un PhD? Solo i PhD parlano di scenari di utilizzo :D):\n\n- Arduino collegato via USB a Raspberry Pi\n- Raspberry Pi connesso ad una rete WiFi o Ethernet local\n- Un computer/tablet/smartphone connesso alla stessa rete\n\nIl progetto doveva permettere di programmare Arduino e di accedere al monitor seriale (esattamente come fa l'IDE Arduino ufficiale).\n\n## Installazione\n\nTrovate tutto il codice sviluppato a questo <a href=\"https://github.com/ludusrusso/arduino-compiler-web\">link GitHub</a>. Per utilizzarlo è necessario accedere alla shell del Raspberry Pi e configurarlo come segue:\n\n### Installazione Dipendenze\n\nPrima di tutto dobbiamo installare le dipendenze, che sono:\n\n- Arduino-mk: un progetto che permette di interagire con Arduino da linea di comando\n- pySerial: libreria Python per accedere alla porta seriale\n- Flask: libreria Python per creare e gestire webapp\n\nArduino-mk si installa da apt-get da linea di comando\n\n```bash\n$ sudo apt-get install arduino-mk\n```\n\nPer le librerie Python, invece, conviene creare prima di tutto un virtualenv.\n\nPer installare virtualenv basta eseguire il comando\n\n```bash\n$ sudo pip install virtualenv\n```\n\nUna volta installato, entriamo nella cartella dove mettiamo solitamente i nostri progetti (nel mio caso è `devs`), creiamo un ambiente virtuale e installiamo le dipendenze Python\n\n```bash\n$ virtualenv remote-arduino\n$ cd remote-arduino\n$ source bin/activate\n(remote-arduino)$ pip install flask flask-bootstrap flask-script pyserial\n```\n\nA questo punto possiamo clonare la repository GitHub\n\n```bash\ngit clone https://github.com/ludusrusso/arduino-compiler-web\n```\n\nPrima di lancare la webapp, dobbiamo informare il programma della scheda Arduino che utilizziamo e della porta a cui è collegato. Per farlo, bisogna esportare le seguenti variabili d'ambiente:\n\n```bash\n(remote-arduino)$ export ARDUINO_PORT=/dev/ttyACM0\n(remote-arduino)$ export ARDUINO_BOARD=uno\n```\n\nIn questo caso, utilizziamo un Arduino UNO collegato alla porta ttyACM0.\n\n### Lanciare l'applicazione\n\nPer lanciare l'app, basta entrare nella cartella `arduino-compiler-web` e lancaire il seguente comando\n\n```bash\n./manage.py runserver -h 0.0.0.0 --threaded\n```\n\n### Utilizzo della WebApp\n\nA questo punto, da qualsiasi browser, collegandosi all'url `http://<IP RASPBERRY>:5000` accederemo all'applicazione.\n![index](index.png)\n\nPossiamo utilizzare l'editor di testo per scrivere codice\n\n![code](code.png)\n\nE installarlo su Arduino premendo il tasto <strong>Compile</strong>\n\n![compilation](compilation.png)\n\nAllo stesso modo, possiamo aprire e chiudere il serial monitor dai tasti <strong>Monitor</strong> e <strong>Stop</strong>\n\n![monitor](monitor.png)\n\n## Conclusioni\n\nQuesto progetto è ancora molto acerbo, ma mi ha permesso di sviluppare tantissime competenze in ambito di programmazione web in Python e Flask.\n\nAvete dei commenti e suggerimenti su come migliorarlo? Scrivetemi sulla mia pagina <a href=\"http://facebook.com/ludusrusso.cc\">facebook</a>.\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-06-un-ide-web-arduino-sviluppato-in-python-e-flask/index.md",
    frontMatter: {
      path: "/2017/01/06/un-ide-web-arduino-sviluppato-in-python-e-flask/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "3 mins",
      published: "2017-01-06T00:00:00.000Z",
      publishedReadable: "6 Gen 2017",
      featured: false,
      tags: ["Tutorial", "Raspberry", "Arduino"],
      title: "Un IDE web Arduino sviluppato in Python e Flask",
      description:
        "Un mio progetto dell'estate del 2015 che permette di programmare Arduino da un'interfaccia Web esposta da un Raspberry Pi",
      href: "/2017/01/06/un-ide-web-arduino-sviluppato-in-python-e-flask/",
      image:
        "/content/blog/it/2017-01-06-un-ide-web-arduino-sviluppato-in-python-e-flask/main.jpg",
      imagePath:
        "/content/blog/it/2017-01-06-un-ide-web-arduino-sviluppato-in-python-e-flask",
    },
  },
  {
    content:
      "\n![](./WhatsApp-Image-2017-01-04-at-14.05.08.jpeg)\n\n## Premessa\n\nRecentemente sono stato contattato dalla mia ex scuola (Liceo G. Stampacchia di Tricase) per aiutare a creare un corso di robotica e automazione per i nuovi studenti del liceo. Ho preso molto a cuore l'iniziativa e sto supportando i professori e il preside nell'implementazione. Da questo progetto è nata, tra le varie cose, l'idea di iniziare a sperimentare l'accoppiata Python + Arduino (magari su un raspberry pi) per realizzare in modo semplice esperimenti di Fisica e Matematica. Dal mio punto di vista i vantaggi di questo approccio sono molteplici, ecco quelli che mi vengono in mente adesso:\n\n- l'approccio è veramente multidisciplinare, invece del classico laboratorio di fisica, in cui gli studenti dovevano prendere ed elaborare a mano i dati, qui è richiesto allo studente di sviluppare il circuito di misura, scrivere codice Arduino a basso livello e utilizzare Python ad alto livello per l'elaborazione\n- super divertente (almeno secondo me)\n- molto economico da realizzare.\n\nCome primo spunto, propongo un semplicissimo esperimento per la misura della carica di un condensatore in un circuito RC.\n\nNota: ho realizzato questo esperimento per dare alcuni spunti ai miei ex professori su cosa si può fare sfruttando queste tecnologie. Ancora non so se (e in che modo) si può proporre un'esperienza del genere agli studenti, ma credo fortemente che questi strumenti possano essere fortemente istruttivi!\n\n## iPython e pyLab\n\n**iPython** è un'interfaccia di comando per Python molto semplice da utilizzare e potente. In accoppiata con la libreria **matplotlib** permette di ottenere un perfetto tool di lavoro per l'analisi dei dati scientifico, comprendente tool per la visualizzazione grafica dei dati. Una volta installato, è possibile lanciare il tool con il comando bash\n\n```\nipython --pylab\n```\n\n## Teoria sul circuito $RC$\n\nIl circuito $RC$ è un semplice circuito elettronico composto da un condensatore (di capacità $C$) in serie ad una resistenza (di valore $R$). Lo scopo dell'esperimento è misurare l'evoluzione carica $Q$ del condensatore nel tempo, cioè l'andamento della differenza di potenziale $V$ ai terminali del condensatore quando il circuito viene alimentato. Si ricordi, infatti che $Q=CV$.\n\nNoti i parametri $R$ e $C$, sappiamo che la differenza di potenziale $v(t)$ ai capi del consatore, al variare del tempo, è data da\n\n$$\nv(t) = V_\\infty \\cdot \\left(1-e^{-\\frac{t}{RC}}\\right)\n$$\n\ndove $V_\\infty$ è la tensione a cui viene alimentato il circuito $RC$, solitamente $V_\\infty = 5V$.\n\n## Implementazione\n\nL'esperimento realizzato permette, sfruttando Arduino, di misurare l'andamento della tensione $v(t)$ ai due capi del condensatore e mandare (sfruttando la comunicazione seriale) a Python questi dati. Una volta acquisiti i dati possono venire elaborati sfruttando le potenzialità di **iPython**.\n\n### Circuito\n\nIl circuito sviluppato è mostrato nella figura seguente.\nMateriale:\n\n- Arduino UNO.\n- Condensatore (nel mio caso un elettrolitico con $C=100\\mu F$).\n- Resistore (nel mio caso con $R=10k\\Omega$).\n- Breadboard.\n\nImportante: dato che Arduino (specialmente quando comunica in seriale) non è capace di acquisire dati ad una frequenza molto elevata, per riuscire a prendere un numero adeguato di dati conviene scegliere valori di $R$ e $C$ abbastanza elevati, in modo da avere constanti di tempo dell'ordine di qualche di qualche secondo. Nel mio caso, ho scelto $\\tau=RC=1s$ nominale.\n\n![RC-Scheme](./RC.png)\n\nEssendo il condensatore che ho utilizzato elettrolitico, i suoi terminali sono polarizzati, ossia è necessario collegare il terminale positivo (anodo) ad un punto del circuito avente potenziale più elevato rispetto al punto di collegamento del terminale negativo (catodo). Nel caso si utilizzi un condesatore ceramico, non è importante la polarità!\n\nColleghiamo quindi il catodo ($-$) del condensatore al PIN GND di Arduino ,e l'anodo ($+$) tramite breadboard al pin $A0$. Colleghiamo inoltre, per mezzo di una resistenza, l'anodo del condensatore al PIN $2$ di Arduino.\n\n### Codice Arduino\n\nIl codice Arduino che andremo ad implementare sfrutta il PIN $2$ per caricare e scaricare il condensatore. In fase di carica, utilizzando il PIN $A0$ misura il valore di carica sul considerare e invia i dati in seriale. Il codice che ho sviluppato raccoglie 50 campioni intervallati da un periodo di campionamento $Tc =100ms$.\n\nÈ importante scegliere il tempo $Tc$ in modo da avere abbastanza campioni per valutare riuscire a ricostruire correttamente l'andamento del segnale.\n\nApro una piccola parantesi ingegneristica, esiste il [Teorema di Nyquist](https://it.wikipedia.org/wiki/Teorema_del_campionamento_di_Nyquist-Shannon) che impone che il tempo di campionamento di un qualisasi segnale temporale deve essere $T_c < \\frac{1}{2}\\tau_{min}$, dove $\\tau_{min}$ è la più piccola costante di tempo di segnale stesso. In questo caso abbiamo una sola costante di tempo $\\tau=RC=1s$, quindi dobbiamo scegliere $T_c< 0.5s$.\n\nAll'atto pratico, il mio consiglio è scegliere sempre $Tc =\\frac{\\tau}{10}$. Nel mio caso ho $\\tau = 1s$ e quindi ho scelto $Tc = 100ms$.\n\nUna volta scelto $Tc$ possiamo implementare il codice Arduino. Lo scopo del codice è:\n\n- Scaricare il condensatore per un tempo appropriato $T=50\\cdot Tc$.\n- Iniziare il ciclo di carica.\n- Campionare i dati di $v(t)$ e mandarli in seriale.\n\nIl codice implementato è riportato di seguito.\n\n```\n# define POWER_PIN 2\n\nint cnt = 0;\nint sensorPin = A0;\n\nint Tc = 100; // 100ms\n\nint N_campioni = 50;\n\nvoid setup() {\n  Serial.begin(9600);\n  pinMode(POWER_PIN, OUTPUT);\n  digitalWrite(POWER_PIN, LOW);\n  delay(N_campioni*Tc);\n  digitalWrite(POWER_PIN, HIGH);\n  Serial.println(\"START\");\n}\n\nvoid loop() {\n  if (cnt < N_campioni) {\n      int sensorValue = analogRead(sensorPin);\n      Serial.println(sensorValue);\n      cnt++;\n    } else if (cnt == N_campioni){\n      Serial.println(\"END\");\n      cnt++;\n    }\n  delay(Tc);\n}\n```\n\n#### Testiamo il codice\n\nUna volta implementato e lanciato il codice in Arduino, possiamo testare il programma attraverso il serial monitor. Apriamo il serial monitor e resettiamo la scheda, il programma inizierà a scaricare il condensatore e poi a prendere i dati. Il tutto dovrebbe durare circa $10s$. Sul serial monitor dovreste vedere i valori misurati, come nella foto seguete\n\n![](./Schermata-2017-01-04-alle-15.11.32.png)\n\nSe tutto funziona correttamente, possiamo passare all'utilizzo di Python per salvare i dati ed analizzarli.\n\n### Utilizzo di Python e pyLab\n\nPer utilizzare questi strumenti, è necessario installare sul computer le seguenti librerie\n\n- iPython\n- matplotlib\n- pySerial\n\nLe prime due servono per utilizzare in modo efficace e semplice tutta la potenza di pylab, l'ultima è una libreria che ci permette di sfruttare la comunicazione seriale per parlare con Arduino.\n\n#### Scriviamo il codice per loggare i dati in seriale da Arduino\n\nCreiamo un file chiamato `rc.py` in una cartella vuota, e implementiamo il seguente codice nel nuovo file.\n\n```\nfrom serial import Serial\nimport time\n\ndef get_data(port):\n    print 'RESET CONDENSATORE....'\n    times = []\n    values = []\n    ser = Serial(port)\n    data = ser.readline().rstrip()\n    while data != \"START\":\n        data = ser.readline().rstrip()\n    print 'STARTING....'\n    while data != \"END\":\n        data = ser.readline().rstrip()\n        try:\n            m = float(data)/1024.0 * 5\n            times.append(time.time())\n            values.append(m)\n        except:\n            continue\n    print 'STOP....'\n    ser.close()\n\n    times = [t - times[0] for t in times]\n\n    return times, values\n```\n\nSalviamo il file e apriamo la cartella all'interno del terminale.\n\n#### Utilizzo di pyPlot\n\nAll'interno del terminale lanciamo iPython con PyLab utilizzando il seguente comando.\n\n```\nipython --pylab\n```\n\nA questo punto, accedendo alla linea di comando di pyPlot, dovreste vedere una schermata simile alla seguente\n\n![iPython](./Schermata-2017-01-04-alle-15.26.00.png)\n\n#### Campionamento dei Dati\n\nPerfetto, ora possiamo iniziare ad usare pyPlot in modo interattivo. Per prima cosa, bisogna importare il file `rc.py` ed utilizzarlo. Per farlo, eseguiamo i seguenti comandi:\n\nImportiamo il file con il comando\n\n```\nimport rc\n```\n\nCampioniamo i dati.\n\n```\nt_meas, v_meas = rc.get_data(\"/dev/ttyUSB0\")\n```\n\nNota 1: dobbiamo passare alla funzione `get_data` il nome della porta a cui Arduino è collegato. Per trovarla, basta verificare a quale porta è collegato Arduino sfruttando l'IDE di Arduino stesso.\n\nNota 2: Ricordate di chiudere il serial monitor dall'IDE di Arduino prima di eseguire il comando, altrimenti il canale di comunicazione risulterà occupato.\n\nUna volta eseguita la funzione, dovremo aspettare la fine della procedura di acquisizione. A questo punto, troveremo i dati campionati all'interno delle due variabili `t_meas` e `v_meas`, che conterranno, rispettivamente, i tempi e i valori del dati campionati.\n\nPer verificare che la procedura sia andata a buon fine, possiamo semplicemente digitare il nome di una delle due variabili e premere invio per stampare a schermo i valori contenuti all'interno.\n\n#### Disegniamo i dati campionati\n\nPer disegnare i dati possiamo eseguire il seguente comando\n\n```\nplot(t_meas, v_meas, 'ro')\n```\n\nA questo punto, dovrebbe apparire istantaneamente una nuova finestra con il grafico dei dati campionati\n\n![graph1](./Schermata-2017-01-04-alle-15.44.17.png)\n\nNota: `plot` prende due parametri più un parametro opzionale. I primi due sono due vettori contenenti i dati da disegnare rispettivamente sull'asse $x$ e $y$. Il terzo parametro (opzionale) è una stringa che definisce lo stile del disegno. In questo caso `\"ro\"` significa \"disegna i valori in rosso (r) con dei pallini (o)\".\n\n#### Verifichiamo la legge fisica\n\nA questo punto, non ci resta che verificare la legge fisica che regola la carica del circuito $RC$. Per farlo, proviamo a simulare l'andamento della carica sfruttando la legge e sovrapponiamo la simulazione ai dati campionati, per vedere se combaciano.\n\nPer farlo, creiamo prima di tutto una sequenza di valori di tempo da $0s$ a $5s$ abbastanza densa, con il comando\n\n```\nt_sim = arange(0,5,0.01)\n```\n\nTramite il comando, abbiamo generato una sequenza di numeri da $0$ a $5$ a intervalli di $0.01$.\n\nA questo punto, possiamo simulare l'equazione. Prima di tutto, bisogna definire le variabili $R$, $C$ e $V_\\infty$.\n\nUtilizzamo per farlo la notazione scientifica per definire i numeri.\n\n```\nR=10e3\nC=100e-6\nVinf=5\n```\n\nA questo punto, possiamo implementare la legge e simulare i dati:\n\n```\nv_sim = Vinf*(1-exp(-t_sim/(R*C)))\n```\n\nPer finire, plottiamo i dati utilizzando il comando plot (questa volta su una linea continua di colore blu).\n\n```\nplot(t_sim, v_sim, 'b')\n```\n\nE, riaprendo la finestra dell'immagine, otterremo un grafico simile a questo\n\n![graph2](./Schermata-2017-01-04-alle-15.56.05.png)\n\n## Conclusioni\n\nHo ricevuto molti segnale interesse per questo esperimento da parte dei professori della mia scuola. Spero che questo tutorial, che non è perfetto e che andrà migliorato, possa aiutare qualcuno a fare didattica in modo più divertente.\n\nSe avete suggerimenti, trovate errori o volete semplicemente contattarmi, mi trovate su [facebook](https://www.facebook.com/ludusrusso.cc/).\n\n## Ringraziamenti\n\nAlla stesura di questo documento hanno contribuito\n\n- Prof. Michele Maffucci\n- Prof. Giorgio de Nunzio\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2017-01-04-un-laboratorio-di-fisica-con-arduino-e-python/index.md",
    frontMatter: {
      path: "/2017/01/04/un-laboratorio-di-fisica-con-arduino-e-python/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "8 mins",
      published: "2017-01-04T00:00:00.000Z",
      publishedReadable: "4 Gen 2017",
      featured: false,
      tags: ["Arduino", "Python", "Didattica"],
      title: "Un laboratorio di Fisica con Arduino e Python",
      description:
        "Primi esperimenti con Arduino e Python per realizzare un semplice laboratorio di fisica sfruttando la potenza di Python e la versatilità di Arduino",
      href: "/2017/01/04/un-laboratorio-di-fisica-con-arduino-e-python/",
      image:
        "/content/blog/it/2017-01-04-un-laboratorio-di-fisica-con-arduino-e-python/WhatsApp-Image-2017-01-04-at-14.05.08.jpeg",
      imagePath:
        "/content/blog/it/2017-01-04-un-laboratorio-di-fisica-con-arduino-e-python",
    },
  },
  {
    content:
      "\nPrendendo spunta da [Miguel Grinberg](https://blog.miguelgrinberg.com), noto esperto di Flask da cui ho appreso molte delle cose che conosco di questo microframework, ho deciso di seguire, passo passo, in questo tutorial l'implementazione del sito che ho reallizato.\n\nQuindi, questa guida seguirà, passo passo, i vari step che e le varie migliorie che implementerò sul mio stesso blog.\n\n# 1. Setup ambiente di sviluppo\n\nPer prima cosa, iniziamo a creare un [virtualenv](/2017/11/06/virtualenv/) (io lo chiamerò `ludoblog`) e installiamoci all'interno `flask`.\n\n```bash\n$ virtualenv ludoblog\n$ cd ludoblog\n$ source bin/activate\n(ludoblog)$ pip install flask\n(ludoblog)$ mkdir project && cd project\n```\n\n## Organizziamo il progetto\n\nPer progetti grandi e per tenere il codice organizzato, conviene organizzare in modo organico il progetto all'interno di cartelle. Organizzerò il progetto seguendo delle [linee guida che si trovano su internet](http://flask.pocoo.org/docs/0.12/patterns/packages/).\n\nLa cartella `/project` sarà la cartella principale della nostra applicazione. Assicuriamoci di essere all'interno di questa cartella prima di iniziare a lavorare.\n\n## Creiamo il modulo blog\n\nCreiamo una cartella `blog` che conterrà la nostra applicazione, il file `blog/__init__.py` che sarà il core dell'applicazione.\n\n```bash\n(ludoblog)$ mkdir blog\n(ludoblog)$ touch blog/__init__.py\n```\n\nNota Bene: un file `__init__.py` in python assume un significato specifico: fa si che un progetto all'interno di una cartella sia considera un **modulo** python. Quindi ad ora in poi possiamo importare il modulo blog normalmente con la stringa `import blog`.\n\nAprimamo il file `blog/__init__.py` e andiamo ad implementare il seguente codice.\n\n```python\nfrom flask import Flask\n\ndef create_app():\n    app = Flask(__name__)\n    return app\n```\n\n## Creiamo il blueprint main\n\nFlask permette di organizzare un'applicazione in sottoapplicazioni chiamate `blueprint`. I blueprint permettono di organizzare in modo organico la nostra app. Ad esempio, se un'applicazione contiene al proprio interno sia un blog che un forum, possiamo scorporarla in due `blueprint` per gestire, rispettivamente, il blog e il forum.\n\nPersonalmente, a me piace organizzare anche il core principale dell'applicazione (index, gestione errori, ecc.) all'interno di un blueprint chiamato `main`, che è quello che andremo a fare adesso. In questo modo, quando andremo a creare nuove applicazioni, possiamo fare un bel copia-incolla della cartella _main_ e avremo già pronto tutte le varie parti di gestione.\n\nDobbiamo quindi creare una cartella `main` organizzata come segue all'interno della cartella `blog`.\n\n```\nmain/\n├── __init__.py\n├── errors.py\n└── views.py\n```\n\n#### File \\_\\_init\\_\\_.py\n\nQui dentro inseriremo il codice generale del nostro modulo. Principalmente quello che farà questo file in ogni modulo blueprint deve essere:\n\n- Inizializzare il Blueprint\n- importare il file `views.py`\n\nImplementiamo quindi il seguente codice centro il file\n\n```python\nfrom flask import Blueprint\n\nmain = Blueprint('main', __name__)\n\nfrom . import views, errors\n```\n\nA che serve importare i file `views` e `errors` alla fine del file? In questo modo, qualsiasi file importerà il modulo `main`, importerà automaticamente anche tutti i moduli importati dal file `__init__.py`, e quindi, in questo caso, anche questi file.\n\n#### File views.py\n\nQuesto file conterrà tutte le `views` che il nostro modulo esporterà. Per il modomento, accontentiamoci semplicemente di creare una view che risponde all'url `/` con semplice linea di testo.\n\nImplementiamo il seguente codice nel file\n\n```python\nfrom . import main\n\n@main.route('/')\ndef index():\n    return '<h1>Benvenuti nel mio blog</h1>'\n```\n\nSi noti che, invece che usare direttamente l'oggetto `app`, utilizziamo l'oggetto blueprint `main` per generare il route dell'url.\n\n#### File errors.py\n\nQuesto file è simile al file views, ma ha lo scopo di gestire le views da rilasciare nel momento in cui si verificano degli errori all'interno dell'applicazione.\n\nGli errori che andremo a gestire sono tre:\n\n- `error 403 (permesso negato)`, che si verifica quando l'utente accede ad un percorso a cui non ha i permessi di accedere.\n- `error 404 (file non trovato)`, che si verifica quando l'utente accede ad un percorso che non esiste.\n- `error 500 (errore interno al server)`, che viene generato automaticamente quando si verifica un problema nel server.\n\nIn flask, possiamo settare delle views personalizzate in base al problema che si verifica. Per il momento, come su, accontentiamoci di ritornare semplicemente una linea di testo. Implementiamo il seguente codice nel file.\n\n```python\nfrom flask import render_template\nfrom . import main\n\n@main.app_errorhandler(403)\ndef forbidden(e):\n    return 'errore 403 - Accesso Negato', 403\n\n@main.app_errorhandler(404)\ndef page_not_found(e):\n    return 'errore 404 - File non trovato', 404\n\n@main.app_errorhandler(500)\ndef internal_server_error(e):\n    return 'errore 500 - Errore interno al server', 500\n```\n\n### Colleghiamo il Blueprint all'applicazione principale\n\nIl nostro modulo `main` è in una forma base per essere utilizzata. Apriamo il file `ludoblog/__init__.py` e aggiungiamo il seguente codice prima della riga `return app`.\n\n```python\n# ...\ndef create_app():\n\t# ...\n\tfrom .main import main as main_bp\n\tapp.register_blueprint(main_bp)\n\t# ...\n```\n\nCon queste due linee di codice abbiamo registrato alla nostra applicazione il blueprint `main` appena creato.\n\n## Utilizziamo flask-script per gestire l'applicazione\n\nA questo punto, l'applicazione ha il minimo indispensabile per poter essere lanciata e funzionare. Per porterlo fare, però, abbiamo bisogno di creare fisicamente l'app (ricordiamo che abbiamo creato un metodo `create_app()` ma non un vero e proprio oggetto app. Per poter fare questo, basterebbe un semplice script con le seguenti linee di codice\n\n```python\nfrom blog import create_app\napp = create_app()\napp.run()\n```\n\nTuttavia, cerchiamo di fare le cose per bene ed utiliziamo un'estensione di flask chiamata flask-script. Questa estensione fornisce un utilissimo set di script shell per gestire la nostra applicazioni, che permettono di lanciare l'app in varie modalità e gestire il database. Quest'estensione sarà utilissima in seguito quando l'app diventerà più grande, quindi è importante integrarla subito all'interno del nostro progetto.\n\nPrima di tutto, installiamo flask-script come segue\n\n```bash\n(ludoblog)$ pip install flask-script\n```\n\nRitorniamo nella cartella principale `/project` e creiamo un file `manage.py`. Implementiamo all'interno del file il seguente codice\n\n```python\n#!/usr/bin/env python\n\nfrom blog import create_app\nfrom flask_script import Manager\n\napp = create_app()\nmanager = Manager(app)\n\nif __name__ == '__main__':\n    manager.run()\n```\n\nA questo punto, possiamo lanciare l'applicazione con il seguente comando\n\n```bash\n(ludoblog)$ python manage.py runserver\n```\n\nIn alternativa, possiamo rendere il file `manage.py` eseguibile, con il comando\n\n```bash\n(ludoblog)$ chmod +x manage.py\n```\n\nE, da questo momento, possiamo lanciare l'applicazione semplicemente con il comando\n\n```bash\n(ludoblog)$ ./manage.py runserver\n```\n\nUna volta lanciata l'app, accediamo, da browser, all'indirizzo `http://127.0.0.1:5000` e il server risponderà come nella seguente immagine.\n\n![](./index.png)\n\nNotate che il sito realizzato sarà accessibile solo dal computer su cui il server è in funzione. Se volete fare in modo che questo sia accessibile anche dall'esterno, usate l'opzione `-h 0.0.0.0`, come sotto:\n\n```bash\n(ludoblog)$ ./manage.py runserver -h 0.0.0.0\n```\n\nNote\n\nTrovate tutto il codice sviluppato fino ad ora al seguente link <https://github.com/ludusrusso/ludoblog/tree/p1>\n\n# 2. Diamo una veste grafica all'applicazione\n\nIn questo secondo punto, organizzeremo la veste grafica della nostra app per poi iniziare a svilupparla.\n\n## Templating\n\nPer gestire graficamente l'app, utilizzeremo **Bootstrap**. **Bootstrap** è uno dei più popolari framework per lo sviluppo di interfacce grafiche web. Le sue peculiarità sono elencate qui sotto:\n\n- _responsive_: cioè il framework si adatta automaticamente alle dimensioni dello schermo.\n- _mobile first_: cioè è pensato principalmente per dispositivi mobili, ma funziona benissimo anche su classici desktop.\n- _open source_.\n\n### Configurazione Flask-Boostrap\n\nFlask-Bootstrap è un'estensione di flask che automaticamente ed in modo semplice importa bootstrap nella nostra applicazione e permette subito di usarlo. Andiamo quindi a crearlo e configurarlo.\n\nPer installare il pacchetto, utilizziamo (come al solito) il seguente comando.\n\n```bash\n(ludoblog)$ pip install flask-bootstrap\n```\n\nPerfetto, a questo punto andiamo ad inizializzarlo nella nostra applicazione.\nApriamo il file `blog/__init__.py` ed aggiungiamo le seguenti linee di codice\n\n```python\n# ...\nfrom flask_bootstrap import Bootstrap\n\nbootstrap = Bootstrap()\n\ndef create_app():\n    app = Flask(__name__)\n    # ...\n    bootstrap.init_app(app)\n    # ...\n    return app\n```\n\nPerfetto, a questo punto siamo pronti per iniziare a sviluppare la nostra interfaccia grafica.\n\n### Creiamo un Template Base\n\nLa prima cosa da fare è creare un template che useremo come base per tutte le nostre pagine. Questo template, quindi, deve contenere gli elementi principali che si ripeteranno poi in ogni pagina della nostra webapp, come il navbar o il footer. Iniziamo a creare adesso un template base essenziale e poi andremo, piano piano, ad arricchirlo. La cosa bella è che, una volta creato un template base e ricordandoci di far derivare ogni altra pagina web da questo template (vedremo dopo come fare), ogni aggiunta e miglioria al template base apparirà anche nelle altre pagine.\n\nCreiamo due cartella `templates/main` all'interno del blueprint `main` e un file `base.html` all'interno di questa cartella\n\n```bash\n(ludoblog)$ mkdir blog/main/templates\n(ludoblog)$ mkdir blog/main/templates/main\n(ludoblog)$ touch blog/main/templates/main/base.html\n```\n\nAdesso andiamo ad implementare il template base, apriamo il file appena creato e mettiamo dentro il seguente codice.\n\n```html\n{% extends \"bootstrap/base.html\" %} {% block title %}Blog{% endblock %} {% block\ncontent %}\n<div class=\"container\">\n  <div class=\"row\">\n    <div class=\"col-lg-12\">{% block page_content %} {% endblock %}</div>\n  </div>\n</div>\n{% endblock %}\n```\n\nPerfetto, addesso siamo pronti ad usare il nostro template per costruire le view dell'applicazione!\n\n### Pagina principale\n\nPer prima cosa, abbiamo bisogno di informare il blueprint `main` su dove trovare i template che andremo ad utilizzare. Per fare questo, modifichiamo, nel file `blog/main/__init__.py` la linea di codice\n\n```python\nmain = Blueprint('main', __name__)\n```\n\ncon la seguente\n\n```python\nmain = Blueprint('main', __name__, template_folder=\"templates\")\n```\n\nIn questo modo, informiamo il blueprint di cercare i template all'interno della cartella `blog/main/templates`.\n\nAdesso possiamo creare un semplice template da visualizzare nell'index. Creiamo un nuovo file `blog/main/templates/main/index.html` e andiamo ad implementare il seguente codice html\n\n```html\n{% extends \"main/base.html\" %} {% block page_content %}\n<div class=\"page-header\">\n  <h1>Benvenuti nel mio blog!</h1>\n</div>\n{% endblock %}\n```\n\nPerfetto! A questo punto non ci resta che richiamare il template nella view `index`. Modifichiamo il file `views.py`, ed in particolare la funzione `index()` come segue\n\n```python\nfrom . import main\nfrom flask import render_template\n\n@main.route('/')\ndef index():\n    return render_template('main/index.html')\n```\n\nLanciamo l'applicazione e accediamo alla webapp da browser.\n\n![](./index2.png)\n\n### Pagine di errore\n\nCreiamo adesso un template simile per gestire le pagine di errore. Quello devono fare queste pagine sarà semplicemente visualizzare il codice di errore e le informazioni all'interno di una veste grafica ben costruita.\n\nSiccome le 3 pagine di errore dovranno essere graficamente identiche, a parte le stringhe da visualizzare, ho pensato di creare una pagina unica per renderizzarle e di utilizzare delle variabili per visualizzare stringhe diverse in base all'errore generato. In particolare, la pagina dovrà visualizzare con il tag `h1` il codice di errore e con il tag `h2` il messaggio di errore. Andiamo quindi a creare un secondo template `blog/main/templates/main/error.html` e inseriamo dentro il seguente codice html\n\n```html\n{% extends \"main/base.html\" %} {% block page_content %}\n<div class=\"page-header\">\n  <h1>Errore {{ error_code }}</h1>\n  <h2>{{ error_msg }}</h2>\n</div>\n{% endblock %}\n```\n\nPerfetto, a questo punto non dobbiamo fare altro che passare le due variabili `error_code` e `error_msg` al nostro template per generare pagine diverse.\n\nModifichiamo il file `blog/main/errors.py` come segue\n\n```python\nfrom flask import render_template\nfrom . import main\n\n@main.app_errorhandler(403)\ndef forbidden(e):\n    return render_template('main/error.html', error_code=403, error_msg=\"Accesso negato!\"), 403\n\n@main.app_errorhandler(404)\ndef page_not_found(e):\n    return render_template('main/error.html', error_code=404, error_msg=\"File non trovato!\"), 404\n\n@main.app_errorhandler(500)\ndef internal_server_error(e):\n    return render_template('main/error.html', error_code=500, error_msg=\"Errore interno al server!\"), 500\n```\n\nTestiamo la nostra app accedendo ad un URL non esistente, ad esempio `/error` e dovremmo veder generaro l'errore 404.\n\n## NavBar e Footer\n\nLa barra di navigazione e il footer sono due parti importanti di un qualsiasi sito web, e quindi anche della nostra webapp. Entrambi riguardano tutte le views del blog, quindi le implementermo nel template base.\n\n### NavBar\n\nPer implementare la navbar, ci viene in aiuto la comoda estensione di flask chiama flask-nav. Essenzialmente, flask-nav permette di creare NavBar in modo dinamico ogni volta che una view viene generata, ed si integra con flask-bootstrap per la visualizzazione.\n\nIniziamo ad installare il pacchetto flask-nav\n\n```bash\npip install flask-nav\n```\n\nA questo punto, possiamo iniziare ad impostare la nostra navbar. Per prima cosa, inizializziamo il modulo all'interno del file `blog/__init__.py`:\n\n```python\n# ...\nfrom flask_nav import Nav\n# ...\nnav = Nav()\n\ndef create_app():\n    # ...\n    nav.init_app(app)\n    # ...\n    return app\n```\n\nCreiamo quindi un file chiamato `blog/navbar.py` e inseriamoci il seguente codice\n\n```python\nfrom . import nav\nfrom flask_nav.elements import *\n\n@nav.navigation()\ndef main_nav():\n    navbar = Navbar('Blog')\n    navbar.items.append(View('Home', 'main.index'))\n    return navbar\n```\n\nRicordiamoci di aggiugnere la stringa\n\n```python\nfrom .navbar import main_nav\n```\n\nAlla fine del file `blog/__init__.py`. In modo che il file `blog/navbar.py` venga importato correttamente.\n\nLa navbar che abbiamo realizzato è molto semplice, la complicheremo quando andremo ad arricchire il blog. L'ultimo passo però consiste nel renderizzarla. Apriamo il file `blog/main/templates/main/base.html` e aggiungiamo queste linee di codice per renderizzare la barra.\n\n```html\n{% block navbar %} {{nav.main_nav.render()}} {% endblock %}\n```\n\nPerfetto, a questo punto possiamo lanciare l'applicazione che mostrerà la nostra navbar!\n\n![](./indexnav.png)\n\n### Footer\n\nCome per la navbar, il footer deve essere visualizzato in tutte le views della nostra applicazione. Per questo motivo, anche questo va inserito all'interno del templeta base. A differenza della navbar che deve essere dinamica, il footer deve contenere semplicemente informazioni generali di un sito, come il nome dell'autore, le finalità, link a social networks e alla privacy policy, ecc. Per il momento, di nuovo, lo renderò minimale, ma ognuno può customizzarlo come vuole.\n\nPer aggiungere il footer, modifichiamo il file `blog/main/templates/main/base.html` come segue\n\n```html\n#... {% block content %} #...\n\n<footer>\n  <hr />\n  <div class=\"container\">\n    <div class=\"row\">\n      <div class=\"col-lg-12\">Progettato da Me</div>\n    </div>\n  </div>\n</footer>\n{% endblock %}\n```\n\nE riavviamo l'applicazione.\n\n![](./indexfooter.png)\n\n> Trovate tutto il codice sviluppato fino ad ora al seguente link <https://github.com/ludusrusso/ludoblog/tree/p2>\n\n# 3. Configurazione e Database\n\nUna volta impostata graficamente la nostra applicazione, siamo pronti a costruire un database per la gestione di utenti e post del blog. Ma prima di tutto, è importante impostare un file di configurazione per organizzare bene la configurazione della nostra applicazione.\n\n## File di configurazione\n\nLo scopo del file di configurazione è duplice:\n\n- inserire in un unico file tutte le variabili di configurazione della nostra applicazione\n- permettere di avere differenti set di configurazione in base a dove viene lanciata l'applicazione. Possiamo ad esempio avere un set di configurazione di **sviluppo** e un set di configurazione **produzione**, come faremo in seguto.\n\nCreiamo un file `/config.py` e implementiamo il seguente codice\n\n```python\nimport os\nbasedir = os.path.abspath(os.path.dirname(__file__))\n\nclass Config:\n\n    SECRET_KEY = os.environ.get('SECRET_KEY') or 'stringa difficile da indovinare'\n\n    @staticmethod\n    def init_app(app):\n        pass\n\nclass DevelopmentConfig(Config):\n    DEBUG = True\n\nclass ProductionConfig(Config):\n    DEBUG = False\n\nconfig = {\n    'development': DevelopmentConfig,\n    'production': ProductionConfig,\n    'default': DevelopmentConfig\n}\n```\n\nQuesto sarà lo scheletro della nostra applicazione, in particolare abbiamo un oggetto `Config` da cui faremo derivare i vari set di configurazioni della nostra applicazione. Per ora useremo solo l'oggetto `DevelopmentConfig` in cui inseriremo i set di configurazione per la macchina su cui svilupperemo il blog. In futuro, popoleremo il file anche con altri oggetti (ad esempio per il testing) e popoleremo l'oggetto `ProductionConfig`.\n\nIl dizionario `config`, invece, serve semplicemente ad associare un oggetto di configurazione ad una specifica stringa.\n\n### SECRET_KEY\n\nPer il momento, l'unico parametro di configuraizone utilizzato è `SECRET_KEY`. Questa variabile è importante in quanto è usata da `Flask` e da molte estensioni per criptare dati. Quindi è molto importante che sia sicura e che non venga divulgata.\n\n```python\nSECRET_KEY = os.environ.get('SECRET_KEY') or 'stringa difficile da indovinare'\n```\n\nPer ragioni di sicurezza e per evitare di scrivere la chiave direttamente nel file, sfruttiamo le variabili d'ambiente. In questo modo, python controllerà se la variabile d'ambienete `SECRET_KEY` è stata settata ed utilizzerà il suo valore. Se non è stata settata, utilizzerò come default `'stringa difficile da indovinare'`. In fase di sviluppo non è importante settare questa variabile, ma sarà essenziale farlo in fase di produzione.\n\n### Usiamo il file per configurare l'app\n\nUna volta creato il file e gli oggietti di configurazione, dobbiamo usare queste informazioni nella funzione `create_app`. Per farlo, modofichiamo il file `blog/__init__.py` come segue\n\n```python\n# ...\nfrom config import config\n\n#...\n\ndef create_app(config_name='default'):\n    app = Flask(__name__)\n    app.config.from_object(config[config_name])\n    config[config_name].init_app(app)\n\t#...\n#...\n```\n\nIn questo modo, facciamo si che l'applicazione venga configurata in base alle varibabili contenute nell'oggetto di configurazione scelto.\nSi noti che passiamo `'deafult'` come valore di default al parametro `config_name`. In quasto modo, se creiamo l'app senza passare esplicitamente il parametro, verrà automaticamente caricato il set di configurazione `DevelopmentConfig`.\n\n## Configurazione del database con Flask-SQLAlchemy\n\nA questo punto siamo pronti a configurare il nostro database. Per gestirlo, utilizzeremo due importantissime estensioni di Flask:\n\n- **Flask-SQLAlchemy**, molto utile per la gestione del db, in particolare semplifica l'accesso e la creazione di nuove entries del db.\n- **Flask-Migrate**, in accoppiata con flask-script, consente di automatizzare l'evoluzione del database stesso.\n\nInoltre, utilizzeremo fin da subito un'utilissima estensione chiamata **Flask-Security**, che servirà per gestire l'accesso e l'autenticazione agli utenti del blog. Siccome questa estensione è fortemente legata alla struttura del db, la installaremo e utilizzeremo fin da subito.\n\nPer installare questi pacchetti, utilizziamo come al solito il comando\n\n```\n(blog)$ pip install flask-sqlalchemy flask-security flask-migrate\n```\n\n#### Configurazione di SQLAlchemy\n\nPer prima cosa, dobbiamo inizializzare e configurare flask-sqlalchemy. Per inizializzarlo, modificando il file `blog/__init__.py` come segue\n\n```python\n#...\nfrom flask_sqlalchemy import SQLAlchemy\n#...\ndb = SQLAlchemy()\n\n\ndef create_app(config_name='default'):\n\t#...\n    db.init_app(app)\n    #...\n#...\n\n```\n\nInoltre, dobbiamo aggiungere alcune variabili di configurazione nel nostro file `/config.py`.\n\nModifichiamo l'oggetto `Config` come segue:\n\n```python\nclass Config:\n    SECRET_KEY = os.environ.get('SECRET_KEY') or 'stringa difficile da indovinare'\n    SQLALCHEMY_COMMIT_ON_TEARDOWN = True\n\n    @staticmethod\n    def init_app(app):\n        pass\n```\n\n`SQLALCHEMY_COMMIT_ON_TEARDOWN` abilita commit automatici del database ogni volta che gli oggetti vengono creati e modificati senza che questo venga esplicitamente forzato nel codice. Lo inseriamo nell'oggetto `Config` in modo che sia abilitato in ogni altra configurazione che creeremo.\n\nModifichiamo l'oggetto `Config` come segue:\n\n```python\nclass DevelopmentConfig(Config):\n    DEBUG = True\n    SQLALCHEMY_DATABASE_URI = os.environ.get('DEV_DATABASE_URL') or 'sqlite:///' + os.path.join(basedir, 'data-dev.sqlite')\n```\n\nIn questo modo abilitiamo la creazione del database (sqlite) di development nel file `data-dev.sqlite` all'interno della cartella in cui l'applicazione è lanciata. Sfruttiamo la variabile di ambiente `DEV_DATABASE_URL` per cambiare il percordo del db di development senza modificare il file.\n\n### Creiamo i models del nostro DB\n\nI _models_ di un database sono degli oggetti che rappresentano una table all'interno del nostro database, per ora costruiremo i due _models_ richiesti da flask-security per funzionare, cioè il model **User** e il model **Role**.\n\nCreiamo un file `blog/models.py` in cui andremo a implementare i vari models come segue\n\n```python\nfrom . import db\nfrom flask_security import UserMixin, RoleMixin\nfrom datetime import datetime\n\nroles_users = db.Table('roles_users',\n        db.Column('user_id', db.Integer(), db.ForeignKey('users.id')),\n        db.Column('role_id', db.Integer(), db.ForeignKey('roles.id')))\n\nclass Role(db.Model, RoleMixin):\n    __tablename__ = 'roles'\n    id = db.Column(db.Integer(), primary_key=True)\n    name = db.Column(db.String(80), unique=True)\n    description = db.Column(db.String(255))\n\n    def __repr__(self):\n        return \"<Role %r>\"%self.name\n\n\nclass User(db.Model, UserMixin):\n    __tablename__ = 'users'\n    id = db.Column(db.Integer, primary_key=True)\n    email = db.Column(db.String(255), unique=True, required=True)\n    password = db.Column(db.String(255))\n    active = db.Column(db.Boolean())\n    confirmed_at = db.Column(db.DateTime())\n    username = db.Column(db.String(255))\n    about = db.Column(db.Text())\n    roles = db.relationship('Role', secondary=roles_users, backref=db.backref('users', lazy='dynamic'))\n\n    def __repr__(self):\n        return \"<User %r>\"%self.email\n\n\n```\n\nIn questo modo abbiamo creato due models (**User** e **Role**) che sono collegati tra loro da una relazione _Molto a Molti_ (`roles_users`).\nIn altre parole, ogni utente può avere dei ruoli, e viceversa, ogni ruolo può essere associato a più di un utente. Abbiamo inoltre aggiunto le colonne `username` e `about` che non sono richiesti da `flask-security` ma saranno importanti per lo sviluppo del blog. Utilizzando questi due modelli, flask-security permette di gestire gli accessi al sito e anche alle singole pagine del sito stesso.\n\n> > Nota: Se stai usando Python 3, probabilmente otterrai un errore legato al campo `required=True`. Questo è dovuto al fatto che le API di SQLAlchemy sono state recentemente cambiate, e il campo `required` è stato sostituito con `nullable` (che funziona al contrario), perchè più in linea con il linguaggio sql. In questo caso, basta sostituire `required=True` con `nullable=False` per risolvere l'errore. Ringrazione l'utente **Sonak** per avermi segnalato il problema!\n\n### Configuriamo Flask-Security\n\nUna volta creati models essenziali, possiamo inizializzare flask-security in modo da poter gestire in modo semplice l'accesso alla nostra applicazione. Per fare questo, modifichiamo il file `blog/__init__.py` come segue:\n\n```python\n#...\n\nfrom flask_security import Security, SQLAlchemyUserDatastore\n#...\nsecurity = Security()\n#...\n\ndef create_app(config_name='default'):\n    #...\n    from .models import User, Role\n    user_datastore = SQLAlchemyUserDatastore(db, User, Role)\n    security.init_app(app, user_datastore)\n    #...\n```\n\nIn questo modo, abbiamo informato flask-security di utilizzare i due modelli per gestire la sicurezza del nostro blog.\n\n### Inizializzazione del DB\n\nPer poter utilizzare correttamente il blog con flask-security, è importante che esista almeno un utente attivo nel momento in cui viene lanciata l'applicazione. Per questo motivo, è essenziale automatizzare la nostra applicazione in modo da riempire il DB in fase di configurazione. Per fare questo, creeremo delle funzioni `static` all'interno dei due modelli che permettono di automatizzare il processo di inizializzazione dei ruoli e degli utenti.\n\nIn particolare, inizializzeremo il DB con due ruoli, `admin`, `publisher` e `user`. Inoltre, creeremo un utente admin con mail e password salvate dentro due variabili di configurazione `BLOG_ADMIN_MAIL` e `BLOG_ADMIN_PASSWORD`.\n\nAndiamo prima di tutto a settare le due variabili nel file `config.py` ed in particolare nell'oggetto `Config`. Come al solito, utilizzeremo le variabili di ambiente per sovrascrivere queste variabili senza necessariamente riverarle nel file.\n\n```python\nclass Config:\n    #...\n    BLOG_ADMIN_MAIL = os.environ.get('BLOG_ADMIN_MAIL') or 'admin@admin.com'\n    BLOG_ADMIN_PASSWORD = os.environ.get('BLOG_ADMIN_PASSWORD') or 'admin'\n    #...\n```\n\nA questo punto, creiamo la funzione per generare i ruoli, inserendola nell'oggetto `Role` del file `blog/models.py`\n\n```python\nclass Role(db.Model, RoleMixin):\n    #...\n    @staticmethod\n    def insert_roles():\n        for role_name in \"admin publisher user\".split():\n            if Role.query.filter_by(name=role_name).first() is None:\n                role = Role(name = role_name)\n                db.session.add(role)\n        db.session.commit()\n```\n\nLa funzione `insert_roles` controlla che ognuno dei tre ruoli esista nel db utilizzato e nel caso lo inserisce.\n\nAllo stesso modo, creiamo una funzione all'interno dell'oggetto `User` che crea l'utente amministratore.\n\n```python\nclass User(db.Model, UserMixin):\n    #...\n    @staticmethod\n    def insert_admin():\n        from flask import current_app\n        if User.query.filter_by(email=current_app.config['BLOG_ADMIN_MAIL']).first() is None:\n            user = User(\n                email=current_app.config['BLOG_ADMIN_MAIL'],\n                password=current_app.config['BLOG_ADMIN_PASSWORD'],\n                active=True)\n            user.roles.append(Role.query.filter_by(name='admin').first())\n            db.session.add(user)\n            db.session.commit()\n```\n\nNotare che accediamo all'oggetto `current_app` che mette a disposizione flask per indicare l'oggetto applicazione.\n\n## Gezione del Database con Flask-Migrate e Flask-Script\n\nAbbiamo scritto tutto il necessario per creare ed inizializzare il nostro database. A questo punto non resta altro da fare che creare fisicamente il database ed iniziare ad utilizzarlo.\n\nPer fare questo, dobbiamo utilizzare **flask-migrate** per generare i comandi per la gestione del database. Inoltre, creeremo un nostro comando personalizzato per il deploy nel database di ruoli e amministratore.\n\n### Configurazione e Utilizzo di Flask-Migrate\n\nPer utilizzare Flask-Migrate, accediamo al file `/manage.py` e modifichiamolo come segue\n\n```\n#!/usr/bin/env python\n\nfrom blog import create_app, db\nfrom flask_script import Manager\nfrom flask_migrate import Migrate, MigrateCommand\n\n#...\n\nmigrate = Migrate(app, db)\nmanager.add_command('db', MigrateCommand)\n\n#...\n```\n\nA questo punto, siamo pronti per utilizzare flask-migrate.\nPer prima cosa, dobbiamo inizializzare la cartella di gestione delle migrazioni. Questa cartella conterrà tutti gli scripts generati automaticamente da flask-migrate che tengono traccia dell'evoluzione nel tempo dei _models_ del db stesso.\n\nPer farlo, utilizziamo il comando\n\n```\n(blog)$ ./manage.py db init\n```\n\nche restituirà un output simile al seguente se tutto va bene\n\n```\n  Creating directory /Users/ludus/develop/tutorials/ludoblog/project/migrations ... done\n  Creating directory /Users/ludus/develop/tutorials/ludoblog/project/migrations/versions ... done\n  Generating /Users/ludus/develop/tutorials/ludoblog/project/migrations/alembic.ini ... done\n  Generating /Users/ludus/develop/tutorials/ludoblog/project/migrations/env.py ... done\n  Generating /Users/ludus/develop/tutorials/ludoblog/project/migrations/env.pyc ... done\n  Generating /Users/ludus/develop/tutorials/ludoblog/project/migrations/README ... done\n  Generating /Users/ludus/develop/tutorials/ludoblog/project/migrations/script.py.mako ... done\n  Please edit configuration/connection/logging settings in '/Users/ludus/develop/tutorials/ludoblog/project/migrations/alembic.ini' before proceeding.\n```\n\nA questo punto, vedrete apparire una nuova cartella chiamata `migrations/` nella cartella principale. Qui verranno contenuti tutti i file di migrazione che generemo.\n\nPer crare un file di configurazione, utilizziamo il comando\n\n```\n(blog)$ ./manage.py db migrate -m \"creazione User Role\"\n```\n\nche genererà un output simile al seguente\n\n```python\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.autogenerate.compare] Detected added table 'roles'\nINFO  [alembic.autogenerate.compare] Detected added table 'users'\nINFO  [alembic.autogenerate.compare] Detected added table 'roles_users'\n  Generating /Users/ludus/develop/tutorials/ludoblog/project/migrations/versions/fbdace17c6b3_creazione_user_role.py ... done\n```\n\nA questo punto, non ci resta che applicare la migrazione appena generata al database, usando il comando\n\n```\n(blog)$ ./manage.py db upgrade\n```\n\nIl cui output sarà\n\n```\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade  -> fbdace17c6b3, creazione User Role\n```\n\nPerfetto, addesso abbiamo creato un database (che al momento sarà vuoto). Se tutto va bene dovrebbe essere apparso un file chiama `data-dev.sqlite` nella cartella principale dell'applicazione.\n\n### Creazione di uno script di Deploy\n\nPrima di procedere, dobbiamo creare uno script che inizializzi il database, in modo da iniziare a popolarlo. Facciamo anche in modo che questo script esegua il comando `upgrade` del database in modo da non doverlo chiamare ogni volta a mano.\n\nPer farlo, modifichiamo nuovamente il file `manage.py` come segue\n\n```python\n#...\n@manager.command\ndef deploy():\n    \"\"\"Run deployment tasks.\"\"\"\n    from flask_migrate import upgrade\n    from blog.models import Role, User\n\n    print 'INFO  [deploy command] migrate database to latest revision'\n    upgrade()\n\n    print 'INFO  [deploy command] create user roles'\n    Role.insert_roles()\n\n    print 'INFO  [deploy command] create admin user'\n    User.insert_admin()\n#...\n```\n\nE potremmo quindi utilizzare il comando appena definito come segue\n\n```\n(blog)$ ./manage.py deploy\n```\n\nChe rilascerà il seguente output\n\n```\nINFO  [deploy command] migrate database to latest revision\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [deploy command] create user roles\nINFO  [deploy command] create admin user\n```\n\n## Creazione di barre di navigazione dinamiche\n\nA questo punto, il database è pronto ed inizializzato, solo che, al momento, non esistono GUI nella nostra applicazione per gestirlo e visualizzarlo.\n\nLa prima cosa (quella più semplice) per verificare se siamo loggati o no è aggiungere un nuovo elemento nella NavBar che appare solo se l'utente ha correttamente eseguito il login nell'applicazione.\n\nPer seguire lo standard di un po' tutti i siti, dobbiamo inserire questo elemento sulla destra della navbar. Purtroppo, flask-nav non gestisce nativamente gli elementi allineati a destra, ed è un po' complicato aggiungerli. Per questo motivo per il momento lasciamo questo elemento allineato sulla dinistra, e scriverò un tutorial per correggere questo problema in seguito.\n\nAndiamo quindi a modificare il file `blog/navbar.py` come segue\n\n```python\nfrom . import nav\nfrom flask_nav.elements import *\n\nfrom flask_security import current_user\n\n@nav.navigation()\ndef main_nav():\n    navbar = Navbar('Blog')\n    navbar.items.append(View('Home', 'main.index'))\n    if current_user.is_authenticated:\n        usergrp = []\n        usergrp.append(current_user.email)\n        usergrp.append(View('Logout', 'security.logout'))\n        navbar.items.append(Subgroup(*usergrp))\n    return navbar\n```\n\nA questo punto possiamo testare l'applicazione. Lanciamola e accediamo al solito link `http://127.0.0.1:5000`. Noteremo subito che niente è cambiato dall'ultima volta che abbiamo effettuato l'accesso. Infatti la navbar viene modificato solo se l'utente ha effettuato il login.\n\nAccediamo quidni all'URL `http://127.0.0.1:5000/login`. Questa è una view generata automaticamente da flask-security che permette di gestire il login. Inseriamo nome utente e password (ricordo che di default abbiamo messo `admin@admin.com` e `admin`)\n\n![Login View](./login.png)\n\nE potremmo verificare che il login è stato correttamente effettuato\n\n![Index Logged In](./loggedin.png)\n\n## Flask-SuperAdmin per la gestione del Database\n\nVerificato che il database funziona, vediamo come possiamo utilizzare un'utilissima estensione, chiamata **Flask-SuperAdmin** per la creazione di pannelli di amministrazione.\n\nPrima di tutto, installiamo l'estensione\n\n```python\n(blog)$ pip install flask-superadmin\n```\n\nÈ importante notare che Flask-SuperAdmin non è nativamente integrato con Flask-Security. Questo vuol dire che normalmente le view generate da questa estensione sono visibili a tutti, cosa che noi vogliamo certamente evitare.\n\nL'integrazione di Flask-SuperAdmin con Flask-Security da me trovata al momento è un po' macchinosa.\n\nPer prima cosa, è necessario creare un nuovo file, chiamato `blog/adminviews.py` e insere il seguente codice all'interno\n\n```python\nfrom flask_superadmin import AdminIndexView as _AdminIndexView\nfrom flask_superadmin.model import ModelAdmin as _ModelAdmin\nfrom flask_security import current_user\nfrom flask import abort\n\nclass ModelAdmin(_ModelAdmin):\n    def is_accessible(self):\n        return current_user.has_role('admin'):\n\n    def _handle_view(self, name, *args, **kwargs):\n        if not self.is_accessible():\n            abort(403)\n\n\nclass AdminIndexView(_AdminIndexView):\n    @expose('/')\n    def index(self):\n        if not current_user.has_role('admin'):\n            abort(403)\n        return super(AdminIndexView, self).index()\n```\n\nIn questo modo estendiamo gli oggetti che gestiscono normalmente le view di Admin e gli diciamo di lasciare passare solo gli utenti che hanno il ruolo di amministratore.\n\nAdesso possiamo configurare il modulo. Apriamo il file `blog/__init__.py` e modifichiamolo come segue\n\n```python\n#...\nfrom flask_superadmin import Admin\n#...\nfrom .adminviews import ModelAdmin, AdminIndexView\nadmin=Admin(index_view=AdminIndexView())\n\ndef create_app(config_name='default'):\n    #...\n    admin.init_app(app)\n    #...\n\n    from .models import User, Role\n    #...\n    admin.register(User, admin_class=ModelAdmin, session=db.session)\n    admin.register(Role, admin_class=ModelAdmin, session=db.session)\n    #...\n#...\n```\n\nCome ultimo aggiustamente, facciamo in modo che, se l'utente attuale è anche un amministratore, appaia la view admin nella sua navbar, modificando il file `blog/navbar.py` come segue\n\n```python\n#...\n@nav.navigation()\ndef main_nav():\n    #...\n    if current_user.is_authenticated:\n        #...\n        if current_user.has_role('admin'):\n            usergrp.append(View('Admin', 'admin.index'))\n        #...\n    return navbar\n```\n\nA questo punto possiamo testare l'app.\nDopo aver fatto il login, vedremo apparire un nuovo tab nel tab navbar relativa al nostro account\n\n![Admin Tag Navbar](./adminnav.png)\n\nChe rimanda al link di Amministrazione da cui possiamo modificare aggiungere ed eliminare elementi del database.\n\n![Admin View](./adminview.png)\n\nSi noti che se proviamo ad accedere al link o sottolink senza aver fatto correttamente il login `http://127.0.0.1:5000/admin` otterremo l'errore di accesso negato.\n![Accesso Negato](./accessonegato.png)\n\n### GitHub parte 3\n\nTrovate la repo aggiornata con tutto il lavoro svolto finora al [link](https://github.com/ludusrusso/ludoblog/tree/p3).\n\n# 4. Creazione dei Post\n\nPerfetto, la nostra app adesso ha un database, gestisce gli accessi ed ha una sua veste grafica (non completa, ma direi accettabile).\nSiamo pronti, finalmente, per arrivare al nocciolo dell'applicazione: un sistema per la creazione di contenuti: i **Post**.\n\nCosa fare quindi? Andremo ad aggiungere una nuova **Table** al nostro bellissimo database che conterrà i Post della nostra applicazione. Inoltre, creeremo un semplice webform per la creazione e la modifica dei post! Come al solito, facciamo le cose per step: creiamo il minimo indispensabile per far funzionare il nostro blog, e poi andremo a complicarlo a piacere :D!\n\n## Post nel database\n\nCome dice il titolo stesso, andiamo a prendere il nostro database e creiamo una nuova Table chiamata **Post**. Per farlo, aggiungiamo il seguente oggetto al file `blog/models.py`\n\n```python\nclass Post(db.Model):\n    __tablename__ = 'posts'\n    id = db.Column(db.Integer, primary_key=True)\n    title = db.Column(db.String(255), unique=True)\n    body = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, index=True, default=datetime.utcnow)\n    last_edit = db.Column(db.DateTime, index=True, onupdate=datetime.utcnow)\n```\n\nVediamo nel dettaglio la table creato:\n\n- `id` è un numero che identifica univocamente ogni istanza dell'oggetto all'interno della Table **Post**.\n- `title` è una stringa contenente il titolo del post.\n- `body` contiene il testo del post.\n- `created_at` e `last_edit` contengono invece (rispettivamente) la data di creazione e l'ultima data di modifica del post. Notare che l'unica cosa che cambia sono gli argomenti `default` e `onupdate`. Il primo informa di settare la variabile al valore ritornato dalla funzione nel momento in cui viene inserita per la prima volta nel database. Il secondo funziona allo stesso modo ma viene aggiornata ogni volta che la colonna è modificata nel database.\n\n### User Post Relationship\n\nVogliamo che i post vengano associati all'account dell'utente che effettivamente li crea, per questo motivo è importante creare una _relationship_ uno a molti tra le Table **User** e **Post**. Per farlo, modifichiamo i due oggetti come segue:\n\n```python\n\nclass User(db.Model, UserMixin):\n    #...\n    posts = db.relationship('Post', backref='author', lazy='dynamic')\n\n\nclass Post(db.Model):\n\t#...\n\tauthor_id = db.Column(db.Integer, db.ForeignKey('users.id'))\n```\n\nIn questo modo, informiamo il sistema di creare un collegameto tra le due tabelle, in partcolare, ogni utente avrà a disposizione una lista post a di cui è autore, mentre ogni post avrà associato la colonna del proprio autore.\n\nOk, abbiamo una configurazione minima per poter utilizzare i post. Ricordiamoci ora di fare una migrazione del nostro database in modo da includere le modifiche effettuate. Per fare cioè, utilizziamo i comandi visti precedentemente.\n\n```\n(blog)$ ./manage.py db migrate -m \"add posts\"\n(blog)$ ./manage.py db upgrade\n```\n\n## Rendering del post\n\nPer visualizzare il post, dobbiamo creare una pagina html da renderizzare con le informazioni in esso contenuto e una pagina html per l'inserimento (tramite form) dei contenuti.\n\n### Flask-Misaka e Flask-WTF\n\nPer far si che l'utente possa scrivere testi con sintassi ricca in modo semplice e veloce, utilizzeremo il linguaggio di markup [markdown](https://it.wikipedia.org/wiki/Markdown) per renderizzare le pagine. Markdown è un semplicissimo linguaggio che utilizzo tantissimo nella mia produttività (anche questo testo è scritto in markdown).\nPer far questo, abbiamo bisogno di un'estensione di flask chiamata _flask-misaka_, che include un engine di rendering markdown molto semplice da utilizzare.\n\nPer creare il form, ci viene in aiuto un secondo pacchetto noto come`flask-wtf`, nato appunto per la creazione dei form in Flask.\n\nInstalliamo i due pacchetti con il comando `pip`\n\n```\n(blog)$ pip install flask-misaka flask-wtf\n```\n\ne includiamola nel file `blog/__init__.py`\n\n```python\n#...\nfrom flask_misaka import Misaka\n#...\nmarkdown = Misaka()\n#...\n\ndef create_app(config_name='default'):\n    #...\n    markdown.init_app(app)\n    #...\n#...\n```\n\nSi noti che **flask-wtf** è già incluso all'interno di altre librerie che utilizziamo, come flask-security e flask-admin, inoltre, esso non richiede una configurazione esplicita quando si costruisce l'applicazione.\n\n### Form\n\nPer creare il form, definiamolo prima di tutto creando un nuovo file `blog/main/forms.py` ed implementando il seguente codice\n\n```python\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, TextAreaField, SubmitField\nfrom wtforms.validators import DataRequired\n\nclass EditBlogPostForm(FlaskForm):\n    title = StringField('Titolo',validators=[DataRequired()])\n    body = TextAreaField('Testo', validators=[DataRequired()])\n    submit = SubmitField('Ok')\n```\n\nIn questo modo, abbiamo definito un form contenente due aree di testo per il titolo e il testo del post, più un pulsante per sottomettere il tutto.\n\n### View per creare e visualizzare i post.\n\nPer creare la pagina CSS per la renderizzazione del post, andiamo ad implementare in un nuovo file html `blog/main/templates/main/post.html` il seguente codice\n\n```html\n{% extends \"main/base.html\" %} {% block title %}{{post.title}}{% endblock %} {%\nblock styles %} {{super()}}\n\n<style media=\"screen\">\n  .post-body img {\n    max-width: 100%;\n  }\n</style>\n{% endblock %} {% block page_content %}\n\n<div class=\"page-header\">\n  <h1>{{ post.title }}</h1>\n  <p>\n    Autore <span class=\"label label-primary\">{{post.author}}</span> Data\n    <span class=\"label label-info\">{{post.created_at.date()}}</span>\n  </p>\n</div>\n\n<div class=\"post-body\">{{ post.body|markdown }}</div>\n{% endblock %}\n```\n\nSi noti la linea di codice `{{ post.body|markdown }}` che appunto informa di renderizzare con sintassi markdown la stringa contenuta dentro `post.body`.\nSi noti inoltre che aggiungo lo stile CSS `max-width: 100%;` per le immagini, in modo da evitare che immagini troppo grosse vengano renderizzate più grandi della pagina stessa, creando un effetto grafico molto fastidioso!\n\nLa pagina che mostrerà il Form per la creazione del post, invece, andrà implementata nel file `blog/main/templates/main/edit_post.html`. Ecco il codice da inserire.\n\n```html\n{% extends \"main/base.html\" %} {% import \"bootstrap/wtf.html\" as wtf %} {% block\ntitle %}Edit Post{% endblock %} {% block page_content %}\n<div class=\"post-body\">{{ wtf.quick_form(form) }}</div>\n{% endblock %}\n```\n\nFortunatamente, in questo caso, ci viene in contro flask-bootstrap che ha già a disposizione un sistema per renderizzare automaticamente il form.\n\nUna volta realizzati i due html, siamo pronti ad implementare il codice python per renderizzare le view.\n\nApriamo il file `blog/main/view.py` e implementiamo le seguenti view per la visualizzazione e la creazione dei post!\n\n```\nfrom . import main\nfrom flask import render_template, abort, redirect, url_for\n\nfrom flask_security import current_user, roles_accepted\nfrom ..models import Post\nfrom .forms import EditBlogPostForm\nfrom .. import db\n\n# ...\n\n@main.route('/posts/id/<int:id>')\ndef post(id):\n    post = Post.query.get_or_404(id)\n    return render_template('main/post.html', post=post)\n\n@main.route('/posts/new', methods=['post', 'get'])\n@roles_accepted('admin', 'publisher')\ndef get_post():\n    form = EditBlogPostForm()\n    if form.validate_on_submit():\n        post = Post(title=form.title.data, \\\n                    body=form.body.data)\n        post.author = current_user\n        try:\n            db.session.add(post)\n            db.session.commit()\n            return redirect(url_for('main.post', id=post.id))\n        except:\n            abort(500)\n    return render_template('main/edit_post.html', form=form)\n```\n\nSpieghiamo brevemente le parti più importanti del codice:\n\n- la stringa `post = Post.query.get_or_404(id)` permette di ritrovare nel database l'oggetto `Post` con il valore `id` specificato, e genera automaticamente l'errore `404` (non trovato) nel caso in cui l'oggetto non esista nel database. Attenzione però, `get_or_404` accetta solamente la primary key di una table!\n\n- `form.validate_on_submit()` permette di capire se l'utente ha solo aperto la pagina (con una `get` request) o ha effettuato una `post` request sul form. Nel primo caso, la view deve semplicemente renderizzare la pagina, nel secondo caso, dobbiamo creare un nuovo oggetto `Post` nel database e riempirlo!\n\n## Testiamo l'app\n\nA questo punto, è tutto pronto per provare la nostra applicazione. Lanciamo l'app e colleghiamoci al solito url `http://127.0.0.1:5000`. Ricordiamoci di fare il login se non siamo ancora entrati, e a quel punto, accedendo all'url `http://127.0.0.1:5000/posts/new` e compiliamo il form che abbiamo creato.\n\n![Form view](./post_edit.png)\n\nUna volta premuto il tasto _Submit_, verremo rimandati all'url di visualizzazione del post creato, che si chiamerà `http://127.0.0.1:5000/posts/id/1`.\n\n![Post view](./post_view.png)\n\n## Conclusioni\n\nFinalmente la nostra applicazioni inizia a funzionare, adesso possiamo creare e visualizzare post, ed è ormai piccolo il lavoro da fare per raggiungere l'obiettivo. Nel prossimo tutorial ci occuperemo di rendere più semplice l'utilizzo della nostra applicazione, a partire dalla navbar fino alla visualizzazione e navigazione nei post!\n\nCome al solito, trovate il codice implementato su Github, a [questo link](https://github.com/ludusrusso/ludoblog/tree/p4).\n\n# 5. Navigazione\n\nIl nostro blog inizia a prendere forma, al momento siamo in grado di\ncreare nuovi post e visualizzarli, ma ancora l'utente non è semplificato\nnella navigazione del sito. Ed è quello che andremo a migliorare in questo\ntutorial.\n\nDi seguito quindi miglioreremo il nostro prototipo di barra di navigazione in modo da rendere migliore la navigazione del sito sia per i lettori che per gli utenti abilitati\ncome amministratore.\n\n### NavBar: aggiungere elementi a destra\n\nSfortunatamente, l'estensione Flask-Nav che abbiamo usato in questo tutorial non permette di default di creare elementi sulla parte destra della barra di navigazione.\nPer questo motivo, dovremmo andare ad implementare un nuovo elemento custom che fa questo lavoro per noi. Una volta implementato, potremmo visualizzare il menù\nutente (o il pulsante login) sulla parte destra della navbar, cosa comune nella\nmaggior parte delle webapp!\n\n#### Creazione di Renderer Custom\n\nPer far questo, purtroppo bisogna addentrarci nel codice di Flask-Nav e Flask-Bootstrap,\ne le cose si complicano un pochettino.\n\nNon è questo il momento di discutere nel dettaglio delle scelte fatte, ma vorrei dare\nalmeno un'idea a grandi linee di cosa succede prima di vedere il codice. Flask-Nav definisce due\noggetti molto diversi tra loro: l'oggetto `NavBar` e l'oggetto `Renderer`. Il primo\ndescrive la struttura della navbar, mentre il secondo descrive il modo in cui questo\ndeve essere visualizzato all'interno della pagina web.\n\nIl pacchetto Flask-Bootstrap definisce un oggetto `BootstrapRenderer`, che è l'oggetto\nche si occupa di disegnare la navbar. Attualmente, `BootstrapRenderer` non prevede elementi a\ndestra. Ed è questo renderer che dobbiamo modificare per aggiungere questa funzione.\n\nPer far questo, andremo a creare un nuovo renderer come discendente di `BootstrapRenderer`.\nL'unica differenza tra il nostro oggetto e l'oggetto originale sarà nel fatto che il primo\ncontrolla la presenza dell'attributo `right` di ogni elemento della navbar, e, se presente, aggiunge questo\nelemento sulla destra invece che sulla sinistra.\n\nApriamo il file `blog/navbar.py` e aggiungiamo questo codice alla fine del file\n\n```python\nclass RightRenderer(BootstrapRenderer):\n    def visit_Navbar(self, node):\n        node_id = self.id or sha1(str(id(node)).encode()).hexdigest()\n\n        root = tags.nav() if self.html5 else tags.div(role='navigation')\n\n        if hasattr(node, '_class'):\n            root['class'] = node._class\n        else:\n            root['class'] = 'navbar navbar-default'\n\n        cont = root.add(tags.div(_class='container-fluid'))\n\n        header = cont.add(tags.div(_class='navbar-header'))\n        btn = header.add(tags.button())\n        btn['type'] = 'button'\n        btn['class'] = 'navbar-toggle collapsed'\n        btn['data-toggle'] = 'collapse'\n        btn['data-target'] = '#' + node_id\n        btn['aria-expanded'] = 'false'\n        btn['aria-controls'] = 'navbar'\n\n        btn.add(tags.span('Toggle navigation', _class='sr-only'))\n        btn.add(tags.span(_class='icon-bar'))\n        btn.add(tags.span(_class='icon-bar'))\n        btn.add(tags.span(_class='icon-bar'))\n\n        if node.title is not None:\n            if hasattr(node.title, 'get_url'):\n                header.add(tags.a(node.title.text, _class='navbar-brand',\n                                  href=node.title.get_url()))\n            elif hasattr(node.title, 'image'):\n                header.add(tags.span(tags.img(_src=node.title.image, _class='brand-img'), _class='navbar-brand'))\n            else:\n                header.add(tags.span(node.title, _class='navbar-brand'))\n\n        bar = cont.add(tags.div(\n            _class='navbar-collapse collapse',\n            id=node_id,\n        ))\n        bar_list = bar.add(tags.ul(_class='nav navbar-nav'))\n        bar_list_right = bar.add(tags.ul(_class='nav navbar-nav navbar-right'))\n\n        for item in node.items:\n            if hasattr(item, 'right'):\n                bar_list_right.add(self.visit(item))\n            else:\n                bar_list.add(self.visit(item))\n        return root\n```\n\nNonostante questo codice sembri molto complicato, la parte che ho veramente scritto io sono le ultime 8 righe (il resto deriva da `BootstrapRenderer` originale).\n\n```python\n        bar_list = bar.add(tags.ul(_class='nav navbar-nav'))\n        bar_list_right = bar.add(tags.ul(_class='nav navbar-nav navbar-right'))\n\n        for item in node.items:\n            if hasattr(item, 'right'):\n                bar_list_right.add(self.visit(item))\n            else:\n                bar_list.add(self.visit(item))\n```\n\nIn particolare, il codice crea due oggetti chiamati `bar_list` e `bar_list_right`:\n\n- `bar_list` è l'oggetto originale, gestisce la lista di elementi nella navbar ed ha classe css `nav navbar-nav`\n- `bar_list_right` è una nuova lista contenente tutti gli oggetti che vanno posizionati a destra, ed infatti ha classe `nav navbar-nav navbar-right`.\n\nSuccessivamente, all'interno del `for`, ogni elemento da posizionare viene inserito all'interno di una delle due liste. La discriminante è la presenza di un attributo `right` dell'elemento: non è importante il valore, se l'attributo è stato definito allora l'oggetto è posizionato a destra, altrimenti a sinistra.\n\nSi noti che, per far funzionare questo elemento, dobbiamo aggiungere i seguenti import all'interno del file:\n\n```python\nfrom flask_bootstrap.nav import BootstrapRenderer\n\nfrom hashlib import sha1\nfrom dominate import tags\nfrom visitor import Visitor\n```\n\n#### Utilizzo del Renderer\n\nA questo punto, possiamo aggiornare la navbar come segue, settando l'attributo `grp.right = True` al `Subgroup` prima di aggiungerlo alla navbar.\nOltre a questo, nel codice sottostante ho aggiunto il pulsante `Login` nel caso l'utente noi sia attivo. Questo viene visualizzato comunque sulla destra.\n\n```python\n@nav.navigation()\ndef main_nav():\n    navbar = Navbar('Blog')\n    navbar.items.append(View('Home', 'main.index'))\n    if current_user.is_authenticated:\n        usergrp = []\n        usergrp.append(current_user.email)\n        if current_user.has_role('admin'):\n            usergrp.append(View('Admin', 'admin.index'))\n        usergrp.append(View('Logout', 'security.logout'))\n        grp = Subgroup(*usergrp)\n        grp.right = True\n        navbar.items.append(grp)\n     else:\n        login_view = View('Login', 'security.login')\n        login_view.right = True\n        navbar.items.append(login_view)\n    return navbar\n```\n\n#### Registrazione del Renderer\n\nPer far funzionare il nostro nuovo renderer, dobbiamo registrarlo e informare `flask_nav` di utilizzare il renderer sviluppato da noi invece che quello di default.\n\nLa registrazione serve a Flask-Nav per sapere che il nuovo renderer è disponibile. Per farla, apriamo il file `blog/__init__.py` e importiamo la funzione `register_renderer` da `flask_nav`, modificando la riga `from flask_nav import Nav` come segue:\n\n```python\nfrom flask_nav import Nav, register_renderer\n```\n\nA questo punto, all'interno della funzione `create_app`, aggiungiamo le seguenti righe di codice (prima del `return`):\n\n```python\ndef create_app():\n\t# ...\n    from .navbar import main_nav, RightRenderer\n    register_renderer(app, 'right_rendered', RightRenderer)\n\t# ...\n```\n\n#### Utilizzo del Renderer\n\nUna volta registrato il renderer, non ci resta che utilizzarlo. Questo viene fatto nel momento in cui utilizziamo la navbar all'interno del file `blog/main/templates/main/base.html`, modificando la linea\n\n```html\n{{nav.main_nav.render()}}\n```\n\nin questa:\n\n```html\n{{nav.main_nav.render(renderer='right_rendered')}}\n```\n\nIn questo modo, forziamo **flask-nav** a usare `right_rendered` (il nome del renderer registrato in precedenza) per generare la navbar.\n\nA questo punto, lanciando l'applicazione, il risutato sarà questo\n\n![NavBar a destra](./navright.png)\n\n### Conclusioni\n\nLa NavBar è finalmente pronta e funzionante. Nel prossimo tutorial ci dedicheremo alla navigazione attraverso i post.\n\nCome sempre, trovate tutto su github. In partciolare, le modifiche implementate in questo tutorial sono disponibili [qui](https://github.com/ludusrusso/ludoblog/tree/p5).\n\n## 6. Gestione dei Post\n\nSistemata la barra di navigazione, vediamo come semplificare la navigazione vera e propria agli utenti del blog, sviluppando una pagina che visualizza un'anteprima dei _post più recenti_ e rimanda (tramite link) alla pagina di ogniuno di questi post.\n\n### Lista dei post recenti\n\nLa lista dei post recenti non è nient'altro che una pagina che mostra le anteprime degli ultimi N (da definire) post pubblicati nel blog. Ad ogni post dovrà essere associato il link rimandante al post completo, alcune informazioni generali del post e un'anteprima del post stesso.\n\n#### Funzioni `url` e `preview`\n\nPer migliorare la progettazione, implementiamo due metodi di supporto all'interno della classe `Post` che definisce il nostro modello nel database:\n\n- il metodo `url()` ritornerà una stringa contenente il link che rimanda al post in questione;\n- il metodo `preview(nlines)` ritornerà le prime `nlines` righe del nostro post.\n\nApriamo quindi il file `models.py` e aggiungiamo le due funzioni alla classe `Post`\n\n```python\nclass Post(db.Model):\n    #...\n\n    def url(self):\n        return '/posts/id/' + str(self.id)\n\n    def preview(self, nlines=5):\n        return '\\n'.join(self.body.split('\\n')[:nlines])\n```\n\nLa funzione `url()` semplicemente ritorna una stringa nella forma `/posts/id/<id>`, che sappiamo essere l'url unico a cui è associato ogni post.\n\nLa funzione `preview()` è più complicata. Essenzialmente questa utilizza il metodo `split` per separare la stringa `body` in un vettore di stringhe contenente le righe della stringa di partenza (`self.body.split('\\n')`), dopo di che, seleziona le prime `nlines` righe (`[:nlines]`) e reimpacchetta le stringhe selezionate utilizzando il metodo `'\\n'.join()`.\n\nPer chi avesse problemi a leggere il codice, riporto sotto una versione estesa della funzione `preview()` (sia chiaro che preferisco sempre scrivere codice impacchettato):\n\n```\n    def preview(self, nlines=5):\n        lines = self.body.split('\\n')\n        preview_lines = lines[:nlines]\n        preview = '\\n'.join(preview_lines)\n        return preview\n```\n\n#### Template posts\n\nUna volta implementate le due funzioni, possiamo passare a sviluppare la pagina `posts.html`, che conterrà al suo interno una preview dei post più recenti del nostro blog.\n\nCreiamo quindi un file `main/templates/main/posts.html` e apriamolo per iniziare a sviluppare la pagina.\n\nPer prima cosa, sviluppiamo lo scheletro della pagina inserendo il seguente codice\n\n```html\n{% extends \"main/base.html\" %} {% block title %} Posts {% endblock %} {% block\nstyles %} {{super()}}\n\n<style media=\"screen\">\n  .post-body img {\n    max-width: 100%;\n  }\n</style>\n\n{% endblock %} {% block page_content %} ... {% endblock %}\n```\n\nEssenzialmente, questo codice estende il template `main/base.html` come tutte le pagine che andremo a sviluppare, implementa un semplice stile css per far diventare _responsive_ le immagini che inseriremo nell'anteprima.\n\nA questo punto, possiamo iniziare ad implementare il blocco `page_content`, il vero core della pagina `/posts`. All'interno di questo blocco, dovremmo implementare un ciclo `for` sulla lista `posts` (che passeremo da funzione al template). Per ogni `post` nella lista, inseriremo il titolo del post con un link alla pagina, l'anteprima del post, alcune informazioni come autore, data di pubblicazione, ecc... e un link **continua a leggere...** alla fine dell'anteprima.\n\nPer generare il link e l'anteprima, utilizzeremo le funzioni `url()` e `preview()` precedentemente realizzate.\n\n```html\n{% block page_content %} {% for post in posts %}\n<div class=\"post\">\n  <div class=\"page-header\">\n    <a href=\"{{post.url()}}\"> <h1>{{ post.title }}</h1></a>\n    Autore <span class=\"label label-primary\">{{post.author}}</span> Data\n    <span class=\"label label-info\">{{post.created_at.date()}}</span>\n  </div>\n  <div class=\"post-body\">{{ post.preview(10) | markdown }}</div>\n  <a href=\"{{post.url()}}\"> Continua a leggere ...</a>\n</div>\n{% endfor %} {% endblock %}\n```\n\nNotare che genero un'anteprima di 10 righe per ogni post.\n\n#### Usiamo il template\n\nUna volta pronto, possiamo finalmente utlizzare il template e linkarlo, tramite flask, alla pagina `/blog/posts` per iniziare ad utlizzarlo.\n\nApriamo quindi il file `blog/main/views.py` e creiamo una nuova funzione `posts` che risponde al route `/blog/posts`. Questa funzione deve generare una lista `posts` contenente la lista degli ultimi N post e passarla al template.\n\n```python\n@main.route('/posts')\ndef posts():\n    posts = # ...\n    return render_template('main/posts.html', posts=posts)\n```\n\nPer generare la lista `posts`, dobbiamo effettuare una query su Posts in modo da:\n\n1. Chiedere tutti i post nel database.\n2. Ordinarli secondo il campo `created_at` in ordine decrescente.\n3. Filtrare i primi N post.\n\nPer farlo, possiamo usare le funzioni `order_by`, per ordinare la query e `paginate`:\n\n- `order_by` prende in input il campo e l'ordine (crescente o decrescente) secondo il quale si vuole ordinare il campo (in questo caso `Post.created_at.desc()`).\n- `paginate` è una funzione più generale che aiuta a paginare una lista, cioè dividerla in sottoliste di N elementi ciascuna (pagine). Prende in input tre parametri:\n  - il numero di pagina (in questo caso deve essere 1, in quanto a noi interessano i primi N elementi, cioè la prima pagina).\n  - il numero di elementi per pagina, che, per scelta, ho deciso di inserire all'interno dei parametri di configurazione dell'app: `current_app.config['PAGE_ELEM_NUMBER']` (che è il nostro N).\n  - un booleano che, se `True`, genera automaticamente l'errore 404 se la pagina richiesta non estite (ad esempio, se chiediamo la quinta pagina di una lista di 3 pagine).\n\nLa variabile `posts`, quindi, è generata come segue:\n\n```python\nposts = Post.query.order_by(Post.created_at.desc()).paginate(1, current_app.config['PAGE_ELEM_NUMBER'], True).items\n```\n\nSi noti che, per far funzionare il codice, dobbiamo importare da `flask` l'oggetto `current_app`, per accedere alla configurazione dell'applicazione, aggiungendo l'oggetto `current_app` all'import dal modulo `flask` all'inizio del file.\n\n```python\nfrom flask import ..., current_app\n```\n\nInoltre, all'interno del file `config.py`, dobbiamo definire il valore di `PAGE_ELEM_NUMBER`:\n\n```python\nclass Config:\n    # ...\n    PAGE_ELEM_NUMBER = 5\n```\n\nPer concludere, generiamo un nuovo bottone sulla barra di navigazione che rimanda direttamente all'url dei post.\nApriamo quindi il file `blog/nav_bar.py` e modifichiamo la funzione `main_nav()` come segue:\n\n```python\n@nav.navigation()\ndef main_nav():\n    navbar = Navbar('Blog')\n    navbar.items.append(View('Home', 'main.index'))\n    navbar.items.append(View('Posts', 'main.posts'))\n    #...\n    return navbar\n```\n\nLanciamo il server, creiamo alcuni post (almeno 5). Il risultato (dell'URL `/posts`) dovrebbe essere come segue.\n\n![Gestione pagine](./gestionepost.png)\n\nVedrete che ogni anteprima avrà il link al post completo, sia tramite titolo in alto che tramite link _Continua a leggere ..._ (in blu).\n\n### Piccoli aggiustamenti\n\nA questo punto, è doveroso riprendere la nostra applicazione ed implementare alcune piccole migliorie per renderla più efficace.\n\n#### Nome dell'autore del post\n\nCome vedete, il mode dell'autore dei post non viene rapprensentato in modo _User Friendly_, ma con una stringa del tipo `<User u'admin@admin.com'>`.\n\nQuesto succede perchè, non avendo alternative, python usa il metodo `__repr__` della classe `User` per generare una stringa a partire dall'oggetto in questione. Noi abbiamo definito `__repr__` come segue:\n\n```python\nclass User(db.Model, UserMixin):\n    #...\n    def __repr__(self):\n        return \"<User %r>\"%self.email\n```\n\nLa funzione `__repr__`, infatti, è pensata per generare una stringa a partire da un oggetto che serva per una rappresentazione per gli sviluppatori. Python richiede anche di implementare una secondo metodo, chiamata `__str__`, che viene utilizzata per generare una stringa per rappresentare genericamente l'oggetto.\n\nImplementiamo questa funzione in modo che ritorni lo username dell'utente (modificando il file `blog/models.py`):\n\n```python\nclass User(db.Model, UserMixin):\n    def __str__(self):\n        return \"%s\"%self.username\n```\n\nNoterete subito che il nome dell'autore di ogni post viene finalmente visualizzato in modo più user friendly.\n\n![Nome autore](./nomeautore.png)\n\n#### Inseriamo la Table `Post` all'interno di Admin\n\nQuando abbiamo aggiunto la Table `Post` nel database, ho dimenticato di inserirla nella view amministrazione. Per farlo, semplicemente modifichiamo il file `blog/__init__.py` come segue:\n\n```python\n#...\n\ndef create_app():\n    #...\n    from .models import User, Role, Post\n    #...\n    admin.register(Post, admin_class=ModelAdmin, session=db.session)\n    #...\n\n```\n\n### Conclusioni\n\nCome sempre, tutto il codice implementato in questo tutorial è disponibile su [github](https://github.com/ludusrusso/ludoblog/tree/p6).\n\n## 7. Incorporare JavaScript in Flask\n\nOrmai il blog ha preso forma ed è finalmente funzionante. Ci sono tantissime funzionalità che mi interessa implementare sul blog, ma siccome mi è stato chiesto aiuto sull'utilizzo di codice CSS e JavaScript in Flask, dedico questa settimana parte allo sviluppo di una pagina che include JavaScript al suo interno.\n\nL'idea è di sviluppare una pagina iniziale per il nostro blog bella da vedere, lavorando un po' con i CSS e gestendo delle animazioni utlizzando JavaScript, ed in particolare la libreria [Typed JS](http://www.mattboldt.com/demos/typed-js/), che permette di creare elementi testuali animati con effetto di inserimento di testo da tastiera.\n\nMa partiamo subito a sviluppare la pagina!\n\n### Cartella Static\n\n_Flask_ permette la definizione di una cartella `static/` in cui inserire tutti i file statici da inviare al sito internet. Per file statici si intendono tutti i file che non sono templetizzati, principalmente immagini, stili `.css` e script `.js`.\n\nCreiamo quindi una cartella `blog/static/` e, al suo interno, creiamo altre 4 cartelle, chiamate `img/` (in cui inserire le immaigni), `css/` (in cui inserire tutti i file `.css`), `js/` (in cui inserire i gli script `.js`), ed `external/` (in cui inserire file provieniente da terze parti).\n\n### Creazione di una homepage con immagine di background\n\nPer prima cosa, occupiamoci di dare uno stile più bello alla nostra homepage, che al momento è stata lasciata vuota.\n\nPer farlo, iniziamo a scegliere un'immagine di copertina, che andremo ad inserire come copertina di homepage. Chiamiamo questa immagine con un nome semplice (io ho scelto `bg.jpg`) e salviamola nella cartella `blog/static/img/`.\n\nA questo punto, occupiamoci della homepage. Apriamo il file `blog/main/templates/main/index.html` e rimpiazziamo l'intero codice al suo interno con il seguente\n\n```html\n{% extends \"main/base.html\" %} {% block content %}\n\n<div class=\"jumbotron cover\">\n  <div class=\"container\"></div>\n</div>\n\n<footer>\n  <hr />\n  <div class=\"container\">\n    <div class=\"row\">\n      <div class=\"col-lg-12\">Progettato da Me</div>\n    </div>\n  </div>\n</footer>\n\n{% endblock %}\n```\n\nCome vedete, in questo caso non abbiamo più usato il blocco `page_content`, ma direttamente il blocco `content`. In questo modo, sovrascriviamo parte del template `main/base.html`. Ciò ci costringe a dover riscrivere parte del codice (come ad esempio il footer), ma ci da più libertà di movimento, perchè, come ricorderete, il blocco `page_content` viene renderizzato già all'interno di una row di un container.\n\nCome potete vedere, il corpo della nostra pagina è una div (con classe `jumbotron cover`) completamente vuota. Andiamo a definire uno stile **css** per questa div in modo da inserire all'interno un'immagine di blackground. Per farlo, creiamo un file `blog/static/css/index.css` con il seguente codice all'interno:\n\n```css\n.navbar-default {\n  margin-bottom: 0px;\n}\n\n.cover {\n  width: 100%;\n  height: 500px;\n  background-image: url(\"/static/img/bg.jpg\");\n  background-repeat: no-repeat;\n  background-size: cover;\n  background-position: center;\n  position: relative;\n}\n```\n\nIl file contiene due stili. Il primo `.navbar-default` toglie il margine inferiore alla navbar, in modo da evitare di avere uno spazio tra la navbar stessa e la foto di copertina (che secondo me è brutto da vedere).\n\nIl secondo, ridefinisce la classe `cover`, in modo imporgli dimensioni fisse ed un'immagine di background, che (come si può leggere), viene presa dal file `/static/img/bg.jpg`.\n\nUna volta definito questo file, bisogna importarlo all'interno del template `index.html`. Per far questo, `flask_bootstrap` mette a disposizione un blocco chiamato `styles`, pensato proprio per inserire tutti gli stili del documento.\n\nRitoriamo al file `blog/main/templates/main/index.html` e aggiungiamo il seguete codice alla fine del file stesso:\n\n```html\n{% block styles %} {{ super() }}\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/static/css/index.css\" />\n{% endblock %}\n```\n\nCome vedete, in questo blocco, prima di importare effettivamente il file `index.css` appena creato, abbiamo usato la direttiva `{{ super() }}`, che renderizza il blocco `styles` del template che stiamo estendendo (cioè `main/base.html`), prima di aggiungere la riga `<link rel=\"stylesheet\" type=\"text/css\" href=\"/static/css/index.css\">`. Questo è importante perchè il template `main/base.html` estende a sua volta il template `bootstrap/base.html`, che al suo interno importa gli stili di bootstrap. Se volete capire meglio, provate semplicemente a rimuovere la riga `{{ super() }}` e aprire la pagina.\n\nUna volta completato il codice e lanciato il server, il risultato sarà simile a questo:\n\n![immagine copertina](./cover.png)\n\n### Testo sull'immagine\n\nA questo punto, possiamo pensare di inserire del testo sovrapposto all'immagine. Per farlo, basta aggiungere degli elementi html all'interno della div principale del file `blog/main/templates/main/index.html`:\n\n```html\n<div class=\"jumbotron cover\">\n  <div class=\"container\">\n    <div class=\"row\">\n      <div class=\"col-md-12\">\n        <h1>Ludovico Russo</h1>\n        <h2>Sono un roker!</h2>\n      </div>\n    </div>\n  </div>\n</div>\n```\n\nChe predurrà un risultato certamente non bello da vedere\n\n![immagine copertina testo](./cover_text.png)\n\nE' quindi necessario apportare alcuni cambiamenti allo stile `css` per migliorare la grafica. Ad esempio, possiamo creare un backgroud nero in trasparenza e cambiare il colore del testo in bianco. Per farlo, basta modificare lo stile `/static/css/index.css` come segue:\n\n```css\n/* ... */\n.cover {\n  width: 100%;\n  height: 500px;\n  background-image: linear-gradient(rgba(0, 0, 0, 0.2), rgba(0, 0, 0, 0.6)),\n    url(\"/static/img/bg.jpg\");\n  color: white;\n  background-repeat: no-repeat;\n  background-size: cover;\n  background-position: center;\n  position: relative;\n}\n```\n\nrenderndo il risultato più soddisfacente.\n\n![immagine copertina testo con css](./cover_text_css.png)\n\n### Animazioni con Typed.js\n\nA questo punto, proviamo ad inserire del codice JavaScript per aggiungere delle semplicini animazioni alla pagina. In particolare, voglio che il testo dopo **Sono un** cambi dinamicamente come qualcuno stesse digitando del testo da tastiera. Per fortuna, ci aiuta la libreria JavaScript [Typed JS](http://www.mattboldt.com/demos/typed-js/) a sviluppare questa feature in modo semplice.\n\nPer usarla, per prima cosa è necessario installare il file `typed.min.js` all'interno del nostro progetto. Il file è scaricabile [da GitHub](https://github.com/mattboldt/typed.js/blob/master/dist/typed.min.js). Dobbiamo salvarlo ed inserirlo nella cartella `/static/external/`, essendo un file di terze parti.\n\nUna volta fatto questo, creiamo anche un secondo file `index.js` all'interno della cartella `/static/external/`. All'interno del file, inseriamo il seguente codice JavaScript:\n\n```js\ndocument.addEventListener(\"DOMContentLoaded\", function () {\n  Typed.new(\". jobs\", {\n    strings: [\"Maker\", \"Robotico\", \"Roker!\"],\n    typeSpeed: 0,\n  })\n})\n```\n\nEssenzialmente, questo script aspetta che la pagina sia completamente caricata. Una volta caricata, cerca l'elemento html con classe `.jobs` e ne modifica il contenuto con le parole all'interno della lista `[\"Maker\", \"Robotico\", \"Roker!\"]`, aggiungendo l'effetto typing da tastiera.\n\nPer utilizzare questo script, come per lo stile `css` visto su, dobbiamo importarlo (insieme al file `typed.min.js`), all'interno del file `index.html`. Per farlo, flask_bootstrap mette a disposizione un altro blocco chiamato `scripts`, in cui inserire tutti gli script JavaScript da renderizzare nel documento.\n\nApriamo quindi il file `blog/main/templates/main/index.html` e aggiungiamo il seguente codice alla fine del file:\n\n```html\n{% block scripts %} {{ super() }}\n<script src=\"/static/external/typed.min.js\"></script>\n<script src=\"/static/js/index.js\"></script>\n{% endblock %}\n```\n\nCome nel caso degli stili, prima di importare effettivamente i file, abbiamo usato la direttiva `{{ super() }}`, per renderizzare il blocco script del template che stiamo estendendo.\n\nPer finire, per funzionare, il codice ha bisogno che sia definito un elemento di classe `jobs`. Modifichiamo la riga\n\n```html\nSono un roker!\n```\n\ncon\n\n```html\nSono un <strong class=\"jobs\"></strong>\n```\n\ne riapriamo il sito da browser. Se tutto va bene, vedrete il testo modificarsi come se qualcuno stesse digitando sulla tastiera.\n\n![immagine copertina testo con typed](./cover_text_typed.png)\n\n### Conclusioni\n\nAnche questo tutorial è completo. Il codice lo trovate come al solito su [github](https://github.com/ludusrusso/ludoblog/tree/p7).\n",
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2016-12-27-tutorial-flask/index.md",
    frontMatter: {
      path: "/2016/12/27/tutorial-flask/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "41 mins",
      published: "2016-12-27T00:00:00.000Z",
      publishedReadable: "27 Dic 2016",
      featured: false,
      tags: ["Flask", "Python"],
      title: "Scriviamo un Blog in Python e Flask",
      description:
        "Tutorial su come implementare, a partire da zero, un blog personale utilizzando Python e Flask! Prima parte!",
      href: "/2016/12/27/tutorial-flask/",
      image: "/content/blog/it/2016-12-27-tutorial-flask/cover_text_typed.png",
      imagePath: "/content/blog/it/2016-12-27-tutorial-flask",
    },
  },
  {
    content:
      '\n### Un Blog in Python e Flask\n\n![Copertina](./blog.png)\n\nCiao a tutti, mi chiamo Ludovico e sono un **maker** e un **imprenditore**. Sotto consiglio (molto assillante) di [Michele Maffucci](http://www.maffucci.it), ho deciso di aprire questo blog in cui racconterò quello che faccio e dei miei vari progetti.\n\nIo sono cocciuto, e ho una gran voglia di sperimentare nuove tecnologie e imparare nuove cose. Per questo motivo, quando mi hanno convinto a scrivere un blog, ho preso la parola "scrivere" forse troppo alla lettera, e da buon programmatore me lo sono implementato quasi da zero! Sono un amante di Python, e questo sito, completamente sviluppato da me, è stato scritto in Python con una libreria chiamata **Flask**.\nVorrei utilizzare questo sito per condividere le cose che imparo, per questo motivo ho iniziato a scrivere dei tutorial su Flask e Python, che trovate al link sotto!\n\n<http://www.ludusrusso.cc/tutorial/python/flask/intro.html>\n',
    file: "/Users/ludovicorusso/develop/github.com/ludusrusso/www.ludusrusso.dev/public/content/blog/it/2016-12-22-inauguriamo-il-blog/index.md",
    frontMatter: {
      path: "/2016/12/22/inauguriamo-il-blog/",
      author: {
        id: "ludusrusso",
        name: "Ludovico Russo",
        bio: "Dev Passionate",
        profile: "/imgs/authors/ludusrusso.jpg",
      },
      readTime: "1 min",
      published: "2016-12-22T00:00:00.000Z",
      publishedReadable: "22 Dic 2016",
      featured: false,
      tags: [],
      title: "Inauguriamo il Blog",
      description:
        "Ciao a tutti, mi chiamo Ludovico e sono un maker e un imprenditore. Questo Blog è stato scritto da me in Python e Flask, e lo userò per condividere i miei esperimenti!",
      href: "/2016/12/22/inauguriamo-il-blog/",
      image: "/content/blog/it/2016-12-22-inauguriamo-il-blog/blog.png",
      imagePath: "/content/blog/it/2016-12-22-inauguriamo-il-blog",
    },
  },
];
